We make an explicit correspondence between the game denotation of a
term and its syntax. Our approach follows ideas recently introduced
in \cite{OngLics2006}, mainly the notion of computation tree of a
simply-typed $\lambda$-term and traversals over the computation
tree. A computation tree can be regarded as an abstract syntax tree
(AST) of the $\eta$-long normal form of a term. A traversal is a
justified sequence of nodes of the computation tree respecting some
formation rules. Traversals are used to describe computations. An
interesting property is that the \emph{P-view} of a traversal
(computed in the same way as P-view of plays in Game Semantics) is a
path in the computation tree.

The main result of this paper is called the
\emph{Correspondence Theorem} (theorem \ref{thm:correspondence}). It
states that traversals over the computation tree are just
representations of the uncovering of plays in the
strategy-denotation of the term. Hence there is an isomorphism
between the strategy denotation of a term and its revealed game
denotation ({\it i.e.}~its strategy denotation where internal moves are
not hidden after composition). This theorem permits us to explore
the effect that a given syntactic restriction (such as the safety restriction) has on the strategy
denoting a term.

To really make use of the Correspondence Theorem, it will be
necessary to restate it in the standard game-semantic framework in
which internal moves are hidden. For that purpose, we will define a
\emph{reduction} operation on traversals responsible of eliminating
the ``internal nodes'' of the computation. This leads to a
correspondence between the standard game denotation of a term and
the set of reductions of traversals over its computation tree.
Fortunately, the reduction operation preserves the good properties
of traversals. This is guaranteed by the facts that the P-view of
the reduction of a traversal is equal to the reduction of the P-view
of the traversal, and the O-view of a traversal is the same as the
O-view of its reduction (lemma \ref{lem:redtrav_trav}). \vspace{8pt}

\emph{Related works}: Traversals of a computation tree provide a way
to perform \emph{local computation} of $\beta$-reductions as opposed
to a global approach where the $\beta$-reduction is implemented by
performing substitutions. A notion of local computation of
$\beta$-reduction has been investigated in
\cite{DanosRegnier-Localandasynchronou} through the use of special
graphs called ``virtual nets'' that embed the lambda-calculus.

In \cite{DBLP:conf/lics/AspertiDLR94}, a notion of graph based on
Lamping's graphs \citep{lamping} is introduced to represent
$\lambda$-terms. The authors unify different notions of paths
(regular, legal, consistent and persistent paths) that have appeared
in the literature as ways to implement graph-based reduction of
lambda-expressions. We can regard a traversal as an alternative
notion of path adapted to the graph representation of
$\lambda$-expressions given by computation trees.



%Is there any unsafe term whose game semantics is a strategy where
%pointers can be recovered?
%
%The answer is yes: take the term $T_i = (\lambda x y . y) M_i S$
%where $i =1..2$ and $\Gamma \vdash_s S : A$. $T_1$ and $T_2$ both
%$\beta$-reduce to the safe term $S$, therefore
%$\sem{T_1}=\sem{T_2}=\sem{S}$. But $T_1$ is safe whereas $T_2$ is
%unsafe. Since it is possible to recover the pointer from the game
%semantics of $S$, it is as well possible to recover the pointer from
%the semantics of $T_2$ which is unsafe.

\section{Computation tree}
We work in the general setting of the simply-typed
$\lambda$-calculus extended with a fixed set $\Sigma$ of
higher-order uninterpreted constants \footnote{A constant $f$ is
  \emph{uninterpreted} if the small-step semantics of the language
  does not contain any rule of the form $f \dots \rightarrow e$. $f$
  can be regarded as a data constructor.}

For the rest of the section we fix a simply-typed term $\Gamma \vdash M :T$.

\subsection{$\eta$-long normal form}

The $\eta$-long normal form appeared in
\citep{DBLP:journals/tcs/JensenP76} and
\citep{DBLP:journals/tcs/Huet75} under the names \emph{long reduced
form} and \emph{$\eta$-normal form} respectively. It was then
investigated in \citep{huet76} under the name \emph{extensional
form}.

The $\eta$-expansion of $M: A\typear B$ is defined to be the term
$\lambda x . M x : A\typear B$ where $x:A$ is a fresh variable. A
term $M : (A_1,\ldots,A_n,o)$ can be expanded in several steps into
$\lambda \varphi_1 \ldots \varphi_l . M \varphi_1 \ldots \varphi_l$
where the $\varphi_i:A_i$ are fresh variables. The $\eta$-normal
form of a term is obtained by hereditarily $\eta$-expanding every
subterm occurring at an operand position.

\begin{definition}[$\eta$-long normal form]
A simply-typed term is either an abstraction or it can be written uniquely as
$s_0 s_1 \ldots s_m$ where $m\geq0$ and $s_0$ is a variable, a $\Sigma$-constant or an abstraction.
The $\eta$-long normal form of a term $t$, written $\elnf{t}$ or sometimes $\etanf{t}$,
is defined as follows:
\begin{align*}
\elnf{\lambda x . s } &= \lambda x . \elnf{s} \\
\elnf{\alpha s_1 \ldots s_m : (A_1,\ldots,A_n,o)} &= \lambda \overline{\varphi} . \alpha \elnf{s_1}\ldots \elnf{s_m} \elnf{\varphi_1} \ldots \elnf{\varphi_n}
& \mbox{with $m,n\geq0$}\\
\elnf{(\lambda x . s) s_1 \ldots s_p : (A_1,\ldots,A_n,o) } &= \lambda \overline{\varphi} . (\lambda x . \elnf{s}) \elnf{s_1} \ldots \elnf{s_p} \elnf{\varphi_1} \ldots \elnf{\varphi_n}
& \mbox{with $p\geq 1,n\geq 0$}
\end{align*}
where $x$ and each $\varphi_i : A_i$ are variables and $\alpha$ is
either a variable or a constant.
\end{definition}

For $n=0$, the first clause in the definition becomes:
$$\elnf{x s_1 \ldots s_m : o} = \lambda . x \elnf{s_1} \elnf{s_2} \ldots \elnf{s_m},$$
and we deliberately keep the \textsl{dummy} lambda in the right-hand
side of the equation because it will play an important role in the
correspondence with game semantics.



Note that our version of the $\eta$-long normal form is defined not only for $\beta$-normal terms but also for any simply-typed term.
Moreover it is defined in such a way that $\beta$-normality is preserved:
\begin{lemma}
The $\eta$-long normal form of a term in $\beta$-normal form is also in $\beta$-normal form.
\end{lemma}
\begin{proof}
By induction on the structure of the term and the order of its type.
\emph{Base case}:
If $M=x:0$ then $\elnf{x} = \lambda . x$ is also in $\beta$-nf.
\emph{Step case}:
The case $M = (\lambda x . s) s_1 \ldots s_m : (A_1,\ldots,A_n,o)$ with $m>0$ is not possible since $M$ is in
$\beta$-normal form.
Suppose $M = \lambda x . s$ then $s$ is in $\beta$-nf. By the induction hypothesis $\elnf{s}$ is also in $\beta$-nf and therefore
so is $\elnf{M} = \lambda x . \elnf{s}$.

Suppose $M= \alpha s_1 \ldots s_m : (A_1,\ldots,A_n,o)$. Let $i,j$
range over $1..n$ and $1..m$ respectively. The $s_j$ are in
$\beta$-nf and the $\varphi_i$ are variables of order smaller than
$M$, therefore by the induction hypothesis the $\elnf{\varphi_i}$ and
the $\elnf{s_j}$ are in $\beta$-nf. Hence $\elnf{M}$ is also in
$\beta$-nf.
\end{proof}

\begin{lemma}[$\eta$-long normalisation preserves safety]
If $\Gamma \vdash s$ then $\Gamma \vdash \elnf{s}$.
\end{lemma}
\begin{proof}

First we observe that for any variable or constant $x$ we have $x \vdash \elnf{x}$. The proof is by induction on $\ord{x}$. Base case: $x$ is of ground type and we have $x \vdash x = \elnf{x}$. Step case:
$x:(A_1, \ldots, A_n,o)$ with $n>0$. Let $\varphi_i:A_i$ be fresh variables for $1\leq i\leq n$. The (var) rules gives $\varphi_i  \vdash \varphi_i$ and since $\ord{A_i} < \ord{x}$ the induction hypothesis gives $\varphi_i \vdash \elnf{\varphi_i}$. Using (wk) we obtain $x, \overline{\varphi} \vdash \elnf{\varphi_i}$.
The application rule gives $x, \overline{\varphi} \vdash x \elnf{\varphi_1} \ldots \elnf{\varphi_n} : o$ and the abstraction rule gives $ x \vdash \lambda \overline{\varphi} . x \elnf{\varphi_1} \ldots \elnf{\varphi_n} = \elnf{x}$.


We now prove the lemma by induction on the structure of $s$.
The base case (where $s$ is some variable $x$) is covered by the previous observation.
\emph{Step case:}
\begin{itemize}
\item $s = x s_1 \ldots s_m$ with $x: (B_1, \ldots, B_m, A_1, \ldots, A_n, o)$ with $m\geq 0$, $n>0$ and $s_i : B_i$ for $1 \leq i \leq m$.

Let $\varphi_i: A_i$ be fresh variables for $1\leq i \leq n$. By the previous observation we have $\varphi_i \vdash \elnf{\varphi_i}$ which in turn gives $\Gamma , \overline{\varphi} \vdash \elnf{\varphi_i}$ using the weakening rule.

The judgement $\Gamma \vdash x s_1 \ldots s_m$ is formed using the (app) rule therefore each $s_j$ is safe for $1\leq j \leq m$. By the induction hypothesis we have $\Gamma \vdash \elnf{s_j}$ and by weakening we get $\Gamma, \overline{\varphi} \vdash \elnf{s_j}$.

The application rule gives $\Gamma, \overline{\varphi} \vdash
x \elnf{s_1} \ldots \elnf{s_m} \elnf{\varphi_1} \ldots \elnf{\varphi_n} : o$. Finally the (abs) rule gives $\Gamma \vdash \lambda \overline{\varphi} . x \elnf{s_1} \ldots \elnf{s_m}  \elnf{\varphi_1} \ldots \elnf{\varphi_n} = \elnf{s}$, the side-condition of (abs) being met since $\ord{\elnf{s}} = \ord{s}$.


\item $s = t s_0 \ldots s_m$ where $t$ is an abstraction. Again, using the induction hypothesis it is easy to show that $\Gamma \vdash \elnf{s} = \elnf{t} \elnf{s_0} \ldots \elnf{s_m} \elnf{\varphi_1} \ldots \elnf{\varphi_n}$ holds for some fresh variables $\varphi_1$, \ldots, $\varphi_n$.

\item $s = \lambda \overline{\eta} . t$ where $t$ is not an abstraction. By the induction hypothesis we have $\Gamma, \overline{\eta} \vdash \elnf{t}$ and by the abstraction rule we have $\Gamma \vdash \lambda \overline{\eta} . \elnf{t} = \elnf{s}$.
\end{itemize}
\end{proof}

Note that in general the converse does not hold, for instance $\lambda x^o . f^{o,(o,o),o} x^o$ is unsafe although $\elnf{\lambda x . f x} = \lambda x^o \varphi^{o,o} . f x \varphi$ is safe (and not homogeneous). For terms with homogeneous types however, the converse does hold:
\begin{lemma}
If $\Gamma \vdash \elnf{s}$ is homogeneously safe (i.e. it is a safe judgement of the safe $\lambda$-calculus and each sequent occurring at the nodes of the proof tree is homogeneously typed) then
$\Gamma \vdash s$ is homogeneously safe.
\end{lemma}


\subsection{Computation tree}
The computation tree of a term is a certain tree representation of its
$\eta$-long normal form. It is defined as follows:

\begin{definition}
\label{dfn:comptree} Let $M$ be a simply-typed term in $\eta$-normal
form. Then $M$ is either an abstraction or it can be written
uniquely as $s_0 s_1 \ldots s_m : o$ for some $m\geq0$ where $s_0$
is a variable, a constant or an abstraction and each of the $s_j$
for $j\in 1..m$ is in $\eta$-normal form. The
\defname{computation tree} $\tau(M)$ of $M$ is defined by induction
on the structure of the term:
\begin{enumerate}[-]
\item If $n\geq0$ and $s$ is not an abstraction then:
$$ \tau(\lambda x_1 \ldots x_n . s) =
      \pstree[levelsep=3ex]
        { \TR{\lambda x_1 \ldots x_n} }
        { \SubTree{\tau(s)^{-}} }
$$
where $\tau(s)^{-}$ denotes the tree obtained after deleting the root of $\tau(s)$.

\item If $m\geq0$ and $\alpha$ is a variable or constant then:
$$ \tau( \alpha s_1 \ldots s_m : o) =
    \tree{\lambda}
    {
        \pstree[levelsep=3ex]
            { \TR{\alpha} }
            { \SubTree{\tau(s_1)} \SubTree[linestyle=none]{\ldots} \SubTree{\tau(s_m)}
            }
    }
$$

\item If $n \geq 1$ then:
$$ \tau((\lambda x.s) s_1 \ldots s_n : o) =
    \tree{\lambda}
    {
        \pstree[levelsep=3ex]
            { \TR{@} }
            {
            \SubTree{\tau(\lambda x.s)}    \SubTree{\tau(s_1)} \SubTree[linestyle=none]{\ldots} \SubTree{\tau(s_n)}
            }
    }
$$
\end{enumerate}

If $M$ is not in $\eta$-normal form then $\tau(M)$ is defined as the
computation tree of its $\eta$-normal form ($\tau(M) =
\tau(\etanf{M})$).
\end{definition}

The nodes (and leaves) of the tree are of three kinds:
\begin{itemize}
\item $\lambda$-nodes labelled $\lambda \overline{x}$ (note that a $\lambda$-node represents several consecutive variable abstractions),
\item application nodes labelled @,
\item variable or constant nodes labelled $\alpha$ for some constant or variable $\alpha$.
\end{itemize}
A node is said to be \defname{prime} if it is the 0$^{th}$ child of an @-node.

\emph{Notations:} We write $r$ for the root of $\tau(M)$. We write $E$ to denote the parent-child relation
of the tree, $N$ for the set of nodes of $\tau(M)$,
$N_\Sigma$ for the set of $\Sigma$-labelled nodes, $N_@$ for the set
of @-labelled nodes, $N_{\sf var}$ for the set of variable nodes,
$N_{\sf fv}$ for the subset of $N_{\sf var}$ constituted of free-variable
nodes, $N_{\sf spawn}$ for the set $N \inter E \relimg{N_@ \union N_\Sigma}$ constituted of children of constant-nodes and @-nodes and $N_{\sf prime}$ for the set of prime nodes.


Let $\mathcal{T}$ denote the set of $\lambda$-terms.
Each subtree of the computation tree $\tau(M)$ represents a subterm of $\elnf{M}$.
We define the function $\kappa : N \rightarrow \mathcal{T}$ that maps a node $n \in N$ to the subterm of $\elnf{M}$
corresponding to the subtree of $\tau(M)$ rooted at $n$.
In particular $\kappa(r) = \elnf{M}$.

\begin{definition}[Type and order of a node]
\label{def:nodeorder}
Suppose $\Gamma \vdash M : T$.
The \defname{type} of a node $n$ of $\tau(M)$ written $type(n)$ is defined as follows:
\begin{eqnarray*}
type(r) &=& \Gamma \rightarrow T \\
type(\alpha:A) &=& A, \mbox{ where $\alpha$ is a variable or constant} \\
type(n) &=& \hbox{ type of the term $\kappa(n)$ for $n \in (N_\lambda \union N_@) \setminus \{r \}$\ .}
\end{eqnarray*}
The order of a node $n$ written $\ord{n}$ is defined to be the order of the type of $n$.
\end{definition}

In particular, $\ord{@} = 0$, $\ord{\lambda \overline{\xi}} = 1+
\max_{z\in \overline{\xi}} \ord{z}$ for $\lambda \overline{\xi}\neq
r$ and if $r=\lambda \overline{\xi}$ then $\ord{r} = 1 + \max_{z\in
\overline{\xi}\union \Gamma} \ord{z}$ with the convention $\max
\emptyset = -1$.

\begin{remark} \hfill
\begin{itemize}
\item In a computation tree, nodes at even level are $\lambda$-nodes and nodes at odd level are either application nodes,
variable or constant nodes;

\item for any ground type variable or constant $\alpha$,
$\tau(\alpha) = \tau(\lambda . \alpha) =  \pstree[levelsep=3ex]
    { \TR{\lambda } }
    { \TR{\alpha}
    }$;

\item for any higher-order variable or constant $\alpha : (A_1,\ldots,A_p,o)$, the computation tree $\tau(\alpha)$ has the following form:
$ \pstree[levelsep=3ex]{\TR{\lambda}}
        {\pstree[levelsep=3ex]
                { \TR{\alpha} }
                { \tree{\lambda \overline{\xi_1}}{\TR{\ldots}} \TR{\ldots} \tree{\lambda \overline{\xi_p}}{\TR{\ldots}}
                }
        }
$;

\item for any tree of the form
        $ \pstree[levelsep=4ex]
            { \TR{\lambda \overline{\varphi}} }
            { \pstree[levelsep=3ex]
                {\TR{n}}
                {\TR{\lambda \overline{\xi_1}} \TR{\ldots} \TR{\lambda \overline{\xi_p}}}
            }
        $,
    we have $\ord{\kappa(n)}=0$.

\end{itemize}
\end{remark}


\subsection{Pointers and justified sequence of nodes}

\begin{definition}[Binder]
Let $n$ be a variable node of the computation tree labelled $x$. We
say that a node $n$ is bound by the node $m$, and $m$ is called the
binder of $n$, if $m$ is the closest node in the path from $n$ to
the root of the tree such that $m$ is labelled $\lambda
\overline{\xi}$ with $x\in \overline{\xi}$.
\end{definition}

\begin{definition}[Enabling]
The \defname{enabling relation} $\vdash$ is defined on the set of
nodes of the computation tree as follows. We write $m \vdash n$ and
we say that $m$ enables $n$ if and only if
\begin{itemize}
\item $n$ is a bound variable node and $m$ is the binder of $n$. We will write $m \vdash_i n$ to precise that $n$
is the $i^{\sf th}$ variable bound by $m$;
\item or $n$ is a free variable node and $m$ is the root of the computation
tree;
\item or $n$ is a $\lambda$-node and $m$ is the parent node of $n$.
\end{itemize}
\end{definition}

We say that a node $n_0$ of a justified sequence is
\defname{hereditarily justified} by $n_p$ if there are nodes $n_1,
\ldots, n_{p-1}$ in the sequence such that $n_i$ points to $n_{i+1}$
for all $i\in 0..p-1$.

For any set of nodes $S$ we write $S^{\upharpoonright r}$ for $\{ n \in S \ | \ r  \vdash^* n \}$ -- the subset of $S$ constituted of
nodes hereditarily enabled by $r$.
We call \defname{input-variables nodes} the elements of $N_{\sf var}^{\upharpoonright r}$ i.e.\
variables that are hereditarily enabled by the root. $N_{\sf var}^{\upharpoonright r}$ is also the set of nodes that are hereditarily enabled by a free variable or by a variable bound by the root.
\smallskip

We use the following numbering conventions:
the first child of a @-node is numbered $0$;
the first child of a variable or constant node is numbered $1$;
and variables in $\overline{\xi}$ are numbered from $1$ onward ($\overline{\xi} = \xi_1 \ldots \xi_n$).
We write $n.i$ to denote the $i$th child of node $n$.

\begin{definition}[Justified sequence of nodes]
A \defname{justified sequence of nodes} is a sequence of nodes of
the computation tree $\tau(M)$ with pointers such that each variable
or $\lambda$-node $n$ different from the root has a pointer to a
node $m$ occurring before it the sequence and such that $m \vdash
n$.

If $n$ points to $m$ then we say that $m$ \emph{justifies} $n$. We
represent the pointer in the sequence as follows \Pstr[0.4cm]{
(m){m} \ldots (n-m,45:i) n }. where the label indicates that either
$n$ is labelled with the $i$th variable abstracted by the
$\lambda$-node $m$ or that $n$ is the $i^{\sf th}$ child of $m$.
\end{definition}

Note that justified sequences are also defined for open terms:
occurrences of nodes in $N_{\sf fv}$ must point to an occurrence of the
root of the computation tree. Thus a pointer in a justified sequence of nodes has
one of the following forms:
$$
\Pstr[18pt]{ (m){r} \cdot \ldots \cdot (n-m,40){z} }
\hspace{1.5cm}
\Pstr{ (m){\lambda \overline{\xi}} \cdot \ldots \cdot (n-m,40:i){\xi_i} }
\hspace{1.5cm}
\Pstr{ (m){@} \cdot \ldots \cdot (n-m,40:j){\lambda \overline{\eta}} }
\hspace{1.5cm}
\Pstr{ (m){\alpha } \cdot \ldots \cdot (n-m,40:k){\lambda \overline{\eta}} }
$$
for some occurrences $r$ of $\tau(M)$'s root, $z \in N_{\sf fv}$,
bound variables $\xi_1,
\ldots \xi_n$, $\alpha \in N_{\Sigma} \union
N_{\sf var}$, $i \in 1..n$, $j$ ranges from $0$ to the number of
children nodes of @ minus 1 and $k \in 1 ..arity(\alpha)$.
\bigskip

\emph{Notations}: We write $s = t$ to denote that the justified sequences $t$ and $s$
have same nodes \emph{and} pointers. Justified sequence of nodes can
be ordered using the prefix ordering: $t \sqsubseteq t'$ if and only
if $t=t'$ or the sequence of nodes $t$ is a finite prefix of $t'$
(and the pointers of $t$ are the same as the pointers of the
corresponding prefix of $t'$). Note that with this definition,
infinite justified sequences can also be compared. This ordering
gives rise to a complete partial order.
We say that a node $n_0$ of a justified sequence is \defname{hereditarily justified} by $n_p$ if there are nodes $n_1, n_2, \ldots n_{p-1}$ in the sequence such that for all $i\in 0..p-1$, $n_i$ points to $n_{i+1}$.
We write $t^\omega$ to denote the last occurrence of $t$ and $\ip(t)$ for the immediate prefix of $t$ obtained by removing $t$'s last node.

We define a filtering operation on sequences of nodes:
\begin{definition}[Hereditary filtering]
Let $s$ be a justified  sequence of nodes from $\tau(M)$
and $n$ be an occurrence in $t$ of some node $n \in N_{\sf spawn}$.

We write $s \upharpoonright n$ to denote the subsequence of $s$ constituted of nodes that are hereditarily justified by $n$, where the pointer's target of all occurrences of free variable nodes in $t$ are set to $n$ (instead of $t$'s first node).

Thus $s \upharpoonright n$ is a valid justified sequence of nodes of the tree $\tau(\kappa(n))$.
\end{definition}


\begin{lemma}
\label{lem:filtercontinous}
The filtering function $\_ \upharpoonright n$ defined on the cpo of justified sequences ordered by the prefix ordering
is continuous.
\end{lemma}
\begin{proof}
Clearly $\_ \upharpoonright n$ is monotonous.
Suppose that $(t_i)_{i\in\omega}$ is a chain of justified sequence of nodes. Let $u$ be a finite prefix of $(\bigvee t_i) \filter n$.
Then $u = s \filter n$ for some finite prefix $s$ of $\bigvee t_i$. Since $s$ is finite we must have $s \sqsubseteq t_j$ for some $j\in\omega$.
Therefore $u \sqsubseteq t_j \filter n \sqsubseteq \bigvee (t_j \filter  n)$.
This is valid for any finite prefix $u$ therefore $(\bigvee t_i) \filter  n \sqsubseteq \bigvee (t_j \filter n)$.
\end{proof}



The notion of \defname{P-view} $\pview{t}$ of a justified sequence
of nodes $t$ is defined the same way as the P-view of a justified
sequences of moves in Game Semantics:

\begin{definition}[P-view of justified sequence of nodes]
The P-view of a justified sequence of nodes $t$ of $\tau(M)$, written $\pview{t}$, is defined as follows:
\begin{eqnarray*}
 \pview{\epsilon} &=&  \epsilon \\
 \pview{s \cdot n }  &=&  \pview{s} \cdot n \qquad \mbox{for $n \notin N_\lambda$, }\\
 \pview{\Pstr{ s \cdot (m){m} \cdot \ldots \cdot (lmd-m,25){\lambda \overline{\xi}}}} &=&
        \Pstr{ \pview{s} \cdot (m2){m} \cdot (lmd2-m2,60){\lambda \overline{\xi}} } \\
 \pview{s \cdot r }  &=&  r
\end{eqnarray*}
where $r$ is the root of the tree $\tau(M)$.

The equalities in the definition determine pointers implicitly. For
instance in the second clause, if in the left-hand side, $n$ points
to some node in $s$  that is also present in $\pview{s}$ then in the
right-hand side, $n$ points to that occurrence of the node in
$\pview{s}$.
\end{definition}

The O-view of $s$, written $\oview{s}$, is defined dually.
\begin{definition}[O-view of justified sequence of nodes]
The O-view of a justified sequence of nodes $t$ of $\tau(M)$, written $\oview{t}$, is defined as follows:
\begin{eqnarray*}
 \oview{\epsilon} &=&  \epsilon \\
 \oview{s \cdot \lambda \overline{\xi} }  &=&  \oview{s} \cdot \lambda \overline{\xi} \\
 \oview{\Pstr{s \cdot (m){m} \cdot \ldots \cdot (x-m,30){x}}} &=&
    \Pstr{ \oview{s} \cdot (m2){m} \cdot (n2-m2,60){x} } \qquad \mbox{ for $x \in N_{\sf var}$ }\\
 \oview{s \cdot n }  &=&  n \qquad \mbox{ for $x \in N_@ \union N_\Sigma$ }
\end{eqnarray*}
\end{definition}

We borrow some game semantic terminology:
\begin{definition} A justified sequence of nodes $s$ satisfies:
\begin{itemize}[-]
\item \defname{Alternation} if for any two consecutive nodes in $s$, one is a $\lambda$-node
and the other is not;
\item \defname{P-visibility} if every variable node in $s$ points to a node occurring in the P-view a that point;
\item  \defname{O-visibility} if every lambda node in $s$ points to a node occurring in the O-view a that point.
\end{itemize}
\end{definition}

\begin{property}
\label{proper:pview_visibility}
The P-view (resp. O-view) of a justified sequence verifying P-visibility (resp. O-visibility)
is a well-formed justified sequence verifying P-visibility (resp. P-visibility).
\end{property}
This is proved by an easy induction.

\subsection{Adding value-leaves to the computation tree}
\label{sec:adding_value_leaves}

We now add another ingredient to the computation tree defined in
the previous section. Let $\mathcal{D}$
denote the set of values of base type $o$.  We add
\defname{value-leaves} to $\tau(M)$ as follows: Every node $n \in \tau(M)$ has one child leaf labelled $v_n$ for every possible value $v \in \mathcal{D}$.
We write $V$ for the set of nodes and leaves of
the computation tree.  For $\$$ ranging in $\{@, \lambda, var \}$,
we write $V_\$$ to denote the set $N_\$ \union \{ v_n \ | \ n \in
N_\$, v \in \mathcal{D} \}$.

%If $n$ is a $\lambda$-node then its value-leaves are numbered from $1$ onwards.
%If $n$ is a variable or constant node then its children nodes are numbered from $1$ to $arity(n)$ and
%its value-leaves are numbered from $arity(n)+1$ onwards.
%If $n$ is an application node then its value-leaves are numbered from $1$ onwards.

Everything that we have defined for computation tree can be lifted
to this new version of computation tree. The node order of a
value-leaf is defined to be $0$. The enabling relation $\vdash$ is
extended so that every leaf is enabled by its parent node. The
definition of justified sequence does not change.
When representing a link in a justified sequence going from a value-leaf $v_n$ to a node $n$,
we label the link with $v$:
$$
\Pstr{ (n){n} \cdot \ldots \cdot (vn-n,40:v){v_n} }
$$

For the definition
of P-view, O-view and visibility, value-leaves are treated as
$\lambda$-nodes if they are at odd level in the computation tree and
as variable nodes if they are at an even level.

From now the term ``computation tree'' refers to this extended
definition.
\vspace{10pt}

We say that a node $n$ in of a justified sequence of nodes is
\defname{matched} by the value-leaf $v_n$ if there is an occurrence of $v_n$ for some value $v$ in the
sequence that points to $n$, otherwise we say that $n$ is
\defname{unmatched}. The last unmatched node is called the
\defname{pending node}.  A justified sequence of nodes is
\defname{well-bracketed} if each value-leaf occurring in it is justified by the pending node at that point.
If $t$ is a traversal then we write
$?(t)$ to denote the subsequence of $t$ consisting only of unmatched
nodes.

\subsection{Traversal of the computation tree}
\label{subsec:traversal}
A \emph{traversal} is a justified sequence of nodes of the computation tree where each node indicates a step that is taken during the evaluation of the term.

\subsubsection{Traversals for simply-typed $\lambda$-terms}

We first consider the simply-typed $\lambda$-calculus without interpreted constants.
Everything remains valid in the presence of \emph{uninterpreted} constants as we can just
consider them as free variables.

We define the notion of traversal over the computation tree $\tau(M)$.
We will then we show how to extend the notion of traversal to more general settings with interpreted constants.

\begin{definition}[Traversals for simply-typed $\lambda$-terms] \rm
\label{def:traversal} The set $\travset(M)$ of \defname{traversals}
over $\tau(M)$ is defined by induction over the following rules:

\noindent \emph{Initialization rules}
\begin{description}
\item[\rulenamet{Empty}] $\epsilon \in \travset(M)$.
\item[\rulenamet{Root}] The single-node sequence $r$, where $r$ denotes the root of $\tau(M)$, is a traversal.
%$ r \in \travset(M)$.
\end{description}

\noindent \emph{Structural rules}
\begin{description}
\item[\rulenamet{Lam}] If $t \cdot \lambda \overline{\xi}$ is a traversal then so is
$t \cdot \lambda \overline{\xi} \cdot n$ where $n$ denotes $\lambda
\overline{\xi}$'s child.

Moreover if $n$ is a variable node then it
points to the only
occurrence of its enabler that is still present in $\pview{t
\cdot \lambda \overline{\xi}}$.
In particular, if $n$ is a free variable node then $n$ points to the first node of $t$ (the root). (Prop. \ref{prop:pviewtrav_is_path} will show that indeed $n$'s enabler occurs exactly once in the P-view since P-views correspond to paths in the tree.)

\item[\rulenamet{App}] If $t \cdot @$ is a traversal then so is \Pstr[0.4cm]{t \cdot (m) @  \cdot (n-m,40:0) n}.
%{\em i.e.}~the next visited node is the $0^{th}$ child node of
%@: the node corresponding to the operator of the application.
\end{description}

\noindent \emph{Input-variable rules}
\begin{description}
\item[\rulenamet{InputVar$^{val}$}] If $t_1 \cdot x \cdot t_2$ is a traversal
with $x \in N_{\sf var}^{\upharpoonright r}$ and $?(t_1 \cdot x
\cdot t_2)=?(t_1) \cdot x$ then so is \Pstr[0.4cm]{t_1 \cdot
(x){x} \cdot t_2 \cdot (xv-x,38:v){v_x} } for all $v \in
\mathcal{D}$.

\item[\rulenamet{InputVar}] If $t_1 \cdot x \cdot t_2$ is a traversal with
  $x \in N_{\sf var}^{\upharpoonright r}$ and $x$ is the pending node in $t$ ($?(t_1 \cdot x \cdot
  t_2)=?(t_1) \cdot x$) then so is $t_1 \cdot x \cdot t_2 \cdot
  n$ for any $\lambda$-node $n$ whose parent occurs in
  $\oview{t_1 \cdot x}$, $n$ pointing to some occurrence of its
  parent node in $\oview{t_1 \cdot x}$.
\end{description}

\noindent \emph{Copy-cat answer rules}
\begin{description}
\item[\rulenamet{Answer-@-$\lambda$}]
  If \Pstr{t \cdot (app){@} \cdot (lz-app,60:0){\lambda
\overline{z}}  \ldots  (lzv-lz,60:v){v}_{\lambda \overline{z}} }
is a traversal then so is \Pstr[0.6cm]{t \cdot (app){@} \cdot
(lz-app,60){\lambda \overline{z}} \ldots
(lzv-lz,60:v){v}_{\lambda \overline{z}} \cdot
(appv-app,45:v){v}_@}.

\item[\rulenamet{Answer-$\lambda$-@}] If \Pstr[0.4cm]{t \cdot \lambda \overline{\xi} \cdot (x){@}  \ldots   (xv-x,50:v){v}_@}
is a traversal then so is \Pstr[0.5cm]{t \cdot (lmd){\lambda
\overline{\xi}} \cdot (x){@}  \ldots  (xv-x,50:v){v}_@  \cdot
(lmdv-lmd,30:v){v}_{\lambda \overline{\xi}} }.

\item[\rulenamet{Answer-var-$\lambda$}] If \Pstr[0.4cm]{t \cdot y \cdot (lmd){\lambda \overline{\xi}}
\ldots (lmdv-lmd,50:v){v}_{\lambda \overline{\xi}} } is a
traversal for some variable $y\not\in N_{\sf var}^{\upharpoonright
r}$ then so is \Pstr[0.7cm]{t \cdot (y){y} \cdot (lmd){\lambda
\overline{\xi}} \ldots (lmdv-lmd,30:v){v}_{\lambda
\overline{\xi}}  \cdot (vy-y,50:v){v}_y }.

\item[\rulenamet{Answer-$\lambda$-var}] If \Pstr[0.4cm]{t \cdot \lambda \overline{\xi} \cdot (x){x}  \ldots   (xv-x,50:v){v}_x}
is a traversal then so is \Pstr[0.5cm]{t \cdot (lmd){\lambda
\overline{\xi}} \cdot (x){x}  \ldots  (xv-x,50:v){v}_x  \cdot
(lmdv-lmd,30:v){v}_{\lambda \overline{\xi}} }.
\end{description}

\begin{description}
\item[\rulenamet{Var}]
If \Pstr[0.5cm]{t' \cdot (n){n} \cdot (lx){\lambda \overline{x}}
    \ldots (x-lx,50:i){x_i} } is a traversal for some variable
    $x_i$ not in $N_{\sf var}^{\upharpoonright r}$ then
so is \Pstr[0.6cm]{ t' \cdot (n){n} \cdot
    (lx){\lambda \overline{x}}  \ldots (x-lx,30:i){x_i}  \cdot
    (letai-n,40:i){\lambda \overline{\eta_i}}
     }.
\end{description}
A traversal that cannot be extended by any rule is said to be \emph{maximal}.
\end{definition}


A traversal always starts by visiting the root. Then it mainly
follows the structure of the tree.

The \rulenamet{Var} rule is particular and needs further explanation.
This rule permits the traversal to jump across the computation tree. The idea is that after visiting a
non-input variable node $x$, a jump can be made to the node corresponding to
the subterm that would be substituted for $x$ if all the
$\beta$-redexes occurring in the term were to be reduced.


Let $\lambda \overline{x}$ be $x$'s binder and suppose $x$ is the $i$th variable in $\overline{x}$.
The binding node necessarily occurs previously in the traversal (this will be proved in Prop. \ref{prop:pviewtrav_is_path}). Since $x$ is not hereditarily justified by the root, $\lambda \overline{x}$ is not the root of the tree and therefore it is not the first node of the traversal.
We do a case analysis on the node preceding $\lambda \overline{x}$:
    \begin{itemize}[-]
    \item If it is an @-node then $\lambda \overline{x}$ is necessarily the first child node of that node
    and it has has exactly $|\overline{x}|$ siblings:
    $$\pstree[levelsep=7ex]{\TR{\stackrel{\vdots}{@}}}
    {   \pstree[linestyle=dotted,levelsep=4ex]{\TR{\lambda \overline{x}}\treelabel{0}}
            {\TR{x }}
        \tree{\lambda \overline{\eta_1}}{\vdots}\treelabel{1}
        \TR[edge=\dotedge]{}
        \tree{\lambda \overline{\eta_i}}{\vdots}\treelabel{i}
        \TR[edge=\dotedge]{}
        \tree{\lambda \overline{\eta_{|x|}}}{\vdots}\treelabel{|x|}
    }
    $$
    In that case, the next step of the traversal is a jump to $\lambda \overline{\eta_i}$ -- the $i$th child of
    @ -- which corresponds to the subterm that would be substituted for $x$ if the $\beta$-reduction was
    performed:
    $$\Pstr[19pt]{ t' \cdot
            (n){@} \cdot
            (lx){\lambda \overline{x}} \cdot \ldots \cdot
            (x-lx,40:i){x} \cdot
            (mi-n,40:i){\lambda \overline{\eta_i}} \cdot \ldots
            \in {\travset(M)}   }
    $$

    \item If it is a variable node $y$, then
    the node $\lambda \overline{x}$ was necessarily added to the traversal $t_{\leq y}$ using the \rulenamet{Var} rule (see proposition \ref{prop:pviewtrav_is_path}(i)).
    Therefore $y$ is substituted by the term $\kappa(\lambda \overline{x})$ during the evaluation of the term.

    Consequently, during reduction, the variable $x$ will be substituted by the subterm represented by
    the $i$th child node of $y$. Hence the following justified sequence is also a traversal:
    $$\Pstr[18pt]{ t' \cdot
            (y){y} \cdot
            (lx){\lambda \overline{x}} \cdot \ldots \cdot
            (x-lx,40:i){x} \cdot
            (mi-y,40:i){\lambda \overline{\eta_i}} \cdot \ldots
    }
    $$
    \end{itemize}

\begin{remark}
Our notions of computation tree and traversal differ slightly from \cite{OngLics2006}:
\begin{itemize}[-]
    \item In \cite{OngLics2006} computation trees can have uninterpreted first-order constants. But as we have already observed, uninterpreted constants can be just regarded as free variables thus we do not lose any expressivity here.

    \item In \cite{OngLics2006}, constants are restricted to order one at most since computation tree
    are used to model computation of tree structures. Here we don't need this restriction (as long as constants are uninterpreted - so we can regard them as free variables).


    \item In our setting, we have to deal with \emph{free} variables.
    To model free variables we need the traversal rules \rulenamet{InputVar$^{val}$}, \rulenamet{InputVar}
    as well as the copy-cat answer rules. Whereas in \cite{OngLics2006}, the rule called \rulenamet{Sig} suffices to model the first-order constants necessary to construct tree structures.

    \item In our setting, the introduction of value-leaves
    is necessary in order to model free variables as well as interpreted constants. (We will use them to model the constants of \pcf\ and \ialgol).
    \end{itemize}
\end{remark}

\begin{example}
Consider the following computation tree:
$$\tree{\lambda}
{
    \tree{@}
    {
        \pstree[levelsep=8ex,linestyle=dotted]{\TR{\lambda y}\treelabel{0} }
        {
            \pstree[levelsep=8ex]{\TR{y}}
            {
                \tree{\lambda \overline{\eta_1}}{\vdots} \treelabel{1}
                \TR[edge=\dotedge]{}
                \tree{\lambda \overline{\eta_i}}{\vdots}\treelabel{i}
                \TR[edge=\dotedge]{}
                \tree{\lambda \overline{\eta_n}}{\vdots}\treelabel{n}
            }
        }
        \pstree[levelsep=6ex,linestyle=dotted]{\TR{\lambda \overline{x}}\treelabel{1}}{ \tree{x_i}{\TR{} \TR{} } }
    }
}
$$
An example of traversal of this tree is:
\vspace{0.3cm}
$$ \Pstr{ \lambda \cdot
            (app){@}  \cdot
            (ly){\lambda y} \cdot \ldots \cdot
            (y-ly,40:1){y} \cdot
            (lx-app,50:1){\lambda \overline{x}} \cdot \ldots \cdot
            (x-lx,40:i){x_i} \cdot
            (leta-y,50:i){\lambda \overline{\eta_i} } \cdot \ldots
        }$$
\end{example}

\subsubsection{Traversals for interpreted constants}

\begin{definition}[Well-behaved traversal rule]
\label{def:wellbehaved_traversal} A traversal rule is
\defname{well-behaved} if it can be stated under the following form:
$$\rulef{t = t_1\cdot n \cdot t_2 \in \travset \quad ?(t) = ?(t_1) \cdot n \quad P(t)}
  { \stackrel{  \rule{0pt}{3pt} }{\Pstr[5pt]{ t' = t_1\cdot (n){n} \cdot t_2 \cdot (m-n,35){m} \in \travset}}
   }
    \ m\in S(t)
   $$
such that:
\begin{enumerate}[i.]
  \item $n$ is a variable or a constant node ($n \in N_{\Sigma}\union N_{\sf var}$);
  \item $P$ expresses some condition on $t$;
  \item for every traversal $t$, $S(t)$ is some subset of $E(n)$, the set of children $\lambda$-nodes and value-leaves of $n$.
  If $S(t)$ has more than one element then the rule is non-deterministic.
\end{enumerate}
\end{definition}
Note that if $t$ is well-bracketed then $t'$ is also well-bracketed
and if $?(t)$ satisfies alternation and visibility then so does
$?(t')$.


\begin{example} The rule (InputVar$^{val}$) is an example of non-deterministic well-behaved traversal rule for which $S(t)$ is exactly the set of all children value-leaves of $n$:
$S(t) = \{ v_n \ | \ v \in \mathcal{D} \} $.
However (InputVar) is not well-behaved since it can jump to any node in the O-view at that point and not necessarily to a children node of the last pending node.
\end{example}

In the presence of higher-order interpreted constants, additional rules must be specified to indicate how
the constant nodes should be traversed in the computation tree. These rules
are specific to the language that is being studied.
In the last section of this chapter we will define such traversals for the interpreted constants of
\pcf\ and \ialgol.

From now on, we consider a simply-typed $\lambda$-calculus language extended with
higher-order interpreted constants for which some constant traversal rules have been defined
and we take the following condition as a prerequisite:
\begin{center}
  \textbf{(Condition WB)} The constant traversal rules are well-behaved.
\end{center}


\subsubsection{Some properties of traversals}

\begin{proposition}[counterpart of proposition 6 from \cite{OngHoMchecking2006}]
\label{prop:pviewtrav_is_path}
Let $t$ be a traversal. Then:
\begin{itemize}
\item[(i)] $t$ is a well-defined and well-bracketed justified sequence;
\item[(ii)] $t$ is a well-defined justified sequence verifying alternation, P-visibility and O-visibility;
\item[(iii)] If $t^\omega \in N$ {\it i.e.}~$t$'s last node is not a value-leaf, then $\pview{t}$ is the path in the computation tree going from the root to the node $t^\omega$.
\end{itemize}
\end{proposition}

This is the counterpart of proposition 6 from
\cite{OngHoMchecking2006} which is proved by induction on the
traversal rules. This proof can be easily adapted to take into
account the constant rules (using the assumption that constants
rules are well-behaved) and the presence of value-leaves in the
traversal.
\begin{proof}
The proof of (i), (ii) and (iii) is done simultaneously by induction on the traversal rules. We consider the rules \rulenamet{Var} and \rulenamet{Lam} only.

Rule \rulenamet{Var}: we just give a partial proof of (i). See proposition 6 from \cite{OngHoMchecking2006} for the details of (i), (ii) and (iii). We have to show that in the second case of the \rulenamet{Var} rule, where $p$ is a variable node $y$, the node $\lambda \overline{x}$ has necessarily been added to the traversal $t_{\leq y}$ using the \rulenamet{Var} rule. This is immediate since if the rule \rulenamet{InputVar} was used to produce $t_{<y} \cdot y \cdot \lambda \overline{x}$ this would imply that $\lambda \overline{x}$ is hereditarily justified by the root which in turn implies that $x_i$ is an input-variable which contradicts \rulenamet{Var}'s hypothesis.

Rule \rulenamet{Lam}: we need to show that $n$'s enabler occurs only once in the P-view at that point. By the induction hypothesis we have (by (iii)) that $\pview{t \cdot \lambda \overline{\xi}}$ is a path in the computation tree from the root to $\lambda \overline{\xi}$. $n$'s enabler occurs only once in this path: it is precisely it's binding node. Therefore the traversal $t \cdot \lambda \overline{\xi} \cdot n$ is well-defined and $t \cdot \lambda \overline{\xi} \cdot n$ satisfies P-visibility. Thus (i) and (ii) are verified. Furthermore $n$ is a child of $\lambda \overline{\xi}$ therefore (iii) also holds.
\end{proof}

%In particular to prove that the copy-cat rules are well-defined, one needs to ensure that
%if the last two unmatched nodes are $y$ and $\lambda \overline{\xi}$ in that order, for some non input-variable node $y$ then necessary
%      $y$ and $\lambda \overline{\xi}$ are consecutive nodes in the traversal.
%    This is because in a traversal, a non input-variable $y$ is always followed by a lambda node and whenever this lambda node is answered
%    there is only one way to extend the traversal : by using the copy cat rule to answer the $y$ node.

\begin{definition}
The \defname{reduction of a traversal} $t$ is define as the subsequence $ t
\filter r$ where $r$ denotes the first node in $t$ (which is necessarily $\tau(M)$'s root).
\end{definition}
The effect of this transformation is the elimination of the
``internal nodes'' of the computation. Since @-nodes and $\Sigma$-constants do not have pointers, the
reduction of traversal contains only nodes in $N_\lambda \union
N_{\sf var}$.

We define the set
$$\travset(M)^{\upharpoonright r} = \{ t  \upharpoonright r \ | \  t  \in \travset(M) \} \ . $$




\begin{lemma}
\label{lem:var_followedby_child} Suppose $M$ is in $\beta$-normal
form. Let $t \travset(M)$. If
$\Pstr{ t = u_1 \cdot (m){m} \cdot u_2 \cdot (n-m,30){n} }$
 where $m \in (N_{\sf var} \union N_{\Sigma}) \setminus (N^{\upharpoonright r}_{var} \union N^{\upharpoonright r}_{\Sigma})$
then $u_2 = \epsilon$.
\end{lemma}
\begin{proof}
By case analysis on the rule used to visit the node
$n$ in $t$. The only relevant rules are (Var), (Answer-var), (InputVar$^{val}$), (InputVar)
and the constant rules.
Since the term is in $\beta$-normal form, there is no @-node in $\tau(M)$ and therefore (Var) cannot be used.
Since $m$ is not hereditarily justified by the root, it is not an input-variable and therefore the rules
(InputVar$^{val}$) and (InputVar) cannot be used.
For the rule (Answer-var) the result follows from the well-bracketedness of traversals.
For constant rules, the result follows from the well-behaviour of constant rules (condition WB).
\end{proof}

\begin{lemma}[View of a traversal reduction]
\label{lem:redtrav_trav} Suppose that $M$ is a $\beta$-normal term and let $t$ be a traversal of $\tau(M)$ then
\begin{itemize}
\item[(i)] $ \pview{t \upharpoonright  r } = \pview{t} \upharpoonright r$\ ;
\item[(ii)] if $t^\omega \in N^{\filter r}$ {\it i.e.}~$t$'s last node is hereditarily justified by $r$, then
    $\oview{t \upharpoonright r } = \oview{t}$\ .
\end{itemize}
\end{lemma}
In the safe lambda calculus without interpreted constants this lemma
follows immediately from the fact that $\travset(M) =
\travset(M)^{\upharpoonright r }$. Here we prove the result in a
more general setting of a calculus extended with interpreted
constants whose corresponding traversal rules are
\emph{well-behaved}.


\begin{proof}
(i) By induction. It is trivially true for the empty
traversal and for the traversal $t = r$. Step case: consider a traversal $t$ and
suppose that the property (i) is verified for all traversal shorter
than $t$:
\begin{itemize}[-]
\item If $t = t' \cdot n$ with $n \in N_{\sf var} \union N_{\Sigma}$ then:
    \begin{align*}
    \pview{t} \upharpoonright  r
&= \pview{t' \cdot n} \upharpoonright  r & (\mbox{definition of } t)\\
        &= (\pview{t'} \cdot n) \upharpoonright  r  & (\mbox{P-view computation}) \\
        &= \pview{t'} \upharpoonright  r  \cdot (n \upharpoonright  r)            & (\mbox{def. of filtering $\upharpoonright$}) \\
        &= \pview{t' \upharpoonright  r } \cdot (n \upharpoonright  r)           & (\mbox{induction hypothesis}) \\
        &= \pview{t' \upharpoonright  r \cdot (n \upharpoonright  r) } & (\mbox{P-view computation, $n \in N_{\sf var} \union N_{\Sigma}$}) \\
        &= \pview{(t' \cdot n ) \upharpoonright  r  }           & (\mbox{def. of filtering $\upharpoonright$}) \\
        &= \pview{t \upharpoonright  r  }
 & (\mbox{definition of } t).
    \end{align*}


\item If $\Pstr{ t =  t' \cdot (m){m} \cdot  u \cdot (lmd-m,30){n}}$ with $n\in N_\lambda \setminus N^{\upharpoonright r}_\lambda$ then we have $u = \epsilon$ by lemma
    \ref{lem:var_followedby_child} and:
        \begin{align*}
        \pview{t} \upharpoonright  r
        &= \pview{\Pstr{t' \cdot (m){m} \cdot (n-m,60){n}}} \upharpoonright  r
                                                        & (u=\epsilon)\\
        &= (\Pstr{\pview{t'} \cdot (m){m} \cdot (lmd-m,60){n}} ) \upharpoonright  r
                                                        & (\mbox{P-view computation}) \\
        &= \pview{t'} \upharpoonright  r                & (m, n \not\in N^{\upharpoonright r}) \\
        &= \pview{t' \upharpoonright  r }               & \mbox{(induction hypothesis)} \\
        &= \pview{ (\Pstr{t' \cdot (m){m} \cdot (lmd-m,40){n}}) \upharpoonright r }
                                                        & (m, n \not\in N^{\upharpoonright r}) \\
        &= \pview{ t \upharpoonright r }             & \mbox{(def. of $t$ \& $u = \epsilon$).}
        \end{align*}

\item If $\Pstr{ t =  t' \cdot (m){m} \cdot u \cdot (lmd-m,30){n} }$ with $n\in N^{\upharpoonright r}_\lambda$ then:
        \begin{align*}
        \pview{t} \upharpoonright  r
        &= \pview{\Pstr{t' \cdot (m){m} \cdot u \cdot (n-m,40){n}}} \upharpoonright  r
                                                              & (\mbox{definition of } t)\\
        &= (\Pstr{\pview{t'} \cdot (m){m} \cdot  (lmd-m,60){n}}) \upharpoonright  r
                                                              & (\mbox{P-view computation}) \\
        &= \Pstr{ \pview{t'} \upharpoonright  r \cdot (m){m} \cdot  (lmd-m,60){n} }
                                                              & (m, n \in N^{\upharpoonright r}) \\
        &= \Pstr{ \pview{t'\upharpoonright r}  \cdot (m){m} \cdot  (lmd-m,60){n} }
                                                              & \mbox{(induction hypothesis)} \\
        &= \pview{ \Pstr{t' \upharpoonright r \cdot (m){m} \cdot {(u \upharpoonright r)} \cdot (lmd-m,35){n}}}
                                                           & (\mbox{P-view computation}) \\
        &= \pview{ (\Pstr{t' \cdot (m){m} \cdot u \cdot (lmd-m,35){n}}) \upharpoonright r }
                                                           & (m, n \in N^{\upharpoonright r}) \\
        &= \pview{ t \upharpoonright r }                & \mbox{(def. of $t$).}
        \end{align*}
\end{itemize}
(ii) By a straightforward induction similar to (i).
\end{proof}

\begin{remark}
\label{rem:inputvar}
Using the previous lemma we observe that in the definition of the rule \rulenamet{InputVar} we have
$n \in N_\lambda^{\filter r}$. Indeed,
$\oview{t_1 \cdot x } = \oview{ (t_1 \cdot x) \filter r}$ therefore $n$
is hereditarily enabled by $r$.
\end{remark}

\begin{lemma}[Traversal of $\beta$-normal terms]
\label{lem:betaeta_trav}
Let $M$ be a $\beta$-normal term, $r$ be the root of the tree $\tau(M)$ and
$t$ be a traversal of $\tau(M)$.
For any node $n$ occurring in $t$:
\begin{eqnarray*}
r \mbox{ does not hereditarily justify } n  \  \iff \   n \mbox{ is
hereditarily justified by some node in } N_\Sigma.
\end{eqnarray*}
\end{lemma}
\begin{proof}
 In a computation tree, the only nodes that do not have justification pointer are:
the root $r$, @-nodes and $\Sigma$-constant nodes. But since $M$ is
in $\beta$-normal form, there is no @-node in the computation tree.
Hence nodes are either hereditarily justified by $r$ or hereditarily
justified by a node in $N_\Sigma$. Moreover $r$ is not in $N_\Sigma$
therefore the ``or'' is exclusive : a node cannot be hereditarily
justified at the same time by $r$ and by some node in $N_\Sigma$.
\end{proof}


\section{Game semantics correspondence}
\label{sec:gamesemcorresp}

 We are working in the general setting of an applied
simply-typed $\lambda$-calculus with a given set of higher-order
constants $\Sigma$. The operational semantics of these constants is
given by certain reduction rules. We assume that a fully abstract
model of the calculus is provided by means of a category of
well-bracketed games. For instance, if $\Sigma$ consists
of the \pcf\ constants then we consider the traditional
category of games and innocent well-bracketed strategies
\cite{hylandong_pcf,abramsky94full}.


In the literature, a strategy is commonly defined as a set of plays closed by
even-length prefixing. However, for our purpose here, it is more convenient to represent strategies using \emph{prefix-closed} set of plays. This saves us from considerations on the parity of traversal length when
showing the correspondence between traversals and game semantics.
 For the rest of the section we fix a simply-typed term $\Gamma \vdash M :T$. We write $\sem{\Gamma \vdash M : T}$ for its strategy denotation (in the standard cartesian closed category of games and innocent strategies \cite{abramsky94full, hylandong_pcf}). We use the notation $\prefset(S)$ to denote the prefix-closure of the set $S$.

\subsection{Relating computation trees and games}
Let us first study an example:
\subsubsection{Example}
Consider the following term $M \equiv \lambda f z . (\lambda g x . f (f x)) (\lambda y. y) z$ of type $(o \typear o) \typear o \typear o$.
Its $\eta$-long normal form is $\lambda f z . (\lambda g x . f (f x)) (\lambda y. y) (\lambda .z)$.
The computation tree is:

$$
\tree{\lambda f z}
{ \tree{@}
    {
        \tree{\lambda g x}
            { \tree{f}{   \tree{\lambda}{ \tree{f}{  \tree{\lambda}{\TR{x}}} }  }
            }
        \tree{\lambda y}{\TR{y}}
        \tree{\lambda}{\TR{z}}
    }
}
$$

The arena for the type $(o \typear o) \typear o \typear o$ is:
$$\tree{q^1}
{
    \tree{q^3}
        {  \tree{q^4}
                {\TR{a^4_1} \TR{\ldots}}
            \TR{a^3_1} \TR{\ldots} }
    \tree{q^2}
    { \TR{a^2_1} \TR{a^2_2}\TR{\ldots} }
    \TR{a_1} \TR{a_2}\TR{\ldots}
}
$$

\newlength{\yNull}
\def\bow{\quad\psarc{->}(0,\yNull){1.5ex}{90}{270}}

The figure below represents the computation tree (left) and the
arena (right). The dashed line defines a partial function $\psi$
from the set of nodes in the computation tree to the set of moves.
For simplicity, we now omit answers moves when representing arenas.
$$
\tree{ \Rnode{root} {\lambda f z}^{[1]} }
     {  \tree{@^{[2]}}
        {   \tree{\lambda g x ^{[3]}}
                { \tree{\Rnode{f}{f^{[6]}}}{  \tree{\Rnode{lmd}\lambda^{[7]}}{ \tree{\Rnode{f2}{f^{[8]}}} {\tree{\Rnode{lmd2}\lambda^{[9]}}{\TR{x^{[10]}}}}}  }
                }
            \tree{\lambda y ^{[4]}}{\TR{y}}
            \tree{\lambda ^{[5]}}{\TR{\Rnode{z}z}}
        }
    }
\hspace{3cm}
  \tree[levelsep=12ex]{ \Rnode{q1}q^1 }
    {   \pstree[levelsep=4ex]{\TR{\Rnode{q3}q^3}}{\TR{\Rnode{q4}q^4}}
        \TR{\Rnode{q2}q^2}
        \TR{\Rnode{q5}q^5}
    }
\psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
\ncline{->}{root}{q1} \aput*{:U}{\varphi}
\ncarc{->}{z}{q2}
\ncline{->}{f}{q3}
\ncline{->}{lmd}{q4}
\ncline{->}{f2}{q3}
\ncline{->}{lmd2}{q4}
$$

Consider the justified sequence of moves $s \in \sem{M}$:
 $$s = \Pstr[0.6cm][5pt]{(q1){q}^1\ (q3-q1,60){q}^3\ (q4-q3,60){q}^4\ (q3b-q1){q}^3\ (q4b-q3b,60){q}^4\ (q2-q1,30){q}^2 }
\in \sem{M}$$

There is a corresponding justified sequence of nodes in the computation tree:
$$r = \Pstr[0.8cm]{
        (q1){\lambda f z} \cdot
        (q3-q1,60){f}^{[6]} \cdot
        (q4-q3,60){\lambda^{[7]}} \cdot
        (q3b-q1,60){f}^{[8]} \cdot
        (q4b-q3b,50){\lambda^{[9]}} \cdot
        (q2-q1,50){z} }$$
such that $s_i = \psi(r_i)$ for all $i < |s|$.

The sequence $r$ is in fact the reduction of the following
traversal:
$$t = \Pstr[1.1cm]{ (q1){\lambda f z} \cdot
            (n2){@^{[2]}} \cdot (n3-n2,60){\lambda g x^{[3]}} \cdot
            (q3-q1,60){f}^{[6]} \cdot (q4-q3,60){\lambda^{[7]}} \cdot
            (q3b-q1,40){f}^{[8]} \cdot (q4b-q3b,70){\lambda^{[9]}} \cdot
            (n8-n3,35){x^{[10]}} \cdot
            (n9-n2,30){\lambda^{[5]}} \cdot
            (q2-q1,35){z} }
$$

By representing side-by-side the computation tree and the type arena of a term in $\eta$-normal form we have observed
that some nodes of the computation tree can be mapped to question moves of the arena.
In the next section, we show how to define this mapping in a systematic manner.

\subsubsection{Formal definition}

We now establish formally the relationship between games and computation trees. Suppose $\Gamma \vdash M : T$
is in $\eta$-long normal form. We suppose that computation tree $\tau(M)$
is given by a pair $(V,E)$ where $V$ is the set of vertices of
and $E \subseteq V \times V$ is the parent-child relation. We have $V = N \union VL$ where $N$
and $VL$ are the set of nodes and value-leaves respectively.

\emph{Notations:}
We write $V_\$$ for $N_\$ \union (E(N_\$) \inter VL)$ where $\$$ ranges over $\{@, {\sf var}, \Sigma, {\sf fv} \}$.
Let $\mathcal{D}$ be the set of values of the base type $o$. If $n$ is a node in $N$ then the value-leaves attached to the node $n$ are written $v_n$ where $v$ ranges in $\mathcal{D}$.
Similarly, if $q$ is a question in $\sem{A}$ then the answer moves enabled by $q$ are written $v_q$ where $v$ ranges in $\mathcal{D}$.

\begin{definition}[Mapping from nodes to moves]\hfill
\label{def:phi_psi mapping}

    \begin{itemize}[-]
    \item Let $n$ be a node in $N_\lambda \union N_{\sf var}$ and $q$ be a question move of some game $A$
such that $n$ and $q$ are of type $(A_1,\ldots,A_p,o)$ for some $p\geq 0$. The function $\psi^{n,q}_A$ from $V^{\upharpoonright n}$ to $\sem{A}$ is defined as:
        \begin{eqnarray*}
        \psi^{n,q}_A &=& \{ n \mapsto q \} \union  \{ v_n \mapsto v_q \ | \ v \in \mathcal{D} \}\\
         &&\union \left\{
                        \begin{array}{ll}
                          \emptyset, & \hbox{if $p=0$\ ;} \\
                          \Union_{m \in N | n \vdash_i m} \psi^{m, q^i}_A, & \hbox{if $p\geq1$ and $n\in N_{\lambda}$\ ;} \\
                          \Union_{i=1..p} \psi^{n.i, q^i}_A, & \hbox{if $p\geq1$ and $n\in N_{\sf var}$\ .}
                        \end{array}
                      \right.
        \end{eqnarray*}
        where $\{ q^1, \ldots, q^p \} \union \{ v_q \ | \ v \in \mathcal{D} \}$ is the set of moves enabled by $q$ in $A$ (each $q^i$ being of type $A_i$).

    \item We use the abbreviation $\psi_n$
    for $\psi^{n,m}_{T(n)} : V^{\upharpoonright n} \rightarrow \sem{T(n)}$
    where $m$ denotes $\sem{T(n)}$'s initial move.

    \item Similarly we write $\psi_M$ (or just $\psi$ if this does not cause any ambiguity)
    for $\psi^{r,m}_{\Gamma\rightarrow T}$ where $m$ denote $\sem{\Gamma\rightarrow T}$'s initial move.\footnote{Arenas involved in the game semantics of simply-typed $\lambda$-calculus are all trees: they have a single initial move.}
    \end{itemize}
\end{definition}

It can easily be checked that the domain of definition of $\psi_n$ is indeed the set of nodes that are hereditarily enabled by $n$.

Let us detail a little the definition of $\psi_n$:
\begin{itemize}
\item If $p=0$ then $n$ is a dummy $\lambda$-node or a ground type variable: $\psi_n$ maps $n$ to the initial move $q$.

\item  If $p\geq 1$ and $n \in N_{\lambda}$ with $n$ labelled $\lambda \overline{\xi} = \lambda \xi_1 \ldots \xi_p$ then the sub-computation tree rooted at $n$ and the arena $\sem{T(n)}$ have the following forms (value-leaves and answer moves are not represented for simplicity):
    $$ \tree{ \Rnode{r}\lambda \overline{\xi}  ^{[n]}}
        {
            \tree[levelsep=6ex]{\alpha}
            {   \TR{\ldots} \TR{\ldots} \TR{\ldots}
            }
        }
    \hspace{3cm}
    \tree{ \Rnode{q0}m_n }
        {
            \tree[linestyle=dotted]{q^1}{\TR{} \TR{} }
            \tree[linestyle=dotted]{q^2}{\TR{} \TR{} }
            \TR{\ldots}
            \tree[linestyle=dotted]{q^p}{\TR{} \TR{} }
        }
    \psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
    \ncline{->}{r}{q0}
    \ncarc{->}{q2}{z}
    \ncline{->}{q3}{f}
    \ncline{->}{q4}{lmd}
    \ncline{->}{q3}{f2}
    \ncline{->}{q4}{lmd2}
    $$

    For each abstracted variable $\xi_i$ there exists a corresponding question move $q^i$ of the same order in the arena. $\psi_n$ maps each free occurrence of $\xi_i$ in the computation tree to the move $q^i$.

\item If $p\geq 1$ and $n\in N_{\sf var}$ then $n$ is labelled with a variable $x:(A_1,\ldots,A_p,o)$
with children nodes $\lambda \overline{\eta}_1$, \ldots, $\lambda \overline{\eta}_p$. The computation tree $\tau(M)$ rooted at $n$ and the arena $\sem{T(n)}$ have the following forms:
    $$\tree{\Rnode{r}{x^{[n]}}}
        {   \tree{\TR{\lambda \overline{\eta}_1}}{\vdots} \TR{\ldots}
        \tree{\TR{\lambda \overline{\eta}_p }}{\vdots}
        }
    \hspace{3cm}
    \tree{ \Rnode{q0}m_n }
        {
\tree[linestyle=dotted]{\Rnode{q1}{q^1}}{\TR{} \TR{} }
            \tree[linestyle=dotted]{\Rnode{q2}{q^2}}{\TR{} \TR{} }
            \TR{\ldots}
            \tree[linestyle=dotted]{\Rnode{qp}{q^p}}{\TR{} \TR{} }
        }
    \psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
    \ncline{->}{r}{q0}
    \ncarc{->}{q2}{z}
    \ncline{->}{q3}{f}
    \ncline{->}{q4}{lmd}
    \ncline{->}{q3}{f2}
    \ncline{->}{q4}{lmd2}
    $$

    and $\psi_n$ maps each node $\lambda \overline{\eta}_i$ to the question move $q^i$.
\end{itemize}

\begin{example}
Take $M = \lambda x . (\lambda g . g x) (\lambda y . y)$ with $x,y:o$
and $g:(o,o)$. The diagram below represents the computation tree
(middle), the arenas $\sem{(o,o), o}$ (left), $\sem{o , o}$ (right),
$\sem{o\rightarrow o}$ (rightmost), $\psi_{\lambda x}$,
$\psi_{\lambda g}$ and $\psi_{\lambda y}$ (dashed-lines).
$$\psset{levelsep=3.5ex}
\pstree{\TR[name=root]{\lambda x}}
{
    \pstree{\TR[name=App]{@}}
    {
            \pstree{\TR[name=lg]{\lambda g}}
                { \pstree{\TR[name=lgg]{g}}{
                        \pstree{\TR[name=lgg1]{\lambda}}
                        { \TR[name=lgg1x]{x}  } } }
            \pstree{\TR[name=ly]{\lambda y}}
                    {\TR[name=lyy]{y}}
    }
}
\rput(4.5cm,-1cm){
  \pstree{\TR[name=A1lx]{q_{\lambda x}}}
        { \TR[name=A1x]{q_x} }
}
\rput(-6cm,-1.5cm){
    \pstree{\TR[name=A2lg]{q_{\lambda g}}}
    {
        \pstree{\TR[name=A2g]{q_g}}
        {  \TR[name=A2g1]{q_{g_1}}   }
    }}
\rput(2.5cm,-1.5cm){
    \pstree{\TR[name=A3ly]{q_{\lambda y}}}
        { \TR[name=A3y]{q_y}
        }
}
\psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
\ncline{->}{root}{A1lx} \mput*{\psi_{\lambda x}}
\ncarc{->}{lgg1x}{A1x}
\ncline{->}{lg}{A2lg} \mput*{\psi_{\lambda g}}
\ncline{->}{lgg}{A2g}
\ncline{->}{lgg1}{A2g1}
\ncline{->}{ly}{A3ly} \mput*{\psi_{\lambda y}}
\ncline{->}{lyy}{A3y}
$$
\end{example}

\begin{property} \
\label{proper:psi_properties}
\begin{enumerate}[(i)]
\item $\psi$ maps $\lambda$-nodes to O-questions, variable nodes to
P-questions, value-leaves of $\lambda$-nodes to P-answers and
value-leaves of variable nodes to O-answers;
\item $\psi$ maps a node of a given order to a move of the same order;
\item Let $s \in \travset(M)^{\filter r}$. The P-view (resp. O-view) of $\psi(s)$ and $s$ are computed
identically {\it i.e.}~the set of occurrence positions that must be removed
from each sequences in order to obtain their respective P-view (resp. O-view) is the same for both sequence.
\end{enumerate}
\end{property}
\begin{proof}
(i) and (ii) are direct consequences of the definition.

(iii) Because of (i) and since $t$ and $\psi(t)$ have the
same pointers, the computations of the P-view (resp. O-view) of the
sequence of moves and the P-view (resp. O-view) of the sequence of
nodes follow the same steps.
\end{proof}
The fact that we have defined the order of the root node differently from the order of other $\lambda$-nodes
(Def. \ref{def:nodeorder}) should now make more sense to the reader: this definition permits us to state property (ii).
\smallskip

By extension, we can define the function $\psi_M$ on $\travset(M)^{\filter r}$, the set of justified
sequences of nodes that are hereditarily justified by (the only occurrence of) the root $r$:
\begin{definition}[Mapping sequences of nodes to sequences of moves]
We define the function $\psi_M : \travset(M)^{\filter r} \rightarrow \sem{\Gamma \rightarrow T}$ as follows.
If $s = s_0 s_1 \ldots \in \travset(M)^{\filter r}$ then:
$$\psi_M(s) = \psi_M(s_0)\ \psi_M(s_1)\  \psi_M(s_2) \ldots$$
where $\psi_M(s)$ is equipped with $s$'s pointers.

Thus the pointer-free version of this function is a monoid homomorphism.
\end{definition}


\subsection{Interaction games}
\label{sec:interaction_semantics}

In game semantics, strategy composition is achieved by performing a
CSP-like ``composition + hiding''. It is possible to define an
alternative semantics where the internal moves are not hidden when
performing composition. This semantics is named \emph{revealed
semantics} in \cite{willgreenlandthesis} and \emph{interaction}
semantics in \cite{DBLP:conf/sas/DimovskiGL05}.

In addition to the moves of the standard semantics, the interaction
semantics contains certain internal moves of the computation.
Consequently, the interaction semantics depends on the syntactical
structure of the term and therefore cannot lead to a full
abstraction result. However this semantics will prove to be useful
to identify a correspondence between the game semantics of a term
and the traversals of its computation tree.

Our interaction semantics will be calculated from the $\eta$-normal
form of a term. However we do not want to keep all the internal
moves: we only keep the internal moves that are produced when
composing two subterms of the computation tree joint by an @-node.
This means that when computing the strategy denoting $y N_1 \ldots
N_p$ where $y$ is a variable, we preserve the internal moves of
$N_1$, \ldots, $N_p$ while omitting the internal moves produced by
the copy-cat projection strategy denoting $y$.


\begin{definition} \hfill
\begin{itemize}
\item We call \defname{interaction type tree} or just \defname{interaction type},
a tree whose leaves are labelled with linear simple types and
nodes are labelled with symbol in $\{ ;, \langle \_\ ,\_
\rangle, \otimes, \dagger, \Lambda \}$.


Nodes labelled $;$, $\langle \_\ ,\_ \rangle$ or $\otimes$ are
binary nodes and nodes labelled $\dagger$ or $\Lambda$ are unary
nodes. If $T_1$ and $T_2$ are interaction types we write
$\langle T_1, T_2 \rangle$ to denote the interaction type
obtained by attaching $T_1$ and $T_2$ to a $\langle \_\ ,\_
\rangle$-node. Similarly we use the notations $T_1 \otimes T_2$,
$T_1 ; T_2$, $\Lambda(T_1)$ and $T_1^\dagger$.

\item To every node or leaf we can associate a linear type. We write
    $type(T)$ to denote the type associated to the root node. We
    sometime write the type in exponent {\it e.g.}
    $T^{A\rightarrow B}$ if $type(T) =A\rightarrow B$. This type
    is determined by the structure of the tree as follows:
    \begin{itemize}
    \item If $T$ is a leaf then $type(T)$ is define as the type that labels the leaf;

    \item $type\ (T^{!A \multimap B})^\dagger = !A \multimap !B$;

    \item $type\ \Lambda(T_1^{A \otimes B \multimap C}) = A \multimap (B \multimap C)$

    \item $type\ \langle T_1^{C \multimap A} , T_2^{C \multimap B} \rangle =
    C \multimap A \times B$;

    \item $type\ T_1^{A \multimap B} \otimes T_2^{C \multimap D} = (A \otimes C) \multimap (B \otimes D)$;

    \item $type\ T_1^{A \multimap B};T_2^{B \multimap C} = A \multimap C$.
    \end{itemize}

\end{itemize}

For the interaction type tree to be well-defined, it is required
that types of children nodes are consistent with the meaning of the
parent node; for instance the two children nodes of a ;-node must be
of type $A\multimap B$ and $B\multimap C$.

\end{definition}


Let $T$ be an interaction type tree. Each leaf or node of type $A$
in $T$ can be mapped to the (standard) game $\sem{A}$. By taking the
image of $T$ across this mapping we obtain a tree whose leaves and
nodes are labelled by games. This tree, written $\intersem{T}$, is
called an \defname{interaction game}.

A \defname{revealed strategy} $\Sigma$ on the interaction game $\intersem{T}$ is a compositions of several standard strategies in which certain internal moves are not hidden. Formally:
\begin{definition}[Revealed strategy]
A revealed strategy $\Sigma$ on an interaction game $\intersem{T}$,
written $\Sigma: \intersem{T}$, is an annotated interaction type
tree $T$ where
\begin{itemize}
\item each leaf $\sem{A}$ of $T$ is annotated with a (standard) strategy $\sigma$ on the game
$\sem{A}$;
\item each $;$-node is annotated with a set of indices $U \subseteq \nat$.
\end{itemize}
\end{definition}

The intuition behind this definition is that each $;$-node with children of type $A\multimap B$ and $B\multimap C$ is annotated with a set of indices $U$ indicating which components of $B$ should be uncovered when performing composition.
More precisely, if $B = B_0 \times \ldots \times B_l$ then the revealed strategy built by connecting two revealed strategies $\Sigma_1 : \intersem{A\multimap B}$ and $\Sigma_2 : \intersem{B\multimap C}$
using a $;$-node annotated with $U$ represents the
set of uncovered plays obtained
by performing the usual composition while ignoring and copying the internal moves already in $\Sigma_1$ and $\Sigma_2$ and preserving any internal
move produced by the composition in some component $B_k$ for $k \in U$.

\begin{example}
The diagrams below represent an interaction type tree $T$ (left),
the corresponding interaction game $\intersem{T}$ (middle) and a
revealed strategy $\Sigma$ (right):
$$
\pstree[levelsep=6ex]{\TR{;}}
        {
            \pstree[levelsep=6ex]{\TR{;}}
            { \TR{A\multimap B}
              \TR{B\multimap C}
            }
            \TR{C\multimap D}
        }
\hspace{1cm}
\pstree[levelsep=6ex]{\TR{;}}
        {
            \pstree[levelsep=6ex]{\TR{;}}
            { \TR{\sem{A\multimap B}}
              \TR{\sem{B\multimap C}}
            }
            \TR{\sem{C\multimap D}}
        }
\hspace{1cm}
\pstree[levelsep=6ex]{\TR{;^{\{0\}}}}
        {
            \pstree[levelsep=6ex]{\TR{;^{\{0\}}}}
            { \TR{A\multimap B^{\sigma_1}}
              \TR{B\multimap C^{\sigma_2}}
            }
            \TR{C\multimap D^{\sigma_3}}
        }
$$
\end{example}
A revealed strategy can also be written as an expression, for
instance the strategy represented above is given by the expression
$\Sigma = (\sigma_1 ;^{\{0\}} \sigma_2) ;^{\{0\}} \sigma_3$. We will
use the abbreviation $\Sigma_1 \fatsemi^U \Sigma_2$ for
$\Sigma_1^\dagger ; ^U \Sigma_2$.


\subsubsection{Uncovered play}

The analogous of a play in the interaction semantics is called an
\emph{uncovered play}, it is a play containing internal moves. The
moves are implicitly tagged so that it is possible to retrieve in
which component of the arena of which node/leaf-game the move
belongs to. A given move may belong to several games from different
nodes/leaves of the interaction game.

\begin{definition}
The \defname{set of possible moves} $M_T$ of an interaction game
$\intersem{T}$ is defined as $\mathcal{M}_T/\hspace{-0.5em}\sim_T$,
the quotient of the set $\mathcal{M}_T$ by the equivalence relation
$\sim_T \subseteq \mathcal{M}_T \times \mathcal{M}_T$ defined as follows:
For a single leaf tree $T$ labelled by a type $A$ we define
$\mathcal{M}_T = M_A$ and $\sim_T = id_{M_A}$. For other cases:
    \begin{align*}
        \mathcal{M}_{T^\dagger} &= \mathcal{M}_{T} + M_{type(T^\dagger)}
    &
        \mathcal{M}_{\Lambda(T)} &= \mathcal{M}_{T} + M_{type(\Lambda(T))}
    \\
        \sim_{T^\dagger} &= \left( \sim_{T}
        \union \left(type\ T^\dagger \leftrightarrow  type\ T\right)
        \right)^\star
    &
        \sim_{\Lambda(T)} &= \left( \sim_{T}
        \union \left(type\ \Lambda(T) \leftrightarrow type\ T\right)
        \right)^\star
    \end{align*}
    \begin{align*}
        \mathcal{M}_{\langle T_1^{C^1 \multimap A^1}, T_2^{C^2 \multimap B^2}\rangle}
        &= \mathcal{M}_{T_1} + \mathcal{M}_{T_2} + M_{C \multimap (A \otimes B)}
    \\
         \sim_{\langle T_1^{C^1 \multimap A^1}, T_2^{C^2 \multimap B^2}\rangle} &= \left( \sim_{T_1}
        \union \sim_{T_2} \union (C^1 \leftrightarrow C) \union (C^2 \leftrightarrow C)
        \union (A^1 \leftrightarrow A) \union (B^2 \leftrightarrow B)
        \right)^\star
    \\
    \\
        \mathcal{M}_{T_1^{A^1 \multimap B^1}\otimes T_2^{C^2 \multimap D^2}} &= \mathcal{M}_{T_1} +  \mathcal{M}_{T_2} + M_{A \otimes C \multimap B \otimes D }
        \\
         \sim_{T_1^{A^1 \multimap B^1}\otimes T_2^{C^2 \multimap D^2}} &= \left( \sim_{T_1}
        \union \sim_{T_2} \union (A^1 \leftrightarrow A)
        \union (B^1 \leftrightarrow B) \union (C^2 \leftrightarrow C)\union (D^2 \leftrightarrow D)
        \right)^\star
    \\
    \\
        \mathcal{M}_{T_1^{A \multimap B};T_2^{B \multimap C}} &=
            \mathcal{M}_{T_1} + \mathcal{M}_{T_2} + M_{A\multimap C}
        \\
         \sim_{T_1^{A^1 \multimap B^1};T_2^{B^2 \multimap C^2}} &= \left( \sim_{T_1}
        \union \sim_{T_2} \union (A^1 \leftrightarrow A)
        \union (B^1 \leftrightarrow B^2) \union (C \leftrightarrow C^2)
        \right)^\star
    \end{align*}
    where $A\leftrightarrow B$ denotes the implicit bijection between
    two isomorphic arenas $\sem{A}$ and $\sem{B}$; $R^\star$
    denotes the smallest superset of the relation $R$ complete
    by transitivity, reflexivity and symmetry.
\end{definition}

We call \defname{internal move} of the game $\intersem{T}$, any move
from $M_T$ which is not $\sim$-equivalent to any move in
$M_{type(T)}$.


A \defname{justified interaction sequence} of moves on the
interaction game $\intersem{T}$ is a sequence of moves from $M_T$
together with pointers. In contrast to the standard notion of
justified sequence, to each move in the sequence can be attached
several pointers. More precisely, if the equivalence class $m$ is
$\{m_1, \ldots, m_l \}$ then $m$ has one pointer for each
non-initial move $m_i$ in the equivalence class.

\begin{definition}[Filtering] We define several filtering operations
over justified interaction sequences. Let $s$ be a justified
sequence of moves on the interaction game $\intersem{T}$.
\begin{itemize}
\item  Let $T'$ be a subtree of $T$. We define the
filtering operator $s\upharpoonright T'$ to be the subsequence
of $s$ consisting of moves $\sim$-equivalent to some move in
$M_{T'}$. This operation causes some move to ``lose'' some of
their attached pointers: a given move $m$ with equivalence class
$\{m_1, \ldots, m_l \}$ may have up to $l$ pointers, but in
$s\upharpoonright T'$, only pointers associated to a $m_i$
belonging to $\mathcal{M}_{T'}$ are preserved.

Note that since $M_T$ is a set of equivalence classes with
respect to $\sim$, the filtering operator $\_ \filter T'$
implicitly performs the ``retagging'' of the moves to the
appropriate components of each game of the interaction game
$\intersem{T'}$.

\item  For any sub-game $A$ of the standard game $\sem{type(T')}$ we
define the filtering operator $s\upharpoonright A$ to be the
subsequence of $s$ consisting of moves from $A$ where at most
one pointer is kept for each move in the sequence: the one
corresponding to the class citizen from $A$.

\item For any initial move $m$ of the game $\sem{type(T)}$ occurring in $s$, $s
\hjfilter m$ is the subsequence of $s$ consisting of moves
that are \emph{hereditarily justified} by that particular occurrence of $m$ in $s \filter type(T)$.
% NOTE: it is important to precise ``in $s \filter type(T)$'' because $s$'justification
% pointers differs depending on the sub-interaction game considered.

%\item For any initial move $m$ of the game $\sem{type(T)}$, $s
%\hefilter m$ is the subsequence of $s$ consisting of moves
%that are \emph{hereditarily enabled} by $m$ in the game $\sem{type(T)}$.
\end{itemize}
By extension, we also define these operations on sets of justified
interaction sequences.
\end{definition}

Allowing moves to have multiple pointers complicates slightly the
presentation here, but this capability is necessary to model
strategy composition. Indeed, in game semantics after composing
strategies, the pointers from some moves may change! (See definition
of $\filter A,C$ in \cite{abramsky:game-semantics-tutorial}.)
However, for all the other operations on strategies that we will
used, the pointers will just be preserved. Formally we define this
property as follows: Let $s$ be an  interaction sequence on a game
$\intersem{T}$, $T'$ a direct subtree $T$ ({\it i.e.}~a subtree of
$T$ whose root is a child of $T$'s root), $A$ be a sub-game of
$\sem{type(T)}$ and $A'$ be a sub-game of $\sem{type(T')}$, then we
define the predicate $A'\stackrel{s}\hookrightarrow A$ as:
\begin{align*}
 A'\stackrel{s}\hookrightarrow A \mbox{ holds iff } &
 \Pstr{s_1\ (n){n'}\ s_2\ (m-n){m'}\ s_3 } = s\filter A'  \\
 & \implies \exists! m,n \in A | m \sim m' \zand n \sim n' \zand \Pstr{s_1\
(n){n}\  s_2\ (m-n){m}\ s_3} = s\filter A
\end{align*}

and we say that $s$'s justification is preserved from $A'$ to $A$
with respect to $\sim$.



\begin{definition}[Legal uncovered positions] We recall
that in the standard game semantics, the set of legal positions
$L_A$ of a game $A$ is the set of justified sequences of moves from
$M_A$ respecting visibility and alternation. We define the set of
\defname{legal uncovered position} $L_T$ of an interaction game $\intersem{T}$ as
follows:
    \begin{itemize}
    \item If $T$ is a leaf annotated by a type $A$ then $L_T =
    L_A$;
    \item If $T$ is a unary node with child node $T'$ then:
    $$L_T = \{ s \in JustSeq(T) \ | \ s \filter type(T) \in L_{type(T)} \zand  s \filter T' \in L_{T'} \} \ ;$$
    \item If $T$ is a binary node with children nodes $T_1$ and $T_2$ then:
    $$L_T = \{ s \in JustSeq(T) \ | \ s \filter type(T) \in L_{type(T)} \zand  s \filter T_1 \in L_{T_1}
    \zand  s \filter T_2 \in L_{T_2} \} \ .$$
    \end{itemize}
    where $JustSeq(T)$ denotes the set of justified interaction sequences on
    $\intersem{T}$.
\end{definition}

Revealed strategies can alternatively be represented as by means
of sets of uncovered positions:
\begin{definition}[Revealed strategies as set of uncovered positions]
\label{dfn:revealedstrat}
The set of uncovered positions of a revealed strategy is defined inductively on the
structure of the annotated interaction type tree underlying the
interaction strategy:
\begin{itemize}[-]
\item Leaf labelled with type $A$ and annotated by the strategy $\sigma$: The set of positions of the revealed strategy is precisely the set of positions of the standard strategy $\sigma$.

\item Tensor product, pairing, promotion, currying:
\begin{eqnarray*}
(\Sigma_1 : \intersem{T_1}) \otimes (\Sigma_2 : \intersem{T_2}) : \intersem{T} &=\{ s \in L_T \ | \  &s \filter T_1 \in \Sigma_1 \zand\ s \filter T_2 \in \Sigma_2 \\
&& \zand\ type(T_1)\stackrel{s}\hookrightarrow type(T) \\
&& \zand\ type(T_2)\stackrel{s}\hookrightarrow type(T) \}
\\ \\
\langle \Sigma_1 : \intersem{T_1}, \Sigma_2 : \intersem{T_2} \rangle : \intersem{T} &= \{ s \in L_T \ | &
   ( (s \filter T_1 \in \Sigma_1 \zand\ s \filter T_2 = \epsilon) \\
&&  \   \zor ( s \filter T_1 = \epsilon \zand s \filter T_2 \in \Sigma_2)) \\
&& \zand\ type(T_1)\stackrel{s}\hookrightarrow type(T) \\
&& \zand\ type(T_2)\stackrel{s}\hookrightarrow type(T) \}
\\ \\
(\Sigma' : \intersem{T'})^\dagger : \intersem{T} &= \{ s \in L_T \ | \ &
\mbox {for all occurrence $m$ in $s$ of an initial  }\\
&& \mbox{ $\sem{type(T)}$-move, $(s \filter m) \filter T' \in \Sigma'$} \\
&& \zand\ type(T')\stackrel{s}\hookrightarrow type(T) \}
\\ \\
\Lambda(\Sigma' : \intersem{T'}) : \intersem{T} &= \{ s \in L_T \ | & s \filter T' \in \Sigma' \ \zand\ type(T')\stackrel{s}\hookrightarrow type(T) \}
\end{eqnarray*}

\item Uncovered composition $(\Sigma_1 : \intersem{T_1})\ ;^U\ (\Sigma_2
:\intersem{T_2})$ defined on the game $\intersem{T}$ where
$type(T) = A \multimap C$, $type(T_1) = A^1 \multimap B_0 \times
\ldots \times B_l$ and $type(T_2) = B_0 \times \ldots \times B_l
\multimap C^2$. We first define
\begin{eqnarray*}
\Sigma_1 \| \Sigma_2 &= \{ u \in L_T  \ | \ & u \upharpoonright T_1 \in \Sigma_1 \mbox{ and } u \upharpoonright T_2 \in \Sigma_2 \\
&& \zand\ C^2\stackrel{u}\hookrightarrow C\ \zand\ (A^1)^-\stackrel{u}\hookrightarrow A^-  \\
&& \zand\ \parbox[t]{8cm}{for any initial $m$ in $A^1$, if $m$ is justified in $u \filter type(T_1)$ by $b\in B_j$,
itself justified by $c \in C^2$ in $u \filter type(T_2)$ then $m$ justified by $c$ in $u \filter type(T)$ \} }
\end{eqnarray*}
where $A^-$ denotes the set of non-initial moves of the game $A$. We can now define composition as:
$$ \Sigma_1 ;^U \Sigma_2 = \{ cover(u,(0..l)\setminus U) \ | \ u \in \Sigma_1 \| \Sigma_2 \}$$
where $cover(u,C) = u \filter \left( M_T \setminus \Union_{j\in
C} B_j \right)$ {\it i.e.}~the subsequence of $u$ obtained by
removing moves in $\Union_{j\in C} B_j$. Hence
$\Sigma_1;^{\{0..l\}} \Sigma_2 = \Sigma_1 \| \Sigma_2$.

In other words $\Sigma_1 ;^U \Sigma_1$ is the set of uncovered
plays obtained by performing the usual composition while
ignoring and copying the internal moves from arenas in
$\intersem{T_1}$ or $\intersem{T_2}$ and preserving any internal
move produced by the composition in some component $B_k$ for $k
\in U$.
\end{itemize}
\end{definition}

\begin{remark} \hfill
\label{rem:interstrat}
\begin{enumerate}[i.]
\item We observe that for all strategy operator
except composition, pointers associated to moves are preserved.
For strategy composition, additional pointers are
``created'' only for initial $A$-moves.
\item It is straightforward to generalize the pairing operator $\langle \Sigma_1, \Sigma_2 \rangle$ to more than two parameters: an interaction strategy $\langle \Sigma_1, \ldots, \Sigma_p \rangle$ for $p\geq2$
is defined on an interaction game whose root node has $p$ children.
\end{enumerate}
\end{remark}

We write $\mathcal{I}$ for the set of all revealed strategies. Note
that $\mathcal{I}$ is not a category since composition is not
associative and there is no identity interaction strategy.


\begin{lemma}[Complete interaction sequence]
\label{lem:inter_complete}
Let $u$ be an interaction sequence of some interaction strategy $\Sigma : \intersem{T}$
and suppose that the standard strategy denoting the leaves of $\Sigma$ are all well-bracketed.

Then for any node/leaf game $A$ of $T$ and interaction sequence $u\in \Sigma$ we have:
\begin{itemize}[i.]
\item $u \filter A$ is well-bracketed;

\item If $u \filter type(T)$ is complete (all question moves answered) then
    $u \filter A$ is complete.
\end{itemize}
\end{lemma}
\begin{proof}
By induction on the structure of the interaction game $\intersem{T}$. The base case is
trivial. We only treat composition, the other cases being trivial: Let $ u \in \Sigma_1 ; ^U \Sigma_2$ for some $U \subseteq \nat$ with
$\Sigma_1 : \intersem{T_1^{A\multimap B}}$ and $\Sigma_2 : \intersem{T_2^{B\multimap C}}$.

i. During composition, pointers attached to answer moves are preserved with respect to $\sim$
thus non-well-bracketing of $u\filter A\multimap C$ implies
either non-well-bracketing of $u\filter A\multimap B$ or $u\filter B\multimap C$.

For ii., suppose $u \filter type(T) = \Pstr{(q)q\ u'\ (a-q)a }$.
By well-bracketing (i.) and since $q$ and $a$ belong to $C$ we must have
$u \filter B\multimap C = \Pstr{(q)q \ldots (a-q)a}$ thus $u \filter B\multimap C$ is complete.
Suppose that $u \filter A\multimap B$ is not complete, then its first move is unanswered,
but since this is a $B$-move, it must also occur unanswered in $u \filter B\multimap C$ which is a contradiction
since we have just prove that $u \filter B\multimap C$ is complete. Thus $u \filter A\multimap B$  is also complete.

The induction hypothesis permits to conclude.
\end{proof}
Consequently if $u\filter type(T)$ is complete then $u$ is maximal {\em i.e.~no move (and in particular no internal move) can be played after $u$}.

\subsubsection{Modeling the $\lambda$-calculus in $\mathcal{I}$}

We would like to use revealed strategies from $\mathcal{I}$ to model terms of
the simply-typed lambda calculus.
Depending on the internal moves that we wish to hide, we obtain different possible interaction strategies for a given term.
The following definition fixes a unique strategy denotation which is computed from the $\eta$-normal form of the term.

\begin{definition}[Revealed denotation of a term]
\label{dfn:interactionstrategy_ofterms}
Let $\pi_i$ denote the $i^{th}$ projection copycat strategy $\pi_i : \sem{X_1 \times \ldots \times X_l} \rightarrow \sem{X_i}$.

The \defname{revealed game denotation} or \emph{revealed strategy} of
$M$ written $\intersem{\Gamma \vdash M : A}$ is defined as
$\sem{\Gamma \vdash M : A}$ if $M$ is in $\beta$-normal form, otherwise
it is defined by structural induction on the \emph{$\eta$-long normal form of $M$}:
\begin{eqnarray*}
\intersem{\Gamma \vdash \lambda \overline{\xi} . M  : A} &=& \Lambda^{|\overline{\xi}|}(\intersem{\Gamma, \overline{\xi} \vdash M : o })  \\
\intersem{\Gamma  \vdash x_i N_1 \ldots N_p :o} &=& \langle \pi_i, \intersem{\Gamma \vdash N_1 : A_1}, \ldots, \intersem{\Gamma \vdash N_p : A_p}  \rangle \fatsemi ^{\{1..p\}} ev^p \\
\intersem{\Gamma \vdash f N_1 \ldots N_p : o} &=& \langle \intersem{\Gamma \vdash N_1 : A_1}, \ldots, \intersem{\Gamma \vdash N_p : A_p} \rangle^\dagger\  \|\ \sem{f} \\
\intersem{\Gamma \vdash N_0 \ldots N_p : o} &=& \langle \intersem{\Gamma \vdash N_0 : A_0}, \ldots, \intersem{\Gamma \vdash N_p : A_p}  \rangle^\dagger\ \|\ ev^p
\end{eqnarray*}
where $\Gamma = x_1 : X_1 \ldots x_l : X_l$, $f : A_0$ is a $\Sigma$-constants, $p\geq 1$, $A_0 =
(A_1,\ldots,A_p,o)$, $ev^p$ denotes the evaluation strategy with
$p$ parameters and $X_i = A_0$ in the second equation.
\end{definition}

Figure \ref{fig:interaction_strategy_denotations} contains tree representations of the interaction games of the revealed strategy $\intersem{\Gamma \vdash M : A}$ for the application cases. These tree tell us all the information that we need about the strategy involved in $\intersem{M}$. For instance the revealed strategy $\Sigma$ is defined on the interaction arena $\intersem{T^{00}}$ whose root is $!A^0 \multimap B^0$; the strategy $ev$ is defined on the interaction arena $\intersem{T^1}$ with a single arena-node $!B^1 \multimap C^1$; thus plays of $ev$ do not contain uncovered moves.


    \begin{figure}[htbp]
        $$
        \tree[levelsep=6ex,thistreesep=3cm]{\TR{\intersem{N_0 N_1 \ldots N_p :o}:T [!A\multimap C]}}
                {   \tree[levelsep=6ex]{\TR{\Sigma^\dagger:T^0[!A^0\multimap !B_0^0\otimes \ldots \otimes !B_p^0 ]}}
                        {
                            \tree[levelsep=6ex,thistreesep=3cm]{\TR{\Sigma:T^{00}[!A^{00}\multimap B_0^{00}\times \ldots \times B_p^{00}]}}
                            {
                                \tree[levelsep=6ex]{\TR{\intersem{N_0}:T^{000}[!A^{000}\multimap B_0]}}{\Tfan[fansize=10ex]}
                                \TR{\ldots}
                                \tree[levelsep=6ex]{\TR{\intersem{N_p}:T^{00p}[!A^{00p}\multimap B_p]}}{\Tfan[fansize=10ex]}
                            }
                        }
                    \TR{ ev:T^1[!B_0^1 \otimes \ldots \otimes !B_p^1 \multimap C] }
                }
       $$
       \begin{center}
       \emph{Tree-representation of the revealed strategy $\intersem{\Gamma \vdash N_0 N_1 \ldots N_p :o}$.}
       \end{center}

        $$
        \tree[levelsep=6ex,thistreesep=3cm]{\TR{\intersem{x_i N_1 \ldots N_p :o}:T [!A\multimap C]}}
                {   \tree[levelsep=6ex]{\TR{\Sigma^\dagger:T^0[!A^0\multimap !B_0^0\otimes \ldots \otimes !B_p^0 ]}}
                        {
                            \tree[levelsep=6ex,thistreesep=3cm]{\TR{\Sigma:T^{00}[!A^{00}\multimap B_0^{00}\times \ldots \times B_p^{00}]}}
                            {
                                \TR{\pi_i:T^{000}[!A^{000}\multimap B_0]}
                                \tree[levelsep=6ex]{\TR{\intersem{N_1}:T^{001}[!A^{001}\multimap B_1]}}{\Tfan[fansize=10ex]}
                                \TR{\ldots}
                                \tree[levelsep=6ex]{\TR{\intersem{N_p}:T^{00p}[!A^{00p}\multimap B_p]}}{\Tfan[fansize=10ex]}
                            }
                        }
                    \TR{ ev:T^1[!B_0^1 \otimes \ldots \otimes !B_p^1 \multimap C] }
                }
        $$
       \begin{center}\emph{Tree-representation of the revealed strategy $\intersem{\overline{x}:\overline{X}\vdash x_i N_1 \ldots N_p :o}$}
       \end{center}
    \bigskip
    {\small
     Node labels are of the form $\Pi : T' [A]$ where $\Pi$ is a strategy, $T'$ is the corresponding interaction game and $A$ is the standard game lying at the root of the interaction game $T$. The games $A$, $B$ and $C$ are defined as follows:
    \begin{eqnarray*}
        A &=& \Gamma = X_1 \times \ldots \times X_n\\
        B &=& \underbrace{((B_1' \times \ldots \times B_p') \rightarrow o')}_{B_0} \times B_1 \times \ldots \times B_p\\
        C &=& o \ .
    \end{eqnarray*}
    Games are annotated with string  $s \in \{ 0..p \}^*$ in the exponent to indicate the path from the root to the corresponding node in the tree (each number in $s$ indicates which direction to take at the corresponding branch point).
   }
        \smallskip
       \caption{Tree-representation of the revealed strategy in the application case.}
      \label{fig:interaction_strategy_denotations}
    \end{figure}


\begin{remark}
When computing an interaction strategy of the form
$\intersem{y_i N_1 \ldots N_p}$ for some variable $y_i$, the
internal moves of $N_1$, \ldots, $N_p$ are preserved however the
internal moves produced by the copy-cat projection strategy denoting
$y_i$ are omitted.
\end{remark}

\begin{example}
Take the term $\lambda x . (\lambda f . f x) (\lambda y . y)$.
%Its computation tree is:
%$$
%\tree{\lambda x} {
%    \pstree[levelsep=4ex]{\TR{@}}
%    {       \pstree[levelsep=4ex]{\TR{\lambda f}}
%                { \tree{f}{  \tree{\lambda}{ \TR{x}  } } }
%            \pstree[levelsep=4ex]{\TR{\lambda y}}
%                    {\TR{y}}
%    } }
%$$
Its revealed strategy is $$\Lambda ( \langle \sem{ x:X \vdash \lambda f . f
x : (o\rightarrow o) \rightarrow o} , \sem{ x:X \vdash \lambda y . y
: o \rightarrow o} \rangle \| ev_2 ) \ .$$
\end{example}


\subsubsection{From interaction semantics to standard semantics and vice-versa}

In the standard semantics, given two strategies $\sigma : A
\rightarrow B$, $\tau : B \rightarrow C$ and a sequence $s \in
\sigma \fatsemi \tau$, it is possible to (uniquely) recover the
internal moves. The uncovered sequence is written ${\bf u}(s,
\sigma, \tau)$. The algorithm to obtain this unique uncovering is
given in part II of \cite{hylandong_pcf}. Therefore given a term
$M$, we can completely uncover the internal moves of a sequence
$s\in\sem{M}$ by performing the uncovering operation recursively at
every @-node of the computation tree.

Conversely, the standard semantics can be recovered from the
interaction semantics by filtering the moves, keeping only those
played in the root arena:
\begin{eqnarray}
 \sem{\Gamma \vdash M : T} = \intersem{\Gamma \vdash M : T} \upharpoonright \sem{\Gamma \rightarrow T} \label{eqn:int_std_gamsem}
\end{eqnarray}

\subsection{The correspondence theorem for the simply-typed $\lambda$-calculus without interpreted constants}
In this section, we establish a connection between the interaction
semantics of a simply-typed term without constants ($\Sigma =
\emptyset$) and the traversals of its computation tree: we show that
the set $\travset(M)$ of traversals of the computation tree is
isomorphic to the set of uncovered plays of the strategy denotation
(this is the counterpart of the ``Path-Traversal Correspondence'' of
\cite{OngLics2006}), and that the set of traversal reductions is
isomorphic to the strategy denotation.

\subsubsection{@-free traversals}

When defining computation trees, it was necessary to introduce
application nodes (labelled @) in order to connect the operator and
the operand of an application. The presence of @-nodes has also
another advantage: it ensures that the lambda-nodes are all at even
level in the computation tree, and thus a traversal respects a certain form of
alternation.

Application nodes are however redundant in the sense that they do
not play any role in the computation of the term. In fact it is
necessary to filter them out if we want to establish the
correspondence with the interaction game semantics.

\begin{definition}[@-free traversal]
\label{dfn:appnode_filter}
Let $t$ be a traversal of $\tau(M)$.
We write $t-@$ for the sequence of nodes-with-pointers obtained by
\begin{itemize}
\item removing from $t$ all @-nodes and value-leaves of some @-node;
\item replacing any link pointing to an @-node by a link pointing to the immediate predecessor of @ in $t$.
\end{itemize}

Suppose $u = t-@$ is a sequence of nodes obtained by applying the
previously defined transformation on the traversal $t$, then $t$ can
be partially recovered from $u$ by reinserting the @-nodes as
follows. For each @-node @ in the computation tree with parent node
denoted by $p$, we perform the following operations:
\begin{enumerate}
\item replace every occurrence of the pattern $p \cdot n$, where $n$ is a $\lambda$-nodes,
by $p \cdot @ \cdot n$;
\item replace any link in $u$ starting from a $\lambda$-node and pointing to $p$ by a link pointing to the inserted @-node;
\item if there is an occurrence in $u$ of a value-leaf $v_p$ pointing to $p$ then insert a value-leaf $v_@$
immediately before $v_p$ and make it point to the node immediately
following $p$ (which is also the $@$-node that we inserted in 1).
\end{enumerate}
We write $u+@$ for this second transformation.
\end{definition}
These transformations are well-defined because in a traversal, an @-node
always occurs in-between two nodes $n_1$ and $n_2$ such that  $n_1$ is the parent node of @
and $n_2$ is the first child node of @ in the computation tree:
$$      \pstree[levelsep=4ex]{\TR{n_1}\treelabel{0} }
        {
            \pstree[levelsep=3ex]{\TR{@}}
            {
                \tree{n_2}{\vdots}
                \TR[edge=\dedge]{}
                \TR[edge=\dedge]{}
            }
        }
$$
\begin{remark}
Justified sequences of nodes of the form $t-@$ for some traversal $t$ are not, strictly speaking, proper justified sequences of nodes since they do not respect alternation (two $\lambda$-nodes may become adjacent after removing a @-node)
and since any $\lambda$-node justified by @ becomes justified by @'s parent which is also a $\lambda$-node. However we will treat them just as justified sequence.
\end{remark}

\begin{lemma} \label{lem:minus_at_plus_at}
$$\forall t \in \travset(M), \quad (t-@)+@ = \left\{
            \begin{array}{ll}
              t, & \hbox{if $t^\omega \neq @$\ ;} \\
              \ip\ t, & \hbox{if $t^\omega = @$\ .}
            \end{array}
          \right.
$$
\end{lemma}
\proof
The result follows immediately from the definition of the operation -@ and +@.
\qed
\smallskip

We introduce the following notation:
$$
\travset(M)^{-@} = \{ t - @ \ | \  t \in \travset(M) \}
$$

\begin{remark}
If $M$ is $\beta$-normal then $\tau(M)$ does not contain any
@-node therefore all nodes are hereditarily justified by $r$ and we
have $\travset(M)^{-@} = \travset(M) = \travset(M)^{\upharpoonright
r }$.
\end{remark}

\paragraph{Mapping @-free traversals to interaction plays}
\hfill

\notetoself{
\begin{definition}[Mapping from nodes to moves]\hfill
    \label{def:theta mapping}
    Let $T$ be the interaction game of the interaction strategy $\intersem{M}$ and
    $M_T$ be the set of equivalence class of moves from $\mathcal{M}$.


    For $n \in N_{\sf prime}$, let $\Gamma(n) \vdash \kappa(n) : T(n)$ denote the subterm of $\elnf{M}$ rooted at $n$.
    We define the disjoint union of games:
    $$\mathcal{G}_M = \sem{\Gamma\rightarrow T} \quad \uplus \quad  \biguplus_{n \in N_{\sf prime} } \sem{T(n)}.$$
    $$\mathcal{G}_M = \sem{\Gamma\rightarrow T} \quad \uplus \quad  \biguplus_{n \in N_{\sf spawn} } \sem{T(n)}.$$

    We define the function $\varphi_M: V_\lambda \union V_{\sf var} \rightarrow M_T$
    as:
    \begin{equation*}
        \varphi_M = \psi_{M} \quad \union \Union_{n \in N_{\sf prime}} \psi_{n}
    \end{equation*}
    where $q_0$ denotes $\sem{\Gamma\rightarrow T}$'s initial move.

    We omit the subscript in $\varphi_M$ if it does not cause any ambiguity.
\end{definition}


$\varphi_M$ is indeed totally defined on $V_\lambda \union V_{\sf var} = V\setminus (V_@ \union V_\Sigma)$ (since a node is either hereditarily justified by the root, by a @-node or by a $\Sigma$-node).

\begin{remark}
\label{rem:phi_preserves_her_enabling}
$\varphi_M$ \defname{preserves hereditary enabling}: a node $n$ is hereditarily
 enabled by some node $n' \in N \inter E \relimg{N_@ \union N_\Sigma}$ in $\tau(M)$ if and only if
 $\varphi(n)$ and $\varphi(n')$  are both played in the same game $A \in \mathcal{G}$ and
the move $\varphi_M(n)$ is hereditarily enabled by $\varphi_M(n')$ in $A$.
\end{remark}

%If $t$ is a justified sequence of nodes in $V_\lambda \union V_{\sf var}$ then $?(\varphi(t)) =
%\varphi(?(t))$.
%where $?(\varphi(t))$ denotes the subsequence of $\varphi(t)$ consisting of the unanswered questions
%and $?(t)$ denotes the subsequence of $t$ consisting of the unmatched nodes (see the
%definition in section \ref{sec:adding_value_leaves}).

}

As we observed in a previous remark, sequences from $\travset(M)^{-@}$ are not, strictly speaking, proper justified sequences. Consequently the filtering operators introduced up to now are undefined on $\travset(M)^{-@}$. We now introduce a new filtering operation on $\travset(M)^{-@}$:
\begin{definition}
Let $\Delta \vdash \kappa(n) : A$ be some subterm of $\elnf{M}$ for some $n\in N_\lambda$.
We define the \defname{subterm filtering} operator on sequences of the form $t-@$ for some traversal $t$ of $M$ as follows:
$$ (t - @) \subtermfilter \kappa(n) = (t-@)\hefilter n = t\hefilter n \ . $$
\end{definition}
Note that this is well-defined because $t-@ = t'-@$ implies $t\hefilter n = t'\hefilter n$ (since @-nodes have no justifier).
In particular we have:
$$ (t - @) \subtermfilter M = t \hefilter r  = t \hjfilter r \ .$$
(Here hereditary justification and hereditarily enabling coincide because the root node can appear at most once in a traversal.)

\begin{lemma}[Filtering lemma]
\label{lem:varphi_filter}
Let $t$ be a traversal of $M$, $\Delta \vdash N : A$ be some subterm of $\elnf{M}$ and $m$ be an occurrence of an initial $A$-move in $\varphi(t-@)$ then:
$$(i) \quad \varphi_M((t-@)\subtermfilter N) = \varphi_M(t-@) \filter \sem{\Delta\rightarrow A} \ .$$
$$(ii) \quad \varphi_M((t-@)\subtermfilter N) \hjfilter m = \varphi_M(t\hjfilter n) \ .$$
where $n$ denotes the occurrence of $\tau(N)$'s root in $t$ whose image
by $\varphi_M$ is the occurrence $m$.

Consequently:
$$(iii) \quad  \varphi_M(\travset^{-@}(M)) \filter \sem{\Gamma \rightarrow T} = \psi_M(\travset^{\filter r}(M))\ .$$
\end{lemma}
\proof Let $t$ be a traversal of $M$:
$$\begin{array}{lrclr}
\mbox{i.}& \varphi( (t-@) \subtermfilter N ) &=& \varphi_M((t-@) \hefilter n ) & \mbox{(Def. subterm filtering)}\\
          &&=& \varphi_M(t-@) \filter \sem{\Delta \rightarrow A}  & \parbox[t]{5.5cm}{(By remark \ref{rem:phi_preserves_her_enabling}, $\varphi_M$ preserves hereditary enabling,  and  moves in $\sem{\Delta \rightarrow T}$ are all hereditarily enabled by the initial move $m = \varphi_M(n)$).} \\
\\
\mbox{ii.}& \varphi_M((t-@)\subtermfilter N) \hjfilter m
  &=& \varphi_M(t\hefilter n) \hjfilter m & \mbox{(Def. subterm filtering)}\\
  &&=& ( \varphi_M(t) \hefilter \varphi_M(n) ) \hjfilter m & \parbox[t]{5.5cm}{($\varphi_M$ maps the set of nodes hered. \emph{enabled} by $n$ to the set of moves hered. \emph{enabled} by $\varphi_M(n)$)} \\
  &&=& \varphi_M(t) \hefilter  m \hjfilter m & \mbox{($m = \varphi_M(n)$)} \\
  &&=& \varphi_M(t) \hjfilter m \ . \\
  \\
\mbox{iii.} & \varphi(t-@) \filter \sem{\Gamma \rightarrow T}
             &=& \varphi( (t-@) \subtermfilter M ) & \mbox{(by i.)} \\
           &&=& \varphi( (t-@) \hefilter r ) & \mbox{(Def. subterm filtering)} \\
           &&=& \varphi( t \hefilter r ) & \mbox{(@-node are not justified).} \qed
\end{array}$$

The function $\varphi$ regarded as a function from the set of vertices $V_\lambda \union V_{\sf var}$ of the computation tree to moves in arenas is not injective.
For instance the two occurrences of $x$ in the computation tree of the term $\lambda f x. f x x$ are mapped to the same question. However
the function $\varphi$ defined on the set of traversals to interaction plays of game semantics is injective:
\begin{lemma}[$\psi$ and $\varphi$ are injective]
\label{lem:varphiinjective}
For any two traversals $t_1$ and $t_2$:
\begin{itemize}
\item[(i)] If $\varphi (t_1 - @ ) = \varphi (t_2 - @ )$ then $t_1-@ =t_2 -@$\ ;
\item[(ii)] if $\psi (t_1 \upharpoonright r ) = \psi (t_2 \upharpoonright r )$ then $t_1\upharpoonright r = t_2\upharpoonright r$\ .
\end{itemize}
\end{lemma}
\begin{proof}
For any node $n$ of a traversal $t$ let us write $ptr(n)$ to denote the distance between $n$ and its justifier node in $t$. If $n$ has not link then we set $ptr(n)=0$. We also use the same notation for sequences of moves.

\begin{lemma}[Preleminary lemma]
\label{lem:varphiinjective:prelem}
\begin{equation}
\left(
  \begin{array}{ll}
    t \cdot n_1, t \cdot n_2 \in \travset \\
    \zand\ n_1 \neq n_2
  \end{array}
\right)
 \mbox{ implies } n_1,n_2 \in N^{\upharpoonright r}_{\lambda} \zand ( \varphi(n_1) \neq \varphi(n_2) \zor ptr(n_1) \neq ptr(n_2) ) \ . \end{equation}
\end{lemma}
\begin{proof}
Let $t \cdot n_1, t \cdot n_2 \in \travset$.
First we remark that the traversal rules have a weak form of determinism which ensures that $n_1$ and $n_2$ belong to the same category of node i.e.\ they must be both in $N_{\sf var}$, $N_@$ or $N_\lambda$.

Suppose that $n_1, n_2 \in N_@$ then $t \cdot n_1$ and $t \cdot n_2$ were formed using the (App) rule. Since this rule is deterministic we must have $n_1=n_2$ which violates the second hypothesis.


Suppose that $n_1,n_2\in N_{\sf var}$. The traversals $t \cdot n_1$ and $t \cdot n_2$ must have been formed using either rule (Lam) or (App). But these two rules are deterministic and their domains of definition are disjoint. Hence again the second hypothesis is violated.

Suppose that $n_1,n_2\in N_\lambda$ then
the traversals $t \cdot n_1$ and $t \cdot n_2$ must have been formed using either rule (Root), (App), (Var) or (InputVar). Since all these rules have disjoint domains of definition, the same rule must have been use to form $t \cdot n_1$ and $t \cdot n_2$. Supposed that one of the rules (Root), (App) and (Var) has been used then since they are all deterministic we have $n_1=n_2$ which violates the second hypothesis. Consequently, the rule (InputVar) must have been used and therefore $n_1,n_2 \in N_\lambda^{\upharpoonright r}$. By definition of (InputVar), in order to have $n_1\neq n_2$ and $\varphi(n_1) = \varphi(n_2)$, the parent node of the last node in $t$ must occurs at more than one position in $\oview{t}$ and $n_1,n_2$ correspond to the child node of two different occurrences of that parent node in $\oview{t}$. But then the links associated to $n_1$ and $n_2$ will point to their respective occurrence of that parent node in $\oview{t}$ hence $ptr(n_1) \neq ptr(n_2)$.
\end{proof}

\noindent {\it (continuation of the proof of Lemma \ref{lem:varphiinjective})}

(i) The result is trivial is either $t_1$ or $t_2$ is empty.
Suppose that $t_1-@\neq t_2-@$ then necessarily $t_1 \neq t_2$, thus there are some sequences $t'$, $u_1$, $u_2$ and some nodes $n_1,n_2$ such that
 $t_1 = t' \cdot n_1 \cdot u_1$, $t_2 = t' \cdot n_2 \cdot u_2$ with either $n_1\neq n_2$ or $ptr(n_1) \neq ptr(n_2)$.

If $n_1 = n_2$ then $ptr(n_1) \neq ptr(n_2)$ therefore $n_1,n_2 \not\in N_@$ (otherwise $ptr(n_1) = 0 = ptr(n_2)$). Since $ptr(\varphi(n_1)) = ptr(n_1)$ and  $ptr(\varphi(n_2)) = ptr(n_2)$ we must have $\varphi(t' \cdot n_1) \neq \varphi(t' \cdot n_2)$. Since $n_1,n_2 \not\in N_@$ we also have $\varphi((t' \cdot n_1)-@) \neq \varphi((t' \cdot n_2)-@)$. Hence $\varphi(t_1-@) \neq \varphi(t_2-@)$.

If $n_1 \neq n_2$ then by Lemma \ref{lem:varphiinjective:prelem} we have $n_1,n_2 \not\in N_@$ and $\varphi(n_1) \neq \varphi(n_2)$ or $ptr(n_1) \neq ptr(n_2)$ which again implies $\varphi(t_1-@) \neq \varphi(t_2-@)$.


(ii) Suppose that $t \upharpoonright r \neq t' \upharpoonright r$ then necessarily $t \neq t'$ which in turn implies that for some sequences $t_1'$, $t_2'$, $u_1$, $u_2$ and some nodes $n_1 \neq n_2$
we have $t_1 = t' \cdot n_1 \cdot u_1$, $t_2 = t' \cdot n_2 \cdot u_2$ and either $n_1\neq n_2$ or $ptr(n_1) \neq ptr(n_2)$.

If $n_1 = n_2$ then $ptr(n_1) \neq ptr(n_2)$. An   analysis of the traversal rules shows that the rule (InputVar) is the only rule which can visit the same node with two different pointers. Hence $n_1,n_2 \in N_\lambda^{\upharpoonright r}$.
Therefore $\psi( (t'\cdot n_1) \upharpoonright r ) = \psi( (t'\upharpoonright r) \cdot n_1 )  \neq \psi( (t'\upharpoonright r) \cdot n_2 )$. Hence    $\psi( t_1\upharpoonright r ) \neq \psi( t_2\upharpoonright r )$.

If $n_1 \neq n_2$ then we can use Lemma \ref{lem:varphiinjective:prelem}
to obtain $\psi( t_1\upharpoonright r ) \neq \psi( t_2\upharpoonright r )$.
\end{proof}

\begin{corollary} \
\label{cor:varphi_bij}
\begin{itemize}
\item[(i)] $\varphi$ defines a bijection from $\travset(M)^{-@}$
to $\varphi(\travset(M)^{-@})$\ ;
\item[(ii)] $\psi$ defines a bijection from $\travset(M)^{\upharpoonright r}$ to
$\psi(\travset(M)^{\upharpoonright r})$\ .
\end{itemize}
\end{corollary}

\subsubsection{The correspondence theorem}
We now state and prove the correspondence theorem for the
simply-typed $\lambda$-calculus without interpreted constants
($\Sigma = \emptyset$). The result extends immediately to the
simply-typed $\lambda$-calculus with \emph{uninterpreted} constants
since we can regard constants as being free variables.

\begin{lemma}[Local Traversal Extension]
\label{lem:local_traversal_progression}
Let $M'$ be a subterm of $M$, $t \in \travset(M)$,
$t' \in \travset(M')$ such that $t' \neq \epsilon$ and $t\subseqof t'$. If the
traversal $t' \cdot n$ of $\tau(M')$ can be formed using a rule different from \rulenamet{InputVar}
and $\rulename{InputVar^{val}}$ then either $t' \cdot n \subseqof t $ or
$ t' \cdot n \in \travset(M)$.
where $n$'s link in $t \cdot n$ points to the same node occurrence as in $t' \cdot n$.
\end{lemma}
\proof
By Case analysis on the traversal rule used to form $t'\cdot n$.
\qed

This lemma says that extending a traversal locally also extends the traversal globally: the traversal $t$ of $M$ can be extended by extending a ``sub-traversal'' $t'$ of some sub-term $M'$.
This is not obvious since $t'$ is a subsequence of $t$ which means that
the nodes in $t'$ are also present in $t$ with the same pointers but with some other nodes interleaved in between. However these interleaved nodes are inserted in a preservative way which allows us to apply the rule used to extend $t'$ on $t$.

The following theorem establishes a correspondence between the
game-denotation of a term and the set of traversals of its
computation tree:
\begin{theorem}[The Correspondence Theorem]
\label{thm:correspondence}
 For any simply-typed term $\Gamma \vdash M :T$,
the function $\varphi_M$ defines a bijection from $\travset(M)^{\upharpoonright
r}$ to $\sem{\Gamma \vdash M : T}$ and a bijection from
$\travset(M)^{-@}$ to $\intersem{\Gamma \vdash M : T}$:
\begin{eqnarray*}
 \varphi_M  &:& \travset(\Gamma \vdash M : T)^{-@} \stackrel{\cong}{\longrightarrow} \intersem{\Gamma \vdash M :T} \\
 \psi_M  &:& \travset(\Gamma \vdash M : T)^{\upharpoonright r} \stackrel{\cong}{\longrightarrow} \sem{\Gamma \vdash M :T} \ .
\end{eqnarray*}

\end{theorem}

%\begin{proposition}
%\label{prop:rel_gamesem_trav} Let $\Gamma \vdash M : T$ be a
%simply-typed $\lambda$-term and $r$ be the root of $\tau(M)$. Then:
%\begin{itemize}
%\item[(i)]  $\varphi_M(\travset(M)^{-@}) = \intersem{\Gamma \vdash M : T}$ \ ;
%\item[(ii)] $\varphi_M(\travset(M)^{\upharpoonright r}) = \sem{\Gamma \vdash M : T}$ \ .
%\end{itemize}
%\end{proposition}

\begin{remark}
\label{rem:corresp_proofreduction}
    By corollary \ref{cor:varphi_bij}, we just need to show that
    $\varphi_M$ defines \emph{surjections}, that is to
    say:
    \begin{eqnarray*}
    \varphi_M(\travset(M)^{-@}) &=& \intersem{\Gamma \vdash M : T} \\
    \psi_M(\travset(M)^{\upharpoonright r}) &=& \sem{\Gamma \vdash M :
    T}
    \end{eqnarray*}
    The first equation implies the second one, indeed:
    \begin{align*}
    \sem{\Gamma \vdash M : T} &= \intersem{\Gamma \vdash M : T} \upharpoonright \sem{\Gamma \rightarrow T} & \mbox{(eq. \ref{eqn:int_std_gamsem})} \\
            &= \varphi_M(\travset^{-@}(M)) \upharpoonright \sem{\Gamma \rightarrow T} & \mbox{(by (i))}\\
            &= \psi_M(\travset^{\upharpoonright r}(M)) & \mbox{(lemma \ref{lem:varphi_filter})}
    \end{align*}
    therefore we just need to prove the first equation.
\end{remark}

    Let us give a brief overview of the proof before giving it in full details.
    It proceeds by induction on the structure of the computation tree.
    The only non-trivial case is the application: the computation tree
    $\tau(M)$ has the following form:
        $$ \tree[levelsep=4ex]{\lambda \overline{\xi}}
            { \tree[levelsep=4ex]{@}
                {   \TR{\tau(N_0)} \TR{\ldots} \TR{\tau(N_p)}}}
        $$

    A traversal of $\tau(M)$ proceeds as follows: it starts at the root $\lambda \overline{\xi}$ of the tree $\tau(M)$ (rule
    (Root)), it then passes the node @ (rule (Lam)).
    After this initialization part, it proceeds by traversing the term $N_0$ (rule (App)).
    At some point, while traversing $N_0$, some variable $y_i$ bound by the root of $N_0$ is visited. The traversal
    of $N_0$ is interrupted and jumps (rule (Var)) to the root of $\tau(N_i)$. The process then goes on with $\tau(N_i)$.
    When traversing $N_i$, if the traversal encounters a variable bound by the root of $\tau(N_i)$ then the traversal of $N_i$
    is interrupted and
    the traversal of $N_0$ resumes.  This schema is repeated until the traversal of $\tau(N_0)$ is completed\footnote{Since we are considering
    simply-typed terms, the traversal does indeed terminate. However this will not be true anymore in the \pcf\ case.}.

    The traversal of $M$ is therefore made of an initialization part followed by an interleaving of a traversal of $N_0$ and
    several traversals of $N_i$ for $i=1..p$. This schema is reminiscent of the way the evaluation copycat map $ev$ works in game semantics.

    The key idea is that every time the traversal pauses the traversal of a subterm and switches to another one,
    the jump is permitted by one of the four ``copycat'' rules (Var), (Answer-@-$\lambda$), (Answer-$\lambda$-var) or (Answer-var).
    We show by (a second) induction that these copycat rules define precisely what the copycat strategy $ev$ performs on sets of plays.

%    In the game semantics, the evaluation map (a copy-cat strategy) copies this opening move to an initial move $m_0$ in the game
%    $B_0$ and the game continues in $B_0$. We reflect this in the traversal : we make $t$ follow
%    the ``script'' given by the traversal $t^0_{m_0}$.
%    The rule (App) allow us to initiate this simulation  by visiting the  first move in $t^0_{m_0}$: the root of $\tau(N_0)$.
%
%    This simulation continues until it reaches a node $\alpha_0$ which is hereditarily justified by the root
%    $\tau(N_0)$: $\alpha_0$ is present in the reduction of traversal of $t^0_{m_0}$ therefore $\varphi_{N_0}(\alpha_0)$ is an un-hidden move played in $A_0$.
%
%    In the game semantics this corresponds to a move played in a component $A_k$ for some $k\in 1..p$ of
%    of the game $B_0$ in which case the evaluation map copies the move to an initial move $m_1$ in the corresponding component $B_k$.
%
%    To reflect this the traversal now opens up a new thread and simulates the traversal $t^k_{m_1}$.  Again, this simulation stops when we reach a node
%    $\alpha_1$ in $t^k_{m_1}$ which is hereditarily justified by the root of $\tau(N_k)$: $\alpha_1$ must be present in the reduction of traversal
%    of $t^k_{m_1}$ therefore $\varphi_{N_k}(\alpha_1)$ is an un-hidden move played in $A_k$.
%    In the game semantics, this move $\alpha$ is copied back to the component $B_k$ of the game $B_0$.
%
%    The traversal now resumes the simulation of $t^0_{m_0}$. And the process goes continuously.
\smallskip

\begin{proof}
Let $\Gamma \vdash M : T$ be a simply-typed term where $\Gamma =
x_1:X_1,\ldots x_n:X_n$. We assume that $M$ is already in
$\eta$-long normal form. By remark \ref{rem:corresp_proofreduction} we just need to
show that $\varphi_M(\travset(M)^{-@}) = \intersem{\Gamma \vdash M : T}$.
We proceed by induction on the structure of $M$:
\begin{enumerate}[$\bullet$]
    \item (abstraction) $M \equiv \lambda \overline{\xi}. N : \overline{Y} \rightarrow B$ where $\overline{\xi} = \xi_1:Y_1,\ldots \xi_n:Y_n$. On the first hand we have:
\begin{eqnarray*}
\intersem{\Gamma \vdash \lambda \overline{\xi}. N:T} &=& \Lambda^n( \intersem{\overline{\xi}, \Gamma \vdash N: B } ) \\
        &\simeq& \intersem{\overline{\xi}, \Gamma \vdash N: B } \ .
\end{eqnarray*}
On the other hand, the computation tree $\tau(N)$ is isomorphic to
$\tau(\lambda \xi_1\ldots \xi_n . N)$ (up to a renaming of the root
of the computation tree) and $\travset(N)$ is isomorphic to
$\travset(\lambda \xi_1\ldots \xi_n . N)$.
Hence we can conclude using the induction hypothesis.

  \item (variable) $M \equiv x_i$. Since $M$ is in $\eta$-long normal form, $x$ must be of ground
      type. The computation tree $\tau(M)$ and the arena $\intersem{\Gamma \rightarrow o}$ are represented below
      (value leaves and answer moves are not represented):
        $$ \tree[levelsep=6ex]{ \lambda }{\TR{x_i}} \hspace{2cm}
        \tree{ q_0 }
        {   \tree[linestyle=dotted]{q^1}{\TR{} \TR{} }
            \tree[linestyle=dotted]{q^2}{\TR{} \TR{} }
            \TR{\ldots}
            \tree[linestyle=dotted]{q^n}{\TR{} \TR{} }
        }
        $$

        Let $\pi_i$ denote the $i$th projection of the interaction game
        semantics. We have:
        \begin{align*}
        \intersem{M} &= \pi_i = \prefset(\{ \Pstr{(q0){q_0} \cdot (qi){q^i} \cdot (vqi-qi){v_{q^i}} \cdot (vq0-q0){v_{q_0}} } \ | \ v\in \mathcal{D} \})\ .
        \end{align*}

        It is easy to see that traversals of $M$ are precisely
        the prefixes of $ \Pstr{ (lmd)\lambda \cdot (xi){x_i}
        \cdot (vxi-xi){v_{x_i}} \cdot (vlmd-lmd){v_{\lambda}}}$.
        $M$ is in $\beta$-normal therefore $\travset(M)^{-@} =
        \travset(M)$ and since $\varphi_M(\lambda) =
        q_0$ and $\varphi_M(x_i) = q^i$, we have:
        $$ \varphi_M(\travset^{-@}(M)) = \varphi_M(\travset(M)) = \varphi_M(\prefset( \lambda \cdot x_i \cdot v_{x_i} \cdot v_{\lambda}))
         = \intersem{M} \ .
        $$


    \item (application) $M = N_0 N_1 \ldots N_p :o$ where $N_0$ is not a variable.
    We have the typing judgments $\Gamma \vdash N_0 N_1 \ldots
    N_p : o$ and $\Gamma \vdash N_i : B_i$ for $i\in 0..p$ where
    $B_0 = (B_1,\ldots,B_p,o)$ and $p\geq 1$.

    The tree $\tau(M)$ has the following form:
    $$ \tree[levelsep=6ex]{\lambda^{[r]}}
        { \tree[levelsep=6ex]{@}
            {
            \tree[levelsep=3mm,edge=\noedge]{\TR{{\lambda y_1 \ldots y_p}^{[r_0]}}}{\Tr[ref=t]{\pstribox{\tau(N_0)}}}
            \tree[levelsep=3mm,edge=\noedge]{\TR{[r_1]}}{\Tr[ref=t]{\pstribox{\tau(N_1)}}}
             \TR{\ldots}
            \tree[levelsep=3mm,edge=\noedge]{\TR{[r_p]}}{\Tr[ref=t]{\pstribox{\tau(N_p)}}}
        }}
    $$
    where $r_j$ denote the root of $\tau(N_j)$ for $j\in \{0..p\}$.

    We have:
    $$
    \intersem{\Gamma \vdash M : o}
            =  \underbrace{\langle \intersem{\Gamma \vdash N_0 : B_0}, \ldots \intersem{\Gamma \vdash N_p : B_p} \rangle}_{\Sigma} \,^\dagger\ \| \ ev
    $$

    We define the games $A$, $B$ and $C$ are defined as follows:
    \begin{eqnarray*}
        A &=& \Gamma = X_1 \times \ldots \times X_n\\
        B &=& \underbrace{((B_1' \times \ldots \times B_p') \rightarrow o')}_{B_0} \times B_1 \times \ldots \times B_p\\
        C &=& o \ .
    \end{eqnarray*}

    Figure \ref{fig:interaction_strategy_denotations} shows
    a tree-representation of $\intersem{M}$ which fixes the names of the different games involved in the interaction strategy.

%    Since $\varphi_M = \psi_M \union \varphi_{N_0} \union
%    \varphi_{N_1}$ the induction hypothesis gives us:
%    \begin{align}
%    \varphi_{M} (\travset^{-@}(N_0)) &= \intersem{\Gamma \vdash N_0 : B_0} \label{eqn:ih_1} \\
%    \varphi_{M}(\travset^{-@}(N_1)) &= \intersem{\Gamma \vdash N_1 : B_1} \label{eqn:ih_2}
%    \end{align}
\begin{enumerate}
\item[$\subseteq$]
    We first prove that $\intersem{\Gamma \vdash M : T}
    \subseteq \varphi_{M}( \travset^{-@}(M) )$. Suppose $u \in
    \intersem{\Gamma \vdash M : T}$. We give a constructive
    proof that there is a traversal $t$ of $M$ such
    that $\varphi_M(t-@) = u$ by induction on the length of $u$.
    Let $q_o$ and $q_0'$ be the initial question of $C$
    and $B_0$ respectively.

    \emph{Base cases}:
    \begin{compactitem}[-]
    \item If $u=\epsilon$ then we take the empty traversal $t=\epsilon$ formed
with \rulenamet{Empty}. Clearly $\varphi(t) = u$.
    \item If $|u|=1$ then $u=q_0$ is the initial move in $C$. The traversal $t=\lambda$ formed with the rule \rulenamet{Root} verifies $\varphi(t) = u$.
    \item If $|u|=2$ then necessarily $u = q_0 \cdot q_0'$. The rules \rulenamet{Root}, \rulenamet{App}
and \rulenamet{Lam} permit us to build the traversal $t = \lambda^{[r]} \cdot @ \cdot \lambda \overline{y}^{[r_0]}$ which clearly verifies $\varphi_M(t-@) = u$.
    \end{compactitem}

    \emph{Step cases}: Suppose that $u = w \cdot m \in \intersem{\Gamma \vdash M : T}$
    for some move $m \in M_T$ where
    $w = \varphi_M(t-@)$ for some traversal $t$ of $\tau(M)$
    and $|w|>1$.

    By unraveling the definition of $u \in \intersem{\Gamma \vdash M : T}$ we have:
    \begin{eqnarray*}
      &&      \left\{
            \begin{array}{ll}
                u \in L_T\\
                u \upharpoonright T^0  \in \Sigma^\dagger \\
                u \upharpoonright T^1  \in  ev
            \end{array}
            \right. \\
    & \mbox{or equivalently} & \left\{
    \begin{array}{ll}
        u \in L_T \\
        \hbox{for any initial $m$ in $!B_0^0 \otimes \ldots \otimes !B_p^0$ there is $j \in \{0..p\}$ such that } \\
        \left\{\begin{array}{ll}
            u \filter m \filter T^{00j} \in \intersem{N_j} \label{eq:def_z} \\
            u \filter m \filter T^{00k} = \epsilon \quad \mbox{ for every } k\in \{1..p\}\setminus\{j\} \label{eq:b}
        \end{array}
        \right. \\
        u \upharpoonright T^1  \in  ev
    \end{array}
    \right.
    \end{eqnarray*}

We recall that $m \in M_T$ is an equivalence class of moves from $\mathcal{M}_T$. For any game $A$ appearing in the interaction game $T$ we will write ``$m \in A$'' to mean that some citizen of the class $m$ belongs to the set of moves $M_A$. Similarly, for any sub-interaction game $T'$ of $T$, we write ``$m \in T'$'' to mean that some citizen of the class $m$ belongs to the set of moves $\mathcal{M}_A$.

We do a case analysis on $m$: we either have $m\in C$ or $m\in T^0$:
    \begin{enumerate}[-]
    \item Suppose $m \in C$. $m$ is played by the strategy $ev$ whose plays do not contain any internal move. Hence $m$ is either $q_0$ or $v_{q_0}$ for some
    $v\in\mathcal{D}$. But since $q_0$ can occur only once in
    $u$ and $|u|>1$, $m$ must be $v_{q_0}$ for some
    $v\in \mathcal{D}$.  Moreover $m$ is a P-move played by the
    copy-cat strategy $ev$ in $B,C$ therefore it is the copy
    of the some move $v_{q_0'}$ answering the question $q_0'$ in the sub-game $o'$.

    In fact this move $v_{q_0'}$ is precisely $w$'s last move. Indeed
    suppose that $w = \ldots v_{q_0'} \cdot w'$. The play
    $w_{\prefixof v_{q_0'}}\filter A,B$ is complete since its
    first move $q_0'$ is answered by $v_{q_0'}$. Therefore by
    Lemma \ref{lem:inter_complete}(ii), $w_{\prefixof
    v_{q_0'}}\filter T^0$ is maximal. Thus moves in $w'$ must
    be played in $T^1$ by $ev$, but since $ev$ does not play internal
    moves, $w'$ is necessarily empty.

    Consequently, by the induction hypothesis, the last move in $t$ is $\varphi(v_{q_0'}) = v_{\lambda y_1}$.
    The rules \rulenamet{Answer-@-$\lambda$} and \rulenamet{Answer-$\lambda$-@} permits us to extend
    the traversal $t$ into $t \cdot v_@ \cdot v_{\lambda \overline{\xi}}$ where $v_@$ and $v_{\lambda
    \overline{\xi}}$ point to the second and first node of $t$ respectively. Clearly we have $\varphi_M((t\cdot v_@ \cdot v_{\lambda \overline{\xi}})-@) = u$.

    \item Suppose $m\in T^0$. Then $m$ is hereditarily justified by some initial move $b$ in $B_j$ for some $j\in \{0..p\}$.

        Since $u \filter b \filter T^{00j} \in \intersem{N_j}$, the outermost induction hypothesis gives us:
        \begin{equation}
        u \filter b \filter T^{00j} = \varphi_{N_j}(t_j-@)  \label{eqn:corresp_outmost_ih}
        \end{equation}
          for some traversal $t_j \in \travset(N_j)$. W.l.o.g we can assume that $t_j^\omega \neq @$.
        By Corollary \ref{cor:varphi_bij}, $\varphi_{N_j}$ is a bijection from $\travset(N_j)^{-@}$ to
        $\varphi_{N_j}( \travset(N_j)^{-@})$ therefore $t_j-@ = \varphi^{-1}_{N_j}( (u \filter b) \filter T^{00j} )$
        and we have:
        \begin{align}
         t_j - @ &= \varphi^{-1}_{N_j}(u \filter b \filter T^{00j}) &  \nonumber \\
                        &\in \varphi^{-1}_{M}(u \filter b \filter T^{00j}) & \parbox[t]{7cm}{($\varphi_M = \psi_M \union \Union_{k\in \{0..p\}} \varphi_{N_k}$ by definition.)} \label{eqn:proof_corres_1}
        \end{align}

        Note that $\varphi^{-1}_{M}(\ip(u \filter b \filter T^{00j}))$ is not a traversal but \emph{a set of} traversals since $\varphi_{M}^{-1}$ is not necessarily bijective on $\intersem{N_j}$. Thus we have to use set-membership in the equation instead of traversal equality.

        Since $\varphi^{-1}_{M}$ is monotonous and $u \filter b \filter T^{00j} \subseqof u \subseqof w$, all the traversals in $\varphi^{-1}_{M}(u \filter b \filter T^{00j})$ are subsequences of $\varphi^{-1}_{M}( w )$ thus:
        \begin{align*}
        t_j - @ &\subseqof \varphi^{-1}_{M}( w ) & \mbox{(by Eq. \ref{eqn:proof_corres_1})}\\
                &= t -@ & \mbox{($\varphi_{M}$ is bijective on $\travset(M)$ by Cor. \ref{cor:varphi_bij}).}
        \end{align*}

      Thus by Lemma \ref{lem:minus_at_plus_at}(ii) we have
        $\ip( t_j) \subseqof t$.

    Furthermore:
     \begin{align*}
    t_j\subseqof t
        &\implies \varphi_M (t_j) \subseqof \varphi_M (t) \\
        &\iff (w \cdot m) \filter b \filter T^{00j} \subseqof  w \\
        &\iff (w \filter b \filter T^{00j}) \cdot m \subseqof  w  & \mbox{ ($m$ is h.j. by $b$ and belongs to $T^{00j}$)} \\
        &\implies \left( \left(w \filter b \filter T^{00j} \cdot m \right) \filter b \filter T^{00j} \right) \cdot m \subseqof w & \mbox{ (by iterating the previous equation)} \\
        &\iff (w \filter b \filter T^{00j}) \cdot m  \cdot m \subseqof  w \ .
    \end{align*}
    The last equation is false since a given move cannot occur twice consecutively in a legal interaction play! Hence $t_j\not\subseqof t$.

    \begin{enumerate}[(a)]
    \item  Suppose $t_j$'s last move is \emph{not} visited by the rule \rulenamet{InputVar} nor
        $\rulename{InputVar^{val}}$. Since $\ip( t_j) \subseqof t$ and $t_j$ is a traversal of the subterm $N_j$ of $M$, by Lemma \ref{lem:local_traversal_progression}
        we have either $t_j\subseqof t$ or $t \cdot t_j^\omega$ is a traversal of $M$
        where $t_j^\omega$'s pointer is the same as in $t_j$. Hence, since $t_j\not\subseqof t$, $t \cdot t_j^\omega$ is a traversal of $M$.

        Furthermore we have
        \begin{align*}
            \varphi_M (t_j^\omega) &= (\varphi_M (t_j-@))^\omega & \mbox{($t_j^\omega \neq @$ by assumption)}\\
                                   &= ((w \cdot m) \filter b\filter T^{00j})^\omega & \mbox{(by Eq. \ref{eqn:corresp_outmost_ih})}\\
                                   &= ((w \filter b\filter T^{00j}) \cdot m))^\omega & \mbox{($m$ is h.j. by $b$ and belongs to $T^{00j}$)}\\
                                   &= m
        \end{align*}
        and therefore
        \begin{align*}
          \varphi_{M}((t \cdot t_j^\omega)-@)  &=  \varphi_{M}(t -@)  \cdot \varphi_{M}(t_j^\omega-@)\\
                &=   w \cdot \varphi_{M}(t_j^\omega-@) & \mbox{(by the innermost induction hypothesis)}\\
                &=   w \cdot m & \mbox{(by the previous equation).}
        \end{align*}
        Hence the traversal $t \cdot t_j^\omega$ meets the requirement.

    \item Suppose $t_j$'s last move is visited with the rule \rulenamet{InputVar}.

    Then $t_j$ is of the form
    $$\Pstr[18pt]{ t_j = t' (z)z \cdot t'' \cdot (n-z){t_j^\omega}}$$
for some $z \in N_\lambda^{\filter r_j}$ (see remark \ref{rem:inputvar})
and some input-variable $x \in N^{\filter r_j}_{var}$ occurs in $z\cdot t'$ such that $x$ is the pending node in $\ip t_j = t' \cdot z \cdot t''$ ({\it i.e.}~ with $?(t' \cdot z \cdot t'')^\omega = x$).

Suppose that $z\in N^{\filter r}$ then $z$ is a free variable of $M$ (and $N_j$).
Since the O-view of $t_j$ coincides with the O-view of $t$

    \item Suppose $t_j$'s last move is visited with the rule $\rulename{InputVar^{val}}$.
    This case is similar to the previous one but the rule $\rulename{InputVar^{val}}$ is used instead
    of $\rulename{InputVar}$.
    \end{enumerate}



\notetoself{PIECE OF OLD PROOF
%   \item Suppose that $m,m^1 \in T^{000}$.
%    The strategy $ev$ is responsible for switching of thread
%    in $B_0$ therefore, in the interaction semantics, there
%    must be a copycat move in-between two moves belonging to
%    two different threads. Since $m$ and $m^1$ are
%    consecutive moves in the sequence $u$, they must belong
%    to the same thread i.e. there are hereditarily justified
%    by the same initial $m_0$ in $B_0$.

Suppose that $m \in T^{000}$ and $m^1 \in T^{001}$.

    $t$ is obtained from $t-@$ by applying the
    transformation $+@$. We apply the same transformation to
    $u$ in order to make $O$-questions and $P$-questions in
    $u$ match with $\lambda$-nodes and variable nodes in
    $t'$ respectively. We write this sequence $u+@$. The
    $+@$ operation inserts nodes in the sequence but not at
    the end, therefore $m^1$, the last move in $u'$, is also
    the last move in $u'+@$. Let us note $n^1$ for the last
    move in $t'$.


        $n^1$ is a variable node then $m^1$ is a P-move and $m$ is an O-move
            and therefore $m$ is the copy of $m^1$ duplicated in $B_1$ by the evaluation strategy.
            Consequently, $m^1$ points to some $m^2$ and $m$ points to the node preceding $m^2$ denoted by $m^3$.
            The diagram below shows an example of such sequence:
                $$
                \begin{array}{ccccccccccc}
                  & A & \longrightarrow & ( (B_1' &\rightarrow & o') & \times & B_1 ) & \longrightarrow & o' \\
                  &&& &&&&&& \rnode{q0}{q_0 (\lambda \overline{\xi})} & O\\
                  &&& &&&&&  \\
                O &&& && \rnode{q1}{q_0' (\lambda \overline{y})} &&&&& P \\
                P &&& \rnode{m3}{m^3 (y_1)} &&&&&&& O \\
                O &&& &&&& \rnode{m2}{m^2 (\lambda \overline{z}^{[r_1]})} &&& P \\
                P &&& &&&& \rnode{m1}{m^1 (z)} &&& O \\
                O &&& \rnode{m}{m} &&&&&&& P \\
                \end{array}
                \ncline[nodesep=3pt]{->}{q1}{q0} \mput*{@}
                \nccurve[nodesep=3pt,ncurv=2,angleA=180,angleB=180]{->}{m1}{m2}
                \ncarc[nodesep=3pt,ncurv=1,angleA=90,angleB=180]{->}{m3}{q1}
                \ncarc[nodesep=3pt,ncurv=1,angleA=90,angleB=180]{->}{m}{m3}
                \ncline[nodesep=3pt]{->}{m2}{q0}
                $$

        $t'$  and $u+@$ have the following forms:
        \begin{eqnarray*}
                t'&=& \Pstr{ \ldots \cdot n^3 \cdot (n2){n^2} \cdot \ldots \cdot (n1-n2,30){n^1} } \\ \\
                u+@ &=& \Pstr{ \ldots \cdot (m3){m^3} \cdot (m2){m^2} \cdot \ldots \cdot (m1-m2,30){m^1} \cdot (m-m3,30){m} }
        \end{eqnarray*}

        Since $n^1$ is a variable node, $n^2$ must be a $\lambda$-node.
        $n^3$ is either a variable node or an @-node. In fact $n^3$ is necessarily a variable node. Indeed,
        $n^3$ is mapped to $m^3$ by $\varphi_{N_0}$ and $m^3$ belongs to $B_i'$ (i.e. it is not
        an internal move of $T^0$). The function $\varphi_{N_0}$ is defined in such a way that
        only nodes which are hereditarily justified by $r_0$ are mapped to nodes in $B_j'$.
        Consequently, since @-node don't have justifier, $n^3$ cannot be an @-node.

        Hence $n^1$ is a variable node, $n^2$ is a $\lambda$-node and $n^3$ is a variable node.


        We  can therefore apply the (Var) rule to $t'$ and we obtain a traversal of the following form:

        \begin{eqnarray*}
            t&=& \Pstr{ \ldots \cdot (n3){n^3} \cdot (n2){n^2} \cdot \ldots \cdot (n1-n2,30){n^1} \cdot (n-n3,30){n} }
        \end{eqnarray*}

        We have $\varphi(t'-@) = u'$ by the induction hypothesis and $\varphi(n) = m$ by definition of $\varphi$.
        Therefore since $m$ and $n$ point to the same position we have $\varphi(t-@) = u$.
}

    \end{enumerate}

\item[$\supseteq$]
  For the converse, $\varphi_{M}( \travset^{-@}(M) ) \subseteq \intersem{M}$, it is an easy induction
  on the traversal rules. We omit the details here.


\end{enumerate}


    \item (application') $M = x_i N_1 \ldots N_p :o$ with $X_i = B_0 = (B_1' \times \ldots \times B_p') \rightarrow o'$. The tree $\tau(M)$ has the following form:
    $$ \tree[levelsep=6ex]{\lambda^{[r]}}
        { \tree[levelsep=6ex]{x_i}
            {
            \tree[levelsep=3mm,edge=\noedge]{\TR{[r_1]}}{\Tr[ref=t]{\pstribox{\tau(N_1)}}}
             \TR{\ldots}
            \tree[levelsep=3mm,edge=\noedge]{\TR{[r_p]}}{\Tr[ref=t]{\pstribox{\tau(N_p)}}}
        }}
    $$
    The interaction strategy
    $\intersem{\Gamma \vdash M : o}
            =  \underbrace{\langle \pi_i, \intersem{\Gamma \vdash N_1 : B_1}, \ldots \intersem{\Gamma \vdash N_p : B_p} \rangle}_{\Sigma} \,^\dagger\ ;^{\{1..p\}} \ ev$
    is represented on Figure \ref{fig:interaction_strategy_denotations}.

    The proof is identical to the previous case except that in the $\subseteq$ part of the proof:
    \begin{itemize}
        \item In the base case of the induction where $|u|=2$,
        the rule \rulenamet{InputVar} is used instead of \rulenamet{App} to visit the node $x$ instead of $@$;
        \item in the step case of the induction, for the subcase $m\in C$, the rules \rulenamet{Answer-var-$\lambda$} and \rulenamet{Answer-$\lambda$-var} are used instead of \rulenamet{Answer-@-$\lambda$} and \rulenamet{Answer-$\lambda$-@} respectively;
        \item in the step case $m\in T^0$, when $m$ is hereditarily justified by a move $b \in B_j$ for
         $j\in \{1 .. p\}$ the proof remains unchanged. The case where $m$ is hereditarily justified by a move $b \in B_0$ is treated as follows: $m$ is played by the projection strategy $\pi$ denoting $x$.
         Since $m$ is played in $B_0' = B_1' \times \ldots \times B_p'$ it must be also hereditarily justified by some initial move $b'$ of $B_k'$ for some $k \in \{1.. p\}$ or by an initial move in $o'$. But moves of $B_k'$ are $\sim$-equivalent to the corresponding move in $B_k$ and similarly $o'$ is $\sim$-equivalent to $o$, therefore we fall back to the previous case of the induction where $m$ is hereditarily justified by some initial move $b\in B_k$ for $k\in \{1..p\}$ or some initial move in $o$!
    \end{itemize}


\end{enumerate}


\end{proof}


\begin{corollary} \hfill
\begin{enumerate}[i.]
\item Let $\tau(M')$ be a subtree of $\tau(M)$ for some subterm $M'$ of $M$, and  $N'$ denote the set
of nodes of $\tau(M')$. Then
$$t \in \travset(M) \implies t\filter N' \in \travset(M') \ .$$

\item If $M$ is in $\beta$-normal form then for any traversal $t$,
$\varphi_M(t)$ is a maximal play if and only if $t$ is a maximal
traversal.
\end{enumerate}
\end{corollary}
\begin{proof}
\begin{enumerate}[i.]
\item
 \todo
\item If $M$ is in $\beta$-normal form then
$\travset(M)^{\upharpoonright r} = \travset(M)$ therefore
$\varphi$ defines a bijection on $\travset(M)$. Let $t$ be a
traversal such that $\varphi(t)$ is a maximal play. Let $t'$ be
a traversal such that $t \sqsubseteq t'$. By monotonicity of
$\varphi$ we have $\varphi(t) \sqsubseteq \varphi(t')$ which
implies $\varphi(t) = \varphi(t')$ by maximality of $\varphi(t)$
which in turn implies $t'=t$ by injectivity of $\varphi$. The
other direction is proved identically using injectivity and
monotonicity of $\varphi^-1$.
\end{enumerate}
\end{proof}
\smallskip The following diagram recapitulates the main results of
this section:
$$
\xymatrix @C=6pc{
                                           & \travset(M)^{-@} \ar@/_/[dl]_{+@}  \ar[r]^{\varphi_M}_\cong & \intersem{M} \ar@/_/[dd]_{\_ \upharpoonright \sem{\Gamma\rightarrow T}} \\
\travset(M) \ar@/_/[ur]_{-@}^{} \ar[dr]^{\_ \upharpoonright r}  \\
                                           & \travset(M)^{\upharpoonright r} \ar[r]^{\varphi_M}_\cong & \sem{M} \ar@/_/[uu]^{\cong}_{\mbox{full uncovering}}
}
$$


\begin{example}
Take $M = \lambda f z . (\lambda g x . f x) (\lambda y. y) (f z) :
((o,o),o, o)$.  The figure below represents the computation tree
(left tree), the arena $\sem{((o,o),o, o)}$ (right tree) and
$\psi_M$ (dashed line). (Only question moves are shown for clarity.)
The justified sequence of nodes $t$ defined hereunder is an example
of traversal:

\begin{tabular}{lp{6.3cm}}
$\tree[levelsep=2.5ex,treesep=0.3cm]{ \Rnode{root}{\lambda f z} }
     {  \tree{@}
        {   \tree{\lambda g x}{
                  \tree{\Rnode{f}{f^{[1]}}}{
                            \tree{\Rnode{lmd}{\lambda^{[2]}}}
                            {\TR{x}}
                  }
                }
            \tree{ \lambda y }{\TR{y}}
            \tree{\lambda ^{[3]}}{
                \tree{\Rnode{f2}{f^{[4]}}} {
                \tree{\Rnode{lmd2}{\lambda^{[5]}}}{\TR{\Rnode{z}{z}}}
                }
            }
        }
     }
\hspace{1cm}
  \tree[levelsep=8ex,treesep=0.3cm]{ \Rnode{q0}q^0 }
    {   \pstree[levelsep=4ex]{\TR{\Rnode{q1}{q^1}}}{\TR{\Rnode{q2}{q^2}}}
        \TR{\Rnode{q3}q^3}
        \TR{\Rnode{q4}q^4}
    }
\psset{nodesep=1pt,arrows=->,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
\ncline{->}{root}{q0} \mput*{\psi_M}
\ncarc[arcangle=-25]{->}{z}{q3}
\ncarc[arcangle=10]{->}{f}{q1}
\ncarc[arcangle=10]{->}{lmd}{q2}
\ncline{->}{f2}{q1}
\ncline{->}{lmd2}{q2}$
\hspace{2cm}
&
\begin{asparablank}
  \item  \Pstr[0.8cm]{
t = (n){\lambda f z} \
(n2){@} \
(n3-n2,60){\lambda g x} \
(n4-n,45){f^{[1]}} \
(n5-n4,45){\lambda^{[2]}} \
(n6-n3,45){x} \
(n7-n2,35){\lambda^{[3]}} \
(n8-n,35){f^{[4]}} \
(n9-n8,45){\lambda^{[5]}} \
(n10-n,35){z}
}

\item \Pstr[0.9cm]{
t\upharpoonright r = (n){\lambda f z} \ (n4-n,50){f}^{[1]} \
(n5-n4,60){\lambda}^{[2]} \ (n8-n,45){f}^{[4]} \
(n9-n8,60){\lambda}^{[5]} \ (n10-n,40){z}}
\item
\Pstr[0.8cm]{ {\psi_M(t\upharpoonright r) =\ } (n){q^0}\
(n4-n,60){q^1}\ (n5-n4,60){q^2}\ (n8-n,45){q^1}\ (n9-n8,60){q^2}\
(n10-n,38){q^3} \in \sem{M}\ .}
\end{asparablank}
\end{tabular}
\end{example}
