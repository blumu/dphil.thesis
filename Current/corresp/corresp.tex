We make an explicit correspondence between the game denotation of a
term and its syntax. Our approach follows ideas recently introduced
in \cite{OngLics2006}, mainly the notion of computation tree of a
simply-typed $\lambda$-term and traversals over the computation
tree. A computation tree can be regarded as an abstract syntax tree
(AST) of the $\eta$-long normal form of a term. A traversal is a
justified sequence of nodes of the computation tree respecting some
formation rules. Traversals are used to describe computations. An
interesting property is that the \emph{P-view} of a traversal
(computed in the same way as P-view of plays in Game Semantics) is a
path in the computation tree.

The main result of this paper is called the
\emph{Correspondence Theorem} (theorem \ref{thm:correspondence}). It
states that traversals over the computation tree are just
representations of the uncovering of plays in the
strategy-denotation of the term. Hence there is an isomorphism
between the strategy denotation of a term and its revealed game
denotation ({\it i.e.}~its strategy denotation where internal moves are
not hidden after composition). This theorem permits us to explore
the effect that a given syntactic restriction (such as the safety restriction) has on the strategy
denoting a term.

To really make use of the Correspondence Theorem, it will be
necessary to restate it in the standard game-semantic framework in
which internal moves are hidden. For that purpose, we will define a
\emph{reduction} operation on traversals responsible of eliminating
the ``internal nodes'' of the computation. This leads to a
correspondence between the standard game denotation of a term and
the set of reductions of traversals over its computation tree.
Fortunately, the reduction operation preserves the good properties
of traversals. This is guaranteed by the facts that the P-view of
the reduction of a traversal is equal to the reduction of the P-view
of the traversal, and the O-view of a traversal is the same as the
O-view of its reduction (Proposition \ref{prop:oview_trav_filtering}).
\vspace{8pt}

\emph{Related works}: Traversals of a computation tree provide a way
to perform \emph{local computation} of $\beta$-reductions as opposed
to a global approach where the $\beta$-reduction is implemented by
performing substitutions. A notion of local computation of
$\beta$-reduction has been investigated in
\cite{DanosRegnier-Localandasynchronou} through the use of special
graphs called ``virtual nets'' that embed the lambda-calculus.

In \cite{DBLP:conf/lics/AspertiDLR94}, a notion of graph based on
Lamping's graphs \citep{lamping} is introduced to represent
$\lambda$-terms. The authors unify different notions of paths
(regular, legal, consistent and persistent paths) that have appeared
in the literature as ways to implement graph-based reduction of
lambda-expressions. We can regard a traversal as an alternative
notion of path adapted to the graph representation of
$\lambda$-expressions given by computation trees.



%Is there any unsafe term whose game semantics is a strategy where
%pointers can be recovered?
%
%The answer is yes: take the term $T_i = (\lambda x y . y) M_i S$
%where $i =1..2$ and $\Gamma \vdash_s S : A$. $T_1$ and $T_2$ both
%$\beta$-reduce to the safe term $S$, therefore
%$\sem{T_1}=\sem{T_2}=\sem{S}$. But $T_1$ is safe whereas $T_2$ is
%unsafe. Since it is possible to recover the pointer from the game
%semantics of $S$, it is as well possible to recover the pointer from
%the semantics of $T_2$ which is unsafe.

\section{Computation tree}
We work in the general setting of the simply-typed
$\lambda$-calculus extended with a fixed set $\Sigma$ of
higher-order uninterpreted constants \footnote{A constant $f$ is
  \emph{uninterpreted} if the small-step semantics of the language
  does not contain any rule of the form $f \dots \rightarrow e$. $f$
  can be regarded as a data constructor.}

For the rest of the section we fix a simply-typed term $\Gamma \vdash M :T$.

\subsection{$\eta$-long normal form}

The $\eta$-long normal form appeared in
\citep{DBLP:journals/tcs/JensenP76} and
\citep{DBLP:journals/tcs/Huet75} under the names \emph{long reduced
form} and \emph{$\eta$-normal form} respectively. It was then
investigated in \citep{huet76} under the name \emph{extensional
form}.

The $\eta$-expansion of $M: A\typear B$ is defined to be the term
$\lambda x . M x : A\typear B$ where $x:A$ is a fresh variable. A
term $M : (A_1,\ldots,A_n,o)$ can be expanded in several steps into
$\lambda \varphi_1 \ldots \varphi_l . M \varphi_1 \ldots \varphi_l$
where the $\varphi_i:A_i$ are fresh variables. The $\eta$-normal
form of a term is obtained by hereditarily $\eta$-expanding every
subterm occurring at an operand position.

\begin{definition}[$\eta$-long normal form]
A simply-typed term is either an abstraction or it can be written uniquely as
$s_0 s_1 \ldots s_m$ where $m\geq0$ and $s_0$ is a variable, a $\Sigma$-constant or an abstraction.
The $\eta$-long normal form of a term $t$, written $\elnf{t}$ or sometimes $\etanf{t}$,
is defined as follows:
\begin{align*}
\elnf{\lambda x . s } &= \lambda x . \elnf{s} \\
\elnf{\alpha s_1 \ldots s_m : (A_1,\ldots,A_n,o)} &= \lambda \overline{\varphi} . \alpha \elnf{s_1}\ldots \elnf{s_m} \elnf{\varphi_1} \ldots \elnf{\varphi_n}
& \mbox{with $m,n\geq0$}\\
\elnf{(\lambda x . s) s_1 \ldots s_p : (A_1,\ldots,A_n,o) } &= \lambda \overline{\varphi} . (\lambda x . \elnf{s}) \elnf{s_1} \ldots \elnf{s_p} \elnf{\varphi_1} \ldots \elnf{\varphi_n}
& \mbox{with $p\geq 1,n\geq 0$}
\end{align*}
where $x$ and each $\varphi_i : A_i$ are variables and $\alpha$ is
either a variable or a constant.
\end{definition}

For $n=0$, the first clause in the definition becomes:
$$\elnf{x s_1 \ldots s_m : o} = \lambda . x \elnf{s_1} \elnf{s_2} \ldots \elnf{s_m},$$
and we deliberately keep the \textsl{dummy} lambda in the right-hand
side of the equation because it will play an important role in the
correspondence with game semantics.



Note that our version of the $\eta$-long normal form is defined not only for $\beta$-normal terms but also for any simply-typed term.
Moreover it is defined in such a way that $\beta$-normality is preserved:
\begin{lemma}
The $\eta$-long normal form of a term in $\beta$-normal form is also in $\beta$-normal form.
\end{lemma}
\begin{proof}
By induction on the structure of the term and the order of its type.
\emph{Base case}:
If $M=x:0$ then $\elnf{x} = \lambda . x$ is also in $\beta$-nf.
\emph{Step case}:
The case $M = (\lambda x . s) s_1 \ldots s_m : (A_1,\ldots,A_n,o)$ with $m>0$ is not possible since $M$ is in
$\beta$-normal form.
Suppose $M = \lambda x . s$ then $s$ is in $\beta$-nf. By the induction hypothesis $\elnf{s}$ is also in $\beta$-nf and therefore
so is $\elnf{M} = \lambda x . \elnf{s}$.

Suppose $M= \alpha s_1 \ldots s_m : (A_1,\ldots,A_n,o)$. Let $i,j$
range over $1..n$ and $1..m$ respectively. The $s_j$ are in
$\beta$-nf and the $\varphi_i$ are variables of order smaller than
$M$, therefore by the induction hypothesis the $\elnf{\varphi_i}$ and
the $\elnf{s_j}$ are in $\beta$-nf. Hence $\elnf{M}$ is also in
$\beta$-nf.
\end{proof}

\begin{lemma}[$\eta$-long normalisation preserves safety]
If $\Gamma \vdash s$ then $\Gamma \vdash \elnf{s}$.
\end{lemma}
\begin{proof}

First we observe that for any variable or constant $x$ we have $x \vdash \elnf{x}$. The proof is by induction on $\ord{x}$. Base case: $x$ is of ground type and we have $x \vdash x = \elnf{x}$. Step case:
$x:(A_1, \ldots, A_n,o)$ with $n>0$. Let $\varphi_i:A_i$ be fresh variables for $1\leq i\leq n$. The (var) rules gives $\varphi_i  \vdash \varphi_i$ and since $\ord{A_i} < \ord{x}$ the induction hypothesis gives $\varphi_i \vdash \elnf{\varphi_i}$. Using (wk) we obtain $x, \overline{\varphi} \vdash \elnf{\varphi_i}$.
The application rule gives $x, \overline{\varphi} \vdash x \elnf{\varphi_1} \ldots \elnf{\varphi_n} : o$ and the abstraction rule gives $ x \vdash \lambda \overline{\varphi} . x \elnf{\varphi_1} \ldots \elnf{\varphi_n} = \elnf{x}$.


We now prove the lemma by induction on the structure of $s$.
The base case (where $s$ is some variable $x$) is covered by the previous observation.
\emph{Step case:}
\begin{itemize}
\item $s = x s_1 \ldots s_m$ with $x: (B_1, \ldots, B_m, A_1, \ldots, A_n, o)$ with $m\geq 0$, $n>0$ and $s_i : B_i$ for $1 \leq i \leq m$.

Let $\varphi_i: A_i$ be fresh variables for $1\leq i \leq n$. By the previous observation we have $\varphi_i \vdash \elnf{\varphi_i}$ which in turn gives $\Gamma , \overline{\varphi} \vdash \elnf{\varphi_i}$ using the weakening rule.

The judgement $\Gamma \vdash x s_1 \ldots s_m$ is formed using the (app) rule therefore each $s_j$ is safe for $1\leq j \leq m$. By the induction hypothesis we have $\Gamma \vdash \elnf{s_j}$ and by weakening we get $\Gamma, \overline{\varphi} \vdash \elnf{s_j}$.

The application rule gives $\Gamma, \overline{\varphi} \vdash
x \elnf{s_1} \ldots \elnf{s_m} \elnf{\varphi_1} \ldots \elnf{\varphi_n} : o$. Finally the (abs) rule gives $\Gamma \vdash \lambda \overline{\varphi} . x \elnf{s_1} \ldots \elnf{s_m}  \elnf{\varphi_1} \ldots \elnf{\varphi_n} = \elnf{s}$, the side-condition of (abs) being met since $\ord{\elnf{s}} = \ord{s}$.


\item $s = t s_0 \ldots s_m$ where $t$ is an abstraction. Again, using the induction hypothesis it is easy to show that $\Gamma \vdash \elnf{s} = \elnf{t} \elnf{s_0} \ldots \elnf{s_m} \elnf{\varphi_1} \ldots \elnf{\varphi_n}$ holds for some fresh variables $\varphi_1$, \ldots, $\varphi_n$.

\item $s = \lambda \overline{\eta} . t$ where $t$ is not an abstraction. By the induction hypothesis we have $\Gamma, \overline{\eta} \vdash \elnf{t}$ and by the abstraction rule we have $\Gamma \vdash \lambda \overline{\eta} . \elnf{t} = \elnf{s}$.
\end{itemize}
\end{proof}

Note that in general the converse does not hold, for instance $\lambda x^o . f^{o,(o,o),o} x^o$ is unsafe although $\elnf{\lambda x . f x} = \lambda x^o \varphi^{o,o} . f x \varphi$ is safe (and not homogeneous). For terms with homogeneous types however, the converse does hold:
\begin{lemma}
If $\Gamma \vdash \elnf{s}$ is homogeneously safe (i.e. it is a safe judgement of the safe $\lambda$-calculus and each sequent occurring at the nodes of the proof tree is homogeneously typed) then
$\Gamma \vdash s$ is homogeneously safe.
\end{lemma}


\subsection{Computation tree}
The computation tree of a term is a certain tree representation of its
$\eta$-long normal form. It is defined as follows:

\begin{definition}
\label{dfn:comptree} Let $M$ be a simply-typed term in $\eta$-normal
form. Then $M$ is either an abstraction or it can be written
uniquely as $s_0 s_1 \ldots s_m : o$ for some $m\geq0$ where $s_0$
is a variable, a constant or an abstraction and each of the $s_j$
for $j\in 1..m$ is in $\eta$-normal form. We define the
tree $\tau^*(M)$ by induction on the structure of the term as follows:
\begin{enumerate}[-]
\item If $n\geq0$ and $s$ is not an abstraction then:
$$ \tau^*(\lambda x_1 \ldots x_n . s) =
      \pstree[levelsep=3ex]
        { \TR{\lambda x_1 \ldots x_n} }
        { \SubTree{\tau^*(s)^{-}} }
$$
where $\tau^*(s)^{-}$ denotes the tree obtained after deleting the root of $\tau^*(s)$.

\item If $m\geq0$ and $\alpha$ is a variable or constant then:
$$ \tau^*( \alpha s_1 \ldots s_m : o) =
    \tree{\lambda}
    {
        \pstree[levelsep=3ex]
            { \TR{\alpha} }
            { \SubTree{\tau^*(s_1)} \SubTree[linestyle=none]{\ldots} \SubTree{\tau^*(s_m)}
            }
    }
$$

\item If $n \geq 1$ then:
$$ \tau^*((\lambda x.s) s_1 \ldots s_n : o) =
    \tree{\lambda}
    {
        \pstree[levelsep=3ex]
            { \TR{@} }
            {
            \SubTree{\tau^*(\lambda x.s)}    \SubTree{\tau^*(s_1)} \SubTree[linestyle=none]{\ldots} \SubTree{\tau^*(s_n)}
            }
    }
$$
\end{enumerate}

Let $M$ be a simply-typed term not necessarily in $\eta$-normal form. Let $\mathcal{D}$ denote the set of values of base type $o$. The \defname{computation tree} of $M$, written $\tau(M)$ is the tree obtained from
$\tau^*(\etanf{M})$ by adding leaves to the nodes of $\tau^*(\etanf{M})$ as follows:
every node $n \in \tau(M)$ has a child leaf labelled $v_n$ for every possible value $v \in \mathcal{D}$.
These leaves are called the \defname{value-leaves}.
\end{definition}

The inner nodes of the tree are of three kinds:
\begin{itemize}
\item $\lambda$-nodes labelled $\lambda \overline{x}$ (note that a $\lambda$-node represents several consecutive variable abstractions),
\item application nodes labelled @,
\item variable or constant nodes labelled $\alpha$ for some constant or variable $\alpha$.
\end{itemize}
A node is said to be \defname{prime} if it is the 0$^{th}$ child of an @-node.
\bigskip

\emph{Notations:} We write $\theroot$ to denote the root of
$\tau(M)$. We write $E$ to denote the parent-child relation of the
tree, $V$ for the set of vertices (leaves and inner nodes) of the
tree, $N$ for the set of inner nodes and $L$ for the set of
value-leaves. Thus $V = N \union L$.

We write $N_\Sigma$ for the set of $\Sigma$-labelled nodes, $N_@$ for the set
of @-labelled nodes, $N_{\sf var}$ for the set of variable nodes,
$N_{\sf fv}$ for the subset of $N_{\sf var}$ constituted of free-variable
nodes, $N_{\sf spawn}$ for the set $N \inter E \relimg{N_@ \union N_\Sigma}$ constituted of children of constant-nodes and @-nodes and $N_{\sf prime}$ for the set of prime nodes.

For $\$$ ranging in $\{@, \lambda, {\sf var}, {\sf fv} \}$,
we write $L_\$$ to denote the set of value-leaves of nodes from $N_\$$
{\it i.e.}\ $L_\$ = \{ v_n \ | \ n \in N_\$, v \in \mathcal{D} \}$,
and $V_\$$ to denote the set of nodes of $N_\$$ or value-leaves of nodes of $N_\$$
{\it i.e.}\ $V_\$ = N_\$ \union L_\$ $.


Let $\mathcal{T}$ denote the set of $\lambda$-terms.
Each subtree of the computation tree $\tau(M)$ represents a subterm of $\elnf{M}$.
We define the function $\kappa : N \rightarrow \mathcal{T}$ that maps a node $n \in N$ to the subterm of $\elnf{M}$
corresponding to the subtree of $\tau(M)$ rooted at $n$.
In particular $\kappa(r) = \elnf{M}$.

\begin{definition}[Type and order of a node]
\label{def:nodeorder}
Suppose $\Gamma \vdash M : T$.
The \defname{type} of a node $n \in N$ of $\tau(M)$ written $type(n)$ is defined as follows:
\begin{eqnarray*}
type(\theroot) &=& \Gamma \rightarrow T \\
type(\alpha:A) &=& A, \mbox{ where $\alpha \in N_{\sf var} \union N_\Sigma$} \\
type(n) &=& \hbox{ type of the term $\kappa(n)$ for $n \in (N_\lambda \union N_@) \setminus \{r \}$\ .}
\end{eqnarray*}
The order of an inner node $n$ written $\ord{n}$ is defined to be
the order of the type of $n$. The order of a value-leaf $v \in L$ is
$0$.
\end{definition}

In particular, $\ord{@} = 0$, $\ord{\lambda \overline{\xi}} = 1+
\max_{z\in \overline{\xi}} \ord{z}$ for $\lambda \overline{\xi}\neq
r$ and if the root is $\lambda \overline{\xi}$ then $\ord{r} = 1 + \max_{z\in
\overline{\xi}\union \Gamma} \ord{z}$ with the convention $\max
\emptyset = -1$.

\begin{remark} \hfill
\begin{itemize}
\item In a computation tree, nodes at even level are $\lambda$-nodes and nodes at odd level are either application nodes,
variable or constant nodes;

\item for any ground type variable or constant $\alpha$,
$\tau(\alpha) = \tau(\lambda . \alpha) =  \pstree[levelsep=3ex]
    { \TR{\lambda } }
    { \TR{\alpha}
    }$;

\item for any higher-order variable or constant $\alpha : (A_1,\ldots,A_p,o)$, the computation tree $\tau(\alpha)$ has the following form:
$ \pstree[levelsep=3ex]{\TR{\lambda}}
        {\pstree[levelsep=3ex]
                { \TR{\alpha} }
                { \tree{\lambda \overline{\xi_1}}{\TR{\ldots}} \TR{\ldots} \tree{\lambda \overline{\xi_p}}{\TR{\ldots}}
                }
        }
$;

\item for any tree of the form
        $ \pstree[levelsep=4ex]
            { \TR{\lambda \overline{\varphi}} }
            { \pstree[levelsep=3ex]
                {\TR{n}}
                {\TR{\lambda \overline{\xi_1}} \TR{\ldots} \TR{\lambda \overline{\xi_p}}}
            }
        $,
    we have $\ord{\kappa(n)}=0$.

\end{itemize}
\end{remark}


\subsection{Pointers and justified sequence of nodes}
\subsubsection{Definitions}
\begin{definition}[Binder]
Let $n$ be a variable node of the computation tree labelled $x$. We
say that a node $n$ is bound by the node $m$, and $m$ is called the
binder of $n$, if $m$ is the closest node in the path from $n$ to
the root of the tree such that $m$ is labelled $\lambda
\overline{\xi}$ with $x\in \overline{\xi}$.
\end{definition}

\begin{definition}[Enabling]
The \defname{enabling relation} $\vdash$ is defined on the set of
nodes and leaves of the computation tree as follows. We write $m \vdash n$ and
we say that $m$ enables $n$ if and only if
\begin{itemize}
\item $n$ is a value-leaf of $m$ ($n=v_m$ for some $v\in\mathcal{D}$);
\item $n$ is a variable node and $m$ is a prime node occurring in the path from the root to $n$;
\item or $n$ is a bound variable node and $m$ is the binder of $n$. We will write $m \vdash_i n$ to precise that $n$
is the $i^{\sf th}$ variable bound by $m$;
\item or $n$ is a free variable node and $m$ is the root;
\item or $n$ is a $\lambda$-node and $m$ is $n$'s parent node.
\end{itemize}
Note that in particular, free variable nodes are enabled by the root.
Table \ref{tab:enabler_type} recapitulates the possible node types for the enabler node
depending on the type of $n$.
\end{definition}


\begin{table}[htbp]
$$
\begin{array}{ccl}
\mbox{If } n\in \_  & \mbox{then} & m\in \_ \\ \hline
N_\lambda & & N_{\sf var} \union N_\Sigma \union N_@ \\
L_{\sf var} & & N_{\sf var} \\
L_@ & &  N_@ \\
L_\Sigma & & N_\Sigma\\
\\
N_{\sf var} & & N_\lambda\\
N_\Sigma & & \mbox{n.a.} \\
N_@ & & \mbox{n.a.} \\
L_\lambda & & N_\lambda\\
\end{array}
$$
\caption[Type of the justifying node]{Type of the enabler node in $m\vdash n$.}
\label{tab:enabler_type}
\end{table}

We say that a node $n_0$ of the computation tree is \defname{hereditarily enabled} by $n_p \in N$ if there are nodes $n_1,\ldots, n_{p-1} \in N$ such that $n_{i+1}$ enables $n_{i}$
for all $i\in 0..p-1$.

For any set of nodes $S, H \subseteq N$ we write $S^{H\vdash}$ for $S \inter \vdash^*(H) = \{ n \in S \ | \exists n_0 \in H \mbox{ s.t. }n_0  \vdash^* n \}$ -- the subset of $S$ constituted of nodes hereditarily enabled by some node in $H$. For succinctness we sometime write $S^{n_0\vdash}$ for
$S^{\{n_0\}\vdash}$.

We call \defname{input-variables nodes} the elements of $V_{\sf var}^{\theroot\vdash}$ i.e.\
variables that are hereditarily enabled by the root of $\tau(M)$. Thus we have
$V_{\sf var}^{\theroot\vdash} = V \setminus ( V_{\sf var}^{N_@\vdash}
\union V_{\sf var}^{N_\Sigma\vdash})$.
\smallskip

We use the following numbering conventions:
the first child of a @-node -- a prime node -- is numbered $0$;
the first child of a variable or constant node is numbered $1$;
and variables in $\overline{\xi}$ are numbered from $1$ onward ($\overline{\xi} = \xi_1 \ldots \xi_n$).
We write $n.i$ to denote the $i$th child of node $n$.

\begin{definition}[Justified sequence of nodes]
\label{dfn:justseqnode} A \defname{justified sequence of nodes} is a
sequence of nodes $s$ of the computation tree $\tau(M)$ with
pointers. For each occurrence $n$ in $s$:
\begin{itemize}
  \item If $n$ is a value-leaf then it points to a preceding occurrence of its parent node;
  \item If $n$ is an @-node then it has no pointer attached to it;
  \item If $n$ is a $\lambda$-node different from the root
  then is has a main pointer to a node $m$ preceding it in $s$ and verifying $m \vdash n$;
  \item If $n$ is a variable node then it has one main pointer and
  potentially auxiliary pointers; each of them pointing to a
  preceding occurrence of a node $m$ verifying $m \vdash n$.
\end{itemize}

If $n$ points to $m$ then we say that $m$ \defname{justifies} $n$.
If $n$ is a node then we represent this pointer in the sequence as \Pstr[0.4cm]{
(m){m} \ldots (n-m,45:i) n } where the label indicates that either
$n$ is labelled with the $i$th variable abstracted by the
$\lambda$-node $m$ or that $n$ is the $i^{\sf th}$ child of $m$.
For leaves, pointers are represented as
$\Pstr{ (m){m} \cdot \ldots \cdot (vm-m,40:v){v_m} }$.
For a variable node $n$, the main link is represented with a solid
line while auxiliary links are represented with dashed lines:
$$\pstr[0.6cm]{ \ldots
    \nd(l){\lambda \overline{x}}  \ldots
    \nd(l1){\lambda \overline{\xi}_1} \ldots
    \nd(l2){\lambda \overline{\xi}_2 } \ldots
    \nd(n-l,35){n}
    \arrow{n}{l1}{30}{}{blue}{dashed}
    \arrow{n}{l2}{30}{}{blue}{dashed}
} \ .$$
\end{definition}

Thus a pointer in a justified sequence of nodes has
one of the following forms:

\begin{tabular}{cllcp{8cm}}
& \Pstr[13pt]{ (m){r} \cdot \ldots \cdot (n-m,40){z} }
& or
& \pstr{\nd(l){\lambda \overline{\gamma}} \ldots \nd(n){z}
 \arrow{n}{l}{40}{}{blue}{dashed}},
& \parbox[t]{8cm}{ for some occurrences $r$ of $\tau(M)$'s root, $z \in N_{\sf fv}$,
$\lambda \overline{\gamma}$ a prime node occurring in the path from $z$ to the root; }
\\
or
& \Pstr[13pt]{ (m){\lambda \overline{\xi}} \cdot \ldots \cdot (n-m,40:i){\xi_i} }
& or
& \pstr{ \nd(m){\lambda \overline{\gamma}} \cdot \ldots \cdot \nd(n){\xi_i}
 \arrow{n}{m}{40}{}{blue}{dashed}},
& for some variable $\xi_i$ bound by $\lambda \overline{\xi}$, $i \in 1..|\overline{\xi}|$, $\lambda \overline{\gamma}$ a prime node occurring in the path from $\xi_i$ to the root;
\\
or
& \Pstr[13pt]{ (m){@} \cdot \ldots \cdot (n-m,40:j){\lambda \overline{\eta}} }
& or
& \Pstr{ (m){\alpha } \cdot \ldots \cdot (n-m,40:k){\lambda \overline{\eta}} },
& for $\alpha \in N_{\Sigma} \union N_{\sf var}$, $j$ ranges from $0$ to the number of children nodes of @ minus 1 and $k \in 1 ..arity(\alpha)$;
\\
&&or
& $\Pstr[10pt]{ (m){m} \cdot \ldots \cdot (vm-m,40:v){v_m} }$
& for some value $v\in \mathcal{D}$.
\end{tabular}
\bigskip


We say that an inner node $n$ in of a justified sequence of nodes is
\defname{matched} by the value-leaf $v_n$ if there is an occurrence of $v_n$ for some value $v$ in the
sequence that points to $n$, otherwise we say that $n$ is
\defname{unmatched}. The last unmatched node is called the
\defname{pending node}.  A justified sequence of nodes is
\defname{well-bracketed} if each value-leaf occurring in it is justified by the pending node at that point.

For any justified sequence of nodes and leaves $t$ we write $?(t)$ to denote the subsequence of $t$ consisting only of unmatched nodes. Formally:
\begin{align*}
  ?(\Pstr[0.4cm]{u_1 \cdot (n){n} \cdot u_2 \cdot (nv-n){v_n} }  ) &= ?(u_1 \cdot n \cdot u_2) \setminus \{ n \}
        & \mbox{for some value $v\in\mathcal{D}$} \\
  ?(u \cdot n)   &= ?(u)\cdot n    & \mbox{for $n\not\in L$}
\end{align*}
where $u \setminus \{ n \}$ denotes the subsequence of $u$ obtained by removing the occurrence $n$.

If $u$ is a well-bracketed sequences then $?(u)$ can be defined as follows:
\begin{align*}
  ?(\Pstr[0.4cm]{u \cdot (n){n} \ldots (nv-n){v_n} }  ) &= ?(u)
          & \mbox{for some value $v\in\mathcal{D}$}  \\
    ?(u \cdot n) &= ?(u)\cdot n    & \mbox{where $n\not\in L$} \ .
\end{align*}

\bigskip

\emph{Notations}: We write $s = t$ to denote that the justified sequences $t$ and $s$
have same nodes \emph{and} pointers. Justified sequence of nodes can
be ordered using the prefix ordering: $t \sqsubseteq t'$ if and only
if $t=t'$ or the sequence of nodes $t$ is a finite prefix of $t'$
(and the pointers of $t$ are the same as the pointers of the
corresponding prefix of $t'$). Note that with this definition,
infinite justified sequences can also be compared. This ordering
gives rise to a complete partial order.
We say that a node $n_0$ of a justified sequence is \defname{hereditarily justified} by $n_p$ if there are nodes $n_1, n_2, \ldots n_{p-1}$ in the sequence such that for all $i\in 0..p-1$, $n_i$ points to $n_{i+1}$.
We write $t^\omega$ to denote the last occurrence of $t$ and $\ip(t)$ for the immediate prefix of $t$ obtained by removing $t$'s last occurrence. We write $\jp(t)$ for the sequence $t_{\prefixof j}$ where $j$ is
the main justifier of $t^\omega$ in $t$.
\smallskip

\subsubsection{Filtering}

We define two different filtering operation on justified sequences of nodes.

Let $A$ be a subset of $V$, the set of nodes and leaves of $\tau(M)$, and $t$ be a justified sequence of nodes then we write $t\filter A$ for the subsequence of $t$ consisting of nodes in $A$.

\begin{definition}[Hereditary filtering]
Let $t$ be a justified sequence of nodes of $\travset(M)$ and
$n$ be some occurrence in $t$ of a node in $N_\lambda$.

We define the justified sequence $t \filter n$ as the subsequence of $t$ consisting of nodes hereditarily justified by the occurrence $n$ in $t$.
This operation can cause variable nodes to lose some of their pointers. If the main pointer of variable node is
lost then it is replaced in $t\filter n$ by a link pointing to the occurrence $n$.
\end{definition}
Thus $s \filter n$ is a valid justified sequence of nodes of the tree $\tau(\kappa(n))$.

\begin{lemma}
\label{lem:filtercontinous}
The filtering function $\_ \filter n$ defined on the cpo of justified sequences ordered by the prefix ordering is continuous.
\end{lemma}
\begin{proof}
Clearly $\_ \filter n$ is monotonous.
Suppose that $(t_i)_{i\in\omega}$ is a chain of justified sequences. Let $u$ be a finite prefix of $(\bigvee t_i) \filter n$.
Then $u = s \filter n$ for some finite prefix $s$ of $\bigvee t_i$. Since $s$ is finite we must have $s \prefixof t_j$ for some $j\in\omega$.
Therefore $u \prefixof t_j \filter n \prefixof \bigvee (t_j \filter  n)$.
This is valid for any finite prefix $u$ of $(\bigvee t_i) \filter n$ thus $(\bigvee t_i) \filter  n \prefixof \bigvee (t_j \filter n)$.
\end{proof}


The nodes occurrences that do not have pointers in a justified
sequence are called \defname{initial occurrences}. An initial
occurrence is necessarily either the root of the computation tree,
an @-node or a $\Sigma$-node. Let $n$ be occurrence in a justified
sequence of nodes $t$. We call
\defname{thread of the occurrence $n$} the subsequence of $t$
consisting of occurrences that are her.\ just.\ by the same initial
occurrence. In other words the thread of $n$ is $n \filter i$ where
$i$ is the first node in $t$ hereditarily justifying $n$; $i$ is
called the \defname{initial occurrence of the thread of $n$}.

\subsubsection{Views}
The notion of \defname{P-view} $\pview{t}$ of a justified sequence
of nodes $t$ is defined the same way as the P-view of a justified
sequences of moves in Game Semantics:

\begin{definition}[P-view of justified sequence of nodes]
The P-view of a justified sequence of nodes $t$ of $\tau(M)$, written $\pview{t}$, is defined as follows:
$$\begin{array}{rcll}
 \pview{\epsilon} &=&  \epsilon \\
 \pview{s \cdot n }  &=&  \pview{s} \cdot n
    & \mbox{for $n \in N_{\sf var} \union N_\Sigma \union N_@ \union L_\lambda$;}
    \\
 \pview{\Pstr[10pt]{ s \cdot (m){m} \cdot \ldots \cdot (lmd-m,25){n}}} &=&
        \Pstr{ \pview{s} \cdot (m2){m} \cdot (lmd2-m2,60){n} }
    & \mbox{for $n \in L_{\sf var} \union L_\Sigma \union L_@ \union N_\lambda$;}
    \\
 \pview{s \cdot r }  &=&  r
    & \mbox{if $r$ is an occurrence of the root of the tree $\tau(M)$. }
\end{array}$$
The equalities in the definition determine pointers implicitly. For
instance in the second clause, if in the left-hand side, $n$ points
to some node in $s$  that is also present in $\pview{s}$ then in the
right-hand side, $n$ points to that occurrence of the node in
$\pview{s}$.
\end{definition}

The O-view of $s$, written $\oview{s}$, is defined dually.
\begin{definition}[O-view of justified sequence of nodes]
\label{dfn:oview} The O-view of a justified sequence of nodes $t$ of
$\tau(M)$, written $\oview{t}$, is defined as follows:
$$\begin{array}{rcll}
 \oview{\epsilon} &=&  \epsilon \\
 \oview{s \cdot n }  &=&  \oview{s} \cdot n
    & \mbox{for $n \in L_{\sf var} \union L_\Sigma \union L_@ \union N_\lambda$;}
    \\
 \oview{\Pstr[10pt]{s \cdot (m){m} \cdot \ldots \cdot (x-m,30){n}}} &=&
    \Pstr{ \oview{s} \cdot (m2){m} \cdot (n2-m2,60){n} }
    & \parbox[t]{10cm}{for $n \in N_{\sf var} \union L_\lambda$ (if $n \in N_{\sf var}$ then the pointer considered is its main link);}
    \\
 \oview{s \cdot n }  &=&  n
    & \mbox{for $n \in N_@ \union N_\Sigma$ }
\end{array}$$
\end{definition}

We borrow some game semantic terminology:
\begin{definition} A justified sequence of nodes $s$ satisfies:
\begin{itemize}[-]
\item \defname{Alternation} if for any two consecutive nodes in $s$, one is in $V_\lambda$ and not the other one;
\item \defname{P-visibility} if for every variable node in $s$, all its justifiers (main and auxiliaries) occur in the P-view a that point;
\item  \defname{O-visibility} if the justifier of each lambda node in $s$ occurs in the O-view a that point.
\end{itemize}
\end{definition}

\begin{property}
\label{proper:pview_visibility}
The P-view (resp. O-view) of a justified sequence verifying P-visibility (resp. O-visibility)
is a well-formed justified sequence verifying P-visibility (resp. P-visibility).
\end{property}
This is proved by an easy induction.


\subsection{Traversal of the computation tree}
\label{subsec:traversal}
A \emph{traversal} is a justified sequence of nodes of the computation tree where each node indicates a step that is taken during the evaluation of the term.

\subsubsection{Traversals for simply-typed $\lambda$-terms}

We first consider the simply-typed $\lambda$-calculus without interpreted constants.
Everything remains valid in the presence of \emph{uninterpreted} constants as we can just
consider them as free variables.

We define the notion of traversal over the computation tree $\tau(M)$.
We will then we show how to extend the notion of traversal to more general settings with interpreted constants.

\begin{definition}[Traversals for simply-typed $\lambda$-terms] \rm
\label{def:traversal} The set $\travset(M)$ of \defname{traversals}
over $\tau(M)$ is defined by induction over the rules of Table \ref{tab:trav_rules}.
A traversal that cannot be extended by any rule is said to be \emph{maximal}.
\end{definition}

\begin{FramedTable}
\noindent {\bf Initialization rules}
\begin{description}
\item[\rulenamet{Empty}] $\epsilon \in \travset(M)$.
\item[\rulenamet{Root}] The sequence constituted of a single occurrence of $\tau(M)$'s root is a traversal.
\end{description}

\noindent {\bf Structural rules}
\begin{description}
    \item[\rulenamet{Lam}] If $t \cdot \lambda \overline{\xi}$ is a traversal then so is
        $t \cdot \lambda \overline{\xi} \cdot n$ where $n$ denotes
        $\lambda \overline{\xi}$'s child and:
        \begin{compactitem}
            \item If $n \in N_@ \union N_\Sigma$ then it has no justifier;
            \item If $n \in N_{\sf var}$ then it has auxiliary links pointing to each of the prime $\lambda$-nodes in $\pview{t\cdot
                \lambda \overline{\xi}}$ and:
                \begin{compactitem}
                    \item if  $n \not\in N_{\sf fv}$ then its main link points to the only occurrence\footnote{We will show in
                    Prop. \ref{prop:pviewtrav_is_path} that P-views correspond to
                    paths in the tree thus $n$'s enabler occurs exactly once in the
                    P-view.} of its enabler in
                    $\pview{t\cdot \lambda \overline{\xi}}$;
                    \item if  $n \in N_{\sf fv}$ then its main link points
                    to the only occurrence of the root in
                    $\pview{t \cdot \lambda \overline{\xi}}$.
                \end{compactitem}
        \end{compactitem}
    \item[\rulenamet{App}] If $t \cdot @$ is a traversal then so is \Pstr[0.4cm]{t \cdot (m) @  \cdot (n-m,40:0) n}.
\end{description}

\emph{\bf Input-variable rules}
\begin{description}
\item[\rulenamet{InputValue}] If $t_1 \cdot x \cdot t_2$ is a traversal
where $x \in N_{\sf var}^{\theroot\vdash}$ is the pending node then so is \Pstr[0.5cm]{t_1 \cdot
(x){x} \cdot t_2 \cdot (xv-x,38:v){v_x} } for all $v \in
\mathcal{D}$.

\item[\rulenamet{InputVar}] If $t$ is a traversal with pending node  $x \in N_{\sf var}^{\theroot\vdash}$ then so is $t \cdot n$ for any $\lambda$-node $n$ whose parent occurs in  $\oview{t_{\prefixof x}}$, $n$ pointing to some occurrence of its  parent node in $\oview{t_{\prefixof x}}$.
\end{description}

\emph{\bf Copy-cat rules}
\begin{description}
\item[\rulenamet{Value$^{\lambda\mapsto@}$}]
  If \Pstr{t \cdot (app){@} \cdot (lz-app,60:0){\lambda
\overline{z}}  \ldots  (lzv-lz,60:v){v}_{\lambda \overline{z}} }
is a traversal then so is \Pstr[0.5cm]{t \cdot (app){@} \cdot
(lz-app,60){\lambda \overline{z}} \ldots
(lzv-lz,60:v){v}_{\lambda \overline{z}} \cdot
(appv-app,45:v){v}_@}.

\item[\rulenamet{Value$^{@\mapsto\lambda}$}] If \Pstr[0.4cm]{t \cdot \lambda \overline{\xi} \cdot (x){@}  \ldots   (xv-x,50:v){v}_@}
is a traversal then so is \Pstr[0.5cm]{t \cdot (lmd){\lambda
\overline{\xi}} \cdot (x){@}  \ldots  (xv-x,50:v){v}_@  \cdot
(lmdv-lmd,33:v){v}_{\lambda \overline{\xi}} }.

\item[\rulenamet{Value$^{\lambda\mapsto{\sf var}}$}] If \Pstr[0.4cm]{t \cdot y \cdot (lmd){\lambda \overline{\xi}}
\ldots (lmdv-lmd,50:v){v}_{\lambda \overline{\xi}} } is a
traversal where $y\in N_{\sf var}^{@\vdash}$ then so is \Pstr[0.5cm]{t \cdot (y){y} \cdot (lmd){\lambda
\overline{\xi}} \ldots (lmdv-lmd,30:v){v}_{\lambda
\overline{\xi}}  \cdot (vy-y,50:v){v}_y }.

\item[\rulenamet{Value$^{{\sf var}\mapsto\lambda}$}] If \Pstr[0.4cm]{t \cdot \lambda \overline{\xi} \cdot (x){x}  \ldots   (xv-x,50:v){v}_x}
is a traversal where $x\in N_{\sf var}$ then so is \Pstr[0.5cm]{t \cdot (lmd){\lambda
\overline{\xi}} \cdot (x){x}  \ldots  (xv-x,50:v){v}_x  \cdot
(lmdv-lmd,30:v){v}_{\lambda \overline{\xi}} }.
\end{description}

\begin{description}
\item[\rulenamet{Var}]
If \Pstr[0.5cm]{t' \cdot (n){n} \cdot (lx){\lambda \overline{x}}
    \ldots (x-lx,50:i){x_i} } is a traversal where
    $x_i \in N_{\sf var}^{@\vdash}$ then
so is \Pstr[0.5cm]{ t' \cdot (n){n} \cdot
    (lx){\lambda \overline{x}}  \ldots (x-lx,30:i){x_i}  \cdot
    (letai-n,40:i){\lambda \overline{\eta_i}}
     }.
\end{description}
\caption[Traversal rules for the simply-typed
lambda-calculus]{Traversal rules for the simply-typed
$\lambda$-calculus.} \label{tab:trav_rules}
\end{FramedTable}

A traversal always starts with the root node and mainly follows the
structure of the tree. The exception is the \rulenamet{Var} rule
which permits the traversal to jump across the computation tree. The
idea is that after visiting a non-input variable node $x$, a jump
can be made to the node corresponding to the subterm that would be
substituted for $x$ if all the $\beta$-redexes occurring in the term
were to be reduced. Let $\lambda \overline{x}$ be $x$'s binder and
suppose $x$ is the $i$th variable in $\overline{x}$. The binding
node necessarily occurs previously in the traversal (this will be
proved in Prop. \ref{prop:pviewtrav_is_path}). Since $x$ is not
hereditarily justified by the root, $\lambda \overline{x}$ is not
the root of the tree and therefore it is not the first node of the
traversal. We do a case analysis on the node preceding $\lambda
\overline{x}$:
    \begin{itemize}
    \item If it is an @-node then $\lambda \overline{x}$ is necessarily the first child node of that node
    and it has has exactly $|\overline{x}|$ siblings:
    $$\pstree[levelsep=7ex]{\TR{\stackrel{\vdots}{@}}}
    {   \pstree[linestyle=dotted,levelsep=4ex]{\TR{\lambda \overline{x}}\treelabel{0}}
            {\TR{x }}
        \tree{\lambda \overline{\eta_1}}{\vdots}\treelabel{1}
        \TR[edge=\dotedge]{}
        \tree{\lambda \overline{\eta_i}}{\vdots}\treelabel{i}
        \TR[edge=\dotedge]{}
        \tree{\lambda \overline{\eta_{|x|}}}{\vdots}\treelabel{|x|}
    }
    $$
    In that case, the next step of the traversal is a jump to $\lambda \overline{\eta_i}$ -- the $i$th child of
    @ -- which corresponds to the subterm that would be substituted for $x$ if the $\beta$-reduction was
    performed:
    $$\Pstr[19pt]{ t' \cdot
            (n){@} \cdot
            (lx){\lambda \overline{x}} \cdot \ldots \cdot
            (x-lx,40:i){x} \cdot
            (mi-n,40:i){\lambda \overline{\eta_i}} \cdot \ldots
            \in {\travset(M)}   }
    $$

    \item If it is a variable node $y$, then
    the node $\lambda \overline{x}$ was necessarily added to the traversal $t_{\leq y}$ using the \rulenamet{Var} rule (see proposition \ref{prop:pviewtrav_is_path}(i)).
    Therefore $y$ is substituted by the term $\kappa(\lambda \overline{x})$ during the evaluation of the term.

    Consequently, during reduction, the variable $x$ will be substituted by the subterm represented by
    the $i$th child node of $y$. Hence the following justified sequence is also a traversal:
    $$\Pstr[18pt]{ t' \cdot
            (y){y} \cdot
            (lx){\lambda \overline{x}} \cdot \ldots \cdot
            (x-lx,40:i){x} \cdot
            (mi-y,40:i){\lambda \overline{\eta_i}} \cdot \ldots
    }
    $$
    \end{itemize}

\begin{remark}
Our notions of computation tree and traversal differ slightly from \cite{OngLics2006}:
\begin{itemize}[-]
    \item In \cite{OngLics2006} computation trees can have uninterpreted first-order constants. But as we have already observed, uninterpreted constants can be just regarded as free variables thus we do not lose any expressivity here.

    \item In \cite{OngLics2006}, constants are restricted to order one at most since computation tree
    are used to model computation of tree structures. Here we don't need this restriction (as long as constants are uninterpreted - so we can regard them as free variables).


    \item In our setting, we have to deal with \emph{free} variables.
    To model free variables we need the traversal rules \rulenamet{InputValue}, \rulenamet{InputVar}
    as well as the copy-cat answer rules. Whereas in \cite{OngLics2006}, the rule called \rulenamet{Sig} suffices to model the first-order constants necessary to construct tree structures.

    \item In our setting, the introduction of value-leaves
    is necessary in order to model free variables as well as interpreted constants. (We will use them to model the constants of \pcf\ and \ialgol).
    \end{itemize}
\end{remark}

\begin{example}
Consider the following computation tree:
$$\tree{\lambda}
{
    \tree[nodesep=4pt]{@}
    {
        \pstree[levelsep=8ex,linestyle=dotted]{\TR{\lambda y}\treelabel{0} }
        {
            \pstree[levelsep=8ex]{\TR{y}}
            {
                \tree{\lambda \overline{\eta_1}}{\vdots} \treelabel{1}
                \TR[edge=\dotedge]{}
                \tree{\lambda \overline{\eta_i}}{\vdots}\treelabel{i}
                \TR[edge=\dotedge]{}
                \tree{\lambda \overline{\eta_n}}{\vdots}\treelabel{n}
            }
        }
        \pstree[levelsep=6ex,linestyle=dotted]{\TR{\lambda \overline{x}}\treelabel{1}}{ \tree{x_i}{\TR{} \TR{} } }
    }
}
$$
An example of traversal of this tree is:
\vspace{0.3cm}
$$ \Pstr{ \lambda \cdot
            (app){@}  \cdot
            (ly){\lambda y} \cdot \ldots \cdot
            (y-ly,40:1){y} \cdot
            (lx-app,50:1){\lambda \overline{x}} \cdot \ldots \cdot
            (x-lx,40:i){x_i} \cdot
            (leta-y,50:i){\lambda \overline{\eta_i} } \cdot \ldots
        }$$
\end{example}

\subsubsection{Traversals for interpreted constants}

In the presence of higher-order interpreted constants, additional rules must be specified to indicate how
the constant nodes should be traversed in the computation tree. These rules are specific to the language that is being studied.
In the last section of this chapter we will define such traversals for the interpreted constants of
\pcf\ and \ialgol.

From now on, we consider a simply-typed $\lambda$-calculus language extended with higher-order interpreted constants for which some constant traversal rules have been defined and
we take as a  prerequisite that all the constant rules are well-behaved in the following sense:
\begin{definition}[Well-behaved traversal rule]
\label{def:wellbehaved_traversal} A traversal rule is
\defname{well-behaved} if it can be stated under one of the following two forms:
    $$\rulename{\Sigma\mbox{-Value}}\ \rulef{t = t_1\cdot \alpha \cdot t_2 \in \travset(M) \quad ?(t)^\omega = \alpha \quad P(t)}
      {
        \stackrel{\rule{0pt}{3pt} }{
            \Pstr[8pt]{ t' = t_1\cdot (\alpha){\alpha} \cdot t_2 \cdot (v-c,35){v(t)} \in {\travset(M)}}
            }
       }
       $$
or
$$\rulename{\Sigma}/\rulename{\Sigma\mbox{-Var}}\ \rulef{t \in \travset(M) \quad ?(t)^\omega = \alpha \quad P(t)}
  { \stackrel{  \rule{0pt}{3pt} }{\Pstr[5pt]{ t \cdot {n(t)} \in {\travset(M)}}}
   }$$
    where:
    \begin{compactitem}
      \item $\alpha$ is a constant node or a variable node her.\ just.\ by some constant node ($\alpha \in N_\Sigma \union N^{N_\Sigma\vdash}_{\sf var}$);
      \item $P(t)$ is a predicate expressing some condition on $t$;
      \item $v(t)$ is a value-leaf of the constant node $c$ that is determined by the traversal $t$;
      \item $n(t)$ is a lambda-node determined by $t$, and its link, also determined by $t$, points to some occurrence of its parent node in $\oview{t_{\prefixof \alpha}}$.
    \end{compactitem}
%\end{enumerate}
Clearly, such rules preserve well-bracketing, alternation and visibility.
\end{definition}

In addition, we complete the constant rules with the  copy-cat rule:
\begin{quote}
\rulenamet{Value$^{\Sigma\mapsto\lambda}$} If \Pstr[0.4cm]{t \cdot \lambda \overline{\xi} \cdot (x){c}  \ldots   (xv-x,50:v){v}_c}
is a traversal where $c\in\Sigma$ then so is \Pstr[0.5cm]{t \cdot (lmd){\lambda
\overline{\xi}} \cdot (x){c}  \ldots  (xv-x,50:v){v}_c  \cdot
(lmdv-lmd,33:v){v}_{\lambda \overline{\xi}} }.
\end{quote}




\begin{remark}
    We observe that the well-behaved rules give a generalized
    version of the rules \rulenamet{InputValue} and \rulenamet{InputVar}: The extra power of the well-behaved rules over the input-variable rules lies in their ability to restrict the set of possible nodes to visit depending on the shape of the traversal $t$.
    This suggests that interpreted constants can be seen as a generalization of the notion of free variable (whereas uninterpreted constants and free variables can be identified).
\end{remark}

\subsubsection{Property of traversals}

\begin{proposition}[counterpart of proposition 6 from \cite{OngHoMchecking2006}]
\label{prop:pviewtrav_is_path}
Let $t$ be a traversal. Then:
\begin{itemize}
\item[(i)] $t$ is a well-defined and well-bracketed justified sequence;
\item[(ii)] $t$ is a well-defined justified sequence verifying alternation, P-visibility and O-visibility;
\item[(iii)] If $t^\omega \not\in L_\lambda$ {\it i.e.}~$t$'s last occurrence is not a lambda value-leaf, then $\pview{t}$ is the path in the computation tree going from the root to the node $t^\omega$.
\end{itemize}
\end{proposition}

This is the counterpart of proposition 6 from
\cite{OngHoMchecking2006} which is proved by induction on the
traversal rules. This proof can be easily adapted to take into
account the constant rules (using the assumption that constants
rules are well-behaved) and the presence of value-leaves in the
traversal.
\begin{proof}
The proof of (i), (ii) and (iii) is done simultaneously by induction on the traversal rules. We consider the rules \rulenamet{Var} and \rulenamet{Lam} only.

Rule \rulenamet{Var}: we just give a partial proof of (i). See proposition 6 from \cite{OngHoMchecking2006} for the details of (i), (ii) and (iii). We have to show that in the second case of the \rulenamet{Var} rule, where $p$ is a variable node $y$, the node $\lambda \overline{x}$ has necessarily been added to the traversal $t_{\leq y}$ using the \rulenamet{Var} rule. This is immediate since if the rule \rulenamet{InputVar} was used to produce $t_{<y} \cdot y \cdot \lambda \overline{x}$ this would imply that $\lambda \overline{x}$ is hereditarily justified by the root which in turn implies that $x_i$ is an input-variable which contradicts \rulenamet{Var}'s hypothesis.

Rule \rulenamet{Lam}: we need to show that $n$'s main enabler occurs only once in the P-view at that point. By the induction hypothesis we have (by (iii)) that $\pview{t \cdot \lambda \overline{\xi}}$ is a path in the computation tree from the root to $\lambda \overline{\xi}$. $n$'s main enabler occurs only once in this path: it is precisely it's binding node. Therefore the traversal $t \cdot \lambda \overline{\xi} \cdot n$ is well-defined. Furthermore all the auxiliary justifiers of $n$ occurs in the P-view therefore $t \cdot \lambda \overline{\xi} \cdot n$ satisfies P-visibility. Thus (i) and (ii) are verified. Furthermore $n$ is a child of $\lambda \overline{\xi}$ therefore (iii) also holds.

For the constant rules, the proof relies on the fact that these rules are well-behaved.
\end{proof}

%In particular to prove that the copy-cat rules are well-defined, one needs to ensure that
%if the last two unmatched nodes are $y$ and $\lambda \overline{\xi}$ in that order, for some non input-variable node $y$ then necessary
%      $y$ and $\lambda \overline{\xi}$ are consecutive nodes in the traversal.
%    This is because in a traversal, a non input-variable $y$ is always followed by a lambda node and whenever this lambda node is answered
%    there is only one way to extend the traversal : by using the copy cat rule to answer the $y$ node.
\begin{remark}
\label{rem:inputvar_bis}
It is easy to check from the definition of traversals that the pending node always occur in the O-view. Consequently, the rule:
\begin{quote}
\rulenamet{InputVar} If $t$ is a traversal with pending node  $x \in N_{\sf var}^{\theroot\vdash}$ then so is $t \cdot n$ for any $\lambda$-node $n$ whose parent occurs in  $\oview{t_{\prefixof x}}$, $n$ pointing to some occurrence of its  parent node in $\oview{t_{\prefixof x}}$.
\end{quote}
\noindent can be reformulated equivalently as:
\begin{quote}
\rulenamet{InputVar} If $t$ is a traversal with
$t^\omega \in N_{\sf var}\union L_\lambda$ and $t$ contains some unmatched node $y$ in $N_{\sf var}^{\theroot\vdash}$ appearing in $\oview{t}$ then so is $t \cdot n$ for any child node $n$ of $y$, $n$ pointing to $y$.
\end{quote}
\end{remark}

\begin{lemma}
\label{lem:trav_last_not_leaf} If $t \cdot n $ is a traversal with
$n \in N_{\sf var} \union N_\Sigma \union N_@$ then $t^\omega$ is a
lambda node and is $n$'s parent in $\tau(M)$. (Thus $t^\omega$ is
not a leaf: $n\not\in L$).
\end{lemma}
\begin{proof}
By inspecting the traversal rules, we observe that \rulenamet{Lam}
is the only rule  which can visit a node in $N_{\sf var} \union
N_\Sigma \union N_@$. Hence $t'^\omega$ must be $n$'s parent in
$\tau(M)$.
\end{proof}

\subsubsection{Traversal reduction}



\begin{definition}
The \defname{reduction of a traversal} $t$ is define as the subsequence $t\filter r$ where $r$ denotes the only occurrence of $\tau(M)$'s root in $t$.
\end{definition}
The effect of this transformation is the elimination of the
``internal nodes'' of the computation. Since @-nodes and
$\Sigma$-constants do not have pointers, the reduction of traversal
contains only nodes in $V_\lambda \union V_{\sf var}$.

We define the set
$$\travset(M)^{\filter r} = \{ t  \filter r \ | \  t  \in \travset(M) \} \ . $$


\begin{lemma}[Traversal of $\beta$-normal terms]
\label{lem:betaeta_trav}
Let $M$ be a $\beta$-normal term, $r$ be the root of the tree $\tau(M)$ and
$t$ be a traversal of $\tau(M)$.
For any node $n$ occurring in $t$ we have:
$$ n \not\in N^{\theroot\vdash} \quad \iff \quad n \in N^{N_{\Sigma}\vdash}$$
{\it i.e.}~ $r$ does not hereditarily enable $n$ if and only if $n$ is
hereditarily enabled by some node in $N_\Sigma$.
\end{lemma}
\begin{proof}
 In a computation tree, the only nodes that do not have justification pointer are:
the root $r$, @-nodes and $\Sigma$-constant nodes. But since $M$ is
in $\beta$-normal form, there is no @-node in the computation tree.
Hence nodes are either hereditarily enabled by $r$ or hereditarily
enabled by some node in $N_\Sigma$. Moreover $r$ is not in $N_\Sigma$
therefore the ``or'' is exclusive : a node cannot be both hereditarily
enabled by $r$ and by some node in $N_\Sigma$.
\end{proof}




\subsubsection{Removing @-nodes from traversals}

When defining computation trees, it was necessary to introduce
application nodes (labelled @) in order to connect the operator and
the operand of an application. The presence of @-nodes has also
another advantage: it ensures that the lambda-nodes are all at even
level in the computation tree, and thus a traversal respects a
certain form of alternation between lambda nodes and non-lambda
nodes. Application nodes are however redundant in the sense that
they do not play any role in the computation of the term. In fact it
will be necessary to filter them out in order to establish the
correspondence with the interaction game semantics.

\begin{definition}[@-free traversal]
\label{dfn:appnode_filter} Let $t$ be a traversal of $\tau(M)$. We
write $t-@$ for the sequence of nodes-with-pointers obtained by
\begin{itemize}
\item removing from $t$ all @-nodes and value-leaves of some @-node;
\item replacing any link pointing to an @-node by a link pointing to the immediate predecessor of @ in $t$.
\end{itemize}

Suppose $u = t-@$ is a sequence of nodes obtained by applying the
previously defined transformation on the traversal $t$, then $t$ can
be partially recovered from $u$ by reinserting the @-nodes as
follows. For each @-node in the computation tree with parent node
denoted by $p$, we perform the following operations:
\begin{enumerate}
\item replace every occurrence of the pattern $p \cdot n$ for some $\lambda$-node
$n$,
by $p \cdot @ \cdot n$;
\item replace any link in $u$ starting from a $\lambda$-node and pointing to $p$ by a link pointing to the inserted @-node;
\item if there is an occurrence in $u$ of a value-leaf $v_p$ pointing to $p$ then insert a value-leaf $v_@$
immediately before $v_p$ and make it point to the node
immediately following $p$ (which is also the $@$-node that we
inserted in 1).
\end{enumerate}
We write $u+@$ for this second transformation.
\end{definition}
These transformations are well-defined because in a traversal, an
@-node always occurs in-between two nodes $n_1$ and $n_2$ such that
$n_1$ is the parent node of @ and $n_2$ is the first child node of @
in the computation tree:
$$      \pstree[levelsep=4ex]{\TR{n_1}\treelabel{0} }
        {
            \pstree[levelsep=3ex]{\TR{@}}
            {
                \tree{n_2}{\vdots}
                \TR[edge=\dedge]{}
                \TR[edge=\dedge]{}
            }
        }
$$
\begin{lemma} \label{lem:minus_at_plus_at}
$$\forall t \in \travset(M), \quad (t-@)+@ = \left\{
            \begin{array}{ll}
              t, & \hbox{if $t^\omega \neq @$\ ;} \\
              \ip\ t, & \hbox{if $t^\omega = @$\ .}
            \end{array}
          \right.
$$
\end{lemma}
\proof The result follows immediately from the definition of the
operation -@ and +@. \qed
\bigskip

We introduce the following set:
$$
\travset(M)^{-@} = \{ t - @ \ | \  t \in \travset(M) \} \ .
$$

\begin{remark}
Sequences from $\travset(M)^{-@}$ are not, strictly speaking, proper
justified sequences of nodes since after removing @-nodes, all prime
$\lambda$-nodes become justified by their parent's parent which are
also $\lambda$-nodes! Also these sequences do not respect
alternation since two $\lambda$-nodes may become adjacent after
removing a @-node.
\end{remark}


\subsubsection{Removing $\Sigma$-nodes from traversals}

We introduce an operation similar to $-@$ that eliminates the
$\Sigma$-nodes from a traversal.

\begin{definition}[Hiding $\Sigma$-constants in the traversals]
Let $t$ be a traversal of $\tau(M)$. We write $t-\Sigma$ for the
sequence of nodes with pointers obtained by
\begin{itemize}
\item removing from $t$ all nodes labelled with a $\Sigma$-constant or value-leaf justified by a $\Sigma$-constant,
\item replacing any link pointing to a $\Sigma$-constant $f$
by a link pointing to the immediate predecessor of $f$ in $t$.
\end{itemize}

Suppose $u = t-\Sigma$ is a sequence of nodes obtained by applying
the previously defined transformation on the traversal $t$, then $t$
can be partially recovered from $u$ by reinserting the
$\Sigma$-nodes as follows. For each $\Sigma$-node $f$, where $p$
denotes the parent node of $f$, do the following:
    \begin{enumerate}
    \item replace every occurrence of the pattern $p \cdot n$ in $u$ where
    $n$ is a $\lambda$-node by $p \cdot f \cdot n$;

    \item replace any link in $u$ starting from a $\lambda$-node and pointing to $p$ by a link pointing to the inserted node $f$;

    \item for each occurrence in $u$ of a value-leaf $v_p$ pointing to $p$, add the value-leaf $v_f$
    immediately before $v_p$. The links of $v_f$ points to the
    node immediately following $p$.
    \end{enumerate}
We write $u+\Sigma$ for this second transformation.
\end{definition}
These transformations are well-defined since in a traversal, a
$\Sigma$-node $f$ always follows immediately its parent
$\lambda$-node $p$, and an occurrence of a value-node $v_p$ always
follows immediately a value-node $v_f$. In other words, if $f$
occurs in $t$ then $t$ must be a prefix of a traversal of the
following form for some $v \in \mathcal{D}$:
$$ \Pstr{ \ldots \cdot (p){p} \cdot (f){f} \cdot \ldots \cdot (vf-f){v_f} \cdot (vp-p){v_p} \cdot \ldots }$$

Remark: $t-\Sigma$ is not a proper traversal since it does not
satisfy alternation. It is not a proper justified sequence either
since after removing a $\Sigma$-node $f$, any $\lambda$-node
justified by $f$ will become justified by the parent of $f$ which is
also a $\lambda$-node.

The following lemma follows directly from the definition:
\begin{lemma} \label{lem:minus_sig_plus_sig}
$$\forall t \in \travset(M), \quad (t-\Sigma)+\Sigma = \left\{
            \begin{array}{ll}
              t, & \hbox{if $t^\omega \neq \Sigma$\ ;} \\
              \ip\ t, & \hbox{if $t^\omega = \Sigma$\ .}
            \end{array}
          \right.
$$
\end{lemma}

\subsubsection{Removing both @-nodes and $\Sigma$-nodes from traversals}
\label{sec:tstar}
The operations $-@$ and $-\Sigma$ are commutative:
$(t-@)-\Sigma = (t-\Sigma)-@$. We write $t^\star$ to denote
$(t-@)-\Sigma$ {\it i.e.}\ the sequence obtained from $t$ by
removing all the @-nodes as well as the constant nodes together with
their associated value-leaves. We introduce the set
$$\travset(M)^\star = \{ t^\star \ | \  t \in \travset(M) \} \ .$$

\begin{remark}
If $M$ is $\beta$-normal and if there are no $\Sigma$ constant then $\tau(M)$ does not contain any @-node
or $\Sigma$-node therefore all nodes are hereditarily justified by $r$ and we have
$ \travset(M) = \travset(M)^{\filter r} = \travset(M)^{-@} = \travset(M)^\star$.
\end{remark}


Since sequences in $\travset(M)^\star$ are not strictly speaking
proper justified sequences, the operations that we have defined for
justified sequences are undefined on $\travset(M)^\star$. However we
can extend the hereditary filtering operation to sequences of
$\travset(M)^\star$: for $u\in \travset(M)^\star$ and $n$ some node
occurrence in $u$, the sequence $u\filter n$ is defined to be the
subsequence of $u$ consisting of nodes that are hereditarily
justified by $n$. Note that since the operation $-@$ and $-\Sigma$ change the
justification pointers, the hereditary justification relation nodes
of a traversal $t$ is different from the hereditary justification
relation of the sequence $t^\star$. In fact we have $(t\filter n)-@ \subseqof (t-@)
\filter n_0$ but $(t\filter n)-@ \neq (t-@) \filter n$ (and similarly for the operation $-\Sigma$).

Let us write $t^+$ for the sequence-with-pointers obtained from $t$
by adding further pointers as follows: for every occurrence of a $@$
or $\Sigma$ node $m$ in $t$ we add a pointer going from $m$ to its
predecessor in $t$ (which is necessarily an occurrence of its parent
node). Clearly we have:
\begin{equation}
t^\star \filter r_j = (t\filterplus r_j)^\star \label{eqn:starfilter_filterplusstar} \ .
\end{equation}

For any traversal $t\in \travset(M)$ and node $n$ occurring in $t$,
we write $t \filterplus n$ to denote the sequence $t^+ \filter n$:
the sequence of nodes in $t$ that are hereditarily justified by $n$
\emph{with respect to the justification pointers of $t^+$}. In
essence, the effect of this operation is to compute the sequence
$((t-@-\Sigma)\filter n)+\Sigma+@$ (provided that $t$ does not end
with an @/$\Sigma$-node).

We extend this definition to any subsequence of $t$: if $s$ is a
justified subsequence of $t$ then $s \filterplus n$ denotes the
sequence of nodes in $s$ that are hereditarily justified by $n$
\emph{in $t^+$}.


If $n$ is an occurrence of a lambda node $r' \in N_\lambda$ then we
will call $t \filterplus n$ a \defname{sub-traversal of the
computation tree $\tau(M)$}. This appellation will be justified by
Proposition \ref{prop:trav_filtering} stating that $t \filterplus n$
is a traversal of the sub-computation tree of $\tau(M)$ rooted at
$r'$.
\bigskip


\begin{lemma}
\label{lem:he_filter_root_is_hj_filter_r}
For any non-empty traversal $t$ we have  $t^\star\filter V^{\theroot\vdash} = t \filter r$
where $r$ denotes the only occurrence of the root in $t$.
\end{lemma}
\begin{proof}
The result follows immediately from the following two observations:

Nodes that are not her.\ just.\ by $r$ in $t$ may become
her.\ just.\ by $r$ in $t^\star$, however these nodes are not hereditarily \emph{enabled}
 by $\tau(M)$'s root and thus are not in $V^{\theroot\vdash}$.

Reciprocally, all the nodes that are hereditarily justified by $r$ in $t$ are necessarily
hereditarily \emph{enabled} by the root and also appear in $t^\star$.
\end{proof}


\begin{lemma}
\label{lem:ifin_tfilterstar_so_does_justifier}
Let $t$ be a traversal
and  $r_0$ be an occurrence of a lambda node $r'$ in $t$.
\begin{compactitem}
  \item Suppose that \Pstr[0.5cm]{t = \ldots (j){j} \ldots (vj-j){v_j}} with $v_j \in L = L_@ \union L_\Sigma \union L_{\sf var} \union L_\lambda$.
      Then $v_j$ appears in $t\filterplus r_0$ if and only if
      $j$ appears in $t\filterplus r_0$.
  \item Suppose that \Pstr[0.5cm]{t = \ldots (j){j} \ldots (n-j){\lambda \overline{\xi}}} where $\lambda \overline{\xi} \in N_\lambda$
          and $\lambda \overline{\xi} \neq r_0$.
          Then $\lambda \overline{\xi}$ appears in $t\filterplus r_0$ if and only if $j$ appears in $t\filterplus r_0$.

  \item Suppose that \pstr[0.6cm]{t =
    \ldots \nd(j0){j_0}
    \ldots \nd(j1){j_1}
    \ldots \nd(jk){j_k}
    \ldots \nd(n-j0){y}
    \arrow{n}{j1}{30}{}{blue}{dashed}
    \arrow{n}{jk}{30}{}{blue}{dashed}
    } where $y\in N_{\sf var}$ and $j_0$ is $y$'s main justifier
    and $j_1$, \ldots $j_k$ are the auxiliary justifiers.
    Then $y$ appears in $t\filterplus r_0$ if and only if
      for some $i \in \{0..k\}$, $j_i$ appears in $t\filterplus r_0$.
\end{compactitem}
\end{lemma}
\begin{proof}
  It is a direct consequence of the definition of $t\filterplus r_0$: if $t$'s last occurrence is not $r_0$ then it appears in
  $t\filterplus r_0$ if and only if one of its justifiers appears in $t\filterplus r_0$.
\end{proof}
For the third case, we will see later on in Lemma
\ref{lem:ifvar_in_tfilterstar_sodoes_certain_of_its_justifier} that
in fact all $y$'s auxiliary justifiers occurring after $j_i$ must
also appear in $t\filterplus r_0$.


It is easy to see that because traversals are well-bracketed (Proposition \ref{prop:pviewtrav_is_path}), so are the sequences in $\travset^\star(M)$. Moreover:
\begin{lemma}
\label{lem:filterplus_pendingnode}
 Let $t \in \travset(M)$ and $r_0$ be the occurrence in $t$ of a $\lambda$-node $r'$.
 We have:
  $$?(t\filterplus r_0) =\ ?(t) \filterplus r_0 \ .$$
\end{lemma}
\proof
 By definition, the operation $t \filterplus r_0$ removes an occurrence of a value-leaf in $t$
if and only if it also removes its justifier. \qed
% end of proof


%\notetoself{unfinished proof:}
%\begin{lemma}
%Let $t$ be a traversal of $M$, $t'$ be a traversal of some subterm
%$M'$ such that $t'-@ \subseqof t-@$. Then we have $t'\subseqof t$.
%\end{lemma}
%\begin{proof}
%
%\end{proof}


\subsubsection{Sub-traversal filtering}

For any lambda node $r'$ in $N_\lambda$ we write
$M^{(r')}$ for the term $\kappa(r')$ and $V^{(r')}$ for the set of nodes and leaves of the sub computation tree $\tau(M^{(r')})$ (thus $V^{(r')} = E^*(\{r'\})$).

\begin{lemma}
\label{lem:instarfilter_imp_insubtree} Let $r_0$ be an occurrence in
$t$ of a lambda-node $r' \in N_\lambda$. If $n$ occurs in $t
\filterplus r_0$ then $n$ is in $V^{(r')}$.
\end{lemma}
\begin{proof}
Justification pointers attached to a node $n$ in $t^\star$ can only point to
 occurrences of nodes that lies in the path from $n$ to the root
 in the computation tree. Therefore if $n$ is her.\
 just.\ by $r_0$ in $t^\star$ then it must be in the subtree of $\tau(M)$ rooted
 at $r'$ and  therefore $n$ must belong to $V^{(r')}$.
\end{proof}


\begin{lemma}[Filtering of a traversal's P-view]
\label{lem:pview_trav_filtering}
   Let $t \in \travset(M)$ such that $t^\omega \not\in L_\lambda$.
        \begin{compactitem}
        \item[(a)] If $t^\omega$ belongs to $V^{(r')}$ for some lambda node $r'\in N_\lambda$
        ({\it i.e.}\ $t^\omega$ belongs to the subtree of $\tau(M)$ rooted at $r'$) then there is an occurrence $r_0$ of $r'$ in $t$ such that
        \begin{itemize}
        \item $\pview{t} = \ldots r_0 \cdot u$;
        \item all the occurrences in $u$ must appear in $t\filterplus r_0$ and do not appear
        in any sequence $t\filterplus r_1$ for any occurrence
        $r_1$ of $r'$ different from $r'$;
        \item $\pview{t}^M \filter V^{(r')} = r_0\cdot u =  \pview{t\filterplus r_0}^{M^{(r')}}$;
        \end{itemize}

        \item[(b)] If $t$'s last occurrence is not in $V^{(r')}$ then
        all the occurrences in $\pview{t}$ are not in
        $V^{(r')}$ and do not appear in any sequence $t\filterplus r_0$ for some
        occurrence $r_0$ of $r'$ in $t$.
        \end{compactitem}
\end{lemma}
\proof
Firstly we observe that the equality $\pview{t}^M \filter V^{(r')} = r_0\cdot u$
in the fourth point is implied by the third point. Indeed since $t$'s last move in not a lambda leaf,
by Proposition \ref{prop:pviewtrav_is_path}, the P-view $\pview{t_{\prefixof r_0}}^M$ is the path from $r'$ to the root of the computation tree therefore all the nodes preceding $r_0$ are not in $V^{(r')}$, and by the third point all the nodes in $u$ are in $V^{(r')}$.

We prove the result by induction on the traversal rules. The base cases \rulenamet{Empty} and
\rulenamet{Root} are trivial. \emph{Step case:} Take a traversal $t
\in \travset(M)$ such that $|t|>1$. We do a case analysis on the type of the last occurrence in $t$:
    \begin{compactitem}
    \item The cases $t = t' \cdot n$ with $n\in L_\lambda$ does not happen since by assumption $n$ is not a
    lambda leaf.

    \item If $t = t' \cdot n$ with $n \in N_{\sf var} \union
    N_\Sigma \union N_@$ then by lemma
    \ref{lem:trav_last_not_leaf}, $t'^\omega$ is $n$'s
    parent in $\tau(M)$.

    (a) Suppose $n$ is in $V^{(r')}$. Since $n$ is not a lambda
    node, its parent node $t'^\omega$ necessarily belong to
    $V^{(r')}$. Then by the induction hypothesis,
    $\pview{t'^\omega} = \ldots r_0 \cdot u$ where $r_0$ is
    an occurrence of $r'$ in $t^\star$ and all the nodes in
    $u$ appear in $t\filterplus r_0$ and not in any
    other sequence $t\filterplus r_1$ for any occurrence $r_1\neq r_0$ of $r'$. By P-visibility, $n$'s
    justifiers all appear in $\pview{t'}$:
    those occurring before $r_j$ do not belong
    to $V^{(r')}$ since they appear on the path from $r'$ to
    the root $r$; and those occurring in $u$ all appear in $t\filterplus r_0$.
    Consequently, $n$ must also appear in $t\filterplus r_0$ and not in any
    other sequence $t\filterplus r_1$ for any occurrence $r_1\neq r_0$ of $r'$.

    Moreover:
        \begin{align*}
        \pview{t}^M \filter V^{(r')}
    &= \pview{t' \cdot n}^M \filter  V^{(r')} & (\mbox{definition of } t)\\
            &= (\pview{t'}^M \cdot n) \filter  V^{(r')}  & (\mbox{P-view computation}) \\
            &= \pview{t'}^M \filter V^{(r')}  \cdot n             & \parbox[t]{6cm}{(\raggedleft since $n$ is in $V^{(r')}$ and where $n$'s justifiers are those from the sequence $t$ that are in $V^{(r')}$)} \\
            &= \pview{t' \filterplus  r_0 }^{M^{(r')}} \cdot n            & (\mbox{induction hypothesis}) \\
            &= \pview{t' \filterplus  r_0 \cdot n }^{M^{(r')}} & (\mbox{P-view in $M^{(r')}$}) \\
            &= \pview{(t' \cdot n ) \filterplus  r_0  }^{M^{(r')}}           & (\mbox{$n$ is her.\ just.\ by $r_0$ in $t^\star$}) \\
            &= \pview{t \filterplus  r_0  }^{M^{(r')}}
     & (\mbox{definition of } t).
        \end{align*}

    (b) Suppose $n$ is not in $V^{(r')}$ then necessarily its parent node $t'^\omega$ does not belong to $V^{(r')}$ either.
    Therefore by the induction hypothesis, all the nodes in $\pview{t'}$ do not belong to
    $t\filterplus r_0$ for any occurrence $r_0$ of $r'$. By P-visibility, $n$'s justifiers all appear in $\pview{t'}$ therefore, $n$ does not belong to $t\filterplus r_0$ for any occurrence $r_0$ of $r'$.


    \item If $\Pstr[0.6cm]{ t =  t' \cdot (m){m} \cdot u \cdot (lmd-m,30){n} }$
    where $n \in N_\lambda \union L_{\sf var} \union L_@ \union
    L_\Sigma$ and $n$ is not an occurrence of $r'$ then necessarily $m\in N_{\sf var} \union
    N_\Sigma \union N_@$ and $m$ is $n$'s parent in $\tau(M)$.

    (a) Suppose that $n\in V^{(r')}$. Since $m$ is the parent of
    the node $n$ in $V^{(r')}$ which is not the the root of
    $\tau(M^{(r')})$, necessarily $m$ also belongs to
    $V^{(r')}$. Thus we can use the induction hypothesis on $t' \cdot m$: for some occurrence $r_0$
     of $r'$ in $t$ we have
    $\pview{r' \cdot m} = \ldots r_0 \cdot w$; all the
    nodes in $w$ belong to $V^{(r')}$; and all the
    occurrences in $w$ appear in $(t'\cdot m)\filterplus r_0$
    and not in any $(t'\cdot m)\filterplus r_1$ for any occurrence $r_1\neq r_0$ of $r'$.
    Since the justifier of $n$ is in $\pview{t' \cdot  m}$, these properties must clearly also hold for $t$.
    Moreover:
            \begin{align*}
            \pview{t}^M \filter  V^{(r')}            &= \pview{\Pstr{t' \cdot (m){m} \cdot u \cdot (n-m,40){n}}}^M \filter  V^{(r')}
                & (\mbox{definition of } t)\\
            &= (\pstr{\pview{t' \cdot \nd(m){m} }^M \cdot \nd(lmd-m,60){n}}) \filter  V^{(r')}
                & (\mbox{P-view in $M$}) \\
            &= \pstr[0.4cm]{ \pview{t' \cdot \nd(m){m} }^M \filter V^{(r')} \cdot \nd(lmd-m,30){n} }
                & (\mbox{$n \in V^{(r')}$}) \\
            &= \pstr[0.4cm]{ \pview{(t' \cdot \nd(m){m})\filterplus r_0}^{M^{(r')}}  \cdot  \nd(lmd-m,30){n} }
                & \mbox{(induction hypothesis)} \\
            &= \pstr[0.4cm]{ \pview{t' \cdot \filterplus r_0 \cdot \nd(m){m}}^{M^{(r')}}  \cdot  \nd(lmd-m,35){n} }
                & \mbox{($m$ appears in $t\filterplus r_0$)} \\
            &= \pview{ \Pstr{t' \filterplus r_0 \cdot (m){m} \cdot {(u \filterplus r_0)} \cdot (lmd-m,35){n}}}^{M^{(r')}}
                & \parbox[t]{6cm}{(P-view in $M^{(r')}$: nodes and leaves in $(u \filterplus r_0) \cdot n$ are all in $V^{(r')}$
                    by Lemma \ref{lem:instarfilter_imp_insubtree})} \\
            &= \pview{ (\Pstr{t' \cdot (m){m} \cdot u \cdot (lmd-m,35){n}}) \filterplus r_0 }^{M^{(r')}}
                & (\mbox{$m$ and $n$ appear in $t\filterplus r_0$}) \\
            &= \pview{ t \filterplus r_0 }^{M^{(r')}}
                & \mbox{(definition of $t$).}
            \end{align*}

    (b) Suppose $n$ is not in $V^{(r')}$ then necessarily its parent node $m$ does not belong to $V^{(r')}$ either. Therefore by the induction hypothesis, all the nodes in $\pview{t' \cdot m}$ do not belong to
    $t\filterplus r_0$ for any occurrence $r_0$ of $r'$. Hence since the only justifier of $n$ is $m$, $n$ must also not appear in $t\filterplus r_0$ for any occurrence $r_0$ of $r'$


    \item If $t =  t' \cdot r_0$ where $r_0$ is an occurrence of $r'$, then $r_0 \in V^{(r')}$, $\pview{t}^M = \pview{t'}^M \cdot r_0$. Since $\pview{t}$ is the path from the root to $r'$, all the nodes occurring before $r_0$ in $\pview{t'}$ do not belong to $V^{(r')}$. Hence:
        \begin{align*}
        \pview{t}^M \filter V^{(r')}
            &=  \pview{t'}^M \filter V^{(r')} \cdot r_0 & (\mbox{P-view in $M$})\\
            &=  r_0                                     & (\mbox{nodes in $\pview{t'}_{\prefixof r_0}$ do not belong to $V^{(r')}$}) \\
            &=  \pview{r_0 }^{M^{(r')}}                 & (\mbox{P-view in $M^{(r')}$})\\
            &= \pview{t \filterplus  r_0 }^{M^{(r')}} & \mbox{($t \filterplus  r_0 = r_0$)}. \qed
        \end{align*}
    \end{compactitem}
%end of proof

\begin{lemma}
\label{lem:ifvar_in_tfilterstar_sodoes_certain_of_its_justifier}
Let $t$ be a traversal and  $r_0$ be an occurrence of a lambda node $r'$ in $t$ such that
\pstr[0.6cm]{t =
    \ldots \nd(j0){j_0}
    \ldots \nd(j1){j_1}
    \ldots \nd(jk){j_k}
    \ldots \nd(n-j0,30){y}
    \arrow{n}{j1}{30}{}{blue}{dashed}
    \arrow{n}{jk}{30}{}{blue}{dashed}
    } where $y\in N_{\sf var}$, $j_0$ is $y$'s main justifier
    and $j_1$, \ldots $j_k$ are its auxiliary justifiers.

    If $y$ appears in $t\filterplus r_0$ then all $y$'s justifiers occurring after $r_0$ in $t$ appear in $t\filterplus r_0$ and those occurring before $r_0$ do not appear in $t\filterplus r_0$.
\end{lemma}
\proof By P-visibility all $y$'s justifiers appear in the P-view,
and by Lemma \ref{lem:pview_trav_filtering}, all the occurrences in
the P-view preceding $r_0$ appear in $t\filterplus r_0$ and all the
occurrences in the P-view following $r_0$ do not appear in
$t\filterplus r_0$. \qed



\begin{lemma}[The O-view is contained in a single thread]
\label{lem:trav_oview_single_threaded}
Let $t \in \travset(M)$.
\begin{itemize}
\item[(a)] If $t= \ldots \cdot m \cdot n$ where
$m\in N_{\sf var} \union N_\Sigma \union N_@ \union
L_\lambda$ and $n\in N_\lambda \union L_{\sf var}
\union L_\Sigma \union L_@$ then
$m$ and $n$ are in the same thread in $t$: they are her.\ just.\ by the same initial occurrence (which is either $\tau(M)$'s root, a $\Sigma$-constant or an @-node);

\item[(b)] All the nodes in $\oview{t}$ belong to the same thread.
\end{itemize}
\end{lemma}
\proof
Clearly (b) follows immediately from (a) due to the way the O-view is computed. We show (a) by induction on the last traversal rule used to form $t$. The results trivially hold for the case \rulenamet{Empty} and \rulenamet{Root}. For the rules \rulenamet{Lam}, \rulenamet{App}, \rulenamet{Value$^{{\sf var}\mapsto\lambda}$},
 \rulenamet{Value$^{\Sigma\mapsto\lambda}$}and \rulenamet{Value$^{@\mapsto\lambda}$}: $t$'s last node is not in $N_\lambda\union L_{\sf var} \union L_\Sigma \union L_@$ therefore we do not need to show (a).
For the remaining rules:
\begin{compactitem}
    \item[\rulenamet{InputValue}] Take \Pstr[0.4cm]{t =
        t_1 \cdot (x){x} \cdot t_2 \cdot (xv-x,38:v){v_x} } for some
        $v \in \mathcal{D}$.

        \begin{compactitem}
        \item  If $t_2$ is empty then \Pstr[0.4cm]{t = t_1 \cdot (x){x}
        \cdot (xv-x,38:v){v_x} } so the last two nodes in $t$ are
        $x$ and $v_x$.

        Since $x$ justifies $v_x$, they are both in the same thread.

        \item If $t_2$ is not empty then by well-bracketing it is
        necessarily of the form \Pstr[0.4cm]{t_2 = (l){\lambda
        \overline{\xi}}  \ldots (x-l,38:v){v_{\lambda
        \overline{\xi}}}}.

            By the induction hypothesis  $x$ and $\lambda \overline{\xi}$ are in the same thread. Thus since $v_x$
                is justified by $x$ and $v_{\lambda \overline{\xi}}$ is
                justified by $\lambda  \overline{\xi}$, the leaves $v_x$ and $v_{\lambda \overline{\xi}}$ must
                be in the same thread.
        \end{compactitem}

    \item[\rulenamet{InputVar}]  Take $t =
    t' \cdot n$ where $n$ points in $\oview{t_{\prefixof x}}$ where $x$ is the pending node
    in $t'$.

        \begin{compactitem}
        \item  Suppose that $x$ is not the last occurrence in $t'$, then
        \Pstr[0.4cm]{t = \ldots (y){y} \ldots x \cdot (l){\lambda
        \overline{\xi}}  \ldots (vl-l,38:v){v_{\lambda
        \overline{\xi}}} \cdot (n){n} } where $y$ is a variable node occurring in $\oview{t_{\prefixof x}}$
        (and $x$ and $y$ are possibly the same occurrence).

            $n$ is in the same thread as its justifier $y$ which
            by the induction hypothesis, is in the same thread as all the nodes
            in the O-view $\oview{t_{\prefixof \lambda
            \overline{\xi}}}$, and in particular in the thread of $\lambda
            \overline{\xi}$. Since $\lambda
            \overline{\xi}$ justifies $v_{\lambda
            \overline{\xi}}$, this is the same thread as the thread of $v_{\lambda
            \overline{\xi}}$.

        \item Suppose that $x$ is the last occurrence in $t'$, then
        \Pstr[0.4cm]{t = \ldots (y){y} \ldots x \cdot (n){n} } where $y$ is a variable node occurring in $\oview{t_{\prefixof x}}$ (and $x$ and $y$ are possibly the same occurrence).

            Again since $n$ points in the O-view $\oview{t_{\prefixof x}}$, it must belong to the same thread
            as all the nodes in $\oview{t_{\prefixof x}}$ and in particular to the thread of $x$.
        \end{compactitem}

    \item[\rulenamet{Value$^{\lambda\mapsto@}$}]
      Take \Pstr[0.7cm]{t = t' \cdot (app){@} \cdot
    (lz-app,60){\lambda \overline{z}} \ldots
    (lzv-lz,60:v){v}_{\lambda \overline{z}} \cdot
    (appv-app,45:v){v}_@}. Clearly the last two nodes are
    both in the same thread initiated by the @-node.

     \item[\rulenamet{Value$^{\lambda\mapsto{\sf var}}$}] Take \Pstr[0.7cm]{t = t' \cdot (y){y} \cdot
    (lmd){\lambda \overline{\xi}} \ldots
    (lmdv-lmd,30:v){v}_{\lambda \overline{\xi}}  \cdot
    (vy-y,50:v){v}_y } for some variable $y$ in $N_{\sf var}^{@\vdash}$. By the I.H., $y$, $\lambda \overline{\xi}$, $v_{\lambda \overline{\xi}}$ and $v_y$ must all belong to the same thread.

    \item[\rulenamet{Var}]
    Take \Pstr[0.6cm]{ t = t' \cdot (p){p} \cdot (lx){\lambda
        \overline{x}} \ldots (x-lx,30:i){x_i}  \cdot
        (letai-p,40:i){\lambda \overline{\eta_i}} } for some
        variable $x_i$ in $N_{\sf var}^{@\vdash}$.
        Again the induction hypothesis permits us to conclude.

    \item[\rulenamet{$\Sigma$}/\rulenamet{$\Sigma$-var}]
    The proof is similar to the case \rulenamet{InputVar}.
    \item[\rulenamet{$\Sigma$-Value}]
    The proof is similar to the case
    \rulenamet{InputValue}.
    \qed
\end{compactitem}

\begin{lemma}
\label{lem:jump_in_thread}
Take a traversal $t$ ending with an internal node hereditarily justified by an application node @. Then if we represent only the nodes appearing in the O-view, the thread of $t^\omega$ has the following shape:
$$ \Pstr[0.5cm]{ (app){@}\cdot
(l0-app){\lambda \overline{\xi}_0} \ldots (x1-l0){x_1} \cdot
(l1-app){\lambda \overline{\xi}_1} \ldots (x2-l1){x_2} \cdot
(l2-x1){\lambda \overline{\xi}_2} \ldots (x3-l2){x_3} \cdot
(l3-x2){\lambda \overline{\xi}_3} \ldots (x4-l3){x_4} \ldots
(xkm1){x_{k-1}}
(lkm1){\lambda \overline{\xi}_{k-1}} \ldots (xk-lkm1){x_k}
(lk-xkm1){\lambda \overline{\xi}_k}
 } $$
Suppose that the initial node $@$ occurs in the computation as follows:
 $$ \tree{ \ldots}
        {   \tree[levelsep=6ex]{@}
            {   \TR{\lambda \overline{\eta}_1}
                \TR{\ldots} \TR{\lambda \overline{\eta}_q}
            }}$$
Let us write $\tau_i$ for the sub-tree rooted at $\lambda \overline{\eta}_i$ for $i\in \{1.. q\}$.
Then for every $j\in \{1.. k\}$, $x_j$ and $\lambda \overline{\xi}_j$ must belong to two different subtrees $\tau_i$ and $\tau_{i'}$. Furthermore, $x_j$ is hereditarily justified by
some occurrence of $\lambda \overline{\eta}_i$ in $t$ and
$\lambda \overline{\xi}_j$ is hereditarily justified by
some occurrence of $\lambda \overline{\eta}_{i'}$ in $t$
(and therefore $\lambda \overline{\xi}_j \in V^{\lambda \overline{\eta}_{i} \vdash}$
and $x_j \in V^{\lambda \overline{\eta}_{i'} \vdash}$).
\end{lemma}
\proof The proof is by an easy induction. \qed



\begin{lemma}
\label{lem:thread_filterplus}
Take a traversal $t$.  Let $r'$ be a node in $N_\lambda$ and $r_0$ an occurrence of $r'$ in $t$.
Suppose that the thread of $t^\omega$ is initiated by an @-node or a $\Sigma$-node $\alpha$
and that $t^\omega$ appears in $t\filterplus r_0$.

Then all the nodes of the thread occurring after $r_0$ and appearing in $t\filterplus r_0$ are hereditarily
justified by $r_0$. Moreover, if $r_0$ precedes $\alpha$ in $t$ then all the nodes occurring in the thread appear in $t\filterplus r_0$.
\end{lemma}
\proof The proof is by an easy induction using Lemma \ref{lem:pview_trav_filtering}. \qed


\begin{proposition}[Filtering of a traversal's O-view]
\label{prop:oview_trav_filtering}
   Let $t$ be a traversal of $\travset(M)$ such that its last node
   appears in $t \filterplus r_0$ for some occurrence $r_0$ in $t$ of a lambda node $r'$ in $N_\lambda$.
   Then $ \oview{t}_M\filterplus r_0 \subseqof \oview{t\filterplus r_0}_{M^{(r')}}$.
\end{proposition}
%\proof
%We show (c) and (d) simultaneously by induction on the last traversal rule used to form $t$. Suppose that $|t|>0$, $t^\omega\in V^{\theroot\vdash}$. The results trivially hold for the rule \rulenamet{Root}.
%
%(c) Consider the rules \rulenamet{App}, \rulenamet{Value$^{{\sf var}\mapsto\lambda}$}, \rulenamet{Value$^{\Sigma\mapsto\lambda}$} and
%\rulenamet{Value$^{@\mapsto\lambda}$}: for these cases,
%$t^\omega$ is not a variable node and therefore has only one justifier. By Lemma \ref{lem:ifin_tfilterstar_so_does_justifier}, $t^\omega$ appears in
%$t \filterplus r_0$ if and only if its only justifier does. Thus we can conclude using the I.H. on $\jp(t)$.
%\begin{itemize}
%    \item[\rulenamet{Lam}] Take  $t = t' \cdot \lambda \overline{\xi} \cdot n$ where $n$ denotes $\lambda \overline{\xi}$'s child.
%
%%        Since $n$ is in $N^{\theroot\vdash}$, $n$ cannot be an application node nor a $\Sigma$-node.
%        Suppose that $n\in N_@ \union N_\Sigma$ then $n$ has no justifier and $\oview{t} = n$ therefore the result holds trivially.
%
%        Suppose that $n\in N_{\sf var}$.
%        If $n$ is a free variable node then its justifier is $r$ - the first node of $t$ - thus $\oview{t} = r \cdot n$ and (c) holds trivially. If $n$ is a bound variable node and $r_0$ occurs after $x$'s binder in $t$ then (c) holds trivially.
%
%        Suppose $n$ is a bound variable node and $r_0$ occurs before $x$'s binder.
%        If $n$ does not appear in $t \filterplus r_0$ then necessarily its binder does not either.
%        If $n$ appears in $t \filterplus r_0$ then by P-visibility, $x$'s main justifier (its binder) must occur in the P-view, and since it occurs after $r_0$, by Lemma \ref{lem:pview_trav_filtering} it must appear in $t \filterplus r_0$. Therefore we can conclude using the I.H. on $\jp(t)$.
%\end{itemize}
%\smallskip
%
%Let us consider the remaining rules: if $t^\omega = r_0$ then the result trivially holds. Otherwise, suppose that $t^\omega \in V^{\theroot\vdash}$. It suffices to show that $t^\omega$ appears in $t \filterplus r_0$ if and only if $t^{\omega^2}$ does, the I.H. then permits us to conclude.
%\begin{itemize}
%\item[\rulenamet{InputValue}] Take \Pstr[0.4cm]{t =
%    t_1 \cdot (x){x} \cdot t_2 \cdot (xv-x,38:v){v_x} } for some
%    $v \in \mathcal{D}$.
%
%    \begin{compactitem}
%    \item  If $t_2$ is empty then \Pstr[0.4cm]{t = t_1 \cdot (x){x}
%    \cdot (xv-x,38:v){v_x} } so the last two nodes in $t$ are
%    $x$ and $v_x$.
%
%        Since $x$ justifies $v_x$ we clearly have
%        $v_x \in t \filterplus r_0 \iff x \in t \filterplus r_0$.
%
%    \item If $t_2$ is not empty then by well-bracketing it is
%    necessarily of the form \Pstr[0.4cm]{t_2 = (l){\lambda
%    \overline{\xi}}  \ldots (x-l,38:v){v_{\lambda
%    \overline{\xi}}}}.
%
%        Since $v_x$ is in $V^{\theroot\vdash}$, by Lemma \ref{lem:trav_oview_single_threaded} so is $v_{\lambda \overline{\xi}}$ and in turn so is its parent node $\lambda
%        \overline{\xi}$. Thus by the induction hypothesis.
%        $\lambda \overline{\xi} \in t \filterplus r_0 \iff x \in t \filterplus r_0$.
%        Moreover since $x$ justifies $v_x$ and $\lambda
%        \overline{\xi}$ justifies $v_{\lambda
%        \overline{\xi}}$  we have   $x \in t \filterplus r_0 \iff v_x \in t \filterplus r_0$
%        and $\lambda \overline{\xi} \in t \filterplus r_0 \iff v_{\lambda
%        \overline{\xi}} \in t \filterplus r_0$.
%    \end{compactitem}
%
%    \item[\rulenamet{InputVar}]  Take $t =
%    t' \cdot n$ where $n$ points in $\oview{t_{\prefixof x}}$ where $x$ is the pending node
%    in $t'$.
%
%    \begin{compactitem}
%    \item  Suppose that $x$ is not the last occurrence in $t'$, then
%    \Pstr[0.4cm]{t = \ldots (y){y} \ldots x \cdot (l){\lambda
%    \overline{\xi}}  \ldots (vl-l,38:v){v_{\lambda
%    \overline{\xi}}} \cdot (n){n} } where $y$ is a variable node occurring in $\oview{t_{\prefixof x}}$
%    (and $x$ and $y$ are possibly the same occurrence).
%
%        Since $n$ is not the occurrence $r_0$, it appears in $t \filterplus r_0$ if and only if its only justifier $y$ does. But since $y$ occurs in $\oview{t_{\prefixof \lambda \overline{\xi}}}$ using the I.H. (d) on $t_{\prefixof \lambda \overline{\xi}}$ tells us that $y$ appears in $t \filterplus r_0$ if and only if $\lambda \overline{\xi}$ does, which in turn happens if and only if        $v_{\lambda \overline{\xi}}$ does.
%
%
%    \item Suppose that $x$ is the last occurrence in $t'$, then
%    \Pstr[0.4cm]{t = \ldots (y){y} \ldots x \cdot (n){n} } where $y$ is a variable node occurring in $\oview{t_{\prefixof x}}$ (and $x$ and $y$ are possibly the same occurrence).
%
%      Again $n$ appears in $t \filterplus r_0$ if and only if its justifier $y$ does. Moreover since $y$ occurs in $\oview{t_{\prefixof x}}$ by the induction hypothesis, $y$ appears in  $t \filterplus r_0$ if and only if $x$ does.
%
%    \end{compactitem}
%
%    \item[\rulenamet{Value$^{\lambda\mapsto@}$}]
%      Take \Pstr[0.7cm]{t = t' \cdot (app){@} \cdot
%    (lz-app,60){\lambda \overline{z}} \ldots
%    (lzv-lz,60:v){v}_{\lambda \overline{z}} \cdot
%    (appv-app,45:v){v}_@}.
%    This case does not happen since $t$'s last node is in $V_@$
%    which contradicts the hypothesis that $t^\omega$ is in $V^{\theroot\vdash}$.
%
%     \item[\rulenamet{Value$^{\lambda\mapsto{\sf var}}$}] Take \Pstr[0.7cm]{t = t' \cdot (y){y} \cdot
%    (lmd){\lambda \overline{\xi}} \ldots
%    (lmdv-lmd,30:v){v}_{\lambda \overline{\xi}}  \cdot
%    (vy-y,50:v){v}_y } for some variable $y$ in $N_{\sf var}^{@\vdash}$.
%
%       By Lemma \ref{lem:trav_oview_single_threaded}, the last two nodes in $t$ do not belong to $N_{\sf var}^{\theroot\vdash}$.
%           But by assumption $t$'s last node is in $V^{\theroot\vdash}$ therefore this case does not happen.
%
%    \item[\rulenamet{Var}]
%    Take \Pstr[0.6cm]{ t = t' \cdot (p){p} \cdot (lx){\lambda
%        \overline{x}} \ldots (x-lx,30:i){x_i}  \cdot
%        (letai-p,40:i){\lambda \overline{\eta_i}} } for some
%        variable $x_i$ not in $N_{\sf var}^{\theroot\vdash}$.
%
%        By Lemma \ref{lem:trav_oview_single_threaded}, the last two nodes in $t$ are both not in $N_{\sf var}^{\theroot\vdash}$.
%            But by assumption $t$'s last node is in $V^{\theroot\vdash}$ therefore this rules cannot be used.
%
%    \item[\rulenamet{$\Sigma$}/\rulenamet{$\Sigma$-var}]
%    The proof is similar to the case \rulenamet{Var}.
%    \item[\rulenamet{$\Sigma$-Value}]
%    The proof is similar to the case
%    \rulenamet{Value$^{\lambda\mapsto@}$}.
%    \end{itemize}
%    \bigskip
%
%\noindent    (old d) We do a case analysis on the type of $t^\omega$:
%    \begin{itemize}
%    \item $t =  t' \cdot r_0$. We have $t \filterplus r_0 = r_0$ and  $\oview{t}_M \filterplus r_0 = r_0 = \oview{t \filterplus r_0}_{M^{(r')}}$.
%
%    \item $t = t' \cdot n$ with $n \in N_\lambda \union L_{\sf var} \union
%    L_\Sigma \union L_@$ where $n$ is not the occurrence $r_0$.
%
%    Since $n$ appears in $t\filterplus r_0$, its only justifier (which is in $\oview{t'}$ by O-visibility) must also appear in $t\filterplus r_0$.  By Lemma \ref{lem:trav_oview_single_threaded}, $t'^\omega$ is in $V^{(r')}$ and by (c), it appears in $t \filterplus r_0$. Hence we can apply the I.H. on $t'$ which gives us  $\oview{t' \filterplus  r_0}_{M^{(r')}} = \alpha \cdot \oview{t'}_M \filterplus  r_0$
%    where $\alpha = r_0$ if $r_0$ occurs in $\oview{t}_M$
%    and $\alpha =\epsilon$ otherwise.
%    Thus:
%        \begin{align*}
%        \alpha \cdot \oview{t}_M \filterplus r_0
%    &= \alpha \cdot \oview{t' \cdot n}_M \filterplus r_0 & (\mbox{definition of } t)\\
%            &= \alpha \cdot \oview{t'}_M \filterplus r_0 \cdot n  & \parbox[t]{7cm}{(\raggedleft O-view in $M$, $n$'s justifier appears in $\oview{t'}\filterplus r_0$ by the previous remark)} \\
%            &= \oview{t' \filterplus  r_0 }_{M^{(r')}} \cdot n            & (\mbox{induction hypothesis}) \\
%            &=  \oview{t' \filterplus  r_0 \cdot n}_{M^{(r')}} & \parbox[t]{7cm}{\raggedleft (O-view in $M^{(r')}$:
%             $n$ is indeed a node of $\tau(M^{(r')})$ by Lemma \ref{lem:instarfilter_imp_insubtree})} \\
%            &=  \oview{(t' \cdot n ) \filterplus  r_0  }_{M^{(r')}}           & (\mbox{$n$ occurs in $t\filterplus r_0$}) \\
%            &= \oview{t \filterplus  r_0  }_{M^{(r')}}
%     & (\mbox{definition of } t).
%        \end{align*}
%
%    \item $\Pstr{ t =  t' \cdot (m){m} \cdot u \cdot (lmd-m,30){n} }$
%    where $n \in N_{\sf var} \union N_\Sigma \union N_@ \union L_\lambda$. We necessarily have
%    $m\in N_\lambda \union L_{\sf var} \union L_\Sigma \union L_@$.
%
%
%
%By Lemma \ref{lem:trav_oview_single_threaded} the nodes in the O-view are all in the same thread as $n$ therefore $m$ is in $V^{(r')}$.
%
%        \begin{itemize}
%        \item Suppose that $r_0$ occurs before $m$ in $t$.
%
%            By (c) all the nodes and leaves occurring after $r_0$ in the O-view appear in
%            $t \filterplus r_0$, in particular since $m$ is in the O-view $\oview{t}$ and $r_0$ occurs before $m$, $m$ must appear in $t \filterplus r_0$ and we can apply the I.H. on $t' \cdot m$ which gives us $\oview{(t'\cdot m) \filterplus  r_0}_{M^{(r')}} = \alpha \cdot \oview{t' \cdot m}_M \filterplus  r_0$   where $\alpha = r_0$ if $r_0$ occurs in $\oview{t}_M$ and $\alpha =\epsilon$ otherwise.
%            Hence:
%            \begin{align*}
%            \alpha\cdot\oview{t}_M \filterplus r_0
%            &= \alpha\cdot\oview{\Pstr{t' \cdot (m){m} \cdot u \cdot (n-m,40){n}}}_M \filterplus r_0
%                    & (\mbox{definition of } t)\\
%            &= \alpha\cdot(\pstr{\oview{t' \cdot \nd(m){m}}_M  \cdot \nd(lmd-m,60){n}}) \filterplus r_0
%                    & (\mbox{O-view in $M$ }) \\
%            &= \alpha\cdot\pstr[0.4cm]{ \oview{t' \cdot \nd(m){m}}_M \filterplus r_0  \cdot  \nd(lmd-m,30){n} }
%                    & (\mbox{$n$ appears in $t \filterplus r_0$}) \\
%            &= \pstr[0.4cm]{ \oview{(t' \cdot \nd(m){m} )\filterplus r_0}_{M^{(r')}} \cdot \nd(lmd-m,25){n} }
%                    & \mbox{(induction hypothesis)} \\
%            &= \pstr[0.4cm]{ \oview{t'\filterplus r_0 \cdot \nd(m){m}}_{M^{(r')} } \cdot \nd(lmd-m,25){n} }
%                    & \mbox{($m$ appears in $t \filterplus r_0$)} \\
%            &= \oview{ \Pstr[0.4cm]{t' \filterplus r_0 \cdot (m){m} \cdot {(u \filterplus r_0)} \cdot (lmd-m,30){n}}}_{M^{(r')}}
%                    & \parbox[t]{5cm}{\raggedleft(O-view in $M^{(r')}$, nodes in $m\cdot (u \filterplus r_0) \cdot n$ are all in $V^{(r')}$)} \\
%            &= \oview{ (\Pstr{t' \cdot (m){m} \cdot u \cdot (lmd-m,35){n}}) \filterplus r_0 }_{M^{(r')}}
%                    & \mbox{($m$ and $n$ both appear in } t \filterplus r_0) \\
%            &= \oview{ t \filterplus r_0 }_{M^{(r')}}
%                    & \mbox{(definition of $t$).}
%          \end{align*}
%
%        \item Suppose that $r_0$ occurs after $m$ in $t$.
%        Let $j_1$, \ldots $j_k$ be the auxiliary justifiers of $m$. By Lemma \ref{lem:ifin_tfilterstar_so_does_justifier} and \ref{lem:pview_trav_filtering}, for some $i \in \{1..k\}$, $j_i = r_0$ and for all $i'\geq i$, $j_{i'}$ appears in $t\filterplus r_0$.
%
%        Thus $j_i = r_0$ is the main justifier of $n$ in $t\filterplus r_0$ and therefore $\oview{t\filterplus r_0} = j_i \cdot n = r_0  \cdot n$.
%        We then have $r_0 \cdot (\oview{t}\filterplus r_0) = r_0 \cdot (\oview{t'} \cdot m \cdot n) \filterplus r_0 =  r_0 \cdot n = \oview{t\filterplus r_0}$.
%        \end{itemize}
%    \end{itemize}
%
%\qed

This result is the counterpart of another known result in game semantics from the seminal paper \cite{hylandong_pcf}:
\begin{proposition}[P-view projection in game semantics]{\cite[Prop.4.3]{hylandong_pcf}}
\label{prop:hylandong_pviewprojection}
  Let $s$ be a legal position of a game $A\rightarrow B$.
  If $s^\omega$ is in $B$ then $\pview{s}^{A\rightarrow B} \filter B \subseqof \pview{s\filter B}^B$.
\end{proposition}
The proof is non-trivial. It can be found in the appendix of
\cite{hylandong_pcf}. In order to avoid redoing a similar proof for our setting,
we will show the proof of this proposition can be
reused to give us Proposition \ref{prop:oview_trav_filtering}. The argument used in
\cite{hylandong_pcf} relies on several properties of a legal position $s$:
\begin{itemize}
  \item (w1) Initial question to start: there first move played in $s$ is an initial move and there is no other occurrence of initial moves in the rest of $s$;
  \item(w2) Alternation: P-moves and O-moves alternate in $s$;
  \item(w3)  Explicit justification: \emph{every} move except the first has a pointer to a preceding move,
  \item(w4)  Well-bracketing: the pending question is answered first;
  \item(w5)  Visibility: $s$ satisfies P-visibility and
O-visibility.
\end{itemize}
Further assumption are also made on the legal positions of the game
$A\rightarrow B$:
\begin{itemize}
  \item(w6) For any occurrence $n$ in the position, $n \in A \iff n \not\in
B$;
  \item(w7) Switching condition: the Proponent is the only player
      who can switch from game $A$ to $B$ or from $B$ to $A$.
  \item(w8) Justification in $A\rightarrow B$: Suppose $m$ justifies $n$ in $s$. Then
    \begin{itemize}
        \item $n \in B$ implies $m\in B$;
        \item if $n$ is a non-initial move in $A$ the $n \in A$;
        \item if $n$ is an initial move in $A$ the $n \in B$.
    \end{itemize}
\end{itemize}
Most of these requirements coincide with properties that we have
already shown for our notion of traversals. However traversals do
not strictly satisfy explicit justification: some nodes in the
traversal do not have justification pointers (@-nodes and
$\Sigma$-nodes). Also, variable nodes can have more than one
pointer. Fortunately we will see that this mismatch can be easily
overcome.


Take a justified sequence of node $t$. We define $\overline{t}$, the \defname{extension of $t$},
to be the sequence of nodes-with-pointers obtained from $\diamond \cdot t$ (where
$\diamond$ is a dummy node) by adding justification pointers going
from occurrences of the root $\theroot$, @-nodes and $\Sigma$-nodes
to their immediate predecessor in $t$. In other words, $\overline{t}$ is
$(\diamond \cdot t)^+$ where $t$'s first node points to $\diamond$
-- the operation $\_^+$ being defined in section \ref{sec:tstar}.
Clearly for any justified sequences $t_1$ and $t_2$ we have:
\begin{equation}
 \overline{t}_1 \subseqof  \overline{t}_2 \quad \iff \quad t_1 \subseqof  t_2 \label{eqn:hat_subseq} \ .
\end{equation}
We also have:
\begin{equation}
 \overline{t} \filterplus r_0 = \overline{t \filterplus r_0} \label{eqn:hatfilter_eq_filterhat}
\end{equation}

\begin{example} Suppose $f$ is a $\Sigma$-constant.
\begin{align*}
\mbox{If }  t &= \pstr[0.4cm]{ \nd(l){\lambda \overline{\xi}} \cdot \nd(at)@ \cdot \nd(lx-at){\lambda x}\cdot   \nd(f)f \cdot \nd(l-f){\lambda} \cdot \nd(x-lx,60)x
            \arrow{x}{l}{80}{}{blue}{dashed}} \\
\mbox{then }  \overline{t} &= \pstr[0.6cm]{ \nd(diam)\diamond \cdot \nd(l-diam){\lambda \overline{\xi}}
 \cdot  \nd(at-l)@\cdot  \nd(lx-at){\lambda x}\cdot
\nd(f-l)f\cdot \nd(l-f){\lambda}\cdot \nd(x-lx)x
\arrow{x}{l}{80}{}{blue}{dashed}}\ .
\end{align*}
\end{example}


Since in $\overline{t}$, @/$\Sigma$-nodes can have pointers,
$\overline{t}$ is not a proper justified sequence of nodes as
defined in Def. \ref{dfn:justseqnode}. Nevertheless, it can be
treated as such since almost all the operations on justified
sequences defined up to now can be trivially extended to such
sequences. In particular, the notion of (hereditarily) filtering is
defined identically. We also define notions of O-view and P-view. To
that end we make use of the ``long O-view'' introduced in
\cite{Harmer2005}:
\begin{definition}[Long O-view of a justified sequence]
The \defname{long O-view} of justified sequence of nodes $t$,
written $\longoview{t}$ is defined as follows:
$$\begin{array}{rcll}
 \longoview{\epsilon} &=&  \epsilon \\
 \longoview{s \cdot n }  &=&  \longoview{s} \cdot n
    & \mbox{for $n \in L_{\sf var} \union L_\Sigma \union L_@ \union N_\lambda$;}
    \\
 \longoview{\Pstr[15pt]{s \cdot (m){m} \cdot \ldots \cdot (x-m,30){n}}} &=&
    \Pstr{ \longoview{s} \cdot (m2){m} \cdot (n2-m2,60){n} }
    & \parbox[t]{10cm}{for $n \in N_{\sf var} \union L_\lambda \union N_@ \union N_\Sigma$ (the link represents $n$'s main pointer).}
\end{array}$$
\end{definition}
Contrary to the O-view $\oview{t}$, $\longoview{t}$ may contain
several threads of $t$.

 Clearly  $\oview{t}$ is a suffix of
$\longoview{t}$:
\begin{equation}
  \longoview{t} = w \cdot \oview{t} \quad \mbox{for some sequence $w$.} \label{eqn:oview_suffix_longoview}
\end{equation}

In $\overline{t}$, the presence of the dummy node $\diamond$ causes
a change in the parity of the alternation between nodes in $N_{\sf
var} \union L_\lambda \union N_@ \union N_\Sigma$ and $N_\lambda
\union L_{\sf var} \union L_\Sigma \union L_@$. Due to this, the
notion of O-view and P-view get swapped for $\overline{t}$: we
define the O-view of $\overline{t}$ to be $\overline{s}$ where $s$
is the P-view of $t$ and the P-view of $\overline{t}$ is defined as
$\overline{u}$ where $u$ is the \emph{long O-view} of $t$:
\begin{equation}
\oview{\overline{s}} = \overline{\pview{s}} \qquad
\mbox{and}
\qquad  \pview{\overline{s}} =
\overline{\longoview{s}} \label{eqn:def_pview_oview_hat}
\end{equation}

We now establish an analogy between our setting and the game
semantic setting. The role of this analogy is purely to reuse the
proof of \cite{hylandong_pcf}. The reader must not confuse this with
a different correspondence, that we will establish in a forthcoming
section, between plays of game semantics and traversals of the
computation tree. (In particular the coloring of nodes used here in
term of P-move/O-move is the opposite of the one used in the
Correspondence Theorem.)

The following correspondences are used:
\begin{center}
\begin{tabular}{r|p{6cm}}
{\bf Traversal} & {\bf Game semantics} \\
\hline\hline
Sequence $\overline{t}$ & Play $s$ \\
Nodes in $n \in N_{\sf var} \union L_\lambda \union N_@ \union N_\Sigma \union \{\diamond\}$ & O-moves $\omove$ \\
Nodes in $n \in N_\lambda \union L_{\sf var} \union L_\Sigma \union L_@$ & P-moves $\pmove$\\
P-view $\pview{\overline{t}}$  & P-view $\pview{s}$\\
O-view $\oview{\overline{t}}$  & O-view $\oview{s}$\\
Occurrence $n$ appearing in $t\filterplus r_0$ & Occurrence $n \in B$ \\
Occurrence $n$ not appearing in $t\filterplus r_0$ & Occurrence $n \in A$ \\
\parbox[t]{6cm}{\raggedleft No notion of initiality: all nodes are considered to be non-initial.} & Distinction between initial and non-initial move.
\end{tabular}
\end{center}

If we ignore auxiliary pointers then the sequence $\overline{t}$
verifies the requirements (w1) to (w5): For (w1), the initial node
becomes $\diamond$. Explicit justification (w4) holds provided that
we ignore auxiliary pointers. Finally, alternation (w3),
well-bracketing (w4) and visibility (w5) of the traversal $t$ (Prop.
\ref{prop:pviewtrav_is_path}) are preserved by the hat operation
(where visibility is defined with respect to the their respective
notion of P-view and O-view).

Clearly, $n \in t\filterplus r_0 \iff \neg ( n \not\in t\filterplus
r_0)$ thus property (w6) holds. So does the switching condition
(w7): suppose that $t = \cdot m \cdot n$ where $n\in N_{\sf var}
\union L_\lambda \union N_@ \union N_\Sigma$ and $m \in N_\lambda
\union L_{\sf var} \union L_\Sigma \union L_@$ then $\pview{t} =
\ldots \cdot m \cdot n$ therefore by Lemma
\ref{lem:pview_trav_filtering}, $m$ appears in $t\filterplus r_0$ if
and only if $n$ does.
For (w8): using the analogy of the preceding table, since all nodes
are considered ``non-initial'' $\overline{t}$, this condition
becomes:
\begin{quote}
 (w8) Suppose $m$ justifies $n$ in $\overline{t}$. Then $n \in t\filterplus r_0$ if and only if $m\in t\filterplus r_0$.
\end{quote}
Unfortunately, the direct implication does not always hold! Indeed, since variable nodes can have several
justifiers, they can very well appear in $t\filterplus r_0$ even
though their main justifier does not. Consequently, the proof of Proposition \ref{prop:hylandong_pviewprojection} cannot be
directly reused in our setting. A weaker version of condition (w8) holds however: we know by Lemma \ref{lem:ifvar_in_tfilterstar_sodoes_certain_of_its_justifier} that
if $r_0$ occurs before $n$'s main justifier then $n$ appears in
$t\filterplus r_0$ if and only if its main justifier does.
This condition turns out to be sufficient to reuse most of the proof from \cite{hylandong_pcf}.

We reproduce here some definition used in \cite{hylandong_pcf}. Let
$s$ be a position of the game $A\rightarrow B$. A bounded segment is
a segment $\theta$ of $s$ of the form
$\Pstr[0.6cm]{(x){\stackrel{x}\pmove} \ldots
(y-x){\stackrel{y}\omove}}$. If $x$ is in $A$, and hence also $y$,
then $\theta$ is an $A$-bounded segment. Respectively if $x$ and $y$
are in $B$ then it is a $B$-bounded segment. By an abuse of notation
we define $\pview{\theta \filter B}$ to be the the subsequence of
$\pview{s_{\prefixof y} \filter B}$ consisting only of moves in
$\theta$ appearing after (and not including) $x$.

%The visibility condition (w5) then gives us the following lemma \cite[Lemma A.1]{hylandong_pcf}:
%\begin{lemma}[Spine decomposition]
%Any bounded segment $\theta$ with end-moves x and y may be decomposed
%in the following way:
%$$ \underbrace{\pstr[0.5cm]{\nd(x){\stackrel{x}\pmove}  \cdot
%            \framebox{\pstr[0.2cm]{\nd(pm){\stackrel{p_m}\omove} \ldots \nd(qm-pm,30){\stackrel{q_m}\pmove}}} \ldots
%            \framebox{\pstr[0.2cm]{\nd(pi){\stackrel{p_i}\omove} \ldots \nd(qi-pi,30){\stackrel{q_i}\pmove}}} \ldots
%            \framebox{\pstr[0.2cm]{\nd(p1){\stackrel{p_1}\omove} \ldots \nd(q1-p1,30){\stackrel{q_1}\pmove}}}
%            \cdot \nd(y-x,20){\stackrel{y}\omove}}}_\theta \ .$$
%\end{lemma}
We then have:
\begin{lemma}[Lemma A.3 from \cite{hylandong_pcf}]
Let $\theta$ be an $A$-bounded segment in $s$ with end-moves $x$ and
$y$.

\begin{enumerate}[(i)]
  \item $ \pview{\theta \filter B} = \Pstr{ (p){\stackrel{p_r}\pmove} \cdot (q-p){\stackrel{q_r}\omove} \ldots
                                     (p1){\stackrel{p_1}\pmove}
\cdot (q1-p1){\stackrel{q_1}\omove} }$ for some $r\geq 0$. Note
that each segment $p_i \ldots q_i$ is B-bounded in $s$, for
$1\leq i \leq r$.
  \item For any P-move $m$ in $\theta$ which appear in
$\oview{s_{<y}}$, $m$ does not belong to any of the $B$-bounded
segment $p_i \ldots q_i$ for $1\leq i \leq r$.
\end{enumerate}
\end{lemma}
This Lemma assumes that the segment $\theta$ verifies the
assumptions (w1) to (w8). As we have seen, (w8) does not always hold for extended traversals. But using our analogy with extended traversals, a  segment $\theta$ is ``A-bounded'' if $\theta$ is bounded by two nodes appearing in $t\filterplus r_0$. This can only happen if $r_0$ occurs before $\theta$ in $t$ or if $\theta$'s left bound is $r_0$.  Thus the condition (w8) necessarily holds (at least for the nodes of the segment $\theta$).
The previous lemma thus translates into:
\begin{lemma}
\label{lem:pview_bounded_segment} Let $t$ be a traversal and
$\theta$ be a segment of $\overline{t}$ bounded by nodes $x$ and $y$ appearing in $t\filterplus r_0$.
\begin{enumerate}[(i)]
  \item $ \pview{\theta \filterplus r_0} = \Pstr{ (p){p_r} \cdot (q-p){q_r} \ldots
(p1){p_1} \cdot (q1-p1){q_1} }$ for some $r\geq 0$ where
$p_i \in N_\lambda \union L_{\sf var} \union L_\Sigma \union
L_@$ and $q_i \in N_{\sf var} \union L_\lambda \union N_@
\union N_\Sigma$, for $1\leq i \leq r$.
  \item For any node $m$ in $N_\lambda \union L_{\sf var} \union L_\Sigma \union L_@$ occurring in $\theta$ and appearing in
$\oview{s_{<y}}$, $m$ does not belong to any of the
segment $p_i \ldots q_i$ for $1\leq i \leq r$.
\end{enumerate}
\end{lemma}
Note that auxiliary justification pointers do not play any role in the proof
and their presence does not affect the argument in any way.
\smallskip

We can now show the analog of Proposition \ref{prop:hylandong_pviewprojection} in the context of extended traversals:
\begin{proposition}
\label{prop:analog_pviewprojection} Let $t$ be a traversal and $r_0$
be an occurrence of some lambda node $r'$.
If $\overline{t}$'s last node appears in $t\filter r_0$ then
 $\pview{ \overline{t}}  \filterplus r_0 \subseqof \pview{ \overline{t}\filterplus
 r_0}$.
\end{proposition}
\proof
By induction on the length of $t$. The base case is immediate. For the inductive case,
we do a case analysis on the type of $t^\omega$:
    \begin{itemize}
    \item $t =  t' \cdot r_0$. We have $\overline{t} \filterplus r_0 = r_0$ and
     $\pview{\overline{t}} \filterplus r_0 = r_0 = \pview{\overline{t} \filterplus r_0}$.

    \item $t = t' \cdot n$ with $n \in N_\lambda \union L_{\sf var} \union
    L_\Sigma \union L_@$ where $n$ is not the occurrence $r_0$.

    There are two cases.
    \begin{itemize}
        \item Suppose that the last node in $t'$ appears in $t\filterplus r_0$. Then
        by the I.H. we have $\pview{\overline{t'}} \filterplus  r_0 \subseqof \pview{\overline{t'} \filterplus  r_0}$.
            \begin{align*}
            \pview{\overline{t}} \filterplus r_0
                &=  \pview{\overline{t'}} \filterplus r_0 \cdot n  & \parbox[t]{8cm}{(\raggedleft P-view for extended justified\\sequences of nodes of $M$)} \\
                &\subseqof  \pview{\overline{t'} \filterplus  r_0} \cdot n            & (\mbox{induction hypothesis}) \\
                &=  \pview{\overline{t'} \filterplus  r_0 \cdot n} & \parbox[t]{8cm}{\raggedleft (P-view for extended justified sequences of nodes of $M^{(r')}$: $n$ belongs to $\tau(M^{(r')})$ by Lemma \ref{lem:instarfilter_imp_insubtree})} \\
                &=  \pview{\overline{t' \cdot n} \filterplus  r_0  }   & (\mbox{$n$ occurs in $t\filterplus r_0$}) \\
                &= \pview{\overline{t} \filterplus  r_0  }     & (\mbox{definition of } t).
            \end{align*}

        \item Suppose that the last node $y_1$ in $t'$ does not appear in $t\filterplus r_0$.
        Let $\underline{m}$ be the last node preceding $m$ in $\pview{\overline{t}}$ that appears in $t\filterplus r_0$. Then for some $q\geq 0$ we have
        \begin{equation*}
        \pview{\overline{t}} = \pview{\overline{t}_{\prefixof \underline{m}}} \cdot \pstr[0.2cm]{ \underbrace{\nd(xq){x_q} \cdot \nd(yq-xq){y_q}\ \ldots\ \nd(x1){x_1} \cdot \nd(y1-x1){y_1}}_{\mbox{all appear in } t\filterplus r_0}} \cdot m
        \end{equation*}
        where the $x_i$s are in $ N_\lambda \union L_{\sf var} \union  L_\Sigma \union L_@$ and the $y_i$s are in $N_{\sf var} \union N_\Sigma \union N_@ \union L_\lambda$.

        Therefore the sequence $\overline{t}$ must be of the following form:
        $$\overline{t}_{\prefixof \underline{m}} \cdot \underbrace{x_q \ldots y_q}_{\theta_q} \ \cdots \ \underbrace{x_1 \cdots y_1}_{\theta_1} \cdot\ m $$
        where each segment $\theta_i$ is bounded by nodes appearing in $t\filterplus r_0$.
        By Lemma \ref{lem:pview_bounded_segment}, when computing the P-view of $\overline{t}$, pointers going from a segment $\theta$ to a node outside the segment are never followed! In other words:
        $$ \pview{\overline{t} \filterplus r_0} =
        \pview{\overline{t}_{\prefixof \underline{m}} \filterplus r_0} \cdot \pview{\theta_q \filterplus r_0} \cdot\ \cdots\
        \cdot \pview{\theta_1 \filterplus r_0} \cdot m \ .$$
        Hence:
            \begin{align*}
            \pview{\overline{t}} \filterplus r_0
            &= \pview{\overline{t}_{\prefixof \underline{m}}} \filterplus r_0 \cdot n \\
            &\subseqof \pview{\overline{t}_{\prefixof \underline{m}} \filterplus r_0}  \cdot n
                    & \mbox{(induction hypothesis)} \\
            &\subseqof \pview{\overline{t}_{\prefixof \underline{m}} \filterplus r_0} \cdot \pview{\theta_q \filterplus r_0} \cdot \cdots \cdot \pview{\theta_1 \filterplus r_0}  \cdot n \\
            &= \pview{\overline{t} \filterplus r_0}
                    & \mbox{(by the previous equation).}
          \end{align*}




    \end{itemize}

    \item $\Pstr{ t =  t' \cdot (m){m} \cdot u \cdot (lmd-m,30){n} }$
    where $n \in N_{\sf var} \union N_\Sigma \union N_@ \union L_\lambda$. We have
    $m\in N_\lambda \union L_{\sf var} \union L_\Sigma \union L_@$ and since $n$ appears in $t\filterplus r_0$, by Lemma \ref{lem:ifvar_in_tfilterstar_sodoes_certain_of_its_justifier} so does $m$. Thus we can apply the I.H. on $t' \cdot m$: \begin{align*}
        \pview{\overline{t}} \filterplus r_0
        &= \pview{\Pstr{\overline{t'} \cdot (m){m} \cdot \overline{u} \cdot (n-m,40){n}}}_M \filterplus r_0
                & (\mbox{definition of } t)\\
        &= (\pstr{\pview{\overline{t'} \cdot \nd(m){m}}  \cdot \nd(lmd-m,60){n}}) \filterplus r_0
                & (\mbox{P-view for extended justified sequences in $M$ }) \\
        &= \pstr[0.4cm]{ \pview{\overline{t' \cdot \nd(m){m}}} \filterplus r_0  \cdot  \nd(lmd-m,30){n} }
                & (\mbox{$n$ appears in $t \filterplus r_0$}) \\
        &\subseqof \pstr[0.4cm]{ \pview{(\overline{t' \cdot \nd(m){m}} )\filterplus r_0} \cdot \nd(lmd-m,25){n} }
                & \mbox{(induction hypothesis on $t' \cdot m$)} \\
        &= \pstr[0.4cm]{ \pview{\overline{t'}\filterplus r_0 \cdot \nd(m){m}} \cdot \nd(lmd-m,45){n} }
                & \mbox{($m$ appears in $t \filterplus r_0$)} \\
        &= \pview{ \Pstr[0.4cm]{\overline{t'} \filterplus r_0 \cdot (m){m} \cdot {(\overline{u} \filterplus r_0)} \cdot (lmd-m,30){n}}}
                & \parbox[t]{7.5cm}{\raggedleft(P-view for extended justified sequences in $M^{(r')}$, nodes in $m\cdot (u \filterplus r_0) \cdot n$ are all in $V^{(r')}$)} \\
        &= \pview{ (\Pstr{t' \cdot (m){m} \cdot \overline{u} \cdot (lmd-m,35){n}}) \filterplus r_0 }
                & \mbox{($m$ and $n$ both appear in } t \filterplus r_0) \\
        &= \pview{ t \filterplus r_0 }
                & \mbox{(definition of $t$).} \qed
      \end{align*}
\end{itemize}
%% end of proof

We are now in a position to prove Proposition
\ref{prop:hylandong_pviewprojection}:

\proof[Proof of Proposition
\ref{prop:hylandong_pviewprojection}]

We have:
\begin{align*}
  \overline{\oview{t}_M\filterplus r_0}
        &= \overline{\oview{t}} \filterplus r_0 & \mbox{By Eq. \ref{eqn:hatfilter_eq_filterhat}} \\
        &\subseqof \overline{\longoview{t}} \filterplus r_0 & \mbox{By Eq. \ref{eqn:oview_suffix_longoview}} \\
        &= \pview{\overline{t}} \filterplus r_0 & \mbox{By definition (Eq. \ref{eqn:def_pview_oview_hat})} \\
        &\subseqof \pview{\overline{t} \filterplus r_0}  & \mbox{By Proposition \ref{prop:analog_pviewprojection}} \\
        &= \pview{\overline{t \filterplus r_0}}  & \mbox{By Eq. \ref{eqn:hatfilter_eq_filterhat}} \\
        &= \overline{\longoview{t \filterplus r_0}}  & \mbox{By Eq. \ref{eqn:def_pview_oview_hat}}
\end{align*}
These equations shows that $\overline{\oview{t}_M\filterplus r_0} \subseqof
\overline{\longoview{t \filterplus r_0}}$ therefore by Lemma
\ref{eqn:hat_subseq} we have $\oview{t}_M\filterplus r_0 \subseqof
\longoview{t \filterplus r_0}$. Furthermore, by Eq.
\ref{eqn:oview_suffix_longoview}, $\oview{t \filterplus
r_0}_{M^{(r')}}$ is a suffix of $\longoview{t \filterplus r_0}$:
$\longoview{t \filterplus r_0} = w \cdot \oview{t \filterplus
r_0}_{M^{(r')}}$ for some $w$ so we have $\oview{t}_M\filterplus r_0
\subseqof w \cdot \oview{t \filterplus r_0}_{M^{(r')}}$. By definition of the filtering operator $\_ \filterplus$, $r_0$ must
necessarily occur after the first node of $t \filterplus r_0$ thus
none of the nodes in $w$ appear in $t\filterplus r_0$. Consequently,
$\oview{t}_M\filterplus r_0 \subseqof \oview{t \filterplus
r_0}_{M^{(r')}}$. \qed

\begin{proposition}[Traversal filtering]
    \label{prop:trav_filtering}
    Let $t \in \travset(M)$. For any occurrence $r_0$ in $t$ of some lambda node
    $r'\in N_\lambda$ we have $t\filterplus r_0 \in \travset(M^{(r')})$.
\end{proposition}
\proof
    We proceed by by induction on the traversal rules. The base cases \rulenamet{Empty} and
    \rulenamet{Root} are trivial. \emph{Step case:} Take a traversal $t = t' \cdot n
    \in \travset(M)$. Suppose that the properties are
    verified for any traversal shorter than $t$.

    Suppose that $n$ does not appear in $t \filterplus r_0$ then
    the result follows by applying the induction hypothesis on $t'$.
    Suppose that $n$ appears in $t \filterplus r_0$.
    We do a case analysis on the last traversal rule used to form $t$:

  \begin{itemize}
    \item \rulenamet{Lam}
        We have $t' = \ldots \cdot \lambda \overline{\xi}$. By the
        induction hypothesis, $t' \filterplus r_0 \in
        \travset(M^{(r')})$.

        Since $\lambda \overline{\xi}$ is in the P-view $\pview{t}$,
        by Lemma \ref{lem:pview_trav_filtering} it must occur in
        $t\filterplus r_0$ and therefore it is the last occurrence
        in $t'\filterplus r_0$. Thus we can use the rule
        \rulenamet{Lam} in $\tau(M^{(r')})$ to produce the traversal
        $u = (t'\filterplus r_0) \cdot n$ of $M^{(r')}$.

        We have $t \filterplus r_0 = (t'\filterplus r_0) \cdot n$,
         but in order to state the equality $u = t \filterplus r_0$
         it remains to prove that $n$'s justifiers in $t \filterplus
         r_0$ are the same as $n$'s justifiers in $u$.

         The justifiers of $n$ in $u$ are defined as follows:
          \begin{compactitem}
                \item If $n \in N_@ \union N_\Sigma$ then it has no justifier;
                \item If $n \in N_{\sf var}$ then it has auxiliary links pointing to each of the prime $\lambda$-nodes in $\pview{t'\filterplus r_0}$. Furthermore,
                    if  $n \not\in N_{\sf fv}$ then its main link
                    points to the only occurrence of its enabler in
                    $\pview{t'\filterplus r_0}$ and if  $n \in
                    N_{\sf fv}$ then its main link points to $r_0$.
            \end{compactitem}

         On the other hand in $t \filterplus r_0$, $n$ points to all
         its justifiers in $\pview{t'}$ that also appear in
         $t'\filterplus r_0$.

         By Lemma \ref{lem:pview_trav_filtering} we have that
         $\pview{t'\filterplus r_0} = \pview{t}_{\suffixof r_0} =
         r_0 \cdot w$ where all the nodes in $w$ occur in $t
         \filterplus r_0$. Hence $n$'s justifiers in $u$ correspond
         precisely to the justifiers of $n$ in $t \filterplus r_0$
         and therefore $u = t \filterplus r_0$.

    \item \rulenamet{App} $t = \ldots \cdot \lambda \overline{\xi} \cdot @$.
        Again, since $\lambda \overline{\xi}$ is in the P-view
        $\pview{t}$, by Lemma \ref{lem:pview_trav_filtering} it must
        be the last occurrence in $t'\filterplus r_0$. By the
        induction hypothesis, $t' \filterplus r_0$ is a traversal of
        $\tau(M^{(r')})$ therefore we can use the rule
        \rulenamet{App} in $\tau(M^{(r')})$ to produce the traversal
        $(t'\filterplus r_0) \cdot n = t \filterplus r_0$ of
        $M^{(r')}$.


    \item \rulenamet{Value$^{@\mapsto\lambda}$} Take \Pstr[0.5cm]{t = t' \cdot (lmd){\lambda
        \overline{\xi}} \cdot (x){@}  \ldots  (xv-x,50:v){v}_@  \cdot
        (lmdv-lmd,30:v){v}_{\lambda \overline{\xi}} }.

        The occurrence $v_{\lambda \overline{\xi}}$ appears
        $t\filterplus r_0$ therefore since $r_0$ is not a lambda
        node, its justifier $\lambda \overline{\xi}$ also appear in
        $t\filterplus r_0$. Moreover since $@$ and $v_@$ are her.\
        just.\ by $\lambda \overline{\xi}$, they must also appear in
        $t\filterplus r_0$.

        By the induction hypothesis $t' \filterplus r_0$ is a
        traversal of $\tau(M^{(r')})$ therefore since the occurence
        $\lambda \overline{\xi}$, @, $v_@$, $v_{\lambda
        \overline{\xi}}$ all appear in $t\filterplus r_0$ we can use
        the rule \rulenamet{Value$^{@\mapsto\lambda}$} in $M^{(r')}$
        to form the traversal $(t'\filterplus r_0) \cdot n = t
        \filterplus r_0$ of $M^{(r')}$.

    \item \rulenamet{Value$^{\lambda\mapsto@}$}
          Take \Pstr[0.7cm]{t = t' \cdot (app){@} \cdot
        (lz-app,60){\lambda \overline{z}} \ldots
        (lzv-lz,60:v){v}_{\lambda \overline{z}} \cdot
        (appv-app,45:v){v}_@}. Again, since $v_@$ appears in $t
        \filterplus r_0$, necessarily the occurrences @, $\lambda
        \overline{z}$, $v_{\lambda \overline{z}}$ and $v_@$ must all
        appear in $t \filterplus r_0$. Hence using the induction
        hypothesis and the rule
        \rulenamet{Value$^{\lambda\mapsto@}$} in $M^{(r')}$ we
        obtain that $t \filterplus r_0$ is a traversal of
        $M^{(r')}$.

    \item \rulenamet{Value$^{{\sf var}\mapsto\lambda}$} Take \Pstr[0.5cm]{t = t' \cdot (lmd){\lambda
    \overline{\xi}} \cdot (x){x}  \ldots  (xv-x,50:v){v}_x  \cdot
    (lmdv-lmd,30:v){v}_{\lambda \overline{\xi}} }.

        Since $v_{\lambda \overline{\xi}}$ is in $t
        \filterplus r_0$, so must be $\lambda \overline{\xi}$, and
        therefore by applying Lemma \ref{lem:pview_trav_filtering}
        on $t_{\prefixof x}$, so must be $x$ and $v_x$. Hence we can
        use the I.H. to form the traversal $t
        \filterplus r_0$ of $M^{(r')}$.


   \item \rulenamet{InputValue} Take \Pstr[0.4cm]{t =
    t_1 \cdot (x){x} \cdot t_2 \cdot (xv-x,38:v){v_x} } for some
    $v \in \mathcal{D}$ where $x$ is the pending node in $t_1 \cdot x \cdot t_2$ and $x \in N_{\sf var}^{\theroot\vdash}$.

    Since $v_x$ appears in $t\filterplus r_0$, so does $x$ hence by Lemma \ref{lem:filterplus_pendingnode}, $x$ is also the pending node in $(t_1 \cdot x \cdot t_2)\filterplus r_0$. Furthermore $M^{(r')}$ is a subterm of $M$, $x$ is necessarily an input-variable node in $\tau(M^{(r')})$. Hence we can conclude using the I.H. and the rule \rulenamet{InputValue}.


    \item \rulenamet{InputVar} We use the alternative definition of the rule from Remark \ref{rem:inputvar_bis}:
    Take $t =  t' \cdot n$ where $n \in N_{\sf var}\union L_\lambda$ points to an occurrence of its parent node $y \in N_{\sf var}^{\theroot\vdash}$ in $\oview{t}$.

    By Lemma \ref{lem:ifin_tfilterstar_so_does_justifier}, $y$ must also appear in $t\filterplus r_0$,
    therefore $y$ also occurs in $\oview{t\filterplus r_0} \subseqof \oview{t}\filterplus r_0$.
    Hence we can conclude using the rule \rulenamet{InputVar} in $M^{(r')}$.


  \notetoself{ unfinished }
%    The proof is identical to the previous case.

    \item \rulenamet{Value$^{\lambda\mapsto{\sf var}}$} Take \Pstr[0.7cm]{t = t' \cdot (y){y} \cdot
    (lmd){\lambda \overline{\xi}} \ldots
    (lmdv-lmd,30:v){v}_{\lambda \overline{\xi}}  \cdot
    (vy-y,50:v){v}_y } for some variable $y$ in $N_{\sf var}^{@\vdash}$.
    

    Consider the node @ that hereditarily enable $y$ in the tree $\tau(M)$.

    Suppose that $r'$ is contained in the subtree rooted at $@$. Then @ also hereditarily enables the node $y$
    in the tree $\tau(M^{(r')})$.

    Suppose that $\lambda \overline{\xi}$ appears in $t\filterplus r_0$ then so does $v_{\lambda \overline{\xi}}$.

    therefore


    \item \rulenamet{Var}
    Take \Pstr[0.6cm]{ t = t' \cdot (p){p} \cdot (lx){\lambda
        \overline{x}} \ldots (x-lx,30:i){x_i}  \cdot
        (letai-p,40:i){\lambda \overline{\eta_i}} } for some
        variable $x_i$ not in $N_{\sf var}^{\theroot\vdash}$.

    If $\lambda \overline{\eta_i}$ is the occurrence $r_0$ then
    the traversal $t\filterplus r_0 = r_0$ can be formed using
    the rule \rulenamet{Root}.

    Suppose that $\lambda \overline{\eta_i}$ is not the occurrence $r_0$.

%    If $p$ is an @-node then we can conclude as in rule \rulename{Value$^{\lambda\mapsto@}$}.
%    Otherwise, $p$ must be a variable node $y$ that does not belong to $N^{\theroot\vdash}$.

    Then both $\lambda \overline{\eta_i}$ and its justifier $p$
    must appear in $t\filterplus r_0$. However $\lambda
    \overline{x}$ and $x_i$ do not necessarily appear in
    $t\filterplus r_0$.

    We do a case analysis on whether or not $x$ belongs to the sub-computation tree  $\tau(M^{(r')})$ or not:
    \begin{compactitem}
    \item If $x \in V^{(r')}$ then since $p$ appears in $t\filterplus r_0$, by applying Lemma \ref{lem:pview_trav_filtering}
    on $t_{\prefixof \lambda \overline{x}}$ we have that $x$ and
    $\lambda \overline{x}$ also appear in $t\filterplus r_0$.
    Hence we can use the I.H. together with the rule
    \rulenamet{Var} in $M^{(r')}$ to form the traversal $t
    \filterplus r_0$ of $M^{(r')}$.

    \item Suppose that $x \not \in V^{(r')}$ then necessarily its binder node $\lambda \overline{x}$ is not in $V^{(r')}$ either. Therefore the two consecutive
        nodes $n$ and $\lambda \overline{x}$ are such that
        the first is in $V^{(r')}$ (by Lemma \ref{lem:instarfilter_imp_insubtree}) but not the other. The only rule capable of performing such a ``jump'' in the computation tree is the rule \rulenamet{Var}. By Proposition \ref{prop:oview_trav_filtering}, these two nodes must belong to the same thread initiated by some @-node. This @-node hereditarily justifies a node lying outside $V^{(r')}$ hence it must be itself outside $V^{(r')}$. Thus the node $y$ is hered.\ just.\ by an @-node
        lying outside $V^{(r')}$ which mean that $y$ is a free variable in $M^{(r')}$!

        We can therefore make use of the rule
        \rulenamet{InputVar} in $M^{(r')}$ to produce the
        traversal $t \filterplus r_0$ of $M^{(r')}$.


    \end{compactitem}

    \item (Constant rules)  using the fact that constant
    rules are well-behaved
  \end{itemize}
\qed
% end of proof

\begin{corollary}
\label{cor:trav_filtering}
Let $t$ be a non-empty traversal of $M$ and $r$ denote the only occurrence of $\tau(M)$'s
root in $t$. If $t^\omega \in V^{\theroot\vdash}$ then $$\oview{t\filter r} = \oview{t}\filter r = \oview{t} \ .$$
\end{corollary}
\begin{proof}
It follows immediately from the fact that, by the previous Lemma \ref{lem:trav_oview_single_threaded}, all the occurrences in $\oview{t}$ belong to the same thread and therefore are all hereditarily justified by $r$.
\end{proof}

\begin{remark}
\label{rem:inputvar} In the rule \rulenamet{InputVar}, the visited node $n$ is necessarily in $N_\lambda^{\theroot\vdash}$. Indeed since $x$ is in $N^{\theroot\vdash}$, by
the previous proposition all the nodes and leaves in
$\oview{t_1 \cdot x}$ must be in the same thread as $x$ and thus are all hereditarily justified
by $r$. Since $n$ points in $\oview{t_1 \cdot x}$ it must also be
hereditarily justified by $r$.
\end{remark}


\begin{lemma}
\label{lem:red_pview_trav}
Suppose that $M$ is in $\beta$-normal form and that $\Sigma$-constants are of order $1$ at most.
Let $t$ be a non-empty traversal of $M$ and $r$ denote the only occurrence of $\tau(M)$'s
root in $t$. If $t$'s last occurrence is not a leaf then
$$ \pview{t \filter  r } = \pview{t} \filter r \ .$$
\end{lemma}
\notetoself{unfinished proof}
\begin{proof}
%Since $M$ is $\beta$-normal we have $t= t-@-\Sigma = t^\star$ and
%$t\filter r = t \filterplus r$. We have $t^\omega \not\in L$.
%Applying the previous lemma with $r'=r$ gives $\pview{t
%\filterplus r} = \pview{t} \filter N^{\theroot\vdash}$. Since there are
%no application or constant node, all the nodes are necessarily her.\
%just.\ by $r$ and therefore $\pview{t} \filter N^{\theroot\vdash} =
%\pview{t}$.

%%%%%%%%%
    %\item If $\Pstr{ t =  t' \cdot (m){m} \cdot  u \cdot (lmd-m,30){n}}$ with
    %$n\in N_\lambda$ and $n\not\in N^{\theroot\vdash}$ then necessarily $m
    %    \in N_@ \union N_{\sf var} \union N_\Sigma $.
    %
    %Let us do a case analysis on the rule used to visit $n$ in $t$.
    %The only relevant rules are \rulenamet{App}, \rulenamet{Var},
    %\rulenamet{InputVar}. Since the term is in $\beta$-normal form,
    %there is no @-node in $\tau(M)$ therefore the rules
    %\rulenamet{App} and \rulenamet{Var} cannot be used. The rule
    %\rulenamet{InputVar} cannot be used either. Indeed, suppose that
    %it is the case then $m$ must belong to $\oview{t_{\prefixof x}}$
    %where $x \in N^{\theroot\vdash}$ is the pending node in $t$. But then
    %by the induction hypothesis ($ii$), all the nodes in
    %$\oview{t_{\prefixof x}}$ are hereditarily justified by $r$
    %therefore we have $m\in N^{\theroot\vdash}$ which contradicts the case
    %hypothesis $n\not\in N^{\theroot\vdash}$.
    %
    %Hence this case does not occur.

      %      \begin{align*}
    %        \pview{t} \filter  r
    %        &= \pview{\Pstr{t' \cdot (m){m} \cdot (n-m,60){n}}} \filter  r
    %                                                        & (u=\epsilon)\\
    %        &= (\Pstr{\pview{t'} \cdot (m){m} \cdot (lmd-m,60){n}} ) \filter  r
    %                                                        & (\mbox{P-view computation}) \\
    %        &= \pview{t'} \filter  r                & (m, n \not\in V^{\theroot\vdash}) \\
    %        &= \pview{t' \filter  r }               & \mbox{(induction hypothesis)} \\
    %        &= \pview{ (\Pstr{t' \cdot (m){m} \cdot (lmd-m,40){n}}) \filter r }
    %                                                        & (m, n \not\in V^{\theroot\vdash}) \\
    %        &= \pview{ t \filter r }             & \mbox{(def. of $t$ \& $u = \epsilon$).}
    %        \end{align*}
\end{proof}







\section{Game semantics correspondence}
\label{sec:gamesemcorresp}

 We are working in the general setting of an applied
simply-typed $\lambda$-calculus with a given set of higher-order
constants $\Sigma$. The operational semantics of these constants is
given by certain reduction rules. We assume that a fully abstract
model of the calculus is provided by means of a category of
well-bracketed games. For instance, if $\Sigma$ consists
of the \pcf\ constants then we consider the traditional
category of games and innocent well-bracketed strategies
\cite{hylandong_pcf,abramsky94full}.


In the literature, a strategy is commonly defined as a set of plays closed by
even-length prefixing. For our purpose, however, it is more convenient to represent strategies using \emph{prefix-closed} set of plays. This saves us from considerations on the parity of traversal length when
showing the correspondence between traversals and game semantics.
 For the rest of the section we fix a simply-typed term $\Gamma \vdash M :T$. We write $\sem{\Gamma \vdash M : T}$ for its strategy denotation (in the standard cartesian closed category of games and innocent strategies \cite{abramsky94full, hylandong_pcf}). We use the notation $\prefset(S)$ to denote the prefix-closure of the set $S$.

\subsection{Interaction games}
\label{sec:interaction_semantics}

In game semantics, strategy composition is achieved by performing a
CSP-like ``composition + hiding''. It is possible to define an
alternative semantics where the internal moves are not hidden when
performing composition. This semantics is named \emph{revealed
semantics} in \cite{willgreenlandthesis} and \emph{interaction}
semantics in \cite{DBLP:conf/sas/DimovskiGL05}.

In addition to the moves of the standard semantics, the interaction
semantics contains certain internal moves of the computation.
Consequently, the interaction semantics depends on the syntactical
structure of the term and therefore cannot lead to a full
abstraction result. However this semantics will prove to be useful
to identify a correspondence between the game semantics of a term
and the traversals of its computation tree.

Our interaction semantics will be calculated from the $\eta$-normal
form of a term. However we do not want to keep all the internal
moves: we only keep the internal moves that are produced when
composing two subterms of the computation tree joint by an @-node.
This means that when computing the strategy denoting $y N_1 \ldots
N_p$ where $y$ is a variable, we preserve the internal moves of
$N_1$, \ldots, $N_p$ while omitting the internal moves produced by
the copy-cat projection strategy denoting $y$.


\begin{definition} \hfill
\begin{itemize}
\item We call \defname{interaction type tree} or just \defname{interaction type},
a tree whose leaves are labelled with linear simple types and
inner nodes are labelled with symbol in $\{ ;, \langle \_\ ,\_
\rangle, \otimes, \dagger, \Lambda \}$.


Nodes labelled $;$, $\langle \_\ ,\_ \rangle$ or $\otimes$ are
binary nodes and nodes labelled $\dagger$ or $\Lambda$ are unary
nodes. If $T_1$ and $T_2$ are interaction types we write
$\langle T_1, T_2 \rangle$ to denote the interaction type
obtained by attaching $T_1$ and $T_2$ to a $\langle \_\ ,\_
\rangle$-node. Similarly we use the notations $T_1 \otimes T_2$,
$T_1 ; T_2$, $\Lambda(T_1)$ and $T_1^\dagger$.

\item To every node we can associate a linear type. We write
    $type(T)$ to denote the type associated to the root node. We
    sometime write the type in exponent {\it e.g.}
    $T^{A\rightarrow B}$ if $type(T) =A\rightarrow B$. This type
    is determined by the structure of the tree as follows:
    \begin{itemize}
    \item If $T$ is a leaf then $type(T)$ is define as the type that labels the leaf;

    \item $type\ (T^{!A \multimap B})^\dagger = !A \multimap !B$;

    \item $type\ \Lambda(T_1^{A \otimes B \multimap C}) = A \multimap (B \multimap C)$

    \item $type\ \langle T_1^{C \multimap A} , T_2^{C \multimap B} \rangle =
    C \multimap A \times B$;

    \item $type\ T_1^{A \multimap B} \otimes T_2^{C \multimap D} = (A \otimes C) \multimap (B \otimes D)$;

    \item $type\ T_1^{A \multimap B};T_2^{B \multimap C} = A \multimap C$.
    \end{itemize}

\end{itemize}

For the interaction type tree to be well-defined, it is required
that types of children nodes are consistent with the meaning of the
parent node; for instance the two children nodes of a ;-node must be
of type $A\multimap B$ and $B\multimap C$.

\end{definition}


Let $T$ be an interaction type tree. Each node of type $A$ in $T$
can be mapped to the (standard) game $\sem{A}$. By taking the image
of $T$ across this mapping we obtain a tree whose leaves and nodes
are labelled by games. This tree, written $\intersem{T}$, is called
an \defname{interaction game}.

A \defname{revealed strategy} $\Sigma$ on the interaction game $\intersem{T}$ is a compositions of several standard strategies in which certain internal moves are not hidden. Formally:
\begin{definition}[Revealed strategy]
A revealed strategy $\Sigma$ on an interaction game $\intersem{T}$,
written $\Sigma: \intersem{T}$, is an annotated interaction type
tree $T$ where
\begin{itemize}
\item each leaf $\sem{A}$ of $T$ is annotated with a (standard) strategy $\sigma$ on the game
$\sem{A}$;
\item each $;$-node is annotated with a set of indices $U \subseteq \nat$.
\end{itemize}
\end{definition}

The intuition behind this definition is that each $;$-node with children of type $A\multimap B$ and $B\multimap C$ is annotated with a set of indices $U$ indicating which components of $B$ should be uncovered when performing composition.
More precisely, if $B = B_0 \times \ldots \times B_l$ then the revealed strategy built by connecting two revealed strategies $\Sigma_1 : \intersem{A\multimap B}$ and $\Sigma_2 : \intersem{B\multimap C}$
using a $;$-node annotated with $U$ represents the
set of uncovered plays obtained
by performing the usual composition while ignoring and copying the internal moves already in $\Sigma_1$ and $\Sigma_2$ and preserving any internal
move produced by the composition in some component $B_k$ for $k \in U$.

\begin{example}
The diagrams below represent an interaction type tree $T$ (left),
the corresponding interaction game $\intersem{T}$ (middle) and a
revealed strategy $\Sigma$ (right):
$$
\pstree[levelsep=6ex]{\TR{;}}
        {
            \pstree[levelsep=6ex]{\TR{;}}
            { \TR{A\multimap B}
              \TR{B\multimap C}
            }
            \TR{C\multimap D}
        }
\hspace{1cm}
\pstree[levelsep=6ex]{\TR{;}}
        {
            \pstree[levelsep=6ex]{\TR{;}}
            { \TR{\sem{A\multimap B}}
              \TR{\sem{B\multimap C}}
            }
            \TR{\sem{C\multimap D}}
        }
\hspace{1cm}
\pstree[levelsep=6ex]{\TR{;^{\{0\}}}}
        {
            \pstree[levelsep=6ex]{\TR{;^{\{0\}}}}
            { \TR{A\multimap B^{\sigma_1}}
              \TR{B\multimap C^{\sigma_2}}
            }
            \TR{C\multimap D^{\sigma_3}}
        }
$$
\end{example}
A revealed strategy can also be written as an expression, for
instance the strategy represented above is given by the expression
$\Sigma = (\sigma_1 ;^{\{0\}} \sigma_2) ;^{\{0\}} \sigma_3$. We will
use the abbreviation $\Sigma_1 \fatsemi^U \Sigma_2$ for
$\Sigma_1^\dagger ; ^U \Sigma_2$.


\subsubsection{Uncovered play}

The analogous of a play in the interaction semantics is called an
\emph{uncovered play}, it is a play containing internal moves. The
moves are implicitly tagged so that it is possible to retrieve in
which component of the arena of which node-game the move belongs to.
A given move may belong to several games from different nodes of the
interaction game.

\begin{definition}
The \defname{set of possible moves} $M_T$ of an interaction game
$\intersem{T}$ is defined as $\mathcal{M}_T/\hspace{-0.5em}\sim_T$,
the quotient of the set $\mathcal{M}_T$ by the equivalence relation
$\sim_T \subseteq \mathcal{M}_T \times \mathcal{M}_T$ defined as follows:
For a single leaf tree $T$ labelled by a type $A$ we define
$\mathcal{M}_T = M_A$ and $\sim_T = id_{M_A}$. For other cases:
    \begin{align*}
        \mathcal{M}_{T^\dagger} &= \mathcal{M}_{T} + M_{type(T^\dagger)}
    &
        \mathcal{M}_{\Lambda(T)} &= \mathcal{M}_{T} + M_{type(\Lambda(T))}
    \\
        \sim_{T^\dagger} &= \left( \sim_{T}
        \union \left(type\ T^\dagger \leftrightarrow  type\ T\right)
        \right)^\star
    &
        \sim_{\Lambda(T)} &= \left( \sim_{T}
        \union \left(type\ \Lambda(T) \leftrightarrow type\ T\right)
        \right)^\star
    \end{align*}
    \begin{align*}
        \mathcal{M}_{\langle T_1^{C^1 \multimap A^1}, T_2^{C^2 \multimap B^2}\rangle}
        &= \mathcal{M}_{T_1} + \mathcal{M}_{T_2} + M_{C \multimap (A \otimes B)}
    \\
         \sim_{\langle T_1^{C^1 \multimap A^1}, T_2^{C^2 \multimap B^2}\rangle} &= \left( \sim_{T_1}
        \union \sim_{T_2} \union (C^1 \leftrightarrow C) \union (C^2 \leftrightarrow C)
        \union (A^1 \leftrightarrow A) \union (B^2 \leftrightarrow B)
        \right)^\star
    \\
    \\
        \mathcal{M}_{T_1^{A^1 \multimap B^1}\otimes T_2^{C^2 \multimap D^2}} &= \mathcal{M}_{T_1} +  \mathcal{M}_{T_2} + M_{A \otimes C \multimap B \otimes D }
        \\
         \sim_{T_1^{A^1 \multimap B^1}\otimes T_2^{C^2 \multimap D^2}} &= \left( \sim_{T_1}
        \union \sim_{T_2} \union (A^1 \leftrightarrow A)
        \union (B^1 \leftrightarrow B) \union (C^2 \leftrightarrow C)\union (D^2 \leftrightarrow D)
        \right)^\star
    \\
    \\
        \mathcal{M}_{T_1^{A \multimap B};T_2^{B \multimap C}} &=
            \mathcal{M}_{T_1} + \mathcal{M}_{T_2} + M_{A\multimap C}
        \\
         \sim_{T_1^{A^1 \multimap B^1};T_2^{B^2 \multimap C^2}} &= \left( \sim_{T_1}
        \union \sim_{T_2} \union (A^1 \leftrightarrow A)
        \union (B^1 \leftrightarrow B^2) \union (C \leftrightarrow C^2)
        \right)^\star
    \end{align*}
    where $A\leftrightarrow B$ denotes the implicit bijection between
    two isomorphic arenas $\sem{A}$ and $\sem{B}$; $R^\star$
    denotes the smallest superset of the relation $R$ complete
    by transitivity, reflexivity and symmetry.
\end{definition}

We call \defname{internal move} of the game $\intersem{T}$, any move
from $M_T$ which is not $\sim$-equivalent to any move in
$M_{type(T)}$.


A \defname{justified interaction sequence} of moves on the
interaction game $\intersem{T}$ is a sequence of moves from $M_T$
together with pointers. In contrast to the standard notion of
justified sequence, to each move in the sequence can be attached
several pointers. More precisely, if the equivalence class $m$ is
$\{m_1, \ldots, m_l \}$ then $m$ has one pointer for each
non-initial move $m_i$ in the equivalence class.

\begin{definition}[Filtering] We define several filtering operations
over justified interaction sequences. Let $s$ be a justified
sequence of moves on the interaction game $\intersem{T}$.
\begin{itemize}
\item  Let $T'$ be a subtree of $T$. We define the
filtering operator $s\filter T'$ to be the subsequence
of $s$ consisting of moves $\sim$-equivalent to some move in
$M_{T'}$. This operation causes some move to ``lose'' some of
their attached pointers: a given move $m$ with equivalence class
$\{m_1, \ldots, m_l \}$ may have up to $l$ pointers, but in
$s\filter T'$, only pointers associated to a $m_i$
belonging to $\mathcal{M}_{T'}$ are preserved.

Note that since $M_T$ is a set of equivalence classes with
respect to $\sim$, the filtering operator $\_ \filter T'$
implicitly performs the ``retagging'' of the moves to the
appropriate components of each game of the interaction game
$\intersem{T'}$.

\item  For any sub-game $A$ of the standard game $\sem{type(T')}$ we
define the filtering operator $s\filter A$ to be the
subsequence of $s$ consisting of moves from $A$ where at most
one pointer is kept for each move in the sequence: the one
corresponding to the class citizen from $A$.

\item For any initial move $m$ of the game $\sem{type(T)}$ occurring in $s$, $s
\filter m$ is the subsequence of $s$ consisting of moves
that are \emph{hereditarily justified} by that particular occurrence of $m$ in $s \filter type(T)$.
% NOTE: it is important to precise ``in $s \filter type(T)$'' because $s$'justification
% pointers differs depending on the sub-interaction game considered.
\end{itemize}
By extension, we also define these operations on sets of justified
interaction sequences.
\end{definition}

Allowing moves to have multiple pointers complicates slightly the
presentation here, but this capability is necessary to model
strategy composition. Indeed, in game semantics after composing
strategies, the pointers from some moves may change! (See definition
of $\filter A,C$ in \cite{abramsky:game-semantics-tutorial}.)
For all the other operations on strategies that we will
used, however, the pointers will just be preserved:
Let $s$ be an  interaction sequence on a game
$\intersem{T}$, $T'$ a subtree of $T$, $A$ be a sub-game of
$\sem{type(T)}$ and $A'$ be a sub-game of $\sem{type(T')}$ such that $A$ and $A'$ are $\sim$-equivalent,
we say that $s$'s \defname{justification is preserved from $A$ to $A'$}
with respect to $\sim$ and we write $A\stackrel{s}\hookrightarrow A'$ if
whenever an occurrence $m$ is justified by $n$ in $s\filter A$ then $m$ is justified by the same occurrence $n$ in $s \filter A'$. Formally:
\begin{align*}
 A\stackrel{s}\hookrightarrow A' \qquad \mbox{ holds iff } \qquad  &
s\filter A = s\filter A' \ .
\end{align*}

\begin{definition}[Legal uncovered positions] We recall
that in the standard game semantics, the set of legal positions
$L_A$ of a game $A$ is the set of justified sequences of moves from
$M_A$ respecting visibility and alternation. We define the set of
\defname{legal uncovered position} $L_T$ of an interaction game $\intersem{T}$ as
follows:
    \begin{itemize}
    \item If $T$ is a leaf annotated by a type $A$ then $L_T =
    L_A$;
    \item If $T$ is a unary node with child node $T'$ then:
    $$L_T = \{ s \in JustSeq(T) \ | \ s \filter type(T) \in L_{type(T)} \zand  s \filter T' \in L_{T'} \} \ ;$$
    \item If $T$ is a binary node with children nodes $T_1$ and $T_2$ then:
    $$L_T = \{ s \in JustSeq(T) \ | \ s \filter type(T) \in L_{type(T)} \zand  s \filter T_1 \in L_{T_1}
    \zand  s \filter T_2 \in L_{T_2} \} \ .$$
    \end{itemize}
    where $JustSeq(T)$ denotes the set of justified interaction sequences on
    $\intersem{T}$.
\end{definition}

Revealed strategies can alternatively be represented as by means
of sets of uncovered positions:
\begin{definition}[Revealed strategies as set of uncovered positions]
\label{dfn:revealedstrat}
The set of uncovered positions of a revealed strategy is defined inductively on the
structure of the annotated interaction type tree underlying the
interaction strategy:
\begin{itemize}[-]
\item Leaf labelled with type $A$ and annotated by the strategy $\sigma$: The set of positions of the revealed strategy is precisely the set of positions of the standard strategy $\sigma$.

%\item Tensor product, pairing, promotion, currying:
%$$
%\begin{array}{lcll}

\item Tensor product: $$\begin{array}{lcll}
(\Sigma_1 : \intersem{T_1}) \otimes (\Sigma_2 : \intersem{T_2}) : \intersem{T} &=\{ s \in L_T \ | \  &s \filter T_1 \in \Sigma_1 \zand\ s \filter T_2 \in \Sigma_2 \\
&& \zand\ A^1\stackrel{s}\hookrightarrow A  \zand\ B^1\stackrel{s}\hookrightarrow B \\
&& \zand\ C^2\stackrel{s}\hookrightarrow C  \zand\ D^2\stackrel{s}\hookrightarrow D \}
\end{array}$$
where $type(T_1) = A^1\multimap B^1$,
$type(T_2) = C^2\multimap D^2$
and $type(T) = A\otimes B \multimap C \otimes D$.

\item Pairing: $$\begin{array}{lcll}
\langle \Sigma_1 : \intersem{T_1}, \Sigma_2 : \intersem{T_2} \rangle : \intersem{T} &= \{ s \in L_T \ | &
   ( (s \filter T_1 \in \Sigma_1 \zand\ s \filter T_2 = \epsilon) \\
&&  \   \zor ( s \filter T_1 = \epsilon \zand s \filter T_2 \in \Sigma_2)) \\
&& \zand\ C^1\stackrel{s}\hookrightarrow C \zand\ A^1\stackrel{s}\hookrightarrow A  \\
&& \zand\ C^2\stackrel{s}\hookrightarrow C \zand\ B^2\stackrel{s}\hookrightarrow B  \}
\end{array}$$
where $type(T_1) = C^1\multimap A^1$,
$type(T_2) = C^2\multimap B^2$
and $type(T) = C\multimap A \times B$.

\item Promotion: $$\begin{array}{lcll}
(\Sigma' : \intersem{T'})^\dagger : \intersem{T} &= \{ s \in L_T \ | \ &
\mbox {for all occurrence $m$ in $s$ of an initial  }\\
&& \mbox{ $\sem{type(T)}$-move, $(s \filter m) \filter T' \in \Sigma'$} \\
&& \zand\ type(T')\stackrel{s}\hookrightarrow type(T) \} \ .
\end{array}$$

\item Currying: $\Lambda(\Sigma' : \intersem{T'}) : \intersem{T} = \{ s \in L_T \ |  s \filter T' \in \Sigma' \ \zand\ type(T')\stackrel{s}\hookrightarrow type(T) \}$.

\item Uncovered composition $(\Sigma_1 : \intersem{T_1})\ ;^U\ (\Sigma_2
:\intersem{T_2})$ defined on the game $\intersem{T}$ where
$type(T) = A \multimap C$, $type(T_1) = A^1 \multimap B_0 \times
\ldots \times B_l$ and $type(T_2) = B_0 \times \ldots \times B_l
\multimap C^2$. We first define
\begin{eqnarray*}
\Sigma_1 \| \Sigma_2 &= \{ u \in L_T  \ | \ & u \filter T_1 \in \Sigma_1 \mbox{ and } u \filter T_2 \in \Sigma_2 \\
&& \zand\ C^2\stackrel{u}\hookrightarrow C\ \zand\ (A^1)^-\stackrel{u}\hookrightarrow A^-  \\
&& \zand\ \parbox[t]{8cm}{for any initial $m$ in $A^1$, if $m$ is justified in $u \filter type(T_1)$ by $b\in B_j$,
itself justified by $c \in C^2$ in $u \filter type(T_2)$ then $m$ justified by $c$ in $u \filter type(T)$ \} }
\end{eqnarray*}
where $A^-$ denotes the set of non-initial moves of the game $A$. We can now define composition as:
$$ \Sigma_1 ;^U \Sigma_2 = \{ cover(u,(0..l)\setminus U) \ | \ u \in \Sigma_1 \| \Sigma_2 \}$$
where $cover(u,C) = u \filter \left( M_T \setminus \Union_{j\in
C} B_j \right)$ {\it i.e.}~the subsequence of $u$ obtained by
removing moves in $\Union_{j\in C} B_j$. Hence
$\Sigma_1;^{\{0..l\}} \Sigma_2 = \Sigma_1 \| \Sigma_2$.

In other words $\Sigma_1 ;^U \Sigma_1$ is the set of uncovered
plays obtained by performing the usual composition while
ignoring and copying the internal moves from arenas in
$\intersem{T_1}$ or $\intersem{T_2}$ and preserving any internal
move produced by the composition in some component $B_k$ for $k
\in U$.
\end{itemize}
\end{definition}

\begin{remark} \hfill
\label{rem:interstrat}
\begin{enumerate}[i.]
\item We observe that for all strategy operator
except composition, pointers associated to moves are preserved.
For strategy composition, additional pointers are
``created'' only for initial $A$-moves.
\item It is straightforward to generalize the pairing operator $\langle \Sigma_1, \Sigma_2 \rangle$ to more than two parameters: an interaction strategy $\langle \Sigma_1, \ldots, \Sigma_p \rangle$ for $p\geq2$
is defined on an interaction game whose root node has $p$ children.
\end{enumerate}
\end{remark}

We write $\mathcal{I}$ for the set of all revealed strategies. Note
that $\mathcal{I}$ is not a category since composition is not
associative and there is no identity interaction strategy.


\begin{lemma}[Complete interaction sequence]
\label{lem:inter_complete}
Let $u$ be an interaction sequence of some interaction strategy $\Sigma : \intersem{T}$
and suppose that the standard strategy denoting the leaves of $\Sigma$ are all well-bracketed.

Then for any node game $A$ of $T$ and interaction sequence $u\in
\Sigma$ we have:
\begin{enumerate}[i.]
\item $u \filter A$ is well-bracketed;

\item If $u \filter type(T)$ is complete (all question moves answered) then
    $u \filter A$ is complete.
\end{enumerate}
\end{lemma}
\begin{proof}
By induction on the structure of the interaction game $\intersem{T}$. The base case is
trivial. We only treat composition, the other cases being trivial: Let $ u \in \Sigma_1 ; ^U \Sigma_2$ for some $U \subseteq \nat$ with
$\Sigma_1 : \intersem{T_1^{A\multimap B}}$ and $\Sigma_2 : \intersem{T_2^{B\multimap C}}$.

i. During composition, pointers attached to answer moves are preserved with respect to $\sim$
thus non-well-bracketing of $u\filter A\multimap C$ implies
either non-well-bracketing of $u\filter A\multimap B$ or $u\filter B\multimap C$.

For ii., suppose $u \filter type(T) = \Pstr{(q)q\ u'\ (a-q)a }$.
By well-bracketing (i.) and since $q$ and $a$ belong to $C$ we must have
$u \filter B\multimap C = \Pstr{(q)q \ldots (a-q)a}$ thus $u \filter B\multimap C$ is complete.
Suppose that $u \filter A\multimap B$ is not complete, then its first move is unanswered,
but since this is a $B$-move, it must also occur unanswered in $u \filter B\multimap C$ which is a contradiction
since we have just prove that $u \filter B\multimap C$ is complete. Thus $u \filter A\multimap B$  is also complete.

The induction hypothesis permits to conclude.
\end{proof}
Consequently if $u\filter type(T)$ is complete then $u$ is maximal {\em i.e.~no move (and in particular no internal move) can be played after $u$}.

\subsubsection{Modeling the $\lambda$-calculus in $\mathcal{I}$}

We would like to use revealed strategies from $\mathcal{I}$ to model terms of
the simply-typed lambda calculus.
Depending on the internal moves that we wish to hide, we obtain different possible interaction strategies for a given term.
The following definition fixes a unique strategy denotation which is computed from the $\eta$-normal form of the term.

\begin{definition}[Revealed denotation of a term]
\label{dfn:interactionstrategy_ofterms}
Let $\pi_i$ denote the $i^{th}$ projection copycat strategy $\pi_i : \sem{X_1 \times \ldots \times X_l} \rightarrow \sem{X_i}$.

The \defname{revealed game denotation} or \emph{revealed strategy} of
$M$ written $\intersem{\Gamma \vdash M : A}$ is defined as
$\sem{\Gamma \vdash M : A}$ if $M$ is in $\beta$-normal form, otherwise
it is defined by structural induction on the \emph{$\eta$-long normal form of $M$}:
\begin{eqnarray*}
\intersem{\Gamma \vdash \lambda \overline{\xi} . M  : A} &=& \Lambda^{|\overline{\xi}|}(\intersem{\Gamma, \overline{\xi} \vdash M : o })  \\
\intersem{\Gamma  \vdash x_i N_1 \ldots N_p :o} &=& \langle \pi_i, \intersem{\Gamma \vdash N_1 : A_1}, \ldots, \intersem{\Gamma \vdash N_p : A_p}  \rangle \fatsemi ^{\{1..p\}} ev^p \\
\intersem{\Gamma \vdash f N_1 \ldots N_p : o} &=& \langle \intersem{\Gamma \vdash N_1 : A_1}, \ldots, \intersem{\Gamma \vdash N_p : A_p} \rangle^\dagger\  \|\ \sem{f} \\
\intersem{\Gamma \vdash N_0 \ldots N_p : o} &=& \langle \intersem{\Gamma \vdash N_0 : A_0}, \ldots, \intersem{\Gamma \vdash N_p : A_p}  \rangle^\dagger\ \|\ ev^p
\end{eqnarray*}
where $\Gamma = x_1 : X_1 \ldots x_l : X_l$, $f : A_0$ is a $\Sigma$-constants, $p\geq 1$, $A_0 =
(A_1,\ldots,A_p,o)$, $ev^p$ denotes the evaluation strategy with
$p$ parameters and $X_i = A_0$ in the second equation.
\end{definition}

Figure \ref{fig:interaction_strategy_denotations} contains tree representations of the interaction games of the revealed strategy $\intersem{\Gamma \vdash M : A}$ for the application cases. These tree tell us all the information that we need about the strategy involved in $\intersem{M}$. For instance the revealed strategy $\Sigma$ is defined on the interaction game $\intersem{T^{00}}$ whose root is $!A^0 \multimap B^0$; the strategy $ev$ is defined on the interaction game $\intersem{T^1}$ with a single game-node $!B_0^1 \otimes \ldots \otimes !B_p^1 \multimap o$; thus plays of $ev$ do not contain any uncovered move.


    \begin{figure}[htbp]
        $$
        \tree[levelsep=8ex,thistreesep=3cm]{\TR{\intersem{N_0 N_1 \ldots N_p :o}:T [!A\multimap o]}}
                {   \tree[levelsep=8ex]{\TR{\Sigma^\dagger:T^0[!A^0\multimap !B_0^0\otimes \ldots \otimes !B_p^0 ]}}
                        {
                            \tree[levelsep=8ex,thistreesep=3cm]{\TR{\Sigma:T^{00}[!A^{00}\multimap B_0^{00}\times \ldots \times B_p^{00}]}}
                            {
                                \tree[levelsep=8ex]{\TR{\intersem{N_0}:T^{000}[!A^{000}\multimap B_0]}}{\Tfan[fansize=10ex]}
                                \TR{\ldots}
                                \tree[levelsep=8ex]{\TR{\intersem{N_p}:T^{00p}[!A^{00p}\multimap B_p]}}{\Tfan[fansize=10ex]}
                            }
                        }
                    \TR{ ev:T^1[!B_0^1 \otimes \ldots \otimes !B_p^1 \multimap o] }
                }
       $$
       \begin{center}
       \emph{Tree-representation of the revealed strategy $\intersem{\Gamma \vdash N_0 N_1 \ldots N_p :o}$.}
       \end{center}

        $$
        \tree[levelsep=6ex,thistreesep=3cm]{\TR{\intersem{x_i N_1 \ldots N_p :o}:T [!A\multimap o]}}
                {   \tree[levelsep=8ex]{\TR{\Sigma^\dagger:T^0[!A^0\multimap !B_0^0\otimes \ldots \otimes !B_p^0 ]}}
                        {
                            \tree[levelsep=8ex,thistreesep=3cm]{\TR{\Sigma:T^{00}[!A^{00}\multimap B_0^{00}\times \ldots \times B_p^{00}]}}
                            {
                                \TR{\pi_i:T^{000}[!A^{000}\multimap B_0]}
                                \tree[levelsep=8ex]{\TR{\intersem{N_1}:T^{001}[!A^{001}\multimap B_1]}}{\Tfan[fansize=10ex]}
                                \TR{\ldots}
                                \tree[levelsep=8ex]{\TR{\intersem{N_p}:T^{00p}[!A^{00p}\multimap B_p]}}{\Tfan[fansize=10ex]}
                            }
                        }
                    \TR{ ev:T^1[!B_0^1 \otimes \ldots \otimes !B_p^1 \multimap o] }
                }
        $$
       \begin{center}\emph{Tree-representation of the revealed strategy $\intersem{\overline{x}:\overline{X}\vdash x_i N_1 \ldots N_p :o}$.}
       \end{center}
    \bigskip
    {\small
     Node labels are of the form $\Pi : T' [A]$ where $\Pi$ is a strategy, $T'$ is the corresponding interaction game and $A$ is the standard game lying at the root of the interaction game $T$. The games $A$ and $B$ are defined as follows:
    \begin{eqnarray*}
        A &=& \Gamma = X_1 \times \ldots \times X_n\\
        B &=& \underbrace{((B_1' \times \ldots \times B_p') \rightarrow o')}_{B_0} \times B_1 \times \ldots \times B_p
    \end{eqnarray*}
    Games are annotated with string  $s \in \{ 0..p \}^*$ in the exponent to indicate the path from the root to the corresponding node in the tree (each number in $s$ indicates which direction to take at the corresponding branch point).
   }
        \smallskip
       \caption{Tree-representation of the revealed strategy in the application case.}
      \label{fig:interaction_strategy_denotations}
    \end{figure}


\begin{remark}
When computing an interaction strategy of the form
$\intersem{y_i N_1 \ldots N_p}$ for some variable $y_i$, the
internal moves of $N_1$, \ldots, $N_p$ are preserved however the
internal moves produced by the copy-cat projection strategy denoting
$y_i$ are omitted.
\end{remark}

\begin{example}
Take the term $\lambda x . (\lambda f . f x) (\lambda y . y)$.
%Its computation tree is:
%$$
%\tree{\lambda x} {
%    \pstree[levelsep=4ex]{\TR{@}}
%    {       \pstree[levelsep=4ex]{\TR{\lambda f}}
%                { \tree{f}{  \tree{\lambda}{ \TR{x}  } } }
%            \pstree[levelsep=4ex]{\TR{\lambda y}}
%                    {\TR{y}}
%    } }
%$$
Its revealed strategy is $$\Lambda ( \langle \sem{ x:X \vdash \lambda f . f
x : (o\rightarrow o) \rightarrow o} , \sem{ x:X \vdash \lambda y . y
: o \rightarrow o} \rangle \| ev_2 ) \ .$$
\end{example}


\subsubsection{From interaction semantics to standard semantics and vice-versa}

In the standard semantics, given two strategies $\sigma : A
\rightarrow B$, $\tau : B \rightarrow C$ and a sequence $s \in
\sigma \fatsemi \tau$, it is possible to (uniquely) recover the
internal moves. The uncovered sequence is written ${\bf u}(s,
\sigma, \tau)$. The algorithm to obtain this unique uncovering is
given in part II of \cite{hylandong_pcf}. Therefore given a term
$M$, we can completely uncover the internal moves of a sequence
$s\in\sem{M}$ by performing the uncovering operation recursively at
every @-node of the computation tree.

Conversely, the standard semantics can be recovered from the
interaction semantics by filtering the moves, keeping only those
played in the root arena:
\begin{eqnarray}
 \sem{\Gamma \vdash M : T} = \intersem{\Gamma \vdash M : T} \filter \sem{\Gamma \rightarrow T} \label{eqn:int_std_gamsem}
\end{eqnarray}




\subsection{Relating computation trees and games}
Let us first study an example:
\subsubsection{Example}
Consider the following term $M \equiv \lambda f z . (\lambda g x . f (f x)) (\lambda y. y) z$ of type $(o \typear o) \typear o \typear o$.
Its $\eta$-long normal form is $\lambda f z . (\lambda g x . f (f x)) (\lambda y. y) (\lambda .z)$.
The computation tree is:

$$
\tree{\lambda f z}
{ \tree{@}
    {
        \tree{\lambda g x}
            { \tree{f}{   \tree{\lambda}{ \tree{f}{  \tree{\lambda}{\TR{x}}} }  }
            }
        \tree{\lambda y}{\TR{y}}
        \tree{\lambda}{\TR{z}}
    }
}
$$

The arena for the type $(o \typear o) \typear o \typear o$ is:
$$\tree{q^1}
{
    \tree{q^3}
        {  \tree{q^4}
                {\TR{a^4_1} \TR{\ldots}}
            \TR{a^3_1} \TR{\ldots} }
    \tree{q^2}
    { \TR{a^2_1} \TR{a^2_2}\TR{\ldots} }
    \TR{a_1} \TR{a_2}\TR{\ldots}
}
$$

\newlength{\yNull}
\def\bow{\quad\psarc{->}(0,\yNull){1.5ex}{90}{270}}

The figure below represents the computation tree (left) and the
arena (right). The dashed line defines a partial function $\psi$
from the set of nodes in the computation tree to the set of moves.
For simplicity, we now omit answers moves when representing arenas.
$$
\tree{ \Rnode{root} {\lambda f z}^{[1]} }
     {  \tree{@^{[2]}}
        {   \tree{\lambda g x ^{[3]}}
                { \tree{\Rnode{f}{f^{[6]}}}{  \tree{\Rnode{lmd}\lambda^{[7]}}{ \tree{\Rnode{f2}{f^{[8]}}} {\tree{\Rnode{lmd2}\lambda^{[9]}}{\TR{x^{[10]}}}}}  }
                }
            \tree{\lambda y ^{[4]}}{\TR{y}}
            \tree{\lambda ^{[5]}}{\TR{\Rnode{z}z}}
        }
    }
\hspace{3cm}
  \tree[levelsep=12ex]{ \Rnode{q1}q^1 }
    {   \pstree[levelsep=4ex]{\TR{\Rnode{q3}q^3}}{\TR{\Rnode{q4}q^4}}
        \TR{\Rnode{q2}q^2}
        \TR{\Rnode{q5}q^5}
    }
\psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
\ncline{->}{root}{q1} \aput*{:U}{\psi}
\ncarc{->}{z}{q2}
\ncline{->}{f}{q3}
\ncline{->}{lmd}{q4}
\ncline{->}{f2}{q3}
\ncline{->}{lmd2}{q4}
$$

Consider the justified sequence of moves $s \in \sem{M}$:
 $$s = \Pstr[12pt][5pt]{(q1){q}^1\ (q3-q1,60){q}^3\ (q4-q3,60){q}^4\ (q3b-q1){q}^3\ (q4b-q3b,60){q}^4\ (q2-q1,30){q}^2 }
\in \sem{M}$$

There is a corresponding justified sequence of nodes in the computation tree:
$$r = \Pstr[0.8cm]{
        (q1){\lambda f z} \cdot
        (q3-q1,60){f}^{[6]} \cdot
        (q4-q3,60){\lambda^{[7]}} \cdot
        (q3b-q1,60){f}^{[8]} \cdot
        (q4b-q3b,50){\lambda^{[9]}} \cdot
        (q2-q1,50){z} }$$
such that $s_i = \psi(r_i)$ for all $i < |s|$.

The sequence $r$ is in fact the reduction of the following
traversal:
$$t = \pstr[1.1cm]{ \nd(q1){\lambda f z} \cdot
            \nd(n2){@^{[2]}} \cdot \nd(n3-n2,60){\lambda g x^{[3]}} \cdot
            \nd(q3-q1,60){f}^{[6]} \cdot \nd(q4-q3,60){\lambda^{[7]}} \cdot
            \nd(q3b-q1,40){f}^{[8]} \cdot \nd(q4b-q3b,70){\lambda^{[9]}} \cdot
            \nd(n8-n3,35){x^{[10]}} \cdot
            \nd(n9-n2,30){\lambda^{[5]}} \cdot
            \nd(q2-q1,35){z}
            \arrow{q3}{n3}{30}{}{blue}{dashed}
            \arrow{q3b}{n3}{30}{}{blue}{dashed} }
$$

By representing side-by-side the computation tree and the type arena of a term in $\eta$-normal form we have observed
that some nodes of the computation tree can be mapped to question moves of the arena.
In the next section, we show how to define this mapping in a systematic manner.

\subsubsection{Formal definition}

We now establish formally the relationship between games and
computation trees. Suppose $\Gamma \vdash M : T$ is in $\eta$-long
normal form.

\emph{Notations:} We suppose that computation tree $\tau(M)$ is given by
a pair $(V,E)$ where $V$ is the set of vertices and $E \subseteq
V \times V$ is the parent-child relation. We have $V = N \union L$
where $N$ and $L$ are the set of nodes and value-leaves respectively.

Let $\mathcal{D}$ be the set of values of the base type $o$. If $n$
is a node in $N$ then the value-leaves attached to the node $n$ are
written $v_n$ where $v$ ranges in $\mathcal{D}$. Similarly, if $q$
is a question in $A$ then the answer moves enabled by $q$ are
written $v_q$ where $v$ ranges in $\mathcal{D}$.

\begin{definition}[Mapping from nodes to moves]\hfill
\label{def:psi mapping}

    \begin{itemize}[-]
    \item Let $n$ be a node in $N_\lambda \union N_{\sf var}$ and $q$ be a question move of some game $A$
such that $n$ and $q$ are of type $(A_1,\ldots,A_p,o)$ for some
$p\geq 0$. Let $D_n$ be the set of nodes and leaves form $N$
that heredirarily enabled by $n$ and which are not free
variables in $\kappa(n)$ nor hereditarily enabled by a free
variable in $\kappa(n)$.

The function $\psi^{n,q}_A$ from $D_n$ to $A$ is defined as:
        \begin{eqnarray*}
        \psi^{n,q}_A &=& \{ n \mapsto q \} \union  \{ v_n \mapsto v_q \ | \ v \in \mathcal{D} \}\\
         &&\union \left\{
                        \begin{array}{ll}
                          \Union_{m \in N_{\sf var} | n \vdash_i m} \psi^{m, q^i}_A, & \hbox{if $n\in N_{\lambda}$\ ;} \\
                          \Union_{i=1..p} \psi^{n.i, q^i}_A, & \hbox{if $n\in N_{\sf var}$\ .}
                        \end{array}
                      \right.
        \end{eqnarray*}
        where $\{ q^1, \ldots, q^p \} \union \{ v_q \ | \ v \in \mathcal{D} \}$ is the set of moves enabled by $q$ in $A$ (each $q^i$ being of type $A_i$).

    \item Suppose $\Gamma = x_1:X_1, \ldots ,
    x_k:X_k$. Let $q_0$ denote $\sem{\Gamma\rightarrow T}$'s
    initial move \footnote{Arenas involved in the game semantics
    of simply-typed $\lambda$-calculus are all trees: they have
    a single initial move.} and suppose that the set of moves
    enabled by $q_0$ in $\sem{\Gamma\rightarrow T}$ is
     $\{ q_{x_1}, \ldots, q_{x_k}, q^1, \ldots, q^p \} \union \{
    v_q \ | \ v \in \mathcal{D} \}$ where each $q^i$ is of type
    $A_i$ and $q_{x_j}$ of type $X_j$.

    We define $\psi_M : V^{\theroot\vdash} \rightarrow
    \sem{\Gamma\rightarrow T}$ (or just $\psi$ if this does not
    cause any ambiguity) as follows:
    \begin{eqnarray*}
     \psi_M = && \{ r \mapsto q_0 \}  \union  \{ v_r \mapsto v_{q_0} \ | \ v \in \mathcal{D} \}\\
& \union& \Union_{n \in N_{\sf var} | \theroot\vdash_i n} \psi^{n, q^i}_\sem{\Gamma\rightarrow T} \\
& \union& \Union_{n \in N_{\sf fv} | n \mbox{ \small labelled } x_j, j \in \{ 1..k \} } \psi^{n, q_{x_j}}_\sem{\Gamma\rightarrow T}
    \end{eqnarray*}
    \end{itemize}
\end{definition}

It can easily be checked that the domain of definition of $\psi_M$
is indeed the set of nodes that are hereditarily enabled by the
root (this includes free variable nodes and nodes that are hereditarily enabled by free variable nodes).

Let us detail a little the definition of $\psi^{n,q}_A$.
\begin{itemize}
\item If $p=0$ then $n$ is a dummy $\lambda$-node or a ground type variable: $\psi^{n,q}_A$ maps $n$ to the initial move $q$.

\item  If $p\geq 1$ and $n \in N_{\lambda}$ with $n$ labelled $\lambda \overline{\xi} = \lambda \xi_1 \ldots \xi_p$ then the sub-computation tree rooted at $n$ and the
 arena $A$ have the following forms (value-leaves and answer
 moves are not represented for simplicity):
    $$ \tree{ \Rnode{r}\lambda \overline{\xi}  ^{[n]}}
        {
            \tree[levelsep=6ex]{\alpha}
            {   \TR{\ldots} \TR{\ldots} \TR{\ldots}
            }
        }
    \hspace{3cm}
    \tree{ \Rnode{q0}q }
        {
            \tree[linestyle=dotted]{q^1}{\TR{} \TR{} }
            \tree[linestyle=dotted]{q^2}{\TR{} \TR{} }
            \TR{\ldots}
            \tree[linestyle=dotted]{q^p}{\TR{} \TR{} }
        }
    \psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
    \ncline{->}{r}{q0}
    \ncarc{->}{q2}{z}
    \ncline{->}{q3}{f}
    \ncline{->}{q4}{lmd}
    \ncline{->}{q3}{f2}
    \ncline{->}{q4}{lmd2}
    $$

    For each abstracted variable $\xi_i$ there exists a
    corresponding question move $q^i$ of the same order in the
    arena. $\psi^{n,q}_A$ maps each free occurrence of $\xi_i$
    in the computation tree to the move $q^i$.

\item If $p\geq 1$ and $n\in N_{\sf var}$ then $n$ is labelled with a variable $x:(A_1,\ldots,A_p,o)$
with children nodes $\lambda \overline{\eta}_1$, \ldots,
$\lambda \overline{\eta}_p$. The computation tree $\tau(M)$
rooted at $n$ and the arena $A$ have the following forms:
    $$\tree{\Rnode{r}{x^{[n]}}}
        {   \tree{\TR{\lambda \overline{\eta}_1}}{\vdots} \TR{\ldots}
        \tree{\TR{\lambda \overline{\eta}_p }}{\vdots}
        }
    \hspace{3cm}
    \tree{ \Rnode{q0}q }
        {
\tree[linestyle=dotted]{\Rnode{q1}{q^1}}{\TR{} \TR{} }
            \tree[linestyle=dotted]{\Rnode{q2}{q^2}}{\TR{} \TR{} }
            \TR{\ldots}
            \tree[linestyle=dotted]{\Rnode{qp}{q^p}}{\TR{} \TR{} }
        }
    \psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
    \ncline{->}{r}{q0}
    \ncarc{->}{q2}{z}
    \ncline{->}{q3}{f}
    \ncline{->}{q4}{lmd}
    \ncline{->}{q3}{f2}
    \ncline{->}{q4}{lmd2}
    $$

    and $\psi^{n,q}_A$ maps each node $\lambda
    \overline{\eta}_i$ to the question move $q^i$.
\end{itemize}


\begin{example} For each of the following examples of term $\Gamma \vdash M :T$, we represent the
computation tree $\tau(M)$, the arena of the game  $\sem{\Gamma \rightarrow T}$, and
the function $\psi_M$ (in dashed lines):
\begin{compactitem}
\item $M = \lambda x^o . x$
$$
\psset{levelsep=3.5ex,arrows=-,nodesep=1pt,linewidth=0.3pt}
\pstree{\TR[name=lx]{\lambda x}}
    { \TR[name=x]{x} }
\hspace{2cm}
  \pstree{\TR[name=Mlx]{q_{\lambda x}}}
        { \TR[name=Mx]{q_x} }
%
\psset{arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
\ncline{->}{lx}{Mlx} \mput*{\psi_M}
\ncline{->}{x}{Mx}
$$

\item $M = \lambda f^{(o,o,o)} . f x y$
$$
\psset{levelsep=3.5ex,arrows=-,nodesep=1pt,linewidth=0.3pt}
    \pstree{\TR[name=lf]{\lambda f}}
        { \pstree{\TR[name=f]{f}}{
                \pstree[levelsep=6ex]{\TR[name=duml]{\lambda}}
                { \TR[name=x]{x}  }
                \pstree[levelsep=6ex]{\TR[name=duml2]{\lambda}}
                { \TR[name=y]{y}  }
                } }
\hspace{3cm}
    \pstree{\TR[name=Mlf]{q_{\lambda g}}}
    {
        \pstree{\TR[name=Mf]{q_f}}
        {  \TR[name=Mf1]{q_{f_1}}   }
        \TR[name=Mx]{q_x}
        \TR[name=My]{q_y}
    }
\psset{arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
\ncline{->}{lf}{Mlf} \mput*{\psi_M}
\ncline{->}{f}{Mf}
\ncarc{->}{x}{Mx}
\ncarc{->}{y}{My}
\ncarc{->}{duml}{Mf1}
\ncline{->}{duml2}{Mf1}
$$

\item $M = \lambda f^{(o,o)} . (\lambda g^{(o,o,o)} . g (f x) z) (\lambda y^o w^o . y)$
$$\psset{levelsep=3.5ex,arrows=-,nodesep=1pt,linewidth=0.3pt}
\pstree{\TR[name=lf]{\lambda f}}
{
    \pstree{\TR[name=App]{@}}
    {
            \pstree{\TR[name=lg]{\lambda g}}
                { \pstree{\TR[name=g]{g}}{
                        \pstree{\TR[name=duml1]{\lambda}}
                        {       \pstree{\TR[name=f]{f}}
                                { \pstree{\TR[name=duml1']{\lambda}}{\TR[name=x]{x}}  }
                        }
                        \pstree{\TR[name=duml2]{\lambda}}
                        { \TR[name=z]{z}  }
                        } }
            \pstree{\TR[name=lyw]{\lambda y w}}
                    {\TR[name=y]{y}}
    }
}
\hspace{2cm}
  \pstree{\TR[name=Mlf]{q_{\lambda f}}}
        {
          \pstree{\TR[name=Mf]{q_f}}
            { \TR[name=Mf1]{q_{f1}}}
          \TR[name=Mz]{q_z}
          \TR[name=Mx]{q_x}
           }
\psset{arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
\ncline{->}{lf}{Mlf} \mput*{\psi_M}
\ncline{->}{f}{Mf}
\ncline{->}{duml1'}{Mf1}
\ncarc{->}{z}{Mz}
\ncarc{->}{x}{Mx}
$$
\end{compactitem}
\end{example}

\begin{property} \
\label{proper:psi_properties}
\begin{enumerate}[(i)]
\item $\psi_M$ maps $\lambda$-nodes to O-questions, variable nodes to
P-questions, value-leaves of $\lambda$-nodes to P-answers and
value-leaves of variable nodes to O-answers;

\item $\psi_M$ preserves hereditary enabling: a node $n \in V^{\theroot\vdash}$ is hereditarily
 enabled by some node $n' \in V^{\theroot\vdash}$ in $\tau(M)$ if and only if
the move $\psi_M(n)$ is hereditarily enabled by $\psi_M(n')$ in $\sem{\Gamma \rightarrow T}$;

\item $\psi_M$ maps a node of a given order to a move of the same order;

\item Let $s \in \travset(M)^{\filter r}$. The P-view (resp. O-view) of $\psi_M(s)$ and $s$ are computed
identically {\it i.e.}~the set of occurrence positions that must be removed
from each sequences in order to obtain their respective P-view (resp. O-view) is the same for both sequence.
\end{enumerate}
\end{property}
\begin{proof}
(i), (ii) and (iii) are direct consequences of the definition.

(iv) Because of (i) and since $t$ and $\psi_M(t)$ have the
same pointers, the computations of the P-view (resp. O-view) of the
sequence of moves and the P-view (resp. O-view) of the sequence of
nodes follow the same steps.
\end{proof}
The fact that we have defined the order of the root node differently from the order of other $\lambda$-nodes
(Def. \ref{def:nodeorder}) should now make more sense to the reader: this definition permits us to state property (iii).
\smallskip

By extension, we can define the function $\psi_M$ on $\travset(M)^{\filter r}$, the set of justified
sequences of nodes that are hereditarily justified by (the only occurrence of) the root $r$:
\begin{definition}[Mapping sequences of nodes to sequences of moves]
We define the function $\psi_M$ from $\travset(M)^{\filter r}$ to justified sequence of moves of $\sem{\Gamma \rightarrow T}$ as follows.
If $s = s_0 s_1 \ldots \in \travset(M)^{\filter r}$ then:
$$\psi_M(s) = \psi_M(s_0)\ \psi_M(s_1)\  \psi_M(s_2) \ldots$$
where $\psi_M(s)$ is equipped with $s$'s pointers.

Thus the pointer-free version of this function is a monoid homomorphism.
\end{definition}



\subsection{Mapping filtered traversals to interaction plays}

    Let $I$ be the interaction game of the interaction strategy $\intersem{\Gamma \vdash M : T}$ and
    $M_I$ be the set of equivalence class of moves from $\mathcal{M}_I$.

    Let $r'$ be a lambda node in $N_{\sf spawn}$ and let $\Gamma(r') \vdash \kappa(r') : T(r')$ denote the subterm of $\elnf{M}$ rooted at $r'$ where $\Gamma(r')\subseteq \Gamma$.
    The function $\psi_{\kappa(r')}$ maps nodes of $V^{r'\vdash}$
    to moves of $\sem{\Gamma(r') \rightarrow T(r')}$. By definition,
    the set of possible moves $\mathcal{M}_I$ of the interaction game $\intersem{I}$ contains the
    moves from the game $\sem{\Gamma(r') \rightarrow A(r')}$. Hence $\psi_{\kappa(r')}$ can be regarded as a function from $V^{r'\vdash}$ to $\mathcal{M}_I$.

    Every node in $n \in V\setminus (V_@ \union V_\Sigma)$ is either hereditarily enabled by the root or by some $\lambda$-node in $N_{\sf spawn}$ (the children nodes of @/$\Sigma$-nodes). Therefore we can define the relation $\psi^*_M$ from
    $V\setminus (V_@ \union V_\Sigma)$ to $\mathcal{M}_I$ as follows:
    $$ \psi^*_M = \psi_{M} \quad \union \Union_{r' \in N_{\sf spawn}} \psi_{\kappa(r')} \ .$$
    It is totally defined on $V\setminus (V_@ \union V_\Sigma)$ since nodes are either hereditarily justified by the root, by an @-node or by a $\Sigma$-node.

    $\psi^*_M$ is a relation and not a function since variable nodes can be hereditarily enabled by more than one nodes in $N_{\sf spawn}$  (a variable node is enabled by all the prime $\lambda$-nodes occurring in the path to the root) and thus the domains of definition of the relations $\psi_{\kappa(r')}$ for $r' \in N_{\sf spawn}$ may overlap.  It can be easily check, however, that for any node $n \in V\setminus (V_@ \union V_\Sigma)$,
    the moves in $\psi^*_M (n)$ are all $\sim$-equivalent. This leads us to the following definition:

    \begin{definition}[Mapping from nodes to moves]
        \label{def:phi mapping}
        We define the \emph{function}
        $\varphi_M:V\setminus (V_@ \union V_\Sigma) \rightarrow M_T$ as follows: for each node $n \in V\setminus (V_@ \union V_\Sigma)$,
        $\varphi_M(n)$ is defined as the $\sim$-equivalence class containing $\psi^*_M (n)$.

        We omit the subscript in $\varphi_M$ if it does not cause any ambiguity.
    \end{definition}
    Assuming that there are not $\Sigma$-nodes, $\varphi_M$ is indeed totally defined on $V \setminus (V_@ \union V_\Sigma) = V_\lambda \union V_{\sf var}$.

\begin{definition}[Mapping sequences of nodes to sequences of moves]
\label{dfn:phi_for_justsequ} We define the function $\varphi_M$ from
$\travset(M)^\star$ to justified sequence of moves of $\intersem{I}$
as follows. If $s = s_0 s_1 \ldots \in \travset(M)^\star$ then:
$$\varphi_M(s) = \varphi_M(s_0)\ \varphi_M(s_1)\  \varphi_M(s_2) \ldots$$
where $\varphi_M(s)$ is equipped with $s$'s pointers.
\end{definition}

\begin{example}
Take $M = \lambda x^o . (\lambda g^{(o,o)} . g x z) (\lambda y^o .
y)$. The diagram below represents the computation tree (middle) and
the relation $\psi^*_M = \psi_{\lambda x}\union \psi_{\lambda g}
\union \psi_{\lambda y}$ (dashed-lines).
$$\psset{levelsep=3.5ex}
\pstree{\TR[name=root]{\lambda x}}
{
    \pstree{\TR[name=App]{@}}
    {
            \pstree{\TR[name=lg]{\lambda g}}
                { \pstree{\TR[name=lgg]{g}}{
                        \pstree{\TR[name=lgg1]{\lambda}}
                        { \TR[name=x]{x}  }
                        \pstree{\TR[name=lgg2]{\lambda}}
                        { \TR[name=z]{z}  }
                        } }
            \pstree{\TR[name=ly]{\lambda y}}
                    {\TR[name=lyy]{y}}
    }
}
\rput(4.5cm,-1cm){
  \pstree{\TR[name=A1lx]{q_{\lambda x}}}
        { \TR[name=A1x]{q_x}
          \TR[name=A1z]{q_z} }
}
\rput(-6cm,-1.5cm){
    \pstree{\TR[name=A2lg]{q_{\lambda g}}}
    {
        \TR[name=A2x]{q_x'}
        \TR[name=A2z]{q_z'}
        \pstree{\TR[name=A2g]{q_g}}
        {  \TR[name=A2g1]{q_{g_1}}   }
    }}
\rput(2.5cm,-1.5cm){
    \pstree{\TR[name=A3ly]{q_{\lambda y}}}
        { \TR[name=A3y]{q_y}
        }
}
\psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
\ncline{->}{root}{A1lx} \mput*{\psi_M}
\nccurve[angleA=-60,angleB=-150]{->}{x}{A1x}
\ncarc{->}{z}{A1z}
\ncarc[arcangle=30]{->}{x}{A2x}
\nccurve[angleA=-150,angleB=-60]{->}{z}{A2z}
\ncline{->}{lg}{A2lg} \mput*{\psi_{\lambda g. g x}}
\ncline{->}{lgg}{A2g}
\ncline{->}{lgg1}{A2g1}
\ncline{->}{ly}{A3ly} \mput*{\psi_{\lambda y.y}}
\ncline{->}{lyy}{A3y}
$$
\vspace{18pt}

where $q_x'\sim q_x$, $q_z'\sim q_z$, $q_g\sim q_{\lambda y}$,
$q_{g_1}\sim q_y$ and $q_{\lambda g}\sim q_{\lambda x}$.
\end{example}


\begin{lemma}[Filtering lemma for @/$\Sigma$-free traversals]
\label{lem:varphi_filter} Let $r'\in N_\lambda$, $\Delta \vdash M^{(r')} :
A$ be the subterm of $\elnf{M}$ rooted at $r'$, $t\in\travset(M)$,
$r'_0$ be an occurrence of $r'$ in $t$ and $m_0$ be the occurrence
of the initial $A$-move $\varphi_M(r'_0)$ in $\varphi_M(t^\star)$ then:
$$\begin{array}{rrcl}
(i)& \varphi_{M^{(r')}}(t^\star \filter r'_0) &=& \varphi_M(t^\star) \filter m_0 \\ \\
(ii) & \varphi_M(\travset^\star(M)) \filter \sem{\Gamma \rightarrow T} &=& \psi_M(\travset^{\filter r}(M))\ .
\end{array}
$$
\end{lemma}
\proof ($i$) Firstly, by Proposition \ref{prop:trav_filtering},
$t\filterplus r'_0$ is a traversal of $\travset(M^{(r')})$ therefore
the sequence $(t\filterplus r'_0) \filter r'_0 = t^\star \filter
r'_0$ belongs of $\travset^\star(M^{(r')})$ and therefore the
expression $\varphi_{M^{(r')}}(t^\star \filter r'_0)$ is
well-defined. By Definition \ref{dfn:phi_for_justsequ}, the
sequences $\varphi_M(t^\star)$ and $t^\star$ have the same
justification pointers therefore
 we must have $\varphi_{M}(t^\star \filter r'_0) = \varphi_M(t^\star) \filter m_0$. Finally, because of the inductive definition of $\varphi_{M}$, $\varphi_{M^{(r')}}$ coincides with
the restriction of $\varphi_{M}$ to $M^{(r')}$.


($ii$) Let $H$ be the set of nodes of $\tau(M)$ which are mapped by
$\psi^*(M)$ to moves that are $\sim$-equivalent to moves in
$\sem{\Gamma \rightarrow T}$. We show that $H = V^{\theroot\vdash}$.

Since $\psi_M \subseteq \psi^*(M)$ and the image of $\psi(M)$ is
$\sem{\Gamma \rightarrow T}$, $H$ must contain the domain of
$\psi(M)$ which is $V^{\theroot\vdash}$.

Conversely, suppose that a node $n \in V\setminus (V_@\union V_\Sigma)$ is mapped by
$\varphi^*(M)$ to some move $m\in \mathcal{M}_I$ which is $\sim$-equivalent
to some move in $\sem{\Gamma \rightarrow T}$.
 If $m = \psi_M(n)$ then $n\in V^{\theroot\vdash}$. Otherwise,
$m = \psi_{\kappa(r')}(n)$ for some $r' \in N_{\sf spawn}$. There
may be several node $r'$ such that $n$ belongs to the domain of
definition of $\psi_{\kappa(r')}$. W.l.o.g. we can take $r'$ to be
the one which is closest to the root $r$. Let $\Gamma(r') \vdash
\kappa(r') : T(r')$.
    \begin{compactitem}
    \item Suppose that $m$ is $\sim$-equivalent to a move in the subgame $\sem{\Gamma}$ of $\sem{\Gamma \rightarrow T}$
    then this means that $n$ is hereditarily justified by a free variable node in $M$ and therefore $n \in V^{\theroot\vdash}$.

    \item Suppose that $m$ is $\sim$-equivalent to a move in the subgame $\sem{T}$ of $\sem{\Gamma \rightarrow T}$
    then $m$ necessarily belongs to the subgame $\Gamma(r')$ of $\sem{\Gamma(r')\rightarrow T(r')}$ .
    Indeed, since $r'$'s parent node is an application node, moves in the subgame
    $\sem{T(r')}$ correspond to internal moves of the application. By definition of
    the interaction strategy for the application case, such moves can only be $\sim$-equivalent to other internal
    moves and thus cannot be equivalent to move in $\sem{T}$.

    Consequently, $n$ is her.\ just.\ by a free variable node $z$ in $\kappa(r')$. By assumption, $r'$ is the closest node to the root $r$ (excluding $r$ itself) for which $n$ belongs to $V^{r'\vdash}$ (the domain of definition of $\psi_{\kappa(r')}$). Hence $z$ is not bound by any $\lambda$-node occurring in the path to the root. Thus $z\in
    V^{\theroot\vdash}$ and therefore $n \in V^{\theroot\vdash}$.
    \end{compactitem}
Hence $H = V^{\theroot\vdash}$.

Hence for any traversal $t$ of $M$, $\varphi_M(t^\star) \filter
\sem{\Gamma \rightarrow T} = \varphi_M(t^\star\filter V^{\theroot\vdash})$
which is in turn equal to $ \varphi_M(t\filter r) = \psi_M(t\filter r)$
by Lemma \ref{lem:he_filter_root_is_hj_filter_r}. \qed


\subsection{The correspondence theorem for the simply-typed $\lambda$-calculus without interpreted constants}
In this section, we establish a connection between the interaction
semantics of a simply-typed term without constants ($\Sigma =
\emptyset$) and the traversals of its computation tree: we show that
the set $\travset(M)$ of traversals of the computation tree is
isomorphic to the set of uncovered plays of the strategy denotation
(this is the counterpart of the ``Path-Traversal Correspondence'' of
\cite{OngLics2006}), and that the set of traversal reductions is
isomorphic to the strategy denotation.


The function $\varphi_M$ regarded as a function from the set of vertices $V \setminus V_@$ of the computation tree to moves in arenas is not injective. (For instance the two occurrences of $x$ in the computation tree of $\lambda f x. f x x$ are mapped to the same question move.) However the function $\varphi_M$ defined on the set of @-free traversals is injective, and similarly the function $\psi_M$ defined on the set of traversal reduction is injective:
\begin{lemma}[$\psi_M$ and $\varphi_M$ are injective]
\label{lem:varphiinjective}
For any two traversals $t_1$ and $t_2$:
\begin{itemize}
\item[(i)] If $\varphi (t_1 - @ ) = \varphi (t_2 - @ )$ then $t_1-@ =t_2 -@$\ ;
\item[(ii)] if $\psi (t_1 \filter r ) = \psi (t_2 \filter r )$ then $t_1\filter r = t_2\filter r$\ .
\end{itemize}
\end{lemma}
For any node occurrence $n$ in a traversal $t$ let us write $ptr(n)$
to denote the distance between $n$ and its main justifier in $t$. If
$n$ has no justifier then we set $ptr(n)=0$. We use the same
notation for occurrences in a sequence of moves.

\begin{lemma}[Preleminary lemma]
\label{lem:varphiinjective:prelem}
\begin{equation*}
\left(
  \begin{array}{ll}
    t \cdot n_1, t \cdot n_2 \in \travset(M) \\
    \zand\ n_1 \neq n_2
  \end{array}
\right)
 \mbox{ implies } n_1,n_2 \in V^{\theroot\vdash}_{\lambda} \zand ( \psi(n_1) \neq \psi(n_2) \zor ptr(n_1) \neq ptr(n_2) ) \ .
 \end{equation*}
\end{lemma}
\proof Let $t \cdot n_1, t \cdot n_2 \in \travset(M)$. First we
remark that the traversal rules have a weak form of determinism
which ensures that $n_1$ and $n_2$ belong to the same category of
node {\it i.e.}\ they must be both in $N_{\sf var}$, $N_@$,
$N_\lambda$, $L_{\sf var}$, $L_@$, or $L_\lambda$.

\begin{compactitem}
\item If $n_1, n_2 \in N_@$ then $t
\cdot n_1$ and $t \cdot n_2$ were formed using the \rulenamet{App}
rule. Since this rule is deterministic we must have $n_1=n_2$ which
violates the second hypothesis.

\item If $n_1, n_2 \in L_@$ then the traversals were formed using the deterministic rule
\rulenamet{Value$^{@\mapsto\lambda}$} which again violates the second
hypothesis.

\item If $n_1,n_2\in N_{\sf var}$ then
     $t \cdot n_1$ and $t \cdot n_2$ were formed using either rule \rulenamet{Lam} or \rulenamet{App}.
     But these two rules are deterministic and their domains of definition are disjoint. Hence again the second
     hypothesis is violated.

\item If  $n_1, n_2 \in L_{\sf var}$ then either the traversals were both formed using the deterministic rule
\rulenamet{Value$^{{\sf var}\mapsto\lambda}$} in which case the second hypothesis
is violated; or they were formed with \rulenamet{InputValue}
in which case $n_1$ and $n_2$ are two different value leaves belonging to
$V^{\theroot\vdash}_\lambda$ and justified by the same input variable node.
Thus by definition of $\psi$, $\psi(n_1)\neq\psi(n_2)$.

\item If  $n_1,n_2\in N_\lambda$ then the traversals $t \cdot n_1$
    and $t \cdot n_2$ must have been formed using either rule
    \rulenamet{Root}, \rulenamet{App}, \rulenamet{Var} or \rulenamet{InputVar}. Since all these rules have
    disjoint domains of definition, the same rule must have been use to
    form $t \cdot n_1$ and $t \cdot n_2$.
    But since the rules \rulenamet{Root}, \rulenamet{App} and \rulenamet{Var} are all deterministic,
    the rule used is necessarily \rulenamet{InputVar}.

    By definition of \rulenamet{InputVar}, $n_1,n_2\in N_\lambda^{\theroot\vdash}$ and the parent node of $n_1$ and the parent node of $n_2$  occur in  $\oview{t_{\prefixof x}}$ where $x \in N^{\theroot\vdash}_{\sf var}$
    denotes the pending node at $t$. If $n_1$ and $n_2$ have the same
    parent node in $\tau(M)$ then since $n_1\neq n_2$, by definition of
    $\psi$, $\psi(n_1)\neq \psi(n_2)$. If their parent node is
    different, then $n_1$ and $n_2$ are necessarily justified by two different
    occurrences in $t$ therefore $ptr(n_1) \neq ptr(n_2)$.

\item If  $n_1,n_2\in L_\lambda$ then either the traversals $t \cdot n_1$
    and $t \cdot n_2$ were formed using
    \rulenamet{Value$^{\lambda\mapsto{\sf var}}$} or they were formed with
    \rulenamet{Value$^{\lambda\mapsto@}$} but this is impossible since these two rules are
    deterministic and $n_1 \neq n_2$. \qed
\end{compactitem}


\proof[Proof of Lemma \ref{lem:varphiinjective}]

(i) The result is trivial is either $t_1$ or $t_2$ is empty.
Suppose that $t_1-@\neq t_2-@$ then necessarily $t_1 \neq t_2$, thus there are some sequences $t'$, $u_1$, $u_2$ and some nodes $n_1,n_2$ such that
 $t_1 = t' \cdot n_1 \cdot u_1$, $t_2 = t' \cdot n_2 \cdot u_2$ with either $n_1\neq n_2$ or $ptr(n_1) \neq ptr(n_2)$.

If $n_1 = n_2$ then $ptr(n_1) \neq ptr(n_2)$ therefore $n_1,n_2 \not\in N_@$ (otherwise we would have $ptr(n_1) = 0 = ptr(n_2)$). Since $ptr(\varphi(n_1)) = ptr(n_1)$ and  $ptr(\varphi(n_2)) = ptr(n_2)$ we must have $\varphi(t' \cdot n_1) \neq \varphi(t' \cdot n_2)$. Since $n_1,n_2 \not\in N_@$ we also have $\varphi((t' \cdot n_1)-@) \neq \varphi((t' \cdot n_2)-@)$. Hence $\varphi(t_1-@) \neq \varphi(t_2-@)$.

If $n_1 \neq n_2$ then by Lemma \ref{lem:varphiinjective:prelem} we have $n_1,n_2 \not\in N_@$ and
either $ptr(n_1) \neq ptr(n_2)$ or $\psi(n_1) \neq \psi(n_2)$ which implies $\varphi(n_1) \neq \varphi(n_2)$.
In both cases, we obtain $\varphi(t_1-@) \neq \varphi(t_2-@)$.


(ii) Suppose that $t \filter r \neq t' \filter r$ then necessarily $t \neq t'$ which in turn implies that for some sequences $t_1'$, $t_2'$, $u_1$, $u_2$ and some nodes $n_1 \neq n_2$
we have $t_1 = t' \cdot n_1 \cdot u_1$, $t_2 = t' \cdot n_2 \cdot u_2$ and either $n_1\neq n_2$ or $ptr(n_1) \neq ptr(n_2)$.

If $n_1 = n_2$ then $ptr(n_1) \neq ptr(n_2)$. An analysis of the traversal rules shows that \rulenamet{InputVar} is the only rule that can visit the same node with two different pointers, thus $n_1,n_2 \in V_\lambda^{\theroot\vdash}$
and therefore $\psi( (t'\cdot n_1) \filter r ) = \psi( (t'\filter r) \cdot n_1 )  \neq \psi( (t'\filter r) \cdot n_2 )$. Consequently $\psi( t_1\filter r ) \neq \psi( t_2\filter r )$.

If $n_1 \neq n_2$ then Lemma \ref{lem:varphiinjective:prelem}
gives $\psi( t_1\filter r ) \neq \psi( t_2\filter r )$. \qed



\begin{corollary} \hfill
\label{cor:varphi_bij}
\begin{itemize}
\item[(i)] $\varphi$ defines a bijection from $\travset(M)^{-@}$
to $\varphi(\travset(M)^{-@})$\ ;
\item[(ii)] $\psi$ defines a bijection from $\travset(M)^{\filter r}$ to
$\psi(\travset(M)^{\filter r})$\ .
\end{itemize}
\end{corollary}

\subsubsection{The correspondence theorem}
We now state and prove the correspondence theorem for the
simply-typed $\lambda$-calculus without interpreted constants
($\Sigma = \emptyset$). The result extends immediately to the
simply-typed $\lambda$-calculus with \emph{uninterpreted} constants
since we can regard constants as being free variables.

\begin{lemma}[Local Traversal Extension]
\label{lem:local_traversal_progression}
Let $M^{(r')}$ be a subterm of $M$, $t \in \travset(M)$,
$t' \in \travset(M^{(r')})$ such that $t,t' \neq \epsilon$, $t\subseqof t'$
and the last occurrence of $t$ and $t'$ coincide.
If we can form a traversal $t' \cdot n$ of $\tau(M^{(r')})$ using a rule different from \rulenamet{InputVar} and $\rulename{InputVar^{val}}$ then
$ t \cdot n$ is a traversal in $\travset(M)$
where $n$'s justifier in $t \cdot n$ is the occurrence corresponding
to $n$'s justifier in $t' \cdot n$.
\end{lemma}
\begin{proof}
  Let $M^{(r')}$ denote the term $\kappa(r')$ and
  $V^{(r')}$ denote the set of nodes of $\tau(M^{(r')})$.

  \notetoself{By induction on the traversal.
  It is trivial for the rules \rulenamet{Empty} and \rulenamet{Root}.
  \begin{itemize}
    \item \rulenamet{Lam}
    Suppose $t = t' \cdot \lambda \overline{\xi} \cdot n \in \travset(M)$.
    By the induction hypothesis,
    $t' \cdot \lambda \overline{\xi} \filter M^{(r')} \in \travset(M^{(r')})$.

    Suppose that $n \in V^{(r')}$ then since $n$ is not a lambda node, its parent node
    $\lambda \overline{\xi}$ is necessarily also in $V^{(r')}$ therefore
    $(t'\filter M^{(r')}) \cdot \lambda \overline{\xi} \in \travset(M^{(r')})$ so we can use the rule \rulenamet{Lam} in $\tau(M^{(r')})$ to produce the traversal
    $(t'\filter M^{(r')}) \cdot \lambda \overline{\xi} \cdot n =
    (t' \cdot \lambda \overline{\xi} \cdot n ) \filter M^{(r')}$ of $M^{(r')}$.


    Suppose that $n \not\in V^{(r')}$ then since $n$ is not a lambda node, its parent node is not in $V^{(r')}$ either therefore
    $(t' \cdot \lambda \overline{\xi} \cdot n) \filter M^{(r')}
    = t' \filter M^{(r')} \in \travset(M^{(r')})$.

    \item \rulenamet{App}
     Suppose $t = t' \cdot @ \cdot n \in \travset(M)$.
    By the induction hypothesis,
    $( t' \cdot @ ) \filter M^{(r')} \in \travset(M^{(r')})$.


  \end{itemize}

  ...}
\end{proof}


This lemma says that extending a traversal locally also extends the traversal globally: the traversal $t$ of $M$ can be extended by extending a ``sub-traversal'' $t'$ of some sub-term $M^{(r')}$.
This is not obvious since $t'$ is a subsequence of $t$ which means that
the nodes in $t'$ are also present in $t$ with the same pointers but with some other nodes interleaved in between. However these interleaved nodes are inserted in a preservative way which allows us to apply the rule used to extend $t'$ on $t$.
\bigskip

The following theorem establishes a correspondence between the
game-denotation of a term and the set of traversals of its
computation tree:
\begin{theorem}[The Correspondence Theorem]
\label{thm:correspondence}
 For any simply-typed term $\Gamma \vdash M :T$,
the function $\varphi_M$ defines a bijection from $\travset(M)^{\filter
r}$ to $\sem{\Gamma \vdash M : T}$ and a bijection from
$\travset(M)^{-@}$ to $\intersem{\Gamma \vdash M : T}$:
\begin{eqnarray*}
 \varphi_M  &:& \travset(\Gamma \vdash M : T)^{-@} \stackrel{\cong}{\longrightarrow} \intersem{\Gamma \vdash M :T} \\
 \psi_M  &:& \travset(\Gamma \vdash M : T)^{\filter r} \stackrel{\cong}{\longrightarrow} \sem{\Gamma \vdash M :T} \ .
\end{eqnarray*}

\end{theorem}

%\begin{proposition}
%\label{prop:rel_gamesem_trav} Let $\Gamma \vdash M : T$ be a
%simply-typed $\lambda$-term and $r$ be the root of $\tau(M)$. Then:
%\begin{itemize}
%\item[(i)]  $\varphi_M(\travset(M)^{-@}) = \intersem{\Gamma \vdash M : T}$ \ ;
%\item[(ii)] $\varphi_M(\travset(M)^{\filter r}) = \sem{\Gamma \vdash M : T}$ \ .
%\end{itemize}
%\end{proposition}

\begin{remark}
\label{rem:corresp_proofreduction}
    By corollary \ref{cor:varphi_bij}, we just need to show that
    $\varphi_M$ defines \emph{surjections}, that is to
    say:
    \begin{eqnarray*}
    \varphi_M(\travset(M)^{-@}) &=& \intersem{\Gamma \vdash M : T} \\
    \psi_M(\travset(M)^{\filter r}) &=& \sem{\Gamma \vdash M :
    T}
    \end{eqnarray*}
    The first equation implies the second one, indeed:
    \begin{align*}
    \sem{\Gamma \vdash M : T} &= \intersem{\Gamma \vdash M : T} \filter \sem{\Gamma \rightarrow T} & \mbox{(eq. \ref{eqn:int_std_gamsem})} \\
            &= \varphi_M(\travset^{-@}(M)) \filter \sem{\Gamma \rightarrow T} & \mbox{(by (i))}\\
            &= \psi_M(\travset^{\filter r}(M)) & \mbox{(lemma \ref{lem:varphi_filter})}
    \end{align*}
    therefore we just need to prove the first equation.
\end{remark}

    Let us give a brief overview of the proof before giving it in full details.
    It proceeds by induction on the structure of the computation tree.
    The only non-trivial case is the application: the computation tree
    $\tau(M)$ has the following form:
        $$ \tree[levelsep=4ex]{\lambda \overline{\xi}}
            { \tree[levelsep=4ex]{@}
                {   \TR{\tau(N_0)} \TR{\ldots} \TR{\tau(N_p)}}}
        $$

    A traversal of $\tau(M)$ proceeds as follows: it starts at the root $\lambda \overline{\xi}$ of the tree $\tau(M)$ (rule \rulenamet{Root}), it then passes the node @ (rule \rulenamet{Lam}).
    After this initialization part, it proceeds by traversing the term $N_0$ (rule \rulenamet{App}).
    At some point, while traversing $N_0$, some variable $y_i$ bound by the root of $N_0$ is visited. The traversal
    of $N_0$ is interrupted and jumps (rule \rulenamet{Var}) to the root of $\tau(N_i)$. The process then goes on with $\tau(N_i)$.
    When traversing $N_i$, if the traversal encounters a variable bound by the root of $\tau(N_i)$ then the traversal of $N_i$
    is interrupted and
    the traversal of $N_0$ resumes.  This schema is repeated until the traversal of $\tau(N_0)$ is completed\footnote{Since we are considering
    simply-typed terms, the traversal does indeed terminate. However this will not be true anymore in the \pcf\ case.}.

    The traversal of $M$ is therefore made of an initialization part followed by an interleaving of a traversal of $N_0$ and
    several traversals of $N_i$ for $i=1..p$. This schema is reminiscent of the way the evaluation copycat map $ev$ works in game semantics.

    The key idea is that every time the traversal pauses the traversal of a subterm and switches to another one,
    the jump is permitted by one of the four ``copycat'' rules \rulenamet{Var}, \rulenamet{Value$^{\lambda\mapsto@}$}, \rulenamet{Value$^{{\sf var}\mapsto\lambda}$} or \rulenamet{Value-var}.
    We show by (a second) induction that these copycat rules define precisely what the copycat strategy $ev$ performs on sets of plays.

%    In the game semantics, the evaluation map (a copy-cat strategy) copies this opening move to an initial move $m_0$ in the game
%    $B_0$ and the game continues in $B_0$. We reflect this in the traversal : we make $t$ follow
%    the ``script'' given by the traversal $t^0_{m_0}$.
%    The rule (App) allow us to initiate this simulation  by visiting the  first move in $t^0_{m_0}$: the root of $\tau(N_0)$.
%
%    This simulation continues until it reaches a node $\alpha_0$ which is hereditarily justified by the root
%    $\tau(N_0)$: $\alpha_0$ is present in the reduction of traversal of $t^0_{m_0}$ therefore $\varphi_{N_0}(\alpha_0)$ is an un-hidden move played in $A_0$.
%
%    In the game semantics this corresponds to a move played in a component $A_k$ for some $k\in 1..p$ of
%    of the game $B_0$ in which case the evaluation map copies the move to an initial move $m_1$ in the corresponding component $B_k$.
%
%    To reflect this the traversal now opens up a new thread and simulates the traversal $t^k_{m_1}$.  Again, this simulation stops when we reach a node
%    $\alpha_1$ in $t^k_{m_1}$ which is hereditarily justified by the root of $\tau(N_k)$: $\alpha_1$ must be present in the reduction of traversal
%    of $t^k_{m_1}$ therefore $\varphi_{N_k}(\alpha_1)$ is an un-hidden move played in $A_k$.
%    In the game semantics, this move $\alpha$ is copied back to the component $B_k$ of the game $B_0$.
%
%    The traversal now resumes the simulation of $t^0_{m_0}$. And the process goes continuously.
\smallskip

\begin{proof}
Let $\Gamma \vdash M : T$ be a simply-typed term where $\Gamma =
x_1:X_1,\ldots x_n:X_n$. We assume that $M$ is already in
$\eta$-long normal form. By remark \ref{rem:corresp_proofreduction} we just need to
show that $\varphi_M(\travset(M)^{-@}) = \intersem{\Gamma \vdash M : T}$.
We proceed by induction on the structure of $M$:
\begin{enumerate}[$\bullet$]
    \item (abstraction) $M \equiv \lambda \overline{\xi}. N : \overline{Y} \rightarrow B$ where $\overline{\xi} = \xi_1:Y_1,\ldots \xi_n:Y_n$. On the first hand we have:
\begin{eqnarray*}
\intersem{\Gamma \vdash \lambda \overline{\xi}. N:T} &=& \Lambda^n( \intersem{\overline{\xi}, \Gamma \vdash N: B } ) \\
        &\simeq& \intersem{\overline{\xi}, \Gamma \vdash N: B } \ .
\end{eqnarray*}
On the other hand, the computation tree $\tau(N)$ is isomorphic to
$\tau(\lambda \xi_1\ldots \xi_n . N)$ (up to a renaming of the root
of the computation tree) and $\travset(N)$ is isomorphic to
$\travset(\lambda \xi_1\ldots \xi_n . N)$.
Hence we can conclude using the induction hypothesis.

  \item (variable) $M \equiv x_i$. Since $M$ is in $\eta$-long normal form, $x$ must be of ground
      type. The computation tree $\tau(M)$ and the arena $\intersem{\Gamma \rightarrow o}$ are represented below
      (value leaves and answer moves are not represented):
        $$ \tree[levelsep=6ex]{ \lambda }{\TR{x_i}} \hspace{2cm}
        \tree{ q_0 }
        {   \tree[linestyle=dotted]{q^1}{\TR{} \TR{} }
            \tree[linestyle=dotted]{q^2}{\TR{} \TR{} }
            \TR{\ldots}
            \tree[linestyle=dotted]{q^n}{\TR{} \TR{} }
        }
        $$

        Let $\pi_i$ denote the $i$th projection of the interaction game
        semantics. We have:
        \begin{align*}
        \intersem{M} &= \pi_i = \prefset(\{ \Pstr{(q0){q_0} \cdot (qi){q^i} \cdot (vqi-qi){v_{q^i}} \cdot (vq0-q0){v_{q_0}} } \ | \ v\in \mathcal{D} \})\ .
        \end{align*}

        It is easy to see that traversals of $M$ are precisely
        the prefixes of $ \Pstr{ (lmd)\lambda \cdot (xi){x_i}
        \cdot (vxi-xi){v_{x_i}} \cdot (vlmd-lmd){v_{\lambda}}}$.
        $M$ is in $\beta$-normal therefore $\travset(M)^{-@} =
        \travset(M)$ and since $\varphi_M(\lambda) =
        q_0$ and $\varphi_M(x_i) = q^i$, we have:
        $$ \varphi_M(\travset^{-@}(M)) = \varphi_M(\travset(M)) = \varphi_M(\prefset( \lambda \cdot x_i \cdot v_{x_i} \cdot v_{\lambda}))
         = \intersem{M} \ .
        $$


    \item (application) $M = N_0 N_1 \ldots N_p :o$ where $N_0$ is not a variable.
    We have the typing judgments $\Gamma \vdash N_0 N_1 \ldots
    N_p : o$ and $\Gamma \vdash N_i : B_i$ for $i\in 0..p$ where
    $B_0 = (B_1,\ldots,B_p,o)$ and $p\geq 1$.

    The tree $\tau(M)$ has the following form:
    $$ \tree[levelsep=6ex]{\lambda^{[r]}}
        { \tree[levelsep=6ex]{@}
            {
            \tree[levelsep=3mm,edge=\noedge]{\TR{{\lambda y_1 \ldots y_p}^{[r_0]}}}{\Tr[ref=t]{\pstribox{\tau(N_0)}}}
            \tree[levelsep=3mm,edge=\noedge]{\TR{[r_1]}}{\Tr[ref=t]{\pstribox{\tau(N_1)}}}
             \TR{\ldots}
            \tree[levelsep=3mm,edge=\noedge]{\TR{[r_p]}}{\Tr[ref=t]{\pstribox{\tau(N_p)}}}
        }}
    $$
    where $r_j$ denote the root of $\tau(N_j)$ for $j\in \{0..p\}$.

    We have:
    $$
    \intersem{\Gamma \vdash M : o}
            =  \underbrace{\langle \intersem{\Gamma \vdash N_0 : B_0}, \ldots \intersem{\Gamma \vdash N_p : B_p} \rangle}_{\Sigma} \,^\dagger\ \| \ ev
    $$

    We define the games $A$, $B$ and $C$ are defined as follows:
    \begin{eqnarray*}
        A &=& \Gamma = X_1 \times \ldots \times X_n\\
        B &=& \underbrace{((B_1' \times \ldots \times B_p') \rightarrow o')}_{B_0} \times B_1 \times \ldots \times B_p\\
        C &=& o \ .
    \end{eqnarray*}

    Figure \ref{fig:interaction_strategy_denotations} shows
    a tree-representation of $\intersem{M}$ which fixes the names of the different games involved in the interaction strategy.

%    Since $\varphi_M = \psi_M \union \varphi_{N_0} \union
%    \varphi_{N_1}$ the induction hypothesis gives us:
%    \begin{align}
%    \varphi_{M} (\travset^{-@}(N_0)) &= \intersem{\Gamma \vdash N_0 : B_0} \label{eqn:ih_1} \\
%    \varphi_{M}(\travset^{-@}(N_1)) &= \intersem{\Gamma \vdash N_1 : B_1} \label{eqn:ih_2}
%    \end{align}
\begin{enumerate}
\item[$\subseteq$]
    We first prove that $\intersem{\Gamma \vdash M : T}
    \subseteq \varphi_{M}( \travset^{-@}(M) )$. Suppose $u
    \in \intersem{\Gamma \vdash M : T}$. We give a
    constructive proof that there is a traversal $t$ of $M$
    such that $\varphi_M(t^\star) = u$ by induction on the
    length of $u$. Let $q_o$ and $q_0'$ be the initial
    question of $C$ and $B_0$ respectively.

    \emph{Base cases}:
    \begin{compactitem}[-]
    \item If $u=\epsilon$ then we take the empty traversal $t=\epsilon$ formed
with \rulenamet{Empty}. Clearly $\varphi(t) = u$.
    \item If $|u|=1$ then $u=q_0$ is the initial move in $C$. The traversal $t=\lambda$ formed with the rule \rulenamet{Root} verifies $\varphi(t) = u$.
    \item If $|u|=2$ then necessarily $u = q_0 \cdot q_0'$. The rules \rulenamet{Root}, \rulenamet{App}
and \rulenamet{Lam} permit us to build the traversal $t = \lambda^{[r]} \cdot @ \cdot \lambda \overline{y}^{[r_0]}$ which clearly verifies $\varphi_M(t-@) = u$.
    \end{compactitem}

    \emph{Step cases}: Suppose that $u = u' \cdot m \in
    \intersem{\Gamma \vdash M : T}$ for some move $m \in
    M_T$ where $u' = \varphi_M(t'^\star)$ for some traversal
    $t'$ of $\tau(M)$ and $|u'|>1$.

    By unraveling the definition of $u \in \intersem{\Gamma \vdash M : T}$ we have:
    \begin{eqnarray*}
      &&      \left\{
            \begin{array}{ll}
                u \in L_T\\
                u \filter T^0  \in \Sigma^\dagger \\
                u \filter T^1  \in  ev
            \end{array}
            \right. \\
    & \mbox{or equivalently} & \left\{
    \begin{array}{ll}
        u \in L_T \\
        \hbox{for any initial $m$ in $!B_0^0 \otimes \ldots \otimes !B_p^0$ there is $j \in \{0..p\}$ such that } \\
        \left\{\begin{array}{ll}
            u \filter m \filter T^{00j} \in \intersem{N_j} \label{eq:def_z} \\
            u \filter m \filter T^{00k} = \epsilon \quad \mbox{ for every } k\in \{1..p\}\setminus\{j\} \label{eq:b}
        \end{array}
        \right. \\
        u \filter B^1_0 = u \filter B^1_1, \ldots, B^1_p, C
    \end{array}
    \right.
    \end{eqnarray*}

We recall that $m \in M_T$ is an equivalence class of moves
from $\mathcal{M}_T$. For any game $A$ appearing in the
interaction game $T$ we will write ``$m \in A$'' to mean
that some citizen of the class $m$ belongs to the set of
moves $M_A$. Similarly, for any sub-interaction game $T'$ of
$T$, we write ``$m \in T'$'' to mean that some citizen of
the class $m$ belongs to the set of moves
$\mathcal{M}_{T'}$.

We do a case analysis on $m$: we either have $m\in C$ or $m\in T^0$:
    \begin{enumerate}[-]
    \item Suppose $m \in C$. $m$ is played by the strategy $ev$ whose plays do not contain any internal move. Hence $m$ is either $q_0$ or $v_{q_0}$ for some
    $v\in\mathcal{D}$. But since $q_0$ can occur only once in
    $u$ and $|u|>1$, $m$ must be $v_{q_0}$ for some
    $v\in \mathcal{D}$.  Moreover $m$ is a P-move played by the
    copy-cat strategy $ev$ in $B,C$ therefore it is the copy
    of the some move $v_{q_0'}$ answering the question $q_0'$ in the sub-game $o'$.

    In fact this move $v_{q_0'}$ is precisely $u'$'s last move. Indeed
    suppose that $u' = \ldots v_{q_0'} \cdot u''$. The play
    $u'_{\prefixof v_{q_0'}}\filter A,B$ is complete since its
    first move $q_0'$ is answered by $v_{q_0'}$. Therefore by
    Lemma \ref{lem:inter_complete}(ii), $u'_{\prefixof
    v_{q_0'}}\filter T^0$ is maximal. Thus moves in $u''$ must
    be played in $T^1$ by $ev$, but since $ev$ does not play internal
    moves, $u''$ is necessarily empty.

    Consequently, by the induction hypothesis, the last move in $t'$ is $\varphi(v_{q_0'}) = v_{\lambda y_1}$.
    The rules \rulenamet{Value$^{\lambda\mapsto@}$} and \rulenamet{Value$^{@\mapsto\lambda}$} permits us to extend
    the traversal $t'$ into $t' \cdot v_@ \cdot v_{\lambda \overline{\xi}}$ where $v_@$ and $v_{\lambda
    \overline{\xi}}$ point to the second and first node of $t$ respectively. Clearly we have $\varphi_M((t'\cdot v_@ \cdot v_{\lambda \overline{\xi}})-@) = u$.

    \item Suppose $m\in T^0$. Then $m$ is hereditarily justified by some initial move $b$ in $B_j$ for some $j\in \{0..p\}$.

        Since $u \filter b \filter T^{00j} \in \intersem{N_j}$, the outermost induction hypothesis gives us:
        \begin{equation}
        u \filter b \filter T^{00j} = \varphi_{N_j}(t_j^\star)  \label{eqn:corresp_outmost_ih}
        \end{equation}
          for some traversal $t_j \in \travset(N_j)$. W.l.o.g we can assume that $t_j^\omega \neq @$.

        We define the sequence of nodes $t = t'\cdot
        t_j^\omega$ where $t_j^\omega$'s justifiers are
        the nodes in $t'$ corresponding to $m$'s
        justifiers in $u$. We have:
        \begin{align*}
            \varphi_M (t_j^\omega) &= (\varphi_M (t_j^\star))^\omega & \mbox{($t_j^\omega \neq @$)}\\
                                   &= ((u' \cdot m) \filter b\filter T^{00j})^\omega & \mbox{(by Eq. \ref{eqn:corresp_outmost_ih})}\\
                                   &= ((u' \filter b\filter T^{00j}) \cdot m))^\omega & \mbox{($m$ is h.j. by $b$ and belongs to $T^{00j}$)}\\
                                   &= m
        \end{align*}
        and therefore
        \begin{align}
          \varphi_{M}(t^\star)  &=  \varphi_{M}(t'^\star)  \cdot \varphi_{M}(t_j) & \mbox{($t_j^\omega \neq @$)} \nonumber \\
                &=   u' \cdot m & \parbox[t]{7cm}{\raggedleft (by the innermost induction hypothesis and by the previous equation)} \nonumber \\
                &=   u & \mbox{(by def. of $u$).} \label{eqn:corresp_phi_t_minu_at_eq_u}
        \end{align}
        It remains to show that $t$ is indeed a traversal of $\tau(M)$.

        We have:
        \begin{align*}
        \varphi_{N_j}(t_j^\star) &= u \filter b \filter T^{00j}
            & \mbox{(By Eq. \ref{eqn:corresp_outmost_ih})} \\
         &= \varphi_{M}(t^\star) \filter b \filter T^{00j}
            & \mbox{(By Eq. \ref{eqn:corresp_phi_t_minu_at_eq_u})} \\
         &= \varphi_{N_j}(t^\star \filter r_j )
            & \mbox{(By Lemma \ref{}).}
        \end{align*}

        By Corollary \ref{cor:varphi_bij}, $\varphi_{N_j}$ is a bijection from $\travset(N_j)^{-@}$ to
        $\varphi_{N_j}( \travset(N_j)^{-@})$ therefore the last equation gives us:
         $$t_j^\star = t^\star \filter r_j $$

        By Eq. \ref{eqn:starfilter_filterplusstar} we
        have $t^\star \filter r_j = (t\filterplus
        r_j)^\star$. Hence since $t_j^\omega$ and
        $t^\omega$ are not in $N_@$ we necessarily have
        $t_j = t \filterplus r_j$.

    \begin{enumerate}[(a)]
    \item  Suppose $t_j$'s last occurrence is \emph{not} visited by the rule \rulenamet{InputVar} nor $\rulename{InputVar^{val}}$. Since $\ip( t_j) \subseqof t'$, $t_j$ is a traversal of the subterm $N_j$ of $M$ and the last occurrence
        of $t$ and $t_j$ coincide, by Lemma
        \ref{lem:local_traversal_progression}, $t =
        t' \cdot t_j^\omega$ is a traversal of $M$.

    \item Suppose $t_j$'s last move is visited with the rule \rulenamet{InputVar}.

    Then $t_j$ is of the form
    $$\Pstr[18pt]{ t_j = t' (z)z \cdot t'' \cdot (n-z){t_j^\omega}}$$
for some $z \in N_\lambda^{r_j\vdash}$ (see remark
\ref{rem:inputvar}) and some input-variable $x \in
N^{r_j\vdash}_{var}$ occurs in $z\cdot t'$ such that
$x$ is
 the pending node in $\ip\ t_j = t' \cdot z \cdot
 t''$ ({\it i.e.}~ with $?(t' \cdot z \cdot
 t'')^\omega = x$).

Suppose that $z\in N^{\theroot\vdash}$ then $z$ is a free variable of $M$ (and $N_j$).
Since the O-view of $t_j$ coincides with the O-view of $t$

    \item Suppose $t_j$'s last move is visited with the rule $\rulename{InputVar^{val}}$.
    This case is similar to the previous one but the rule $\rulename{InputVar^{val}}$ is used instead
    of $\rulename{InputVar}$.
    \end{enumerate}



\notetoself{PIECE OF OLD PROOF
%   \item Suppose that $m,m^1 \in T^{000}$.
%    The strategy $ev$ is responsible for switching of thread
%    in $B_0$ therefore, in the interaction semantics, there
%    must be a copycat move in-between two moves belonging to
%    two different threads. Since $m$ and $m^1$ are
%    consecutive moves in the sequence $u$, they must belong
%    to the same thread i.e. there are hereditarily justified
%    by the same initial $m_0$ in $B_0$.

Suppose that $m \in T^{000}$ and $m^1 \in T^{001}$.

    $t$ is obtained from $t-@$ by applying the
    transformation $+@$. We apply the same transformation to
    $u$ in order to make $O$-questions and $P$-questions in
    $u$ match with $\lambda$-nodes and variable nodes in
    $t'$ respectively. We write this sequence $u+@$. The
    $+@$ operation inserts nodes in the sequence but not at
    the end, therefore $m^1$, the last move in $u'$, is also
    the last move in $u'+@$. Let us note $n^1$ for the last
    move in $t'$.


        $n^1$ is a variable node then $m^1$ is a P-move and $m$ is an O-move
            and therefore $m$ is the copy of $m^1$ duplicated in $B_1$ by the evaluation strategy.
            Consequently, $m^1$ points to some $m^2$ and $m$ points to the node preceding $m^2$ denoted by $m^3$.
            The diagram below shows an example of such sequence in the case $z \in N^{\theroot\vdash}$:
                $$
                \begin{array}{ccccccccccc}
                  & A & \longrightarrow & ( (B_1' &\rightarrow & o') & \times & B_1 ) & \longrightarrow & o' \\
                  &&& &&&&&& \rnode{q0}{q_0 (\lambda \overline{\xi})} & O\\
                  &&& &&&&&  \\
                O &&& && \rnode{q1}{q_0' (\lambda \overline{y})} &&&&& P \\
                P &&& \rnode{m3}{m^3 (y_1)} &&&&&&& O \\
                O &&& &&&& \rnode{m2}{m^2 (\lambda \overline{z}^{[r_1]})} &&& P \\
                P &&& &&&& \rnode{m1}{m^1 (z)} &&& O \\
                O &&& \rnode{m}{m} &&&&&&& P \\
                \end{array}
                \ncline[nodesep=3pt]{->}{q1}{q0} \mput*{@}
                \nccurve[nodesep=3pt,ncurv=2,angleA=180,angleB=180]{->}{m1}{m2}
                \ncarc[nodesep=3pt,ncurv=1,angleA=90,angleB=180]{->}{m3}{q1}
                \ncarc[nodesep=3pt,ncurv=1,angleA=90,angleB=180]{->}{m}{m3}
                \ncline[nodesep=3pt]{->}{m2}{q0}
                $$

        $t'$  and $u+@$ have the following forms:
        \begin{eqnarray*}
                t'&=& \Pstr{ \ldots \cdot n^3 \cdot (n2){n^2} \cdot \ldots \cdot (n1-n2,30){n^1} } \\ \\
                u+@ &=& \Pstr{ \ldots \cdot (m3){m^3} \cdot (m2){m^2} \cdot \ldots \cdot (m1-m2,30){m^1} \cdot (m-m3,30){m} }
        \end{eqnarray*}

        Since $n^1$ is a variable node, $n^2$ must be a $\lambda$-node.
        $n^3$ is either a variable node or an @-node. In fact $n^3$ is necessarily a variable node. Indeed,
        $n^3$ is mapped to $m^3$ by $\varphi_{N_0}$ and $m^3$ belongs to $B_i'$ (i.e. it is not
        an internal move of $T^0$). The function $\varphi_{N_0}$ is defined in such a way that
        only nodes which are hereditarily justified by $r_0$ are mapped to nodes in $B_j'$.
        Consequently, since @-node don't have justifier, $n^3$ cannot be an @-node.

        Hence $n^1$ is a variable node, $n^2$ is a $\lambda$-node and $n^3$ is a variable node.

        Suppose $z\in N^{\theroot\vdash}$.
        We  can therefore apply the (Var) rule to $t'$ and we obtain a traversal of the following form:

        \begin{eqnarray*}
            t&=& \Pstr{ \ldots \cdot (n3){n^3} \cdot (n2){n^2} \cdot \ldots \cdot (n1-n2,30){n^1} \cdot (n-n3,30){n} }
        \end{eqnarray*}

        We have $\varphi(t'-@) = u'$ by the induction hypothesis and $\varphi(n) = m$ by definition of $\varphi$.
        Therefore since $m$ and $n$ point to the same position we have $\varphi(t-@) = u$.

                Suppose $z\not\in N^{\theroot\vdash}$. we have to use the rule $\rulename{InputVar^{val}}$...
}

    \end{enumerate}

\item[$\supseteq$]
  For the converse, $\varphi_{M}( \travset^{-@}(M) ) \subseteq \intersem{M}$, it is an easy induction
  on the traversal rules. We omit the details here.


\end{enumerate}


    \item (application') $M = x_i N_1 \ldots N_p :o$ with $X_i = B_0 = (B_1' \times \ldots \times B_p') \rightarrow o'$. The tree $\tau(M)$ has the following form:
    $$ \tree[levelsep=6ex]{\lambda^{[r]}}
        { \tree[levelsep=6ex]{x_i}
            {
            \tree[levelsep=3mm,edge=\noedge]{\TR{[r_1]}}{\Tr[ref=t]{\pstribox{\tau(N_1)}}}
             \TR{\ldots}
            \tree[levelsep=3mm,edge=\noedge]{\TR{[r_p]}}{\Tr[ref=t]{\pstribox{\tau(N_p)}}}
        }}
    $$
    The interaction strategy
    $\intersem{\Gamma \vdash M : o}
            =  \underbrace{\langle \pi_i, \intersem{\Gamma \vdash N_1 : B_1}, \ldots \intersem{\Gamma \vdash N_p : B_p} \rangle}_{\Sigma} \,^\dagger\ ;^{\{1..p\}} \ ev$
    is represented on Figure \ref{fig:interaction_strategy_denotations}.

    The proof is identical to the previous case except that in the $\subseteq$ part of the proof:
    \begin{itemize}
        \item In the base case of the induction where $|u|=2$,
        the rule \rulenamet{InputVar} is used instead of \rulenamet{App} to visit the node $x$ instead of $@$;
        \item in the step case of the induction, for the subcase $m\in C$, the rules \rulenamet{Value$^{\lambda\mapsto{\sf var}}$} and \rulenamet{Value$^{{\sf var}\mapsto\lambda}$} are used instead of \rulenamet{Value$^{\lambda\mapsto@}$} and \rulenamet{Value$^{@\mapsto\lambda}$} respectively;
        \item in the step case $m\in T^0$, when $m$ is hereditarily justified by a move $b \in B_j$ for
         $j\in \{1 .. p\}$ the proof remains unchanged. The case where $m$ is hereditarily justified by a move $b \in B_0$ is treated as follows: $m$ is played by the projection strategy $\pi$ denoting $x$.
         Since $m$ is played in $B_0' = B_1' \times \ldots \times B_p'$ it must be also hereditarily justified by some initial move $b'$ of $B_k'$ for some $k \in \{1.. p\}$ or by an initial move in $o'$. But moves of $B_k'$ are $\sim$-equivalent to the corresponding move in $B_k$ and similarly $o'$ is $\sim$-equivalent to $o$, therefore we fall back to the previous case of the induction where $m$ is hereditarily justified by some initial move $b\in B_k$ for $k\in \{1..p\}$ or some initial move in $o$!
    \end{itemize}


\end{enumerate}


\end{proof}


\begin{corollary} \hfill
If $M$ is in $\beta$-normal form then for any traversal $t$,
$\varphi_M(t)$ is a maximal play if and only if $t$ is a maximal
traversal.
\end{corollary}
\begin{proof}
If $M$ is in $\beta$-normal form then
$\travset(M)^{\filter r} = \travset(M)$ therefore
$\varphi$ defines a bijection on $\travset(M)$. Let $t$ be a
traversal such that $\varphi(t)$ is a maximal play. Let $t'$ be
a traversal such that $t \sqsubseteq t'$. By monotonicity of
$\varphi$ we have $\varphi(t) \sqsubseteq \varphi(t')$ which
implies $\varphi(t) = \varphi(t')$ by maximality of $\varphi(t)$
which in turn implies $t'=t$ by injectivity of $\varphi$. The
other direction is proved identically using injectivity and
monotonicity of $\varphi^-1$.
\end{proof}
\smallskip The following diagram recapitulates the main results of
this section:
$$
\xymatrix @C=6pc{
                                           & \travset(M)^{-@} \ar@/_/[dl]_{+@}  \ar[r]^{\varphi_M}_\cong & \intersem{M} \ar@/_/[dd]_{\_ \filter \sem{\Gamma\rightarrow T}} \\
\travset(M) \ar@/_/[ur]_{-@}^{} \ar[dr]^{\_ \filter r}  \\
                                           & \travset(M)^{\filter r} \ar[r]^{\varphi_M}_\cong & \sem{M} \ar@/_/[uu]^{\cong}_{\mbox{full uncovering}}
}
$$


\begin{example}
Take $M = \lambda f z . (\lambda g x . f x) (\lambda y. y) (f z) :
((o,o),o, o)$.  The figure below represents the computation tree
(left tree), the arena $\sem{((o,o),o, o)}$ (right tree) and
$\psi_M$ (dashed line). (Only question moves are shown for clarity.)
The justified sequence of nodes $t$ defined hereunder is an example
of traversal:

\begin{tabular}{lp{6.3cm}}
$\tree[levelsep=2.5ex,treesep=0.3cm]{ \Rnode{root}{\lambda f z} }
     {  \tree{@}
        {   \tree{\lambda g x}{
                  \tree{\Rnode{f}{f^{[1]}}}{
                            \tree{\Rnode{lmd}{\lambda^{[2]}}}
                            {\TR{x}}
                  }
                }
            \tree{ \lambda y }{\TR{y}}
            \tree{\lambda ^{[3]}}{
                \tree{\Rnode{f2}{f^{[4]}}} {
                \tree{\Rnode{lmd2}{\lambda^{[5]}}}{\TR{\Rnode{z}{z}}}
                }
            }
        }
     }
\hspace{1cm}
  \tree[levelsep=8ex,treesep=0.3cm]{ \Rnode{q0}q^0 }
    {   \pstree[levelsep=4ex]{\TR{\Rnode{q1}{q^1}}}{\TR{\Rnode{q2}{q^2}}}
        \TR{\Rnode{q3}q^3}
        \TR{\Rnode{q4}q^4}
    }
\psset{nodesep=1pt,arrows=->,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
\ncline{->}{root}{q0} \mput*{\psi_M}
\ncarc[arcangle=-25]{->}{z}{q3}
\ncarc[arcangle=10]{->}{f}{q1}
\ncarc[arcangle=10]{->}{lmd}{q2}
\ncline{->}{f2}{q1}
\ncline{->}{lmd2}{q2}$
\hspace{2cm}
&
\begin{asparablank}
  \item  \Pstr[0.8cm]{
t = (n){\lambda f z} \
(n2){@} \
(n3-n2,60){\lambda g x} \
(n4-n,45){f^{[1]}} \
(n5-n4,45){\lambda^{[2]}} \
(n6-n3,45){x} \
(n7-n2,35){\lambda^{[3]}} \
(n8-n,35){f^{[4]}} \
(n9-n8,45){\lambda^{[5]}} \
(n10-n,35){z}
}

\item \Pstr[0.9cm]{
t\filter r = (n){\lambda f z} \ (n4-n,50){f}^{[1]} \
(n5-n4,60){\lambda}^{[2]} \ (n8-n,45){f}^{[4]} \
(n9-n8,60){\lambda}^{[5]} \ (n10-n,40){z}}
\item
\Pstr[0.8cm]{ {\psi_M(t\filter r) =\ } (n){q^0}\
(n4-n,60){q^1}\ (n5-n4,60){q^2}\ (n8-n,45){q^1}\ (n9-n8,60){q^2}\
(n10-n,38){q^3} \in \sem{M}\ .}
\end{asparablank}
\end{tabular}
\end{example}
