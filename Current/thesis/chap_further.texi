
\section{Summary of contribution}

\emph{Safety} is a syntactic constraint for higher-order grammars.
A grammar is \emph{safe} if the right-hand side of each rule is such that no operand
occurring in operand position contains parameters of order smaller than
the order of the subterm. Motivated by the appealing algorithmic properties of safety, we derived a new typing system, the \emph{safe lambda calculus}, by imposing
this syntactic constraint on the simply typed lambda calculus.
An interesting property of this calculus is that it is not necessary to rename variables when performing substitution.
Thus in some sense, safe terms are ``easier'' to compute than unsafe ones.
Computation in our calculus is standardly done via the concept of $\beta$-reduction. Safety is not preserved by beta-reduction in general, but it is preserved when sufficiently many consecutive redexes are contracted simultaneously. This is formalized by the notion of \emph{safe beta-reduction}: If a safe term contains a $\beta$-redex then this redex can always be ``enlarged'' into a group of consecutive beta-redexes, called a safe redex, such that contracting all of them produces a safe term. The notion of normal form thus remains unchanged. Safety is also preserved by taking the eta-long normal form of a term. More precisely, a term is safe if and only if its eta-long normal form is. From a semantic point of view, this means that safety can be studied extensionally.

The typing system of the safe lambda calculus has desirable properties: the
type-checking (Can a given type be assigned to a given term?)
and typability (Given a term, is there a type that can be assigned to it?) problems are both decidable.
On the other-hand, we only know that the type-inhabitation problem
(Given a type, is there a safe term of that type?) is at least semi-decidable (there is an algorithm that tells if a type is inhabited by a safe term in a finite amount of time if it is the case, but may not terminate otherwise).

The loss of expressivity incurred by safety can be characterized in terms of expressible numeric functions:
they are precisely the multivariate polynomials; the conditional operator, which is definable in the lambda calculus,
is not expressible by any safe term.

We then looked at the complexity of the calculus by considering the beta-equivalence problem:
we hinted that it probably lies in the complexity class ELEMENTARY by showing how both Statman and Mairson's encoding of finite type theory in the simply typed lambda calculus fail in the safe fragment.
We showed however that the problem is PSPACE-hard.
\medskip

Seeking for a semantic explanation of the safety constraint, we focused on the analysis of the game semantics of safe terms. This led us to the other main contribution of this thesis: the development of a new presentation of Game semantics based on the theory of traversals\cite{OngLics2006}.

\todo{Finish the conclusion...}

Armed with the Correspondence Theorem, we were able to give a precise account of the game
semantics of the safe $\lambda$-calculus. A notable property of safe terms is that its variables are incrementally-bound:
the binder of a variable node $x$ in the computation tree is precisely the last lambda-node in the path from $x$ to the root with order strictly greater than $\ord x$. By the Correspondence Theorem, this implies that the strategy denotation of a safe term is \emph{P-incrementally justified}. In such strategy, a P-question's justifier is given by the last O-move in the P-view with a strictly higher order.

In the last chapter we finally investigated the categorical model of the safe lambda
calculus. We proposed the notion of Incremental Closed Category (ICC) that soundly interprets the safe lambda calculus in the same way Cartesian Closed Categories model the simply typed lambda calculus. We then exhibited such an ICC by constructing a game model of P-incrementally justified strategies. (We showed in particular that P-incremental justified strategies compose.) 

To conclude, we look at safety from the point of view of Algorithmic Game Semantics. We considered the problem of observational equivalence of \ialgol\ term with respect to \emph{safe} context. 
By suitably constraining O-moves by the dual notion of \emph{O-incremental justification}, we
obtain a model of safe PCF and safe \ialgol\ that is fully abstract with respect to
this notion of observational equivalence. Furthermore, the model is effectively presentable: two safe terms are observationally equivalent with respect to safe context if and only if their denotations have the same set of \emph{complete O-incrementally justified} plays.

Up to order $3$, the addition of unsafe contexts to safe ones is conservative with respect to observational equivalence. Furthermore, all the complexity results---lower and upper bounds---known about observational equivalence of the (unrestricted) lower-order fragments of \ialgol\ also hold in the safe sub-fragments. At order-$4$, however, the two notions of observational equivalence (with respect to unrestricted or safe contexts) differ. For Safe $\ialgol_4$, we conjecture the problem to be reducible to the DPDA-equivalence problem (which is decidable).

\section{Related work}


\subsection*{The safety condition for higher-order grammars}

 We have mentioned the result of Knapik et~al.\ \cite{KNU02} that
 infinite trees generated by \emph{safe} higher-order grammars have
 decidable MSO theories.  A natural question to ask is whether the
 \emph{safety condition} is really necessary.  This has been
 partially answered by Aehlig et~al.\
 \cite{DBLP:conf/tlca/AehligMO05} where it was shown that safety is not
 a requirement at level $2$ to guarantee MSO decidability. Also, for
 the restricted case of word languages, the same authors have shown
 \cite{DBLP:conf/fossacs/AehligMO05} that level $2$ safe higher-order
 grammars are as powerful as (non-deterministic) unsafe ones.  De
 Miranda's thesis \cite{demirandathesis} proposes a unified framework
 for the study of higher-order grammars and gives a detailed analysis
 of the safety constraint at level 2.

 More recently, Ong obtained a more general result and showed
 that the MSO theory of infinite trees generated by higher-order
 grammars of any level, \emph{whether safe or not}, is decidable
 \cite{OngLics2006}.  Using an argument based on innocent
 game-semantics, he establishes a correspondence between the tree
 generated by a higher-order grammar called \emph{value tree} and the \emph{computation tree}
 of the grammar: Paths in the value tree correspond to P-views of traversals of the computation tree.
 Decidability is then obtain by reducing the problem to the acceptance
 of the (annotated) computation tree by a certain alternating parity
 tree automaton.

 The equivalence of \emph{safe} higher-order grammars and higher-order
 deterministic push-down automata for the purpose of generating
 infinite trees \cite{KNU02} has its counterpart in the general (not
 necessarily safe) case: the paper \cite{hmos-lics08}
 establishes the equivalence of order-$n$ higher-order grammars and
 order-$n$ \emph{collapsible pushdown automata}. Those automata form a
 new kind of pushdown systems in which every stack symbol has a link to
 a stack situated somewhere below it and with an additional stack
 operation whose effect is to ``collapse'' a stack $s$ to the state
 indicated by the link from the top stack symbol.

\section{Further works}

The nature of the safe lambda calculus is still not completely
understood. Some questions remain about the safe $\lambda$-calculus pertaining for instance to its computational power, the complexity classes that it characterizes and its interpretation under the Curry-Howard isomorphism.
We now propose possible directions for further works and highlight some open questions.


\subsection*{Extensions}

Untype lambda calculus, second-order lambda caluclus.

\subsection*{Logic}
What kind of reasoning principles does the safe lambda calculus support, via the Curry-Howard Isomorphism?

\subsection*{Complexity}
Does the safe lambda calculus characterize a complexity class, in the same way that the simply typed lambda calculus characterizes the polytime-computable numeric functions \cite{DBLP:conf/tlca/LeivantM93}?

%%%%%A pressing question concerns the complexity of the safe lambda calculus.

% (note that it is unlikely to obtain the complexity PSPACE because the
% set of complete plays of the safe term $\lambda f^{(o,o),o} . f
% (\lambda x^o . x)$ is not regular \cite{DBLP:journals/apal/Ong04}).


\subsection*{Representability of functions over free algebras}

\emph{What are the function over \emph{free-algebras} definable in the safe simply typed lambda calculus?} \cite{DBLP:journals/tcs/Leivant93,DBLP:journals/apal/Zaionc91}

There is an isomorphism between binary trees and closed simply typed terms of
type $\tau =(o\typear o\typear o) \typear o \typear o$. Thus any
closed term of type $\tau\typear\tau \typear \ldots \typear \tau $
represents an $n$-ary function over trees. Zaionc gave a
characterization of the set of tree functions representable in the
simply typed lambda calculus \cite{DBLP:conf/aluacs/Zaionc88}: it is
precisely the minimal set containing constant functions, projections
and closed under composition and limited primitive recursion. Zaionc
showed that the same characterization holds for the general case of
functions expressed over free algebras
\cite{DBLP:journals/apal/Zaionc91}: they are given by the
minimal set containing constant functions, projections and closed
under composition and limited primitive recursion. This result subsumes
Schwichtenberg's result on definable numeric functions as well as
Zaionc's own results on definable word and tree functions.

All these basic operations are safe except limited primitive recursion.
This suggests that one needs to restrict further the primitive recursion in order to obtain a characterization of free-algebra functions representable in the
safe lambda calculus. Such result would generalized our expressivity result for numeric and word functions from Sec.\ \ref{sec:expressivity}.

\subsection*{Expressibility}
Murawski introduced a notion of language expressibility by game semantics \cite{Murawski2003}. He showed that the $4th$ order finitary fragment of \ialgol\ is expressive enough to give the full class of recursively enumerable languages. Does the safe fragment have the same expressive power? Another line of research would be to investigate whether the class of word languages recognizable by higher-order pushdown automata can be characterized in Murawski's sense by some higher-order fragment of safe \ialgol.

\subsection*{Game semantics}

Is the game model of safe \pcf\ universal? (\ie, is every recursive incremental strategy denoted by some safe \pcf\ term?)

\subsection*{Algorithmic game semantics}

\emph{Is observational equivalence for \emph{safe} $\ialgol_4$ decidable?}

We have seen that up to order $3$, the problem of observational equivalence has the same complexity in the safe finitary fragments as in the unrestricted finitary fragments. An obvious direction is to investigate this problem at order $4$. Murawski \cite{Murawski2003} showed the undecidability of program equivalence in $\ialgol_i$ for $i\geq4$ by encoding Turing machine computations into a finitary $IA_4$ term.  
  His encoding relies on unsafe terms, thus the argument cannot be directly transposed to
 the safe fragment of \ialgol. Thus the question of whether observational
 equivalence of safe $\ialgol_4$ is decidable remains opened.

\subsection{Compilation of recursion schemes to pushdown automata}

% traversal theory to show n-safe RS->nPDA


\subsection*{PUR languages}

In this thesis, we have shown that the safety constrained produces
languages whose game semantics enjoy the property that some justification pointers are uniquely recoverable from the underlying sequence of moves. Safe $\ialgol_3$ is an example of language in which \emph{all} pointers are recoverable.
We name this class \emph{PUR} for ``\emph{Pointer Uniquely Recoverable}''. Finitary $\ialgol_2$ (finite base types and no recursion) is the paradigmatic example of a PUR-language (The fact that it is a sublanguage of Safe $\ialgol_3$ is another proof of this fact). But safe fragments are clearly not the only PUR-languages: singleton languages (\ie, containing only one term) are trivial examples of PUR languages. Also the language consisting of all $\ialgol_3$ terms whose beta-reduction is safe is also a PUR language.

A more interesting example is \emph{Serially Re-entrant Idealized  Algol} \cite{abramsky:mchecking_ia}, a version of \ialgol\ where multiple uses of arguments are allowed only if they do not ``overlap in time''.
In the game semantics denotation of a SRIA term
there is at most one pending occurrence of a question at any time.
Each move has therefore a unique justifier and consequently
justification pointers may be ignored. Safe \ialgol\ is not a
sublanguage of SRIA. One reason for this is that none of the two
Kierstead terms $\lambda f . f (\lambda x . f (\lambda y .y ))$ and
$\lambda f . f (\lambda x . f (\lambda y .x ))$ are Serially
Re-entrant whereas the first one is safe. Conversely, SRIA is not a
sublanguage of safe \ialgol\ since the term $\lambda f g. f (\lambda
x . g (\lambda y .x ))$ where $f,g:((o,o),o)$ belongs to SRIA but
not to safe \ialgol.


Another way to generate PUR-languages may consist in constraining types. Joly introduced a notion of ``complexity'' for $\lambda$-terms and proved that there is a constant bounding the
complexity of every closed normal $\lambda$-term of a given type $T$
if and only if $T$ can be generated from a finite set of combinators;
Consequently, the only inhabited finitely generated types are the
types of order $\leq 2$ and the types $(A_1, A_2, \ldots, A_n, o)$
such that for all $i = 1..n$: $A_i = o$ , $A_i = o \rightarrow o$ or
$A_i = (o^k \rightarrow o) \rightarrow o$ \cite{DBLP:conf/tlca/Joly01}.
We already know that imposing the first type restriction to Finitary \ialgol\ leads to a
PUR language. Does the second restriction also give a PUR language?

With a view to algorithmic game semantics and its applications, the PUR class is of particular interest. 
Indeed, PUR-languages are good candidates of languages with decidable observational equivalence. This is because the simplification of the game semantic model resulting from the nonnecessity of pointers makes the observational equivalence problem more manageable: In \ialgol, for instance one just need to compare the set of complete plays underlying the denotation of a term, forgetting the justification pointers altogether.
For lower-order fragments, a machine characterization of this set is sometimes possible (\eg, finite-state automaton at order-$2$, and deterministic pushdown automata for the order-$3$ fragment with $Y_0$ recursion),

It was for instance proved that the finitary some lower-order fragments of $\ialgol$ are decidable.
