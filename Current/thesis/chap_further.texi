\section{Summary of Contribution}

In this thesis we have introduced a new calculus and studied it
under different angles. We have given an account of the game
semantics of safe $\lambda$-calculus. \notetoself{bla bla bla}

\section{Future Works}

The nature of the safe lambda calculus is still not completelty
understood. We propose the following possible directions for further
research:
\begin{enumerate}
\item give a detailed account of
P-incrementally-justified strategies that treats the problem of
compositionality;
\item find a categorical interpretation of the safe $\lambda$-calculus;
\item study the proof theory obtained by the Curry-Howard isomorphism and determine whether it has nice properties that can be helpful in theorem proving;
\item identify a non-trivial fragment of safe \ialgol\ for which observational equivalence is decidable;
\item in \cite{DBLP:conf/tlca/LeivantM93}, the $\lambda$-calculus is used to
give several characterisations of the complexity class P. We
would like to investigate whether, by following similar
techniques, we can obtain a characterisation of a different
complexity class using the safe $\lambda$-calculus.
\end{enumerate}


More generally, we would like to study the class of languages for
which pointers are uniquely recoverable. We name this class PUR for
``Pointer Uniquely Recoverable''.

An example is the Serially Re-entrant Idealized Algol (SRIA)
proposed by Abramsky  in \cite{abramsky:mchecking_ia}. This language
allows multiple occurrences or uses of arguments, as long as they do
not overlap in time. In the game semantics denotation of a SRIA term
there is at most one pending occurrence of a question at any time.
Each move has therefore a unique justifier and consequently
justification pointers may be ignored. Safe \ialgol\ is not a
sublanguage of SRIA. One reason for this is that none of the two
Kierstead terms $\lambda f . f (\lambda x . f (\lambda y .y ))$ and
$\lambda f . f (\lambda x . f (\lambda y .x ))$ are Serially
Re-entrant whereas the first one is safe. Conversely, SRIA is not a
sublanguage of safe \ialgol\ since the term $\lambda f g. f (\lambda
x . g (\lambda y .x ))$ where $f,g:((o,o),o)$ belongs to SRIA but
not to safe \ialgol.

Finitary $\ialgol_2$ is also an example of PUR-language for which
observational equivalence is decidable. As we indicated in the first
chapter, decidability of observational equivalence is a very
appealing property which has immediate applications in the domain of
program verification. Intuitively, PUR-languages seem to be good
candidates of languages for which observational equivalence is
decidable. It would be interesting to discover classes of PUR
languages having this appealing property. Safe $\ialgol_3$ seems to
be a good candidate.

Another possible way to generate PUR-languages may be to constrain
the types of an existing language. In \cite{DBLP:conf/tlca/Joly01},
a notion of ``complexity'' is defined for $\lambda$-terms. It is
proved that a type $T$ can be generated from a finite set of
combinators if and only if there is a constant bounding the
complexity of every closed normal $\lambda$-term of type $T$;
consequently, the only inhabited finitely generated types are the
type of rank $\leq 2$ and the types $(A_1, A_2, \ldots, A_n, o)$
such that for all $i = 1..n$: $A_i = o$ , $A_i = o \rightarrow o$ or
$A_i = (o^k \rightarrow o) \rightarrow o$. We know that imposing the
first of these two type restrictions to Finitary \ialgol\ leads to a
PUR language. Is it also the case when imposing the second type
restriction?


\section{Further work and open problems}

The safe lambda calculus is still not well understood. Many basic
questions remain. What is a (categorical) model of the safe lambda
calculus? Does the calculus have interesting models?  What kind of
reasoning principles does the safe lambda calculus support, via the
Curry-Howard Isomorphism? Does the safe lambda calculus characterize
a complexity class, in the same way that the simply-typed lambda
calculus characterizes the polytime-computable numeric functions
\cite{DBLP:conf/tlca/LeivantM93}?  Is the addition of unsafe
contexts to safe ones conservative with respect to observational (or
contextual) equivalence?
%Can we obtain a fully abstract model of safe PCF by suitably
%constraining O-moves ({\it i.e.}~``O-incremental justification'')?

With a view to algorithmic game semantics and its applications, it
would be interesting to identify sublanguages of Idealised Algol
whose game semantics enjoy the property that pointers in a play are
uniquely recoverable from the underlying sequence of moves. We name
this class PUR. $\ialgol_2$ is the paradigmatic example of a
PUR-language. Another example is \emph{Serially Re-entrant Idealized
  Algol} \cite{abramsky:mchecking_ia}, a version of \ialgol\ where
multiple uses of arguments are allowed only if they do not ``overlap
in time''.  We believe that a PUR language can be obtained by
imposing the \emph{safety condition} on $\ialgol_3$. Murawski
\cite{Murawski2003} has shown that observational equivalence for
$\ialgol_4$ is undecidable; is observational equivalence for
\emph{safe} $\ialgol_4$ decidable?
