% -*- TeX -*- -*- Soft -*-

\section*{Background}

The \emph{safety condition} was introduced by Knapik, Niwi{\'n}ski
and Urzyczyn at FoSSaCS 2002 \cite{KNU02} in a seminal study of the
algorithmics of infinite trees generated by higher-order grammars.
The idea, however, goes back some twenty years to Damm \cite{Dam82}
who introduced an essentially equivalent\footnote{See de Miranda's
 thesis \cite{demirandathesis} for a proof.} syntactic
restriction (for generators of word languages) in the form of
\emph{derived types}.
% Level-$n$ tree grammars as defined by Damm correspond exactly to a
% subset of safe level-$n$ grammars---namely the safe complete grammars---and every safe grammar corresponds to a safe complete one.
A higher-order grammar (that is assumed to be \emph{homogeneously
  typed}) is said to be \emph{safe} if it obeys certain syntactic
conditions that constrain the occurrences of variables in the
production (or rewrite) rules according to their type-theoretic
order. Though the formal definition of safety is somewhat intricate,
the condition itself is manifestly important. As we survey in the
following, higher-order \emph{safe} grammars capture fundamental
structures in computation, offer clear algorithmic advantages, and
lend themselves to a number of compelling characterizations:

\begin{itemize}
\item \emph{Word languages}. Damm and Goerdt \cite{DG86} have shown
  that the word languages generated by order-$n$ \emph{safe}
  grammars form an infinite hierarchy as $n$ varies over the
  natural numbers. The hierarchy gives an attractive
  classification of the semi-decidable languages: Levels 0, 1
  and 2 of the hierarchy are respectively the regular,
  context-free, and indexed languages (in the sense of Aho
  \cite{Aho68}), although little is known about higher orders.

  Remarkably, for generating word languages, order-$n$
  \emph{safe} grammars are equivalent to order-$n$ pushdown
  automata \cite{DG86}, which are in turn equivalent to
  order-$n$ indexed grammars \cite{Mas74,Mas76}.

\item \emph{Trees}. Knapik et~al.\ have shown that the Monadic
  Second Order (MSO) theories of trees generated by \emph{safe}
  (deterministic) grammars of every finite order are
  decidable\footnote{It has recently been shown
    \cite{OngLics2006} that trees generated by \emph{unsafe}
    deterministic grammars (of every finite order) also have
    decidable MSO theories. More precisely, the MSO theory of
    trees generated by order-$n$
recursion schemes is $n$-EXPTIME complete.}.

  They have also generalized the equi-expressivity result due to
  Damm and Goerdt \cite{DG86} to an equivalence result with
  respect to generating trees: A ranked tree is generated by an
  order-$n$ \emph{safe} grammar if and only if it is generated
  by an order-$n$ pushdown automaton.

\item \emph{Graphs}. Caucal \cite{Cau02} has shown that the MSO
  theories of graphs generated\footnote{These are precisely the
    configuration graphs of higher-order pushdown systems.} by
  \emph{safe} grammars of every finite order are decidable. In a
  recent paper \cite{hmos-lics08}, however, Hague et~al. have shown that the MSO theories of graphs generated by
  order-$n$ \emph{unsafe} grammars are undecidable, but deciding
  their modal mu-calculus theories is $n$-EXPTIME complete.
\end{itemize}



\section*{Overview}

The aim of this thesis is to understand the safety condition in the setting of the typed lambda calculus. Our first task is to transpose it to the lambda calculus and pin it down as an appropriate sub-system of
the simply-typed theory. A first version of the \emph{safe lambda calculus} has appeared in an unpublished technical report
\cite{safety-mirlong2004}. Here we propose a more general and
cleaner version where terms are no longer required to be
homogeneously typed (see Section~\ref{sec:safe} for a definition).
The formation rules of the calculus are designed to maintain a
simple invariant: Variables that occur free in a safe $\lambda$-term
have orders no smaller than that of the term itself.  We can now
explain the sense in which the safe lambda calculus is safe by
establishing its salient property: No variable capture can ever
occur when substituting a safe term into another. In other words, in
the safe lambda calculus, it is \emph{safe} to use
capture-\emph{permitting} substitution when performing
$\beta$-reduction.


There is no need for new names when computing $\beta$-reductions of
safe $\lambda$-terms, because one can safely ``reuse'' variable
names in the input term. Safe lambda calculus is thus cheaper to
compute in this na\"ive sense. Intuitively one would expect the
safety constraint to lower the expressivity of the simply typed
lambda calculus. Our next contribution is to give a precise measure
of the expressivity deficit of the safe lambda calculus. An old
result of Schwichtenberg \cite{citeulike:622637} says that the
numeric functions representable in the simply typed lambda calculus
are exactly the multivariate polynomials \emph{extended with the
conditional function}.  In the same vein, we show that the numeric
functions representable in the safe lambda calculus are exactly the
multivariate polynomials. We further obtain a similar characterization concerning representable word-functions.

In order to get a better understanding of our calculus, it is interesting to recast common problems studied in the literature on the simply typed lambda calculus in the setting of the safe lambda calculus.
We show for instance that the type-checking and typability problems remain decidable. We also consider the type-inhabitation problem: ``Is there a term inhabiting a given type?''. This problem is already relatively complex in the simply-typed lambda calculus---Statman showed that it is PSPACE-complete.
Because of the somewhat intricate way in which safety constrains the occurrences of the variables, the inhabitation problem becomes even more
complex in the safe lambda calculus. We do not know whether the problem is decidable.

Another famous result by Statman is that deciding beta-equality of two simply typed terms is non-elementary. There are several proofs of this results in the literature. All of them proceed by reduction of a non-elementary problem---such as quantifier elimination in finite type theory---into the simply typed lambda calculus. Interestingly, all these encodings make use of unsafe terms in some place. This suggests that such encoding is impossible in the safe lambda calculus and that the beta-equivalence problem may be simpler when restricted to safe terms. We have not been able to establish an upper-bound on the complexity of this problem. A lower-bound can however be obtained: the True Quantifier Boolean Formula (TQBF) problem (deciding whether a quantified boolean formula is true or not) can be encoded in the safe lambda-calculus. Since the latter problem is PSPACE-complete, this implies that beta-equivalence is PSPACE-hard for safe lambda terms.
A particularity of this encoding is that it relies on the entire type hierarchy and thus we only have PSPACE-hardness for the safe lambda calculus in its entirety. This contrasts with another result by Statman which shows that there exists a finite set of types such that the beta-eta equivalence problems in the simply type lambda calculus restricted to terms of these types is PSPACE-hard.


\subsection*{Extensions}

\pcf\ is the simply typed lambda calculus augmented with basic
arithmetic operators, if-then-else branching and a family of
recursion combinator $Y_A : ((A,A),A)$ for any type $A$.  We define
\emph{safe} \pcf\ to be \pcf\ where the application and abstraction
rules are constrained in the same way as the safe lambda calculus.
This language inherits the good properties of the safe lambda
calculus: No variable capture occurs when performing substitution
and safety is preserved by the reduction rules of the small-step
semantics of \pcf. Similarly, we define safe \ialgol\ as safe \pcf\ augmented
with the imperative features of Idealized Algol (\ialgol\ for short)
\cite{Reynolds81}. A version of the no variable capture lemma also holds in safe \ialgol.


\subsection*{A concrete game semantics}
Game semantics has emerged as a powerful paradigm for the study of higher-order functional programming languages in general, and in particular for the mother of all functional languages: the lambda calculus.
The game approach was for instance the first to give rise to a full abstract model of PCF \cite{abramsky94full,hylandong_pcf}.
An inevitable question to ask is whether the safety constraint has a noticeable impact on the game denotation of a term. Answering this question would help us to gain a better understanding of the nature of the safety restriction on a fundamental level.

In the traditional presentation of game semantics, a lot of attention is taken to abstract away entirely the syntax of the language from the definition of the semantics. This syntax-independent aspect of game models constitutes their salient feature. But when it comes to analyze the safety restriction it becomes more a complication than a benefit because safety is precisely a \emph{syntactic} constraint.

A substantial part of the thesis is therefore devoted to giving a presentation of game semantics that is more concrete than the traditional one in the sense that the semantic denotation of a term carries some information about its syntax.
This presentation is based on ideas recently introduced by Ong \cite{OngLics2006}: a term is canonically represented by a certain abstract syntax tree of its
 $\eta$-long normal form referred as the \emph{computation tree}.
The computation itself is then described by a justified sequence of nodes of the computation tree  respecting some formation rules and called a
 \emph{traversal}. Traversals permit us to model $\beta$-reductions
 without altering the structure of the computation tree via
 substitution. A notable property is that \emph{P-views} (in the
 game-semantic sense) of traversals corresponds to paths in the
 computation tree.  We show that traversals are just representations of
 the \emph{revealed game semantic} denotation: the set of uncovering of plays of the game-semantic denotation with respect to the syntax of the eta-long normal form of the term. The standard game denotation can then be recovered by mean of a \emph{reduction} operation which eliminates traversal nodes that are ``internal'' to the computation, thus implementing the
 counterpart of the hiding operation of game semantics. This leads to
 an isomorphism between the standard strategy denotation of a term and the set  of reductions of traversals of its computation tree.


We then extend our presentation of game semantics to PCF and IA.
We accommodate the notion of computation tree to recursively defined terms as follows: the computation tree of a \pcf\ term is defined as the least
upper-bound of the chain of computation trees of its \emph{syntactic
approximants} \cite{abramsky:game-semantics-tutorial}.
Think of it as the tree obtained by expanding Y-combinators {\it ad infinitum}. For instance the computation tree of $Y (\lambda f x. f x)$ is given by the abstract syntax tree of the $\eta$-long form of the infinite lambda-term $(\lambda f x. f x)  ((\lambda f x. f x) ((\lambda f x. f x) ( \ldots $.
It is then possible to define traversal rules modeling the
arithmetic constants of \pcf. A version of the Correspondence Theorem for \pcf\ holds. We show it first for term approximants and then lift the result to
full \pcf\ by a continuity argument.

The extension to \ialgol\ is slightly more complicated by the presence of the base type $\iavar = \iacom^{\nat} \times \iaexp$. Since the game denotation of $\iavar$ has infinitely many initial moves, there is a mismatch between the tree representation of the term of type $\iavar$ and the arena underlying the game induced by the type $\iavar$. It is also possible, however, to adapt the game-semantic correspondence to \ialgol\ by replacing computation tree by computation hyper-trees. These are trees in which several nodes can be grouped into a single hyper-node.

\subsection*{Game semantics of safety}

 This last contribution constitutes a significant detour from the main topic of this thesis, but it is particularly useful to the analysis of the safety constraint. Using the correspondence result relating the game semantics of a
$\lambda$-term $M$ to a set of \emph{traversals} over its \emph{computation tree}, we are able to show that safe terms are denoted by \emph{P-incrementally justified strategies}. In such a
strategy, pointers emanating from the P-moves of a play are uniquely
reconstructible from the underlying sequence of moves and the
pointers associated to the O-moves therein: Specifically, a
P-question always points to the last pending O-question (in the
P-view) of a greater order. Consequently pointers in the game
semantics of safe $\lambda$-terms are only necessary from order 4
onwards. More precisely, we show that a $\beta$-normal $\lambda$-term is
\emph{safe} if and only if its strategy denotation is (innocent and)
\emph{P-incrementally justified}.


\subsection*{Model of safe lambda calculi}
Our last contribution is to establish a game model of the safe lambda calculus. A fundamental result in theoretical computer science is the connection between Cartesian Closed Categories (CCC) and models of typed lambda calculi: it was observed by Lambek \cite{lambek1986ccc} that any extensional model of the simply typed lambda calculus is a CCC, and converserly, any typed lambda calculus induces a CCC.

A similar categorical connection can be made for models of the safe lambda calculus. The categorical counterparts of safe lambda calculi are the \emph{Incremental Closed Categories} (ICC). These categories are subcategories of CCC in which \emph{Currying} is restrained. By showing that P-incrementally justified strategies compose, we can construct an ICC of games with morphisms given by P-incrementally justified strategies. This gives rise to a categorical game model of the safe lambda calculus.

\subsection*{Full abstraction}

A common concept in game semantics is that the pure functional core of a programming language can be modeled by strategies verifying the properties of \emph{visibility}, \emph{innocence} and \emph{well-bracketing}. Adding features to the language corresponds to relaxing one of these properties in the game model. For instance adding imperative features breaks innocence, adding exceptions-handling breaks well-bracketing and adding general references break visibility. Furthermore in each of these cases, the game model gives rise to a fully abstract model of the considered language.
For instance the well-bracketed and visible strategies gives rise to a fully abstract game model of the language Idealized Algol (IA) (PCF extended with block-allocated variables).

Conversely, restricting the language corresponds to imposing more constraint on the strategy. As mentioned before, the strategy counterpart of the safety restriction is P-incremental justification. As expected, this restriction gives rise to a fully-abstract model of the safe fragment of \pcf. These results are summarized in the following table:

\begin{tabular}{l|l}
Language & Strategy constraints\\ \hline\hline
Safe IA & deterministic + visible + w.b.\ + P-i.j.\\
Safe PCF & deterministic + visible + w.b.\ + innocent + P-i.j.\\
PCF & deterministic + visible + w.b.\ + innocent \\
IA & deterministic + visible + w.b.\  \\
IA + exceptions & deterministic + visible  \\
IA + exceptions + general references & deterministic
\end{tabular}

\subsection*{Algorithmic game semantics}

The game semantic approach has become a very successful paradigm after solving the long-standing full abstraction problem of PCF; its success story did not stop here however. Game semantics turned out to be useful to the study of the observational equivalence problem: Given two terms, can they be used interchangeably? The research activity consisting of studying the observational equivalence problem via game semantics is called \emph{Algorithmic game semantics}. A major breakthrough was the observation that the game model of Idealized Algol is effectively presentable \cite{AM97a} (a property that is not enjoyed by any model of PCF \cite{loader2001fpn}). This result paved the way to interesting characterization of the game denotation of lower-order IA terms.
Ghica and McCusker observed \cite{ghicamccusker00} that pointers are
unnecessary for representing plays in the game semantics of the second-order finitary fragment of Idealized Algol ($\ialgol_2$ for short). Consequently observational equivalence for this fragment can
be reduced to the problem of equivalence of regular expressions. Similar characterization were later obtain for other finitary fragments. For instance at order $3$, although pointers are necessary, deciding observational
equivalence of $\ialgol_3$ is EXPTIME-complete \cite{DBLP:journals/apal/Ong04,DBLP:conf/fossacs/MurawskiW05}. These results are all based on the same observation: at lower orders, the justification pointers present in the game denotation are either not required (\eg, at order $2$) or can be encoded succinctly (\eg, at order $3$). The possibility of representing plays \emph{without some or all of their pointers} under the safety assumption strongly suggests that similar result can be obtained for safe fragments of \ialgol.


Our last contribution consist therefore in studying the safety from the point of view of algorithmic game semantics.
We introduce a new notion of observational equivalence for IA: A \emph{safe context} is a safe IA term-in-context with a hole (a distinguished variable exactly once in the term); two terms are considered equivalent if no safe context can distinguish them.
We show that up to order three this notion of observational equivalence coincides with the usual one.
A basic result in Algorithmic game semantics is the Characterization Theorem: observational equivalence of two IA terms is characterized by the equality of their set of complete plays. We show a version of this theorem adapted to our notion of observational equivalence: two terms are equivalent with respect to safe context if and only if they have the same set of P-incremental justified complete plays.
Finally, based on these results, we show that all the known result about the complexity of observational equivalence up to order $3$ are also true for our new notion of observational equivalence.  The problem is known to be undecidable for the order-$4$ finitary fragment; We conjecture that observational equivalence for \emph{safe terms} and with respect to \emph{safe context} is decidable.


\section*{Prerequisite}
The reader is assumed to be familiar with the simply-typed lambda calculus. A brief account is given in the background chapter;
For more details, we refer the reader to introductions on the subject by Barendregt \citet{Barendregt:92} and Hindley \cite{Hindley1997}. Familiarity with game semantics would be very helpful, in particular for Chapter \ref{chap:syntactic_gamesem} and \ref{chap:model}, although it is not a requirement since the background chapter contains an introduction on the topic.
A very good tutorial is \citet{abramsky:game-semantics-tutorial}.


\section*{Organization of the thesis}
The first chapter lays down the background for the rest of the thesis. It introduces briefly the simply-type lambda calculus and
 two of its extensions that will be studied throughout the thesis, namely PCF and Idealized Algol.
 It then presents \emph{higher-order grammars}, the original setting in which the safety restriction firstly
appeared, and presents the safety restriction with some related
results.
Finally, the last section is devoted to the presentation of the basics and main results of game semantics. It also fixes notation that will be use in other chapters when we study the game semantics of the safety restriction.

Chapter \ref{chap:safelambda} introduces the definition of the \emph{safe lambda calculus}. It establishes basic properties of the calculus and gives an account of its expressivity and complexity.
The chapter concludes with a generalization of the safety restriction to other applied lambda calculi such as PCF and Idealized Algol.

Chapter \ref{chap:concrete_gamesem} takes a detour from the safety restriction. It presents and extends the theory of traversals
originally introduced by Ong \cite{OngLics2006}. It defines the notions of computation tree of a simply typed term and traversals over the computation tree. The ultimate goal of this chapter is to prove an important result called the Correspondence Theorem which establishes a correspondence between traversals of the computation tree and the game semantics of a term.

This correspondence theorem allows us to give in Chapter \ref{chap:syntactic_gamesem} an account
of the game semantics of safety using a very simple syntactic argument.

Chapter \ref{chap:model} establishes a categorical model of the safe lambda calculus, safe \pcf\ and safe Idealized Algol. A complete fully abstract game model is established. The chapter concludes with application to Algorithmic Game Semantics.
