In this chapter we assume make the following assumptions on games. Let $\bot$ denote the game with a single initial. For any game $A \neq \bot$:
\begin{itemize}
\item (A1) Each question move in the game enables at least one answer move;
\item (A2) Answer moves do not enable any other move.
\end{itemize}
Clearly, simple, \pcf\ and \ialgol\ types all verify these two assumptions. An arena is said to be \defname{prime} if it has a single initial move; a type is prime if its arena denotation is prime.


\section{Models of the safe lambda calculus}

It is well-known \cite{lambek1986ccc} that any extensional model of the simply-typed lambda calculus is a Cartesian-Closed Category (CCC) (a category with a terminal object, finite product and exponential). \emph{Question: what is the categorical interpretation of the safe lambda calculus?}
This section introduces \emph{incremental closed categories} and show how such categories can be used to model the safe lambda calculus.

\subsection{Safe lambda calculus with product}
\label{sec:safelmd_product}
The safe lambda calculus defined in Chapter \ref{chap:safelambda}
does not have a product. It is fairly easy to add it to the language.
The type grammar is given by:
$$
T ::= \ B\ | \ T \rightarrow T | \ T \times T
$$
for some set $B$ of base types, and the typing system is extended with three rules corresponding to pairing, first projection and second projection (respectively
$\rulename{\times}$, $\rulename{\pi_1}$ and $\rulename{\pi_2}$ in
Def.\ \ref{def:safecalc_withprod}). For the abstraction and application rules, we could keep the same definition as in Chapter \ref{chap:safelambda}. This would guarantee that the basic property of the safe-lambda calculus is verified (free variables have order greater than the term itself) and in turn implies the No-variable-renaming Lemma. Although this definition conveys the syntactic notion of safety, it does not have desirable semantic properties. For instance take the following two simply-typed terms:
\begin{align*}
 x:(o\typear o)\times o &\stentail \lambda z^o.\, (\pi_2 x) : (o\typear (o\typear o)) \equiv M_1\\
 x_1:(o\typear o), x_2:o &\stentail \lambda z^o.\, x_2 : (o\typear (o\typear o)) \equiv M_2
\end{align*}
In the categorical model of the simply-typed lambda calculus, these two terms are denoted by the same morphism. However the first term would be considered safe and the second one unsafe!


One way to overcome this problem is to impose that for any context-variable of type $A \times B$ we have $\ord A = \ord B$. Another solution is to forbid the use of variables of product type and only allow product types for terms created with the pairing rule. But these two approaches are too restrictive.

The right approach consists in modifying slightly the side-condition of the application and abstraction rules: instead of requiring that all variables in the context have order greater than the order of the term, we require that the order
of \emph{any prime sub-type of any variable} in the context has
order greater that that of the term, where the set $Pr(A)$ of
\defname{prime sub-types} of a type $A$ is given by:
\begin{align*}
Pr(B) &= \{ B \} & \mbox{ if $B$ is a base type,}\\
Pr(A\rightarrow B) &= \{ A\rightarrow B \} \\
Pr(A\times B) &= Pr(A) \union Pr(B) \ .
\end{align*}
Then for any finite typed alphabet $\Gamma$ and type $B$, we define the \defname{safety predicate} $SC(\Gamma ; B)$ as
$$SC(\Gamma ; B) \quad \defeq \quad  \forall x:A\; \in \Gamma . \forall A' \in Pr(A) . \ord A' \geq \ord B$$
where $Pr(A)$ denotes the set of prime sub-types of $A$.

We can now replace the side-condition in the abstraction and application rules by $SC(\Gamma ; B)$ where $B$ is the type of the term being formed and $\Gamma$ its context.

This change partly fixes the problem: the terms $M_1$ are $M_2$ are now both considered unsafe, but unfortunately we still do not capture adequately the notion of safety. Take the two simply-typed terms:
\begin{align*}
 x:(o\typear o)\times o &\stentail \lambda z^o.\, (\pi_1 x) : (o\typear (o\typear o)) \equiv N_1\\
 x_1:(o\typear o), x_2:o &\stentail \lambda z^o.\, x_1 : (o\typear (o\typear o)) \equiv N_2 \ .
\end{align*}
Again, these terms are denoted by the same morphism in the categorical model. But
with our modified calculus $N_1$ is unsafe whereas $N_2$ is safe. (This is because in $N_1$, the variable $x$ has to be introduced first in the derivation tree, whereas in $N_2$, $x_1$ has to be introduced first but $x_2$ can be added to the context at the end of the derivation using the weakening rule.)

We therefore need to change the system to be able to type terms like $N_2$. This is done using a new kind of weakening rule that alters the type of a context-variable instead of extending the context with new variables:
$$
\rulename{wk^\times} \ \rulef{\Gamma, x:A \sentail s : T}{\Gamma, x:A\times B \sentail s\subst{(\pi_1 x)}{x} : T}
$$
This rule, which is semantically equivalent to the weakening rule, allows us to type the term $N_1$.

We can now give the full system of rules of the safe calculus with product:
\begin{definition}
\label{def:safecalc_withprod}
 The \defname{safe lambda calculus with product}, or safe $\Lambda^{\rightarrow}_\times$ for short, is given
by induction over the following rules (the framed parts show the differences with the safe lambda calculus):
$$ \rulename{var} \ \rulef{}{x : A\sentail x : A} \qquad
\rulename{const} \ \rulef{}{\sentail f : A}~f \in \Xi \qquad
\rulename{wk} \ \rulef{\Gamma \sentail s : A}{\Delta \sentail s : A}
\quad \Gamma \subset \Delta$$
\begin{center}
\framebox{
\begin{Bcenter}
$\dps \rulename{\times} \ \rulef{\Gamma \sentail s : A \qquad \Gamma \sentail t : B}
{\Gamma \sentail \langle s, t \rangle : A \times B}
\qquad \rulename{\pi_1} \ \rulef{\Gamma \sentail s : A \times B}
{\Gamma \sentail \pi_1 s : A} \qquad
 \rulename{\pi_2} \ \rulef{\Gamma \sentail s : A \times B}
{\Gamma \sentail \pi_2 s : B}$
\\[10pt]
$\rulename{wk^\times} \ \rulef{\Gamma, x:A \sentail s : T}{\Gamma, x:A\times B \sentail s\subst{(\pi_1 x)}{x} : T}$
\end{Bcenter}
}
\end{center}
$$ \rulename{app_{as}} \ \rulef{\Gamma \sentail s : (A_1, \ldots , A_n,B)
\quad \Gamma \sentail t_1 : A_1 \quad \ldots
\quad \Gamma \sentail t_n : A_n} {\Gamma \asappentail s~t_1 \ldots t_n : B} $$

$$ \rulename{app} \ \rulef{\Gamma \sentail s : (A_1, \ldots , A_n,B)
\quad \Gamma \sentail t_1 : A_1 \quad \ldots
\quad \Gamma \sentail t_n : A_n} {\Gamma \sentail s~t_1 \ldots t_n : B} \quad \ \framebox{$SC(\Gamma ; B)$}$$

$$ \rulename{abs_{as}} \ \rulef{\Gamma, x_1 : A_1, \ldots, x_n : A_n
  \asappentail s : B} {\Gamma \sentail \lambda x_1 \ldots x_n . s :
  (A_1, \ldots ,A_n,B)} \ \framebox{$SC(\Gamma ; (A_1, \ldots ,A_n,B) )$}
$$
$$ \rulename{abs} \ \rulef{\Gamma, x_1 : A_1, \ldots, x_n : A_n
  \sentail s : B} {\Gamma \sentail \lambda x_1 \ldots x_n . s :
  (A_1, \ldots ,A_n,B)} \ \framebox{$SC(\Gamma ; (A_1, \ldots ,A_n,B) )$}
$$
\end{definition}
\begin{example}
The terms $M_1$, $M_2$ are unsafe and the terms $N_1$ and $N_2$ are safe.
\end{example}


% category theory
\newcommand\catobj[1]{{\rm Obj}(#1)}
\newcommand\cathom[1]{{\rm Hom}(#1)}

\subsection{Categorical interpretation}

\subsubsection*{Cartesian closed category}
We recall some basic categorical notions and fix some notations.

A \defname{category} $\mathbf{C}$ is given by a class $\catobj{\mathbf{C}}$ of objects
and a class $\cathom{\mathbf{C}}$ of morphisms between objects: for each pair of objects $A$, $B$, a set
of morphisms $\mathbf{C}(A,B)$, written $f:A\typear B$, where $A$ is the domain and $B$ is the codomain
Further for any three objects $A$, $B$ and $C$, and morphisms $f:A\typear B$ and $g:B\typear C$ there is a composite morphism
written $f;g$ or $g\circ f$ such that the composition operation is associative and for each object $A$ there is a morphism $id_A$ that is the identity
for composition.

A \defname{subcategory} of a category $\mathbf{C}$ is a category whose objects and morphisms are objects and morphisms of $\mathbf{C}$.
It is a \emph{lluf} subcategory if it contains all the objects of $\mathbf{C}$.

A object $I$ is \defname{terminal} if for every object $A$ there is a unique morphism from $A$ to $I$.

A category has \defname{products} if for any two objects $A$ and $B$ there is an object $A\times B$ and two morphisms $\pi_1$, $\pi_2$ mapping $A\times B$ to $A$ and $B$ respectively such that for any morphisms $f:C\typear A$, $g:C\typear B$, there is a unique morphism
$\langle f,g\rangle : C \typear A\times B$, called the \defname{pairing} of $f$ and $g$ such that
$\pi_2 \circ \langle f,g\rangle = g$ and $ \pi_1 \circ \langle f,g\rangle = f$, where $f \circ g$ denotes the composition of $g$ with $f$ in the category.

A category has \defname{exponential} if for any two objects $B$ and $C$ there is a distinguished object $C^B$ and
  a morphism $ev_{B,C} : (C^B\times B) \typear C$ such that for any object $A$ and morphism $f:(A\times B) \typear C$ there is a unique morphism $\Lambda(f) : A \typear C^B$ such that the following diagram commutes:
\begin{center}
\begin{tikzpicture}
\matrix [matrix of math nodes,row sep=1cm, column sep=2cm]
{
|(AB)|  A\times B \\
|(CBB)| C^B \times B & |(C)| C \\
};
\begin{scope}[every node/.style={midway,font=\scriptsize}]
\draw[->] (AB) -- node[above] {$f$} (C);
\draw[->,dashed] (AB) -- node[left] {$\Lambda(f) \times id_B$} (CBB);
\draw[->] (CBB) -- node[below] {$ev_{B,C}$} (C);
\end{scope}
\end{tikzpicture}
\end{center}

\begin{definition}
A \defname{cartesian closed category}, CCC for short, is a category with a terminal object, binary products and exponentials.
\end{definition}

\subsubsection*{Incremental closed category}

Let $\mathbf{C}$ be a CCC. We define an \emph{order} function $\ord : {\sf Obj}(\mathbf{C}) \rightarrow \nat \union \{-1\}$ and a function $\mathrm{dro} : {\sf Obj}(\mathbf{C}) \rightarrow \nat \union \{-1\}$ on objects as follows:
\begin{compactitem}
    \item $\ord(I) = \mathrm{dro}(I) = -1$,
    \item $\ord(A\times B) = \max(\ord A,\ord B)$ and $\mathrm{dro}(A\times B) = \min(\mathrm{dro}(A),\mathrm{dro}(B))$,
    \item $\ord(B^A) = \mathrm{dro}(B^A) = \max(1+\ord A ,\ord B)$,
    \item $\ord{A} = \mathrm{dro}(A) = 0$ for any other object $A$.
\end{compactitem}

Clearly we have $\ord \geq \mathrm{dro}$ hence:
\begin{lemma}
\label{lem:increm_transitive}
For any objects $A$, $B$ and $C$ of an ICC, if $\mathrm{dro}(A) \geq \ord(B)$ and $\mathrm{dro}(B) \geq \ord(C)$
then $\mathrm{dro}(A) \geq \ord(C)$.
\end{lemma}

We say that a morphism $f:A\typear B$ is \defname{incremental} if
we have $\delta(A_1)<\ord(B)$. We say that a subcategory of a CCC is \defname{incremental} if all the morphism
of the subcategory are incremental.

\begin{definition}
A category $\mathbf{I}$ is \defname{incremental closed}, or ICC for short, if it is a lluf subcategory of a cartesian closed category $\mathbf{C}$ such that:
\begin{enumerate}[1.]
\item it contains all the projections: for all objects $C_1$ and $C_2$, $\pi_1:C_1\times C_2\typear C_1$ and $\pi_2: C_1\times C_2\typear C_2$ are in $\cathom{\mathbf{I}}$;

\item it is closed under pairing: if $f:C\typear A$ and  $g:C\typear B$ are in $\cathom{\mathbf{I}}$ then so is $\langle f,g\rangle$;

\item it contains all the incremental evaluation morphisms: for any objects $B$ and $C$ such that $\mathrm{dro}(B)\geq\ord(C)$,  $ev_{B,C} : (C^B\times B) \typear C$
is in $\cathom{\mathbf{I}}$;

\item it is closed under incremental currying: if $f:(A\times B) \typear C \in \cathom{\mathbf{I}}$ with $\mathrm{dro}(A)\geq\ord(C^B)$ then $\Lambda(f) : A \typear C^B \in \cathom{\mathbf{I}}$;

\item all morphisms are incremental modulo weakening:
 for any morphism $f:A\typear B$, either $f$ is incremental, or $A=A_1\times A_2$ and $f = \pi_1 ; g$ for some incremental morphism $g:A_1\typear B$.
\end{enumerate}
\end{definition}

%In any cartesian-closed category lies an incremental closed category:

Let $\mathbf{C}$ be a CCC. The \defname{canonical incremental subcategory} of $\mathbf{C}$ is the subcategory $\mathbf{I}$ obtained by keeping only the morphisms that are incremental modulo weakening \ie for any objects $A$, $B$:
\begin{align*}
\mathbf{I}(A,B) &= \mathbf{C}(A,B) & \mbox{if } \mathrm{dro}(A)\geq\ord(B);\\
\mathbf{I}(A,B) &= \emptyset & \mbox{if $\mathrm{dro}(A)<\ord(B)$ and $A$ is not a product;} \\
\mathbf{I}(A_1\times A_2,B) &= \{ \pi_1;f \ |\ f \in \mathbf{I}(A_1,B) \} & \mbox{otherwise.}
\end{align*}

\begin{proposition}
 The canonical ICC is a well-defined lluf ICC subcategory of the CCC.
\end{proposition}
\proof
Let $\mathbf{C}$ denote the CCC and $\mathbf{I}$ the canonical ICC.
We first show that $\mathbf{I}$ is indeed a subcategory:
The identity morphisms $id_A$ are all incremental therefore they are all in $\cathom{\mathbf{I}}$, an the class of morphism is closed under composition. Indeed take two morphisms $f:A\typear B$ and $g:B\typear C$:
\begin{compactitem}
  \item if $f$ and $g$ are incremental then by Lemma \ref{lem:increm_transitive}, $f;g$ is incremental;
  \item if $f= \pi_1;f'$ and $f'$ and $g$ are incremental for some projection $\pi_1$ then $f;g=(\pi_1;f');g = \pi_1;(f';g)$ by associativity. Since $f'$ and $g$ are incremental, so is $f';g$ therefore $f;g$ is incremental modulo weakening;
  \item if $g=\pi_1;g'$ and $f$ and $g'$ are incremental for some projection $\pi_1$ then
  we have $B=B_1\times B_2$ and $\mathrm{dro}(A)\geq\ord(B) \geq\ord(B_1) \geq \mathrm{dro}(C)\geq\ord(C) $, therefore $f;g:A\typear C$ is incremental;
  \item if $f= \pi_1;f'$ and $g=\pi_1;g'$ where $f'$ and $g'$ are incremental then the last two points show that $f;g$ is incremental modulo weakening.
\end{compactitem}
Hence $\mathbf{I}$ is a subcategory. Clearly $\mathbf{I}$ contains the projections (a projection $\pi_1:C_1\times C_2\typear C_1$ that is not incremental can always be written $\pi_1 = \pi_1 ; id_{C_1}$ where $id_{C_1}$ is incremental), and it is closed under pairing. Also by definition it contains all the incremental evaluation morphism from $\mathbf{C}$, it is closed under incremental currying, and all morphisms in the category are incremental modulo weakening. Hence $\mathbf{I}$ is \emph{incremental closed}.
\qed
\smallskip

\noindent An object $A$ of a CCC is said to be \defname{homogeneous} if
\begin{compactitem}
\item $A$ is not a product, nor an exponential;
\item or $A=B\times C$ where $B$ and $C$ are homogeneous and $\ord{B}\geq\ord{C}$;
\item or $A=B\typear C$ where $B$ and $C$ are homogeneous and $\ord{B}\geq\ord{C}-1$.
\end{compactitem}

An \defname{homogeneous incremental category} is a sub-category of a ICC such that
its objects are the homogeneous objects of the CCC and its morphisms are the incremental morphism
(\ie not those that are only incremental modulo weakening).

\subsubsection*{Interpretation}

Lambek showed that the simply-typed lambda calculus is the internal language of any CCC \cite{lambek1986ccc}. Conversely, any CCC provides a model of the simply-typed lambda calculus that is sound with respect to $\beta\eta$-equality: If $M=_{\beta\eta}N$ then $M$ and $N$ are denoted by the same morphism in the category. We show here that ICCs provide a sound model of the safe lambda calculus.

\begin{proposition}
The safe lambda calculus with product can be soundly interpreted (with respect to $=_{\beta\eta}$) in any ICC.
\end{proposition}
\proof
Let $\mathbf{I}$ be an ICC. By definition it is the subcategory of a CCC
$\mathbf{C}$. The interpretation $\sem{\cdot}$ of the safe lambda calculus with product in $\mathbf{I}$ is induced by the standard interpretation in the CCC:
Ground types are interpreted as objects of the category, and by extension, using product and exponential, any simple type $\sigma$ is interpreted as an object $\sem{\sigma}$. A closed term of type $\sigma$ is interpreted by a morphism $I \typear \sem{\sigma}$, and an opened term of type $\sigma$ is interpreted by a morphism from the denotation of the types of its free variables to $\sem{\sigma}$.

The types are inte
\Lambda^{\rightarrow}_\times
Let $\Gamma \sentail M : T$ be a safe lambda term with product. W.l.o.g.\ we can assume that it is in $\eta$-long normal form. Therefore its derivation tree does not make use of the rules \rulenamet{app_{as}} or \rulenamet{abs_{as}}. Because
we give a model up to
\torework{
to finsihs
}
\qed

\section{P-incremental justification}

\subsection{Order of a move}

The \defname{order of a move} $m$ in an arena $A$, written $\ord_A{m}$ (or just $\ord{m}$ where there is no ambiguity) is defined as the length of the path from $m$ to its furthest leaf in $A$ minus one.
The \defname{order of an arena} is defined as the maximal order of its initial moves.

We recall that for any type $T$ built up from base types, product and function space, the order of $T$, written $\ord{T}$, is defined by induction  as follows: a base type has order 0, $\ord{(A\rightarrow B)} = \max(1+\ord{A},\ord{B})$, and  $\ord(A\times B) = \max(\ord A, \ord B)$ for any types $A$ and $B$. Clearly, this definition coincides with the definition given above: the order of a type is equal to the order of the arena denoting it \ie $\ord{T} = \ord{\sem{T}}$ for all type $T$.


Because of assumptions (A1) and (A2), for any move $m$ of $A \neq \bot$, $m$ is a question move if and only if $\ord{m} \geq 0$, and $m$ is an answer move if and only if $\ord{m} = -1$.


\subsubsection*{Move-order after composition}

Consider the arena $X\lingamear Y$ and let $m$ be a move of
$X\lingamear Y$. We write $\ord_{X\lingamear Y}{m}$ to denote the
order of $m$ in the arena ${X\lingamear Y}$. If $m$ belongs to $X$
(resp.~$Y$) then we write $\ord_X{m}$ (resp.~$\ord_Y{m}$) to denote
the order of the move $m$ in the arena $X$ (resp.~$Y$).

\begin{lemma}
\label{lem:compositionorder} Let $A$, $B$ and $C$ be three arenas.
We have:
$$\begin{array}{lll}
\forall m \in A:
    &  \ord_{A\lingamear B}{m} = \ord_{A\lingamear C}{m} \ ,\\
\forall m \in B:
    & \ord_{A\lingamear B}{m} \geq \ord_{B\lingamear C}{m}  & \mbox{for $m$ initial,}\\
    & \ord_{A\lingamear B}{m} = \ord_{B\lingamear C}{m} & \mbox{for $m$ non initial,} \\
\forall m \in C:
    & \ord_{A\lingamear C}{m} \geq \ord_{B\lingamear C}{m} \iff
\ord{A} \geq \ord{B}\ & \mbox{for $m$ initial,}\\
    & \ord_{A\lingamear C}{m} = \ord_{B\lingamear C}{m}   & \mbox{for $m$ non initial.}
\end{array}
$$
\end{lemma}

\subsection{Well-bracketing}

We call \defname{pending question} of a sequence of moves $s \in L_A$ the last unanswered question in $s$.

\begin{definition}
A strategy $\sigma$ is said to be \defname{P-well-bracketed} if for any play $s \, a \in \sigma$ where $a$ is a  P-answer, $a$ points to the pending question in $s$.
\end{definition}



P-well-bracketing can be restated differently as the following proposition shows:
\begin{proposition}
\label{prop:char_wellbrack}
We make assumption (A1) and (A2).
Let $\sigma$ be a strategy on an arena $A\neq \bot$.
The following statements are equivalent:
\begin{enumerate}
\item[(i)] $\sigma$ is P-well-bracketed,
\item[(ii)] for $s \, a \in \sigma$ with $a$ a P-answer, $a$ points to the pending question in $\pview{s}$,
\item[(iii)] for $s \, a \in \sigma$ with $a$ a P-answer, $a$ points to the last O-question in $\pview{s}$,
\item[(iv)] for $s \, a \in \sigma$ with $a$ a P-answer, $a$ points to the last O-move in $\pview{s}$ with order $>\ord{a}$.
\end{enumerate}
\end{proposition}
\proof
$(i)\iff(ii)$: \cite[Lemma 2.1]{McC96b} states that if P is to move then the pending question in $s$ is the same as that of $\pview{s}$.

$(ii)\iff(iii)$: Assumption (A2) implies that the pending question in $\pview{s}$ is also the last O-question occurring in $\pview{s}$.

$(iii)\iff(iv)$: Because of assumption (A1) and (A2),
for any move $m$, we have $m$ is a question move
if and only if $\ord{m} \geq 0$ if and only if $\ord{m} > \ord{a} = -1$.
\qed
%end of proof
\bigskip



\begin{lemma}
\label{lem:justfied_by_unanswered}
Under assumption (A2), if $s$ be a justified sequence of moves satisfying alternation and visibility then any O-move (resp. P-move) in $s$ points to an \emph{unanswered} P question (resp. O-question).
\end{lemma}
\proof
Suppose that an O-move $c$ points to a P-move $d$ that has already been answered by the O-move $a$. The sequence $s$ as the following form:
$$ s= \ldots \Pstr{(d){d}  \ldots  (a-d,20){a}  \ldots  (c-d,20){c}}$$

By O-visibility, $d$ must belong to $\oview{s_{<c}}$. But since $a$ is an answer, by assumption (A2), it cannot justify any P-move, therefore
$\oview{s_{<q}}$ must contain an OP-arc ``hoping'' over $a$. We name the nodes of this arc $d^1$ and $c^1$:
$$ s = \ldots \Pstr[0.7cm]{(d){d}  \ldots  (d1){d^1} \ldots (a-d,20){a} \ldots
 (c1-d1,20){c^1} \ldots (c-d,25){c}}$$

By P-visibility, $d^1$ must belong to $\pview{s_{<c^1}}$. Consequently, $a$ does not belong to $\pview{s_{<c^1}}$ (otherwise the PO-arc $\Pstr[0.5cm]{(d){d} \quad (a-d,45){a}}$ would cause the P-view to jump over $d^1$).
Therefore there must be a PO-arc $\Pstr[0.5cm]{(d2){d^2} \quad (c2-d2,45){c^2}}$ in $\pview{s_{<c^1}}$ hoping over $a$:
$$s = \ldots \Pstr[0.7cm]{(d){d}  \ldots
(d1){d^1} \ldots (d2){c^2} \ldots
(a-d,20){a} \ldots
 (c2-d2,20){d^2} \ldots (c1-d1,20){c^1} \ldots (c-d,25){c}}$$

This process can be repeated infinitely often by using alternatively O-visibility and P-visibility. This gives a contradiction since the sequence of moves $s_{<c}$ has finite length.
Hence $d$ cannot point to a question that has already been answered. Since, by assumption (A2), a question is enabled by another question, $d$ is necessarily justified by an unanswered question.
\qed
%end of proof
\bigskip

\begin{lemma}
\label{lem:oq_in_pview_unanswered}
Under assumption (A2), if $s$ is a P-well-bracketed justified sequence of moves of odd length satisfying alternation and visibility then  all O-questions occurring in $\pview{s}$ are unanswered in $s$.
\end{lemma}
\proof
We proof the first part by induction on $s$. The base case ($s = q$
with $q$ initial O-move) is trivial. Suppose $\Pstr[0.4cm]{ s = s'
\cdot (q)q \cdot u \cdot (m-q,45){m} }$. We have $\pview{s} =
\pview{s'} \cdot q \cdot m$. Clearly $m$ is unanswered in $s$. Let
$r$ be an O-question in $\pview{s'}$ and suppose that $r$ is
answered in $s$ by some move $a$. By the induction hypothesis, $r$
is unanswered in $s'$ therefore $a$ necessarily appears in the
segment $u$:

\begin{center}
\ifLoadPGFengine
\pstr[0.7cm]{
\nd{s = }(l1){\cdots \ }
\nd(r){r^O}
\nd(r1){\cdots}
\nd{\ }(q){q^P}
\nd{\ }(l2){\cdots\ }
\nd(a-r,35){a^P}
\nd(r2){\cdots}
\nd{\ }(m-q,30){m^O}
\pstrPGFbrace{l1}{r1}{5pt}{$s'$}
\pstrPGFbrace{l2}{r2}{5pt}{$u$}
}\ .
\else
\pstr[0.7cm]{ s = \underbrace{\cdots\ \nd(r){r^O}
\cdots }_{s'} \ \nd(q){q^P} \ \underbrace{\cdots\ \nd(a-r,35){a^P}
\cdots }_{u} \ \nd(m-q,30){m^O} } \ .
\fi
\end{center}


But since $m$ is justified by $q$, by lemma \ref{lem:justfied_by_unanswered} $q$ must be unanswered in $s_{< m}$. In particular, the pending
question at $s_{\prefixof a}$ cannot be $r$ since the unanswered question $q$  is played after $r$. This gives a contradiction since by well-bracketing $a$ should answer the pending question. Hence $r$ is unanswered in $s$.
\qed


\subsection{P-incremental justification}
P-incremental justification is a generalization of well-bracketing to question moves:

\begin{definition}
A play $s m$ of even length is said to be \defname{P-incrementally
justified}, or \emph{P-i.j.} for short, if $m$ points to the last
unanswered O-question in $\pview{s}$ with order strictly greater
than $\ord{m}$.

 A strategy $\sigma$ is said to be \defname{P-incrementally justified}, if all plays in $\sigma$ ending with a P-question are
P-incrementally justified.
\end{definition}
Let $\sigma$ be a strategy. We write $\mathcal{P}(\sigma)$ to denote the subset of $\sigma$ consisting of plays whose even-length prefixes are all P-i.j.
Hence P-i.j.\ strategies are precisely those verifying the relation $\sigma = \mathcal{P}(\sigma)$.
\begin{proposition}
\label{prop:char_pincr}
Let $\sigma$ be a \emph{P-well-bracketed} strategy on an arena $A\neq \bot$.
Under assumptions (A1) and (A2), the following statements are equivalent:
\begin{enumerate}
\item[(i)] $\sigma$ is P-incrementally justified,
\item[(ii)] for $s \, q \in \sigma$ with $q$ a P-question, $q$ points to the last O-question in $\pview{s}$ with order $>\ord{q}$,
\item[(iii)] for $s \, q \in \sigma$ with $q$ a P-question, $q$ points to the last O-move in $\pview{s}$ with order $>\ord{q}$.
\end{enumerate}
\end{proposition}
\proof
$(i)\iff(ii)$: By lemma \ref{lem:oq_in_pview_unanswered}, O-question occurring in $\pview{s}$ are all unanswered.

$(ii)\iff(iii)$: Because of (A1) and (A2), $\ord{q} \geq 0$ thus an O-move with order $>\ord{q}$ is necessarily an O-question.
\qed
\bigskip

Putting proposition \ref{prop:char_pincr} and
\ref{prop:char_wellbrack} together we obtain:
\begin{proposition}
Under assumption (A1) and (A2),
a strategy $\sigma$ on $A\neq \bot$
is \emph{P-well-bracketed} and
 \emph{P-incrementally justified} if and only if
for $s \, m \in \sigma$, $m$ points to the last O-move in $\pview{s}$ with order $>\ord{m}$.
\end{proposition}

\subsection{Closed P-incremental justification}
\label{sec:closedpij}

\begin{definition}
\label{def:closedpij} Let $s m$ be an even-length play on some game
$A \rightarrow B$. $s m$ is said to be
\defname{closed P-incrementally justified} (closed P-i.j.\ for short)
just if
\begin{itemize}
\item $s m$ is P-incrementally justified;
\item and if $m$ is an initial move in $A$ then its justifier $n$ (initial in
$B$) verifies $\ord_A m \geq \ord_B n$.
\end{itemize}

\noindent A strategy $\sigma$ is \defname{closed P-i.j.} just if all
plays in $\sigma$ ending with a P-questions are closed P-i.j.
\end{definition}

\begin{example}
For any game $A$, the identity strategy $id_A$ is closed P-i.j.
\end{example}


\begin{lemma}
\label{lem:closedpij_singleBinitmove} Let $\sigma : A \lingamear B$
be a P-i.j.\ strategy.
\begin{enumerate}[(i)]
\item If for each initial move $m$ of $A$ occurring in some play of $\sigma$ we have $\ord_A m \geq \ord{B}$, then $\sigma$ is closed P-i.j.
\item Suppose that $A=A_1\times \ldots \times A_n$ where each  of the $A_i$ are prime arenas. If for each initial move $m_i$ of $A_i$, for $i \in \{1..n\}$, occurring in some play of $\sigma$ we have $\ord A_i \geq \ord{B}$, then $\sigma$ is closed P-i.j.
\end{enumerate}
\end{lemma}
\proof
(i) This is a direct consequence of the definition since $\ord B \geq \ord_B b$ for every move $b$ initial in $B$. (ii) Take an initial move $m$ of $A$. We have $\ord_A m = \ord_{A_i} m$ for some $i$. This is in turn equal to $\ord A_i$ since $A_i$ is prime. By hypothesis it is greater than $\ord{B}$ hence we can conclude using (i).
\qed
%end of proof
\smallskip

\begin{example}
The simply-typed term $x : (o^1\rightarrow o^2)\times o^3 \vdash \lambda y^o . \pi_2 x : o^4 \rightarrow o^5$ has a P-i.j.\ denotation. The second part of the previous Lemma cannot be used because its hypothesis is not verified, and indeed the denotation is not closed P-i.j.\ since it contains the play $q^5 q^3$ and we have $\ord_{(o^1\rightarrow o^2)\times o^3} q^3 = 0 < 1 = \ord_{o^4 \rightarrow o^5} q^5$.
\end{example}


We observe that every P-i.j.\ strategy $\sigma$ on the game $I
\lingamear A$ is closed P-i.j.\ while $\sigma : A$ is not
necessarily closed P-i.j.\footnote{In particular, every P-i.j.\
strategy $\sigma$ on the game $!A_1 \otimes \ldots \otimes !A_n
\lingamear B$, is isomorphic, up to arena-tagging of the moves, to
the closed P-i.j.\ strategy $\Lambda^n(\sigma)$ on the game $I
\lingamear (A_1,\ldots,A_n,B)$, where $\Lambda$ denotes the usual
{\it currying} isomorphism.}; hence the distinction between $I
\lingamear A$ and $A$ matters. This is because the definition of closed P-i.j.\ strategy specifically refers to the moves of the
arena in the left-hand side of the function space arrow
$\lingamear$, therefore the property is not valid up to an
isomorphism that retags the moves such as {\it currying}.

Consequently, it is possible to have two isomorphic strategies $\sigma$ and
$\mu$ such that one is closed P-i.j.\ but not the other. In contrast, P-incremental
justification is preserved across the  {\it curry} isomorphism. A consequence of this remark is that the category of closed P-i.j.\ strategies
that we will introduce later on, is not closed (neither monoidal closed nor cartesian closed).



\section{Compositionality}

\subsection{Interaction sequences}
In this preliminary section we recall some basic definitions and results on interaction sequences.

Let $A$,$B$ and $C$ be three games. We say that $u$  is an
\defname{interaction sequence} of $A$,$B$ and $C$ whenever $u\filter
A,B$ is a valid position of the game $A\lingamear B$ (\ie $u\filter
A,B \in P_{A\lingamear B}$) and  $u\filter B,C$ is a valid position
of the game $B\lingamear C$. We write $Int(A,B,C)$ to denote the set
of all such interaction sequences.

Let $\sigma:A\lingamear B$ and $\mu:B\lingamear C$ be two
strategies. We write $\sigma \parallel \mu$ to denote the set of
interaction sequences that unfold according to the strategy $\sigma$
in the $A,B$-projection of the game and to $\mu$ in the
$B,C$-projection:
$$ \sigma \parallel \mu = \{ u \in Int(A,B,C) \ | \ u\filter A,B \in \sigma \wedge u \filter B,C \in \mu \} \ .$$
The composite of $\sigma$ and $\mu$ is then defined as $\sigma ; \mu
= \{ u \filter A,C \ | \ u \in \sigma \parallel \tau \}$.

The diagram below shows the structure of an interaction sequence
from $\sigma \parallel \mu$. There are four states represented by
the rectangular boxes. The content of the state shows who is to play
in each of the game $A\lingamear B$, $B\lingamear C$ and
$A\lingamear C$. For instance in state $OPP$, it is O's turn to play
in $A\lingamear B$ and P's turn to play in $B\lingamear C$ and
$A\lingamear C$. Arrows represent the moves. When specifying
interaction sequence, the following bullet symbols are used to
represent moves: $\pmove$ for P-moves, $\omove$ for O-moves,
$\pomove$ for a move playing the role of P in $A\lingamear B$ and O
in $B\lingamear C$ and $\opmove$ for the symmetric of $\pomove$. We
sometimes add a subscript to the symbols $\pmove$ and $\omove$ to
denote the component in which the moves is played ($A$ or $C$).


\tikzstyle{state}=[rectangle,draw=blue!50,fill=blue!20,thick,minimum
height = 4ex, text width=4cm] \tikzstyle{move}=[->,shorten
<=1pt,>=latex',line width=1pt] \tikzstyle{intmove}=[dashed]
\tikzstyle{extomove}=[color=\extomovecolor]
\tikzstyle{genomove}=[]%[dashed]
\tikzstyle{genpmove}=[color=\genpmovecolor]
\def\sep{1.5cm}
\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}[node distance=1.7cm]

% the four states
\path
 node(oooT)  [state] {}
 node(opp)   [state, below of=oooT] {}
 node(pop)   [state, below of=opp]  {}
 node(oooB)  [state, below of=pop] {}
 node(title) [anchor=south, at=(oooT.north), minimum height = 4ex, text width=4cm] { };

\path
% text in the title centered in 3 columns
  ([xshift=-\sep]title) node {$A\lingamear B$}
        (title) node {$B\lingamear C$}
        ([xshift=\sep]title) node {$A\lingamear C$}

% text in the states centered in 3 columns
  ([xshift=-\sep]oooT) node {O}
        (oooT) node {O}
        ([xshift=\sep]oooT) node {O}
  ([xshift=-\sep]opp) node {O}
        (opp) node {P}
        ([xshift=\sep]opp) node {P}
  ([xshift=-\sep]pop) node {P}
        (pop) node {O}
        ([xshift=\sep]pop) node {P}
  ([xshift=-\sep]oooB) node {O}
        (oooB) node {O}
        ([xshift=\sep]oooB) node {O}

% text in between two arrows giving the arena of the move
  (oooT) to node {\bf C} (opp)
  (opp) to node {\bf B} (pop)
  (pop) to node {\bf A} (oooB)

% arrows representing the moves
  (opp.20)    edge[move, genpmove]
        node[right] {$\mu$}
        node[left]{$\pmove$} (oooT.-20)
  (oooT.-160) edge[move, extomove, genomove]
        node[left] {$env_\mu$}
        node[right]{$\omove$} (opp.160)
  (pop.20)    edge[move, genomove,genpmove,intmove]
        node[right] {$\sigma$}
        node[left]{$\pomove$} (opp.-20)
  (opp.-160)  edge[move, genomove, genpmove,intmove]
        node[left] {$\mu$}
        node[right]{$\opmove$}  (pop.160)
  (oooB.20)   edge[move, extomove,genomove]
        node[right] {$env_\sigma$}
        node[left]{$\omove$} (pop.-20)
  (pop.-160)  edge[move, genpmove]
        node[left] {$\sigma$}
        node[right]{$\pmove$} (oooB.160);

%\draw[move, genpmove] (3.5cm,-1cm) -- +(1,0) node[right] {Generalised P-move \& External P-move };
%\draw[move, genomove,genpmove] (3.5cm,-2cm) -- +(1,0) node[right] {Generalised O-move \& Generalised P-move};
%\draw[move, genomove,extomove] (3.5cm,-3cm) -- +(1,0) node[right] {Generalised O-move \& External O-move};
\draw[move] (3.5cm,-1cm) -- +(1cm,0cm) node[right] {External move};
\draw[move,intmove] (3.5cm,-2cm) -- +(1cm,0cm) node[right] {Internal
move}; \draw (3.5cm,-3cm) node[anchor=west]
{\textcolor{\extomovecolor}{External O-moves: $\omove$}}; \draw
(3.5cm,-4cm) node[anchor=west]
{\textcolor{\genpmovecolor}Generalised P-move: $\opmove, \pomove,
\pmove$};
\end{tikzpicture}
\end{center}
\caption{Structure of an interaction sequence.} \label{fig:interseq}
\end{figure}

Note that in state OPP, the alternation condition (for each of the
three games involved) prevents the players from playing in A.
Indeed, the O-moves in component $A$ of $A\lingamear B$ are also
$O$-moves in component $A$ of $A\lingamear C$ however the state name
indicates that the next move in $A\lingamear B$ must be an O-move
and the next move in $A\lingamear C$ must be a P-move.

Similarly, in the top state OOO, the players cannot make move in B
since the O-moves in component B of the game $B\lingamear C$
correspond to P-moves in the component B of $A\lingamear B$. However
the state name indicates that the next move in $A\lingamear B$ and
the next move in $B\lingamear C$ must be played by O.


Let $u \in Int(A,B,C)$ and $m$ be a move of $u$. The
\defname{component} of $m$ is $A,B$ if after playing $m$ the game is
under the control of the strategy $\sigma$ and $B,C$ otherwise (if
$\mu$ has control). In other words, the moves $\omove, \pmove \in A$
and $\opmove \in B$ shown on the diagram of Figure
\ref{fig:interseq} have component $A,B$ and $\omove, \pmove \in C$
and $\pomove \in B$ have component $B,C$.


Also we call \defname{generalized O-move in component $A,B$} moves
that play the role of O in the game $A\lingamear B$, that is to say
moves represented by $\opmove$ and $\omove_A$. Similarly $\pomove$
and $\pmove_A$ moves are the \defname{generalized P-moves in
component $A,B$}, $\omove_C$ and $\pomove$ moves are the
\defname{generalized O-moves in component $B,C$} and  $\pmove_C$ and
$\opmove$ moves are the \defname{generalized P-moves in component
$B,C$}.

The P-view (also called \emph{core} in
\cite{McCusker-GamesandFullAbstrac}) of an interaction sequence $u
\in Int(A,B,C)$, written $\overline{u}$ or $\pview{u}$ is defined
as:
\begin{align*}
\pview{u\cdot \extomove{n}} &= \extomove{n} &
\mbox{ if \extomove{$m$} is an \extomove{external O-move} initial in C,}\\
\pview{\Pstr{u\cdot (m)m\cdot v \cdot (n-m,45){\extomove{n}} }} &= \extomove{n} &\mbox{ if \extomove{$m$} is an \extomove{external O-move} non initial in C,}\\
\pview{u \cdot \genpmove{m}} &= \pview{u}\cdot \genpmove{m}  & \mbox{ if \genpmove{$m$} is a \genpmove{generalised P-move}.}\\
\end{align*}

We can show the following property by an easy induction :
\begin{lemma}
\label{lem:pviewAC_eq_ACpview}
 Let $u$ be an interaction sequence in $Int(A,B,C)$ then
$$\pview{u} \filter A,C = \pview{u \filter A,C} \ .$$
\end{lemma}
\proof
  By induction on $u$. It is trivial for the empty sequence.
Let $b$ be a move in $B$. We have $\pview{u\cdot b} \filter A,C =
\pview{u} \filter A,C$. By the I.H.\ this is equal to $\pview{u
\filter A,C} = \pview{u\cdot b\filter A,C}$. Let $m$ be a P-move in
$A$ or $C$ then $\pview{u\cdot m} \filter A,C = (\pview{u} \filter
A,C) \cdot m$ and by the I.H.\ this is equal to $\pview{u \filter
A,C}\cdot m = \pview{(u \filter A,C)\cdot m} = \pview{u \cdot m
\filter A,C}$. Let $c$ be an initial move in $C$. We have $\pview{u
\cdot c \filter A,C}  = \pview{(u \filter A,C) \cdot c} = c =  c
\filter A,C = \pview{u\cdot c} \filter A,C$. Let $u = \Pstr{u_1\cdot
(m){m}\cdot u_2\cdot (n-m){n}}$ with $n$ an O-move in $A\rightarrow
C$. Then necessarily $m\in A,C$ and $ \pview{u\filter A,C} =
\pview{\Pstr[5mm]{u_1\filter A,C \cdot (m){m} \cdot u_2\filter A,C
\cdot (n-m,30){n}}} =
 \pview{u_1 \filter A,C} \cdot \Pstr{(m){m}\cdot (n-m){n}}$. By the I.H.\ this is equal to
$(\pview{u_1}\filter A,C) \cdot \Pstr{(m){m}\cdot (n-m){n}} =
(\pview{u_1}\cdot  \Pstr{(m){m}\cdot (n-m){n}} ) \filter A,C  =
\pview{u_1 \cdot \Pstr[4mm]{(m){m} \cdot u_2\cdot (n-m){n}}} \filter
A,C$
\qed
%end of proof
\bigskip

\subsection{Preliminary results}
\emph{Notations:} In plays representations, the symbol $\omove$ stands
for an O-move and $\pmove$ for a P-move. Suppose the game considered
is $L\lingamear R$ for some game $L$ and $R$ then whenever the
sub-arena in which the move is played is known, it is specified in
subscripts ($\omove_L$, $\pmove_L$, $\omove_R$ or $\pmove_R$). For
interaction sequences in $Int(A,B,C)$ we use the symbols $\omove_A$,
$\pmove_A$, $\omove_C$, $\pmove_C$, $\opmove$ and $\pomove$ as
defined in Figure \ref{fig:interseq}. We use the variable $X$ to
denote one of the component $A,B$ or $B,C$ and the variable $Y$ to denote the opposite component. We write $s \subseqof t$ to say that
$s$ is a subsequence (with pointers) of $t$, $s \prefixof t$ to say
that $s$ is a prefix (with pointers) of $t$ and  $s \suffixof t$ to
say that $s$ is a suffix of $t$.

We now prove several useful lemmas which will help us to study compositionality of P-i.j.\ strategies.

\begin{lemma}
\label{lem:interjump}
Let $X$ be a component (either  $A,B$ or  $B,C$).
Let $u$ be an interaction sequence of the form
$ u =
\Pstr[0.5cm][2pt]{ \ldots (b){\stk \beta \pmove}  \ldots
 {n}  \ldots  (a-b,30){\stk \alpha\omove}
\ldots m}$ where:
\begin{itemize}[-]
\item $\alpha,\beta$ are external moves in component $X$ (necessarily both played in $A$ or in $C$),
\item  $m$ is either played in $B$ or an external P-move in $X$,
\item  $\alpha$ is visible at $m$ in $X$ \ie $\alpha\in \pview{u \filter X}$ (consequently $\beta$ is also visible).
\end{itemize}
Then $n \not\in \pview{u \filter A, C}$.
\end{lemma}
\proof
Since $\alpha$ is an O-move, $\alpha$ and $\beta$ are necessarily
played in the same arena ($A$ or $C$). Take $v=u$ if $m$ is a
generalized O-move in $X$ and $v=u_{<z}$ otherwise (if $m$ is a
generalized P-move in $X$). The third assumption implies
$\alpha,\beta\in \pview{v}$. The last move in $v$ is necessarily a
generalized O-move in component $X$ (see diagram of Figure
\ref{fig:interseq}) therefore by \cite[Lemma 3.3.1]{Harmer2005} we
have $\pview{v \filter X} = \pview{\overline{v} \filter X} \subseqof
\overline{v} \subseqof \overline{u}$. Thus $\alpha,\beta \in
\overline{u}$ and since $\alpha,\beta$ are played in $A,C$ we have
$\alpha,\beta  \in \overline{u} \filter A,C = \pview{u
\filter A,C}$ (Lemma \ref{lem:pviewAC_eq_ACpview}). Finally
since $n$ lies underneath the $\beta$-$\alpha$ PO-arc it cannot
appear in the P-view  $\pview{u \filter A,C}$. \qed
\bigskip


\begin{lemma}
\label{lem:in_pviewAC_imp_in_pviewX}
Let $u$ be an interaction sequence in $Int(A,B,C)$ and
$n$ be a move of $u$ such that $n\in\pview{u \filter A,C}$:
\begin{enumerate}[i.]
\item
if all the moves in $u_{\suffixof n}$
are played in $C$  then $n \in \pview{u \filter B,C}$;
\item
if all the moves in $u_{\suffixof n}$ are played in $A$ then $n \in \pview{u \filter A,B}$.
\end{enumerate}
\end{lemma}
\proof
\begin{enumerate}[(i)]
\item
We show the contrapositive. Suppose that $n \not\in\pview{u \filter B,C}$. This must be due to one of the following  two
reasons:
\begin{itemize}[-]
\item $\pview{u \filter B,C}$ contains an initial move $c_0 \in C$
occurring after $n$ in $u$.


By \cite[Lemma 3.3.1]{Harmer2005}
we have $\pview{u \filter B,C} = \pview{\overline{u} \filter B,C} \subseqof \pview{u}$, thus $c_0$ also occurs in $\pview{u}$.
Since $c_0$ belongs to $C$ we have
$c_0 \in \pview{u} \filter A,C=
\pview{u \filter A,C}$ (Lemma \ref{lem:pviewAC_eq_ACpview}).
Thus the P-view $\pview{u \filter A,C}$
starts with the initial move $c_0$ and
since $n$ occurs before $c_0$, $n$ does not occur in the P-view.

\item $n$ lies underneath a PO-arc $\beta$-$\alpha$ visible
at $ u \filter B,C$.
By assumption, since $\alpha$ occurs after $n$ in $u$, it must belong to $C$. We can therefore apply Lemma \ref{lem:interjump}
with $X\assignar B,C$ which gives
$n \not\in\pview{u \filter A,C}$.
\end{itemize}

\item Suppose that $n \not\in\pview{u \filter A,B}$ then either:
\begin{itemize}[-]
\item $\pview{u \filter A,B}$ contains an initial move $b_0 \in B$
occurring after $n$ in $u$. But this is impossible since by assumption all the moves occurring after $n$ in $u$ belong to $A$.

\item or $n$ lies underneath a PO-arc $\beta$-$\alpha$ in $A,B$.
By assumption, since $\alpha$ occurs after $n$ it must belong to $A$. We can then conclude using
Lemma \ref{lem:interjump} with $X\assignar A,B$. \qed
\end{itemize}
\end{enumerate}
%end of proof
\bigskip

Note that we cannot completely relax the assumption
which says that moves in $u_{\suffixof n}$ are all in the same component.
For instance take $u = \Pstr[0.5cm]{(co){\omove_C}\thinspace
(b0-co){\opmove} \thinspace
(n){\stk{\pmove_A}{n}} \thinspace
(b1-co){\opmove}}$ then we have $n\in\pview{u\filter A,C}$ but $n\notin\pview{u\filter A,B}$.


%%%%%%%%%%%
% This commented Lemma could be useful be we did not make use of it eventually.
%
% \begin{lemma}
%\label{lem:oviewsegmentinB}
%For any legal sequence $s = \ldots x \cdot r \cdot y$ of a game $A\lingamear B$ if $x, y \in A$ and $x$ is O-visible from $y$ then any move in $r$ occurring in $\oview{s}$ belongs to $A$.
%\end{lemma}
%\proof
%We proceed by induction on the length of the segment $r$.
%Base case $r=\epsilon$ is trivial. Suppose $r = r' \cdot m$.
%If $y$ is an O-move then by the Switching Condition
%$m$ is necessarily in $A$. Clearly $x$ is O-visible from $m$ thus  by the I.H.\ any move from $r$ occurring in the O-view is in $A$.
%
%If $y$ is a P-move then it cannot point to an initial move in $B$. Indeed, suppose that it points to an initial O-move $b_0 \in B$ then
%we have $\oview{s} = b_0 \cdot y$ which contradicts the fact that $x\in \oview{s}$.
%Thus $y$ points to a move in $A$ and again we can conclude using the induction hypothesis.
%\qed
%end of proof
%\bigskip


\begin{lemma}[P-visibility decomposition (from $C$)]
\label{lem:middlepomove}
Let $u = \ldots n' \cdot r \cdot m \in Int(A,B,C)$ where
$n'$ is a $\omove_A$-move verifying $n' \in \pview{u\filter A,C}$ and $m$ is in $\{ \pmove_C, \opmove, \pomove \}$. Then there is a $\pomove$-move $\gamma$ in $r \cdot m$ such that $\gamma \in \pview{u\filter B,C}$ , $n' \in \pview{u_{\leq \gamma} \filter A,B}$ and $\gamma$ is justified by a move occurring before $n'$.
\end{lemma}
\proof
By induction on $|r|$.
If $r=\epsilon$ then necessarily $u = \ldots \stk{\omove_A}{n'} \thinspace\stk \pomove m$ where $m$ points before $n'$ ($n'$ being played in $A$ cannot justify $m$ played in $B$) so we just need to take $\gamma = m$.
If $|r|=1$ then either
$u = \ldots \stk{\omove_A}{n'} \pomove\thinspace\stk {\pmove_C} m$
or $u = \ldots \stk{\omove_A}{n'} \pomove\thinspace\stk \opmove m$.
In both cases we can take $\gamma$ to be the $\pomove$-move between $n'$ and $m$.
Suppose $|r|>1$. Let $m^-$ denote the move preceding $m$ in $u$.
We proceed by case analysis:
\begin{asparaenum}[-]
\item Suppose $m = \pmove_C$ and $m^- = \omove_C$.
Let $q$ be the external P-move that justifies $m^-$.
Since $n' \in \pview{u\filter A,C}$, $q$ must occur after $n'$ in $u$:
\begin{center}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes]
{
A & \stackrel\sigma{\longrightarrow} & B & \stackrel\mu{\longrightarrow} & C \\
&\vdots&&\vdots\\
n' \omove\\
&\vdots&&\vdots  \\
&& & &  \node(q){\pmove q};  \\
&\vdots&&\vdots  \\
&& & &  \node(mp){\omove m^-};  \\
&& & &  \pmove m\  \\
};
\draw[tableptr] (mp.west) .. controls +(120:0.5cm) and +(210:0.5cm) .. (q.west);
\end{tikzpicture}
\end{center}

Thus we can use the induction hypothesis (with $u\assignar u_{\prefixof q}$): there is a $\pomove$-move $\gamma$
in $u_{]n',q]}$ pointing before $n'$ such that $\gamma \in \pview{u_{\prefixof q} \filter B,C}$, $n' \in \pview{u_{\prefixof \gamma} \filter A,B}$.
Moreover $\pview{u_{\prefixof q} \filter B,C} \prefixof \pview{u_{\prefixof m} \filter B,C}$ (since $q$ is visible from $m$ in $B,C$) thus we have $\gamma \in \pview{u_{\prefixof m} \filter B,C}$ as required.

\item Suppose $m = \pmove_C$ and $m^- = \pomove \in B$.
Again we can conclude using
the induction hypothesis with $u \assignar u_{\prefixof m^-}$.

\item Suppose $m = \pomove \in B$.

Suppose that all the moves in $r$ are in $A$.
Then $r$ is of the form $(\pmove_A \omove_A)^*$ (where $(\cdot)^*$ denotes the Kleenee star operator).
We just need to take $\gamma = m$.
Indeed, moves in $u_{\suffixof m}$ are all in $A$
and by assumption $n'\in\pview{u\filter A,C}$  therefore
Lemma \ref{lem:in_pviewAC_imp_in_pviewX}(ii) gives
$n'\in\pview{u\filter A,B}$.
Also, since $m$ is a $\pomove$-move,
its justifier is a $\opmove$-move but $r$ contains only $\omove$ and $\pmove$ moves hence $m$'s justifier must occur before $n'$.

Suppose that $r$ contains at least one move in $B$. Let $b$ be the last such move, then $u$ is of the form $\ldots n' \cdot \ldots \cdot \stk\opmove  b \cdot (\pmove_A \omove_A)^* \cdot\thinspace\stk\pomove m $. We then have
$u\filter B,C = \ldots n' \cdot \ldots \cdot
\thinspace\stk\opmove b \thinspace\cdot \stk\pomove m $ thus $b \in \pview{u\filter B,C}$. We can then conclude by applying the induction hypothesis with $u \assignar u_{\prefixof b}$.

\item Suppose $m = \pomove \in B$.
If $m^- = \opmove \in B$ then the I.H.\ with $u \assignar u_{\prefixof m^-}$ permits us to conclude.
If $m^- = \omove \in C$ then we conlude by applying  the I.H.\ on $u \assignar u_{\prefixof q}$ where $q$ is the external P-move in $C$ justifying
$m^-$. \qed
\end{asparaenum}
%end of proof
\bigskip

We now show the lemma symmetric to the previous one:
\begin{lemma}[P-visibility decomposition (from $A$)]
\label{lem:middleopmove}
Let $u = \ldots n' \cdot r \cdot m \in Int(A,B,C)$ where
$n'$ is an O-move \emph{non initial} in $C$ verifying $n' \in \pview{u\filter A,C}$ and $m$ is in $\{\pmove_A, \opmove, \pomove\}$. Then there is a $\opmove$-move $\gamma$ in $r \cdot m$ such that $\gamma \in \pview{u\filter A,B}$ , $n' \in \pview{u_{\leq \gamma} \filter B,C}$ and $\gamma$ is justified by a move occurring before $n'$.
\end{lemma}
\proof
The proof is almost symmetrical to the previous one (Lemma \ref{lem:middlepomove}). We proceed by induction on $|r|$.
If $r=\epsilon$ then necessarily $u = \ldots \stk {\omove_C} {n'} \thinspace\stk \opmove m$ where $m$ points before $n'$ (it cannot point to $n'$
since $n'$ is not initial in $C$). Thus we just need to take $\gamma = m$.

If $|r|=1$ then either
$u = \ldots \stk {\omove_C} {n'} \thinspace\opmove\thinspace\thinspace\stk{\pmove_A} m$
or $u = \ldots \stk {\omove_C} {n'} \thinspace\opmove\thinspace\thinspace\stk \pomove m$.
In both cases we can take $\gamma$ to be the $\opmove$-move between $n'$ and $m$.
Suppose $|r|>1$. Let $m^-$ denote the move preceding $m$ in $u$.
We do a case analysis:
\begin{enumerate}[i.]
\item Suppose $m = \pmove_A$ and $m^- = \omove_A$.
Let $q$ be the external P-move that justifies $m^-$.
Since $n' \in \pview{u\filter A,C}$, $q$ must occur after $n'$ in $u$:
\begin{center}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes]
{
A & \stackrel\sigma{\longrightarrow} & B & \stackrel\mu{\longrightarrow} & C \\
&\vdots&&\vdots\\
&&&& \omove\ n'\\
&\vdots&&\vdots  \\
\node(q){q \pmove};  \\
&\vdots&&\vdots  \\
\node(mp){m^- \omove};  \\
m \pmove  \\
};
\path (mp) edge[tableptr] (q);
\end{tikzpicture}
\end{center}

Thus we can use the induction hypothesis (with $u\assignar u_{\prefixof q}$): there is a $\opmove$-move $\gamma$
in $u_{]n',q]}$ pointing before $n'$ such that $\gamma \in \pview{u_{\prefixof q} \filter A,B}$, $n' \in \pview{u_{\prefixof \gamma} \filter B,C}$.
Moreover $\pview{u_{\prefixof q} \filter A,B} \prefixof \pview{u_{\prefixof m} \filter A,B}$ (since $q$ is visible from $m$ in $A,B$) thus we have $\gamma \in \pview{u_{\prefixof m} \filter A,B}$ as required.

\item Suppose $m = \pmove_A$ and $m^- = \pomove$ then again we can conclude using the I.H.\ with $u \assignar u_{\prefixof m^-}$.

\item Suppose $m = \opmove$.
\begin{itemize}[-]
\item Suppose that $r$ does not contain any move in $B$  then $r$ is of the form $(\pmove_C \omove_C)^*$.

We just need to take $\gamma = m$.
Indeed:
\begin{enumerate}
\item By lemmma \ref{lem:in_pviewAC_imp_in_pviewX}(i)
we have $n'\in \pview{u\filter B,C}$.

\item  $m$ is justified by a move occurring before $n'$.
Indeed, if $m$ is justified by a $\pomove$-move then since $n' \cdot r$ contains only $\omove$ and $\pmove$ moves, $m$'s justifier must occur before $n'$.
If $m$'s justifier is an initial $\omove_C$-move $c_i$, then
by P-visibility we have $c_i \in \pview{u\filter B,C}$
but since the P-view computation ``stops'' when reaching an initial moves, in order to guarantee that $n'$ also belongs to the P-view (as shown in (a)) it must
occurs after $c_i$.
\end{enumerate}


\item Suppose that $r$ contains some move in $B$. Let $b$ be the last such move. Then $u$ is of the form $u = \ldots n' \cdot \ldots \cdot \stk\opmove  b \cdot (\pmove_A \omove_A)^* \cdot\ \stk\pomove m $.
So we have
$u\filter B,C = \ldots n' \cdot \ldots \cdot \stk\opmove  b \cdot \stk\pomove m $ hence $b \in \pview{u\filter B,C}$. We can now
conclude by applying the I.H.\ with $u \assignar u_{\prefixof b}$.
\end{itemize}

\item Suppose $m = \pomove \in B$.
If $m^- = \pomove \in B$ then the I.H.\ with $u \assignar u_{\prefixof m^-}$ permits us to conclude.
If $m^- = \omove \in A$ then we conclude by applying the I.H.\ on $u \assignar u_{\prefixof q}$ where $q$ is the external P-move in $A$ justifying $m^-$.
\qed
\end{enumerate}
%end of proof
\bigskip

We now use the two preceding Lemmas to show
the following useful result:
\begin{lemma}[Increasing order lemma]
\label{lem:increasing_order}
Let $u = \ldots n' \cdot r \cdot m \in Int(A,B,C)$ where
\begin{enumerate}
\item
$n'$ is an external O-move in compoment $X$
($n'=\omove_A$ and $X=A,B$, or $n'=\omove_C$ and $X=B,C$)  non initial in $C$,
\item $n' \in \pview{u\filter A,C}$,
\item $m$ is either played in $B$
($\opmove$ or $\pomove$) or is an external
 P-move in $Y$
($\pmove_C$ if $n'=\omove_A$ and
$\pmove_A$ if $n'=\omove_C$),
\item $m$'s justifier occurs before $n'$,
\item $u\filter X$ is P-i.j.,
\item $u_{\prefixof b}\filter Y$ is P-i.j.\ for all non-initial B-move $b$ occurring in $u$.
\end{enumerate}
Then:
$$ \ord_{Y} m \geq \ord_{A\lingamear C} n' \ .$$
\end{lemma}
\proof
If $n' =\omove_C$ (resp.~if $n'=\omove_A$)
then by Lemma \ref{lem:middleopmove}
(resp.~Lemma \ref{lem:middlepomove})
there is an occurrence in $r \cdot m$ of a non-initial B-move $\gamma$ of type $\opmove$
(resp.~$\pomove$) such that $\gamma \in \pview{u\filter Y}$ , $n' \in \pview{u_{\leq \gamma} \filter X}$ and $\gamma$ is justified by a move occurring before $n'$. By the $6^{th}$ hypothesis, $u_{\prefixof \gamma}\filter Y$ is P-i.j.

There are six possible cases depending on
the type of the moves $n'$ and $m$:
$(n',m) \in \{ \omove_A \} \times \{\pmove_C,\opmove,\pomove \}
\union \{ \omove_C \} \times \{\pmove_A,\opmove,\pomove \} $).
The following diagram illustrates the cases $(n',m)
 = (\omove_A,\pmove_C)$ (left)
and  $(n',m)
 = (\omove_C,\pmove_A)$  (right):
\begin{center}
\begin{tikzpicture}
\matrix [matrix of math nodes]
{
A & \longrightarrow & B &
 \longrightarrow & C \\
&\vdots&&\vdots\\
&&&& \node(n){\omove}; \\
&\vdots&\node(gj){\opmove};&\vdots\\
n' \omove \\
&\vdots&&\vdots  \\
&&\node(g){\gamma \pomove}; \\
&\vdots&&\vdots  \\
&&&&\node(m){m \pmove}; \\
};
\path (m) edge[tableptr] (n)
      (g) edge[tableptr] (gj);
\end{tikzpicture}
\hspace{2cm}
\begin{tikzpicture}
\matrix [matrix of math nodes]
{
A & \longrightarrow & B & \longrightarrow & C \\
&\vdots&&\vdots\\
& \node(n){\omove}; \\
&\vdots& &\node(gj){\vdots};\\
&&&&n' \omove \\
&\vdots&&\vdots  \\
&&\node(g){\gamma \opmove}; \\
&\vdots&&\vdots  \\
\node(m){m \pmove}; \\
};
\path (m) edge[tableptr] (n)
      (g) edge[tableptr] (gj);
\end{tikzpicture}
\end{center}



We have:
\begin{equation}
\ord_Y \gamma \geq \ord_X \gamma \label{eqn:gammaorderXY}
\end{equation}
Indeed, if $n' =\omove_C$ then $X=B,C$ and $Y=A,B$ and by Lemma
\ref{lem:compositionorder} we have $\ord_{A\lingamear B} \gamma \geq
\ord_{B\lingamear C} \gamma$. If $n=\omove_A$ then $\gamma$ is a
$\pomove$-move therefore it is not initial in $B$ and Lemma
\ref{lem:compositionorder} gives $\ord_{A\lingamear B} \gamma =
\ord_{B\lingamear C} \gamma$.

Hence:
\begin{align*}
\ord_{A\lingamear C} n'
& = \ord_{X} n' & \mbox{(n' non initial in $C$ \& Lemma \ref{lem:compositionorder})} \\
& \leq \ord_{X} \gamma & \mbox{($u_{\prefixof \gamma}\filter Y$ is P-i.j. \& $\gamma$'s justifier occurs before $n'$)} \\
& \leq \ord_{Y} \gamma & \mbox{(By Eq.\ \ref{eqn:gammaorderXY})} \\
& \leq \ord_{Y} m & \mbox{($u\filter X$ is P-i.j. \&
4$^{th}$ assumption: $m$'s justifier occurs before $\gamma$)}. \qed
\end{align*}
%end of proof
\bigskip


\begin{lemma}
\label{lem:visibleatprefixofu}
Let $u\in Int(A,B,C)$ such that
$u = \ldots \gamma \ldots \delta \ldots m$
where $m$ is a generalized P-move in $X$,
$\gamma \in \pview{u\filter A,C}$  and $\delta \in \pview{u\filter X}$. Then $\gamma \in \pview{u_{\prefixof \delta} \filter A,C}$.
\end{lemma}
\proof
First we remark than $\delta$ must occur in $\pview{u}$.
Indeed, $\delta \in \pview{u\filter X} = \pview{u_{< m} \filter X} \cdot m$ therefore $\delta \in \pview{u_{< m} \filter X}$ and since the move preceding $m$ in $u$ is necessarily a generalized O-move in $X$, we can use Lemma 3.3.1 from \cite{Harmer2005}:
\begin{align*}
\delta \in \pview{u_{< m} \filter X}
&= \pview{\pview{u_{<m}}\filter X} & \mbox{(Lemma 3.3.1 from \cite{Harmer2005})}\\
&\subseqof \pview{u_{<m}} \\
&\subseqof \pview{u} \ .
\end{align*}

Clearly, $\pview{u_{\prefixof \delta} \filter A,C}$ is a prefix of $\pview{u \filter A,C}$, indeed:
\begin{align*}
\pview{u_{\prefixof \delta} \filter A,C}
& = \pview{u_{\prefixof \delta}}\filter A,C
  & \mbox{(Lemma \ref{lem:pviewAC_eq_ACpview})}  \\
& \prefixof \pview{u}\filter A,C
  & \mbox{($\delta \in \pview{u}$)} \\
& = \pview{u\filter A,C}
  & \mbox{(Lemma \ref{lem:pviewAC_eq_ACpview})} \ .
\end{align*}

Finally since $\gamma \in \pview{u\filter A,C}$ and $\gamma$ occurs before $\delta$ in $u$, we necessarily have $\gamma \in \pview{u_{\prefixof \delta}\filter A,C}$.
\qed
%end of proof
\bigskip

\begin{lemma}
\label{lem:compos_auxiliary_lemma}
Let $X$ be a component and $u \in Int(A,B,C)$ such that
the projection of $u$ on the component $X$ has the form:
$$ u \filter X =
\Pstr[0.5cm][2pt]{ \ldots (n){n}  \ldots
 {\stk {n'}{\omove}}  \ldots  (m-n,30){\stk m {\pmove}}
}$$
and
\begin{enumerate}
  \item $m$ and $n'$ are external move in $X$ (\ie in $A$ if $X =A,B$ and in $C$ if $X=B,C$);
  \item $u\filter X$ is P-i.j.;
  \item $u_{\prefixof b}\filter Y$ is P-i.j.\ for all non-initial B-move $b$ occurring in $u$.
\end{enumerate}
Then either $\ord_{A\lingamear C} n' \leq \ord_{A\lingamear C} m$ or
$n' \not \in \pview{u\filter A,C}$.
\end{lemma}
\proof

Suppose that $n'$ occurs in the P-view $\pview{u\filter X}$. Then we have
\begin{equation}
\ord_{A\lingamear C} n'  = \ord_{B\lingamear C} n' \ . \label{eqn:ordnp}
\end{equation}
Indeed, if $X$ is the component $B,C$ then necessarily $n'$ is not initial in $C$ (otherwise it would be the first move in $\pview{u \filter B,C}$, which is not the case since by visibility $n$ must occur before $n'$ in the P-view) and
if $X=A,B$ then $n'$ is in $A$. Thus in both cases, Lemma \ref{lem:compositionorder} gives us the claimed equality.

Hence we have
\begin{align*}
\ord_{A\lingamear C} n'
& = \ord_{X} n' & \mbox{(Eq.\
\ref{eqn:ordnp})} \\
& \leq \ord_{X} m & \mbox{($u\filter X$ is P-i.j.)} \\
& = \ord_{A\lingamear C} m & \mbox{(Lemma \ref{lem:compositionorder} \& $m$ is not initial in $C$)} \ .
\end{align*}

Suppose that $n'$ does not occur in the P-view $\pview{u \filter X}$, then $n'$ lies underneath a PO arc occurring in $\pview{u \filter X}$. Let us denote this arc by $\beta$-$\alpha$ where $\beta$ and $\alpha$ denote the arc's nodes. We have:
$$ u \filter X = \ldots
\Pstr[0.5cm]{
 (n){n} \ldots (b){\stk\beta \pmove} \ldots \stk{n'} {\omove}
\ldots (a-b){\stk\alpha \omove}  \ldots (m-n){\stk m {\pmove} }
} $$
with $\ord_X \alpha \leq \ord_X m$ (by P-i.j.\ of $u \filter X$).

\begin{asparaenum}[i.]
\item Suppose $\alpha$ is an external move then so is $\beta$. Indeed, if $X=B,C$ and $\alpha = \omove_C$ then $\alpha$ can only point to another move in $C$ and
if $X=A,B$ and $\alpha = \omove_A$ then since $\alpha$ is an O-move in $A,B$, it is not initial in $A$ and therefore its justifier must also be in $A$.

Then instancing Lemma \ref{lem:interjump} with
$n \assignar n'$ gives us $n' \not\in\pview{u \filter A,C}$.

\item Suppose $\alpha$ is a $B$-move then necessarily so is $\beta$. Indeed, if $X=A,B$ then $\alpha \in B$
can only point to a move in $B$, and if $X=B,C$ then
since $\alpha$ is an O-move in the game $B,C$ it is not initial in $B$ and therefore its justfier must also be in $B$.

Now suppose that $n' \in \pview{u\filter A,C}$,
then by Lemma \ref{lem:visibleatprefixofu}
(with $\delta,\gamma \assignar \alpha,n'$)
we have $n' \in \pview{u_{\prefixof \alpha}\filter A,C}$,
and $u_{\prefixof \alpha}\filter Y$ is P-i.j.\ by hypothesis 3. This permits us to apply Lemma \ref{lem:increasing_order} on $u_{\prefixof \alpha}$:
\begin{align*}
\ord_{A\lingamear C} n'
& \leq \ord_{Y} \alpha & \mbox{(Lemma \ref{lem:increasing_order} with $u\assignar u_{\prefixof \alpha}$)} \\
& = \ord_{X} \alpha & \mbox{(Lemma \ref{lem:compositionorder} \& $\alpha$ non initial in $B$)} \\
& \leq \ord_{X} m & \mbox{($u \filter X$ is P-i.j.)} \\
& = \ord_{A\lingamear C} m & \mbox{(Lemma \ref{lem:compositionorder} \& $m$ is not initial in $C$)} \ . \qed
\end{align*}
\end{asparaenum}
%end of proof
\bigskip


\subsection{Linear composition}

\begin{proposition}[Linear composition]
\label{prop:closedpijcompose} Let $\sigma : A \lingamear B$ and $\mu
: B \lingamear C$ be two well-bracketed (P-visible) strategies then
\begin{enumerate}[(I)]
\item $\sigma$ closed P-i.j.\ $\wedge$ $\mu$ P-i.j.
$\implies$ $\sigma ; \mu$  P-i.j.;
\item $\sigma, \mu$ closed P-i.j.
$\implies$ $\sigma ; \mu$ closed P-i.j.
\end{enumerate}
\end{proposition}

\proof
Since well-bracketing is preserved by strategy composition \cite[Proposition 2.5]{abramsky94full}, $\sigma ; \mu$ is well-bracketed so we can use the definition of P-i.j.\ from Proposition \ref{prop:char_wellbrack}.

\noindent (I) Let us prove that $\sigma ; \mu$ is P-i.j..
Let $u$ be a play of the interaction $\sigma\ \|\ \mu$
ending with an external P-move $m$
justified by $n$ in $\pview{u \filter A , C}$.
Let $n'$ be an external O-move occurring betweeen $n$ and $m$:
$$ u \filter A,C =
\Pstr[0.5cm][2pt]{ \ldots (n){\stk {n} \omove}  \ldots
 {\stk {n'} \omove}  \ldots  (m-n,30){\stk m \pmove}
}
$$
To show that $u \filter A,C$ is P-incrementally justified, we just
need to prove that either $n'\not\in \pview{u \filter A,C}$ or
$\ord_{A\lingamear C} n' \leq \ord_{A\lingamear C} m$. Note that if
$n'\in \pview{u \filter A,C}$ then necessarily $n'$ is not initial
in $C$ because $n$ occurs before $n'$ in $\pview{u \filter A,C}$.

Let $E$ denote one of the two external arenas ($A$ or $C$), $X$ be
the corresponding component (\ie $X=A,B$ if $E=A$ and $X=B,C$
if $E=C$) and $Y$ denote the other component.
    \begin{enumerate}[1)]
    \item Suppose $m$ and $n$ are two external moves in $E$.

        \begin{enumerate}[{1}.a)]
        \item Suppose $n' \in E$.

        This case corresponds to the situation handled by
        Lemma \ref{lem:compos_auxiliary_lemma}: we have
        either $\ord_{A\lingamear C} n' \leq
        \ord_{A\lingamear C} m$ or $n' \not\in \pview{u
        \filter A,C}$.

        \item Suppose $n' \not\in E$.

        Suppose that $n' \in \pview{u\filter A,C}$, then by
        Lemma \ref{lem:increasing_order} with $X\assignar Y$
        we have $ \ord_{A\lingamear C} n'  \leq \ord_X m$
        and since $m$ is not initial in $C$, Lemma
        \ref{lem:compositionorder} gives $\ord_X m =
        \ord_{A\lingamear C} m$, thus $\ord_{A\lingamear C}
        n' \leq \ord_{A\lingamear C} m$.
        \end{enumerate}

        \item \label{case:mA} Suppose $m \in A$ and $n \in C$.

        Then $m$ is an initial move in $A$
        pointing to a $\opmove$-move
        $b_0$ initial in $B$ which in turn points to the $\omove_C$-move $n$ initial in $C$.

        This situation cannot be handled similarly as the
        previous case. Indeed the pointer associated to the move
        $m$ in the game $A,C$ is not the same as the one
        attached to the corresponding move in the game $A,B$
        (see in \cite{Abr02} for the definition of the
        projection operation over the overall component A,C),
        hence we cannot use Lemma \ref{lem:increasing_order}
        since the condition requiring that $m$ points before
        $n'$ is not necessarily met. A more detailed analysis is
        therefore required.

        Let us assume that $n'\in \pview{u\filter A,C}$ and
        prove that we necessarily have $\ord_{A\lingamear C} n'
        \leq \ord_{A\lingamear C} m$. We do a case analysis:
        \begin{itemize}[-]
        \item Suppose $n'$ occurs before $b_0$.
        Note that we cannot apply Lemma \ref{lem:increasing_order} on $u$
        since $m$ does not point before $b_0$.
        Up to now we have only used the fact that $\sigma$ and $\mu$ are P-i.j. The assumption that $\sigma$ is  \emph{closed} P-i.j.\ now becomes crucial.

        Since $n' \in \pview{u\filter A,C}$ and
        $b_0 \in \pview{u\filter B,C}$, applying Lemma \ref{lem:visibleatprefixofu}
        with $X\assignar B,C$ and $\delta,\gamma \assignar b_0,n'$ gives
        $n' \in \pview{u_{\prefixof b_0}\filter A,C}$. This allows us to apply Lemma \ref{lem:increasing_order} on $u_{\prefixof b_0}$:
            \begin{align*}
            \ord_{A\lingamear C} m
            = \ord_A m
            & \geq \ord_B b_0 & \mbox{($u \filter A,B$ is closed P-i.j., $m$ is initial in $A$)} \\
            & = \ord_{B\lingamear C} b_0  \\
            & \geq \ord_{A\lingamear C} n' & \mbox{(Lemma \ref{lem:increasing_order} on $u_{\prefixof b_0}$ with $X\assignar A,B$)} \ .
            \end{align*}

        \item Suppose $n'$ occurs after $b_0$ (and necessarily before $m$).

            \begin{enumerate}[a.]
            \item Suppose $n'\in C$. Since $m$'s justifier occurs before $n'$ in $u$, we can use Lemma \ref{lem:increasing_order} which gives $\ord_{A\lingamear C} n' \leq \ord_{A\lingamear B} m
                = \ord_{A\lingamear C} m$.

            \item Suppose $n'\in A$.
By Lemma \ref{lem:compos_auxiliary_lemma} with $X
\assignar A,B$, since $n' \in \pview{u \filter A,C}$, we
have $\ord_{A\lingamear C} n' \leq \ord_{A\lingamear C}
m$.
\smallskip

        Note that we could not use Lemma
        \ref{lem:increasing_order} on $u$ directly since
        both $m$ and $n'$ are played in $A$. Also, in
        the ideal case where $n'$ is hereditarily
        enabled by the initial move $m$, we can
        immediately conclude $\ord_{A\lingamear C} n'
        \leq \ord_{A\lingamear C} m$; however this
        argument does not work in general since there may be
        more than one initial move in $A$, in which case
        $n'$ can be hereditarily enabled by an initial
        $A$-move distinct from $m$.
            \end{enumerate}
        \end{itemize}

    \end{enumerate}

\noindent (II) We now show that $\sigma;\mu$ is closed P-i.j.\
provided that both $\sigma$ and $\mu$ are. Take a play $s m \in
\sigma ; \mu$ such that $m$ is initial in $A$ and let $n$ be the
initial move of $C$ justifying $m$. Let $u \in \sigma \ \|\ \mu$ be
the uncovering of $s m$ ($s m = u \filter A,C$) and $b_0$ be the
initial $B$-move justifying $m$ in $u$.
 We have:
\begin{align*}
\ord_A m & \geq \ord_B b_0 & \mbox{($u \filter A,B \in \sigma$ is closed P-i.j.)} \\
 & \geq \ord_C n & \mbox{($u_{\prefixof b_0} \filter B,C \in \mu $ is closed P-i.j.)}. \qed
\end{align*}
%end of proof
\smallskip

{\it Remark:} The second part of the proposition only gives a
\emph{sufficient} condition for $\sigma ; \mu$ to be closed P-i.j.
It is possible that $\sigma ; \mu$ is closed P-i.j.\
although $\mu$ is not.


\subsection{Composition}

\subsubsection*{Tensor product}

 Given two strategies $\sigma :\ A
\lingamear B$  and $\tau :\ C\lingamear D$, their tensor product is denoted $\sigma \otimes \tau :\ A\otimes B \lingamear C\otimes D$ where $A\otimes B$ denotes the tensor product of the games $A$ and $B$ (See Sec.\ \ref{sec:monoidal}).
\begin{proposition}
If $\sigma :\ A \lingamear B$ and $\tau :\ C\lingamear D$ are P-i.j.\
(resp closed P-i.j.) then so is $\sigma \otimes \tau$.
\end{proposition}
\proof
By establishing the state diagram of the game $A\otimes C \lingamear
B\otimes D$ one can show easily that only player O can switch
between the subgames $A\lingamear B$ and $C\lingamear D$.
Consequently, in the P-view of a play of the game $A\otimes C
\lingamear B\otimes D$, all the moves are played in the same subgame
(\ie all in $A\lingamear B$ or all in $C\lingamear D$).
Hence if the last move of a play $m$ is played in $A\lingamear B$
then $\pview{s\filter A,B} = \pview{s} \filter A,B = \pview{s}$ (and
conversely if $m$ is played in $C\lingamear D$). The result follows
immediately.
\qed
%end of proof
\smallskip

\subsubsection*{Pairing and projection} Given two strategies $\sigma :\ C \lingamear A$ and $\tau :\ C\lingamear B$, let $\langle \sigma , \tau \rangle :\ C \lingamear A\& B$ denote the
pairing strategy as defined in  Sec.\ \ref{sec:pairing}
 where $A\& B$ denotes the product of the games $A$ and $B$.

\begin{proposition}[Pairing]
\label{prop:pij_pairing_projection} \hfill
\begin{itemize}
\item If $\sigma :\ C \lingamear A$ and $\tau :\
C\lingamear B$ are P-i.j.\ (resp.\ closed P-i.j.) then so is $\langle \sigma , \tau \rangle$;

\item For any objects $A$ and $B$, the projections $\pi_1:A\times B \lingamear A$ and $\pi_2:A\times B \lingamear B$ are closed P-i.j.
\end{itemize}
\end{proposition}
The proof is immediate.

\subsubsection*{Promotion}

Let $s$ be a play. We call
\defname{thread} a maximal subsequence of $s$ constituted of moves
that are hereditarily justified by the same occurrence of an initial
move. Let $m$ be a move occurring in $s$. We call thread of $m$ the
only thread in $s$ containing $m$.


Recall that the promotion $\sigma^\dag :\ !A\lingamear !B$ of a strategy  $\sigma :\ !A \lingamear B$, for two well-opened games $A$ and $B$, is given by:
$$ \sigma^\dag = \{ s \in L_{!A\lingamear !B}\ |\ \mbox{for all inital $m$ in $B$, } s\filter m \in \sigma \}$$

Since $B$ is well-opened, plays of $\sigma$ are constituted of a
single thread initiated by some initial $B$-move. Plays of
$\sigma^\dag$ however, are interleaves of potentially infinitely many single-threaded
plays of $\sigma$. One can show easily, using the visibility condition, that the thread of a $P$-move
is always the same as the thread of the preceding $O$-move. Consequently, the P-view of a play is equal to the P-view of the current thread:
if the current thread of a play $s$ is opened by an initial move $b \in B$ then
$\pview{s} = \pview{s \filter b} = \pview{s} \filter b$.


The state of the game is given by an infinite sequence of symbols in $\{O, P\}$, each element of the
sequence indicating who is to play in the corresponding thread.
The diagram on Figure \ref{fig:promotion_state_diagram} illustrates
how the state changes as a play of $\sigma^\dag$ unfolds.
The initial state of the game is $O^\omega$ - an infinite
sequence of O's -- which indicates that O is to play in all the
threads. When O plays an initial move in $B$, it ``opens'' a new
thread so the state of the game becomes $O^k P O^\omega$ where $k$
is the index of the thread being opened. By alternation, $P$ now has to play. His move must be played in a thread
already opened by $O$ and in which $P$ is to play; only one thread is in such state: the $k$th one. Hence after P's move
we are back to state $O^\omega$.

\tikzstyle{state}=[rectangle,draw=blue!50,fill=blue!20,thick,minimum
height = 4ex, text width=1.2cm, text centered]
\tikzstyle{state_nobg}=[thick,minimum
height = 4ex, text width=1.2cm, text centered]
\tikzstyle{omove}=[->,shorten <=1pt,>=latex',line width=0.5pt,bend left=10]
\tikzstyle{pmove}=[->,shorten <=1pt,>=latex',line width=0.5pt,bend left=10, draw=blue!50]
\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}[node distance=2cm]
% the states
\path
 node(init)  [state, text width=4cm] {$O^\omega$}
 (init)+(-2.8cm,-3cm)
 node(p)     [state, anchor=east,] {$PO^\omega$}
 node(p1)    [state, right of=p]  {$OPO^\omega$}
 node(p2)    [state_nobg, right of=p1] {\ldots}
 node(p3)    [state, right of=p2] {$O^kPO^\omega$}
 node(p4)    [state_nobg, right of=p3] {\ldots} ;
\path
% arrows representing the moves
  ([xshift=-1.4cm]init.south)  edge[omove] node[right]{O} ([xshift=0.2cm]p.north)
  (p.north)    edge[pmove] node[left]{P} ([xshift=-1.5cm]init.south)
  ([xshift=-0cm]init.south)   edge[omove] node[right]{O} ([xshift=0.2cm]p1.north)
  (p1.north)   edge[pmove] node[left]{P} ([xshift=-0.2cm]init.south)
  ([xshift=1cm]init.south)   edge[omove] node[right]{O} ([xshift=0cm]p3.north)
  ([xshift=-0.2cm]p3.north)   edge[pmove] node[left]{P} ([xshift=0.8cm]init.south);
\end{tikzpicture}
\end{center}
\caption{State diagram for plays of $\sigma^\dag$.}
\label{fig:promotion_state_diagram}
\end{figure}



\begin{proposition}[Promotion]
\label{prop:fatcompos_pij} If $A$ and $B$ are two well-opened games
and $\sigma :\ !A \lingamear B$ is a well-bracketed P-i.j.\ strategy
then $\sigma^\dag$ is also well-bracketed and P-i.j. Furthermore if
$\sigma$ is closed P-i.j.\ then so is $\sigma^\dagger$.
\end{proposition}
\proof
$\sigma^\dag$ is well-bracketed by \cite[Proposition
2.10.]{abramsky94full}. For P-incremental justification, the result is a direct consequence of the
fact that the P-view of a play in $\sigma^\dag$ is equal to the P-view of the current thread.
For closed P-incremental justification, the result is immediate.
\qed
%end of proof

\subsubsection*{Composition}

We recall that the composite of $\sigma :\ !A \lingamear B$,
and $\mu :\ !B\lingamear C$ in the co-Kleisli category of games $\mathcal{C}$, written $\sigma
\fatcompos \mu$, is defined as:
$$ \sigma \fatcompos \mu = \sigma^\dag ; \mu \ .$$
From propositions \ref{prop:closedpijcompose} and
\ref{prop:fatcompos_pij} we obtain:
\begin{corollary}
Let $A$ and $B$ be two well-opened games. Let $\sigma :\ !A
\lingamear B$ and $\mu :\ !B\lingamear C$ be two well-bracketed
strategies then:
\begin{enumerate}
\item If $\sigma$ is closed P-i.j.\ and $\mu$ is P-i.j.\ then $\sigma \fatcompos \mu :\ !A \lingamear
C$ is also P-i.j.;
\item If $\sigma$ and $\mu$ are closed P-i.j.\ then so is $\sigma \fatcompos \mu :\ !A \lingamear C$.
\end{enumerate}
\end{corollary}

\subsection{The category of closed P-i.j.\ strategies}

We define the category $\mathcal{G}_{Pij}$ of closed P-incrementally justified strategies as follows:
\begin{asparaitem}
\item Objects: games (as defined in Sec.\ \ref{sec:games}),
\item Morphisms $\sigma: A\gamear B$: closed P-i.j.\ strategies for $A\lingamear B$,
\item Composition: the linear strategy composition.
\end{asparaitem}
This indeed defines a category:
\begin{proposition}
$\mathcal{G}_{Pij}$ is a luff-subcategory of $\mathcal{G}$.
\end{proposition}
\proof
The objects and morphisms of $\mathcal{G}_{Pij}$ are subclasses of objects and morphisms of $\mathcal G$. For every object $A$, the identity strategy $id_A$ is closed P-i.j. For every pair of morphisms in $\mathcal{G}_{Pij}$ the composite is also in $\mathcal{G}_{Pij}$ by Proposition \ref{prop:closedpijcompose}. Thus $\mathcal{G}_{Pij}$ is a subcategory of $\mathcal G$
It is a lluf-subcategory because the objects of $\mathcal{G}_{Pij}$ are exactly those of $\mathcal{G}$.
\qed
\bigskip


This category is not cartesian closed, not even monoidal closed. Indeed, remember that a P-i.j.\ strategy from $A$ to $B$ is said to be \emph{closed} P-i.j.\ provided that some condition on the move of the game $A\lingamear B$ holds. The problem is that this condition is sensitive to the individual structure of the game $A$ and $B$, and therefore it does not necessarily hold for another game that is isomorphic to $A\lingamear B$.

In particular, any P-i.j.\ strategy $\sigma$ on $A\lingamear B$ is isomorphic, up to \emph{currying}, to a \emph{closed} P-i.j.\ strategy on $I \lingamear (A\lingamear B)$. However $\sigma$ itself is not necessarily closed P-i.j. Take for instance the two simply-typed terms $\stentail \lambda x:o\, y:o . y$ and $y :o \stentail \lambda x:o . y$. These two terms have isomorphic denotations. However the first term has a closed P-i.j.\ denotation while the second is only P.i.j.


We define $\mathcal{C}_{Pij}$ as the co-Kleisli category of $\mathcal{G}_{Pij}$.
This category will be used to give the intentional game model of safe \pcf\ and safe \ialgol. We write $\mathcal{C}_{Pij.ib}$, $\mathcal{C}_{Pij.b}$ and
$\mathcal{C}_{Pij.i}$ to denote its lluf subcategories of innocent, well-bracketed and innocent and well-bracketed strategies respectively.


\section{\texorpdfstring{Modeling safe functional languages in $\mathcal{C}_{Pij}$}
{Game model of safe functional languages}}

In Chapter \ref{chap:syntactic_gamesem} we have shown that in the standard game
model, safe lambda terms are denoted by P-i.j.\ strategies.
The argument used to show this property was syntactic: we proceeded by analyzing the structure of some abstract syntax tree (the computation tree) of the term. Using the result proved in the previous section, it is now possible to reprove the same result using a purely semantic argument. This shows that the safe lambda calculus, safe \pcf\ and safe \ialgol, can all be modeled in the category $\mathcal{C}_{Pij}$.

\subsection{Safe lambda calculus with product}

We consider the more general setting of the safe lambda calculus with product
(Sec.\ \ref{sec:safelmd_product}).
\begin{proposition}
\label{prop:safe_closepij_sem}
  Terms of the safe simply-typed lambda calculus with product are denoted by closed P-i.j.\ strategies.
\end{proposition}
\proof
  By induction on the formation rules that almost safe terms are denoted by P-i.j.\ strategies and safe terms are denoted by \emph{closed} P-i.j.\ strategies.
  \begin{itemize}
    \item \rulenamet{var} $\sem{x:A \sentail x:A }$ is the identity strategy $id_A$ which is closed P-i.j.

    \item \rulenamet{wk} Take $\Gamma \subset \Delta $ and suppose $\sem{\Gamma \sentail
    s : A}$ is closed P-i.j. Up to a retagging of
    the moves, the two strategies $\sem{\Delta \sentail s : A}$
    and $\sem{\Gamma \sentail s : A}$ are isomorphic. Hence
    $\sem{\Delta \sentail s : A}$ is P-i.j. It is also closed
    P-i.j.\ since none of the new initial moves introduced by
    $\Delta$ occurs in any play of the strategy.

    \item \rulenamet{\times}, \rulenamet{\pi_1} and \rulenamet{\pi_2}: The result follows from the I.H.\ and Proposition \ref{prop:pij_pairing_projection}.

    \item \rulenamet{wk^\times} This case is similar to \rulenamet{wk}.

    \item \rulenamet{app_{as}} Suppose that $\Gamma \asappentail t_0 t_1 \ldots t_n : B$
with $\Gamma \sentail t_0 : (A_1,\ldots,A_n,B)$ and $\Gamma \sentail t_i : A_i$ for $i \in\{ 1..n\}$. By the I.H., for $i \in \{0..n\}$ the strategy
 $\sem{t_i}$ is closed P-i.j. We then have $\sem{t_0 t_1 \ldots t_n} = \langle \sem{ t_0}, \sem{t_1}, \ldots, \sem{t_n} \rangle \fatsemi ev^n$
    where $ev^n$ is the $n$-parameter evaluation strategy. By
    Proposition \ref{prop:pij_pairing_projection} the strategy $\langle \sem{t_0}, \sem{  t_1} , \ldots, \sem{t_n} \rangle$ is closed P-i.j. Since the evaluation map
    $ev^n$ is P-i.j.\ (but not necessarily closed P-i.j.),
    by Proposition \ref{prop:closedpijcompose}.I.\
    $\sem{ \Gamma \sentail t_0 t_1 \ldots t_n : B}$ is P-i.j.

    \item \rulenamet{app} Terms formed with this rule can also be formed with the rule \rulenamet{app_{as}}, therefore by the previous case
    the denotation of the term formed is P-i.j. By the side-condition of the
    rule, all the prime nodes in $\ord{\Gamma}$ have order greater than the order of the term, therefore by
    by Lemma \ref{lem:closedpij_singleBinitmove}(ii), $\sem{ \Gamma \sentail t_0 t_1 \ldots t_n : B}$ is \emph{closed} P-i.j.


    \item \rulenamet{abs} and \rulenamet{abs_{as}}: By the I.H., the premise of the rule has a P-i.j.\ denotation.
    The denotation of the term in the conclusion of the rule is isomorphic, up to currying, to the denotation of the premise. Therefore it is also P.i.j.
    And by the side-condition and Lemma \ref{lem:closedpij_singleBinitmove}(ii) this implies that it is \emph{closed} P-i.j.
        \qed
  \end{itemize}
%end of proof

\subsection{Safe PCF}

\begin{proposition}
\label{prop:safepcf_closedpij} Safe PCF terms are denoted by closed
P-incrementally justified strategies.
\end{proposition}
\proof
We first prove the result for $\pcf_1$ - the fragment of \pcf\
containing terms of the form $\Omega_A = Y (\lambda x : A.x)$ but
where no other use of Y is allowed (see
\cite{abramsky:game-semantics-tutorial}). The proof is by structural
induction over the structure of the term:
\begin{asparaitem}
\item The strategy $\sem{\Omega_A} = \bot$ is
clearly closed P-i.j.;
\item The functional rules are treated the same way as in the
corresponding proof for the safe lambda calculus;
\item For the arithmetic rules, we observe that the strategies
$succ$, $pred$ and $cond$ are all closed P-i.j. The fact that
pairing and strategy composition preserve closed P-incremental
justification permits us to conclude.
\end{asparaitem}

We now lift the result to full PCF using the technique of
\emph{syntactic approximant} (see
\cite{abramsky:game-semantics-tutorial}). By \cite[lemma
16]{abramsky:game-semantics-tutorial} we have
$$ \sem{M} = \Union_{n\in\omega} \sem{M_n}$$
where $M_n$ is the $\pcf_1$ term obtained from $M$ by replacing each
subterm of the form $Y N$ with $Y^n N_n$, and $Y^n F$ denotes the
$n$th approximant of $Y F$. Since the $M_n$s are $\pcf_1$ terms, by
the previous result each $\sem{M_n}$ is closed P-i.j.\ and since
closed P-incremental justification is clearly a continuous property,
$\sem{M}$ is also closed P-i.j.
\qed
%end of proof
\bigskip

Hence safe \pcf\ can be modeled in the sub-category
$\mathcal{G}_{Pij.ib}$ of innocent well-bracketed closed P-i.j.\ strategies.


\subsection{Safe Idealized Algol}

We now extend the game-semantic characterization to safe \ialgol. The constants of \ialgol\ are all denoted by closed P-incrementally justified strategies:
\begin{lemma} \hfill
\label{lem:iaconst_pij}
\begin{enumerate}[(i)]
\item The strategy denotations of the \ialgol\ constants \iaskip, \iaassign, \iaderef, \iamkvar, $\iaseq_{\iaexp}$,
and $\iaseq_{\iacom}$ are all closed P-i.j.;
\item The memory-cell strategy $cell : I \lingamear\ !\iavar$ is closed P-i.j.
\end{enumerate}
\end{lemma}
\proof
(i) A quick inspection at the view function of these denotations (as defined in Sec.\ \ref{sec:ia_gamemodel}) reveals that they are indeed all closed P-i.j.

(ii) Since the game \iavar\ does not contain any P-question, any strategy on the game $I \lingamear\ !\iavar$ is P-i.j.\ (and therefore also closed P-i.j.). \qed
\bigskip

Our game-semantic analysis of safe \pcf\ trivially extends to strongly safe \ialgol:
\begin{proposition}
  Strongly safe \ialgol\ terms are denoted by closed P-i.j. strategies.
\end{proposition}
\proof
The proof is an adaptation of the proof for Safe PCF. We first show that the result holds for the fragment of \emph{strongly safe \ialgol} in which the only allowed uses of $Y$ are in terms of the form $\Omega$. This is done by induction over the structure of the term: For the functional and arithmetic rules, the proof is the same as for Safe \pcf.
For the imperative rules, the result follow from the fact that \ialgol\ constants are denoted by closed P-i.j.\ strategies (Lemma \ref{lem:iaconst_pij}(i)) and because tensor product and composition both preserve closed P-incremental justification.
For the block-allocation construct, the result follows from the fact that
$cell$ is closed P-i.j.\ (Lemma \ref{lem:iaconst_pij}(ii)) and that pairing and strategy composition both preserve closed P-incremental justification.

The result is then lifted to the whole of strongly safe \ialgol\ using the technique of syntactic approximants as in the PCF case.
\qed
\bigskip

We now want to extend this result to safe \ialgol. This turns out to be slightly more difficult than for the strongly-safe fragment.
Indeed, in safe \ialgol\, the safety restriction only constrains variables that are bound by a $\lambda$-abstraction. The fact that block-allocated variables are not constrained should somehow be reflected in the semantics, and indeed safe \emph{split}-terms are not necessarily closed P-i.j. (\eg $ \emptyset | x:\iavar \sentail \lambda f:\iaexp\typear \iaexp . \iaderef\ x$).
Remember however that safe \ialgol\ is defined as the set of safe split-terms in which the second context component is empty (\eg $ \Gamma| \emptyset \sentail M : A$). It turns out that ``abstracting'' the variables from the second context component using the block-variable allocator \ianew\ has the effect of eliminating plays that are not closed P-i.j. Consequently, safe \ialgol\ terms are denoted by closed P-i.j.\ strategies.

So our argument proceeds as follows: we show that safe split-terms are denoted by strategies in which almost all the plays are closed P-i.j.\ except those plays containing moves in the second component of the context. Consequently when restricted to safe \ialgol\ terms, this shows that their denotation is closed P-i.j.

\begin{definition}[P-i.j.\ modulo $\mathfrak{M}$]
\label{def:pij_modulo} Let $\sigma$ be a strategy on some game $A$
and $\mathfrak{M}$ be a set of moves. We say that $\sigma$ is \defname{P-i.j.\
modulo $\mathfrak{M}$} iff for all $s m \in \sigma$ with $m \not\in
\mathfrak{M}$, the play $s m$ is P-i.j. Similarly we say that $\sigma$ is \emph{closed} P-i.j.\ modulo $\mathfrak{M}$ iff for all $s m \in \sigma$ with $m \not\in \mathfrak{M}$ the play $s m$ is \emph{closed} P-i.j.
\end{definition}
Hence a strategy is P-i.j. if and only if it is P-i.j.\ modulo
$\emptyset$.
\smallskip

The common operations on strategies preserve the property of being P-incremental justification modulo a set of moves:
\begin{lemma}[Composition]
\label{lem:leftcompos_preserv_pijmodulo}
 Let $\sigma : A \rightarrow
B$ and $\mu : B \rightarrow C$.
  Let $\mathfrak{M}$ be any set of moves initial in $A$.
  If $\sigma$ is closed  P-i.j. modulo $\mathfrak{M}$ and $\mu$ is
  P-i.j. (resp. closed P-i.j.) then $\sigma \fatsemi \mu$ is P-i.j. (resp. closed P-i.j.) modulo $\mathfrak{M}$.
\end{lemma}
\proof
The whole argument used to prove compositionality for closed P-i.j. strategies can be adapted to show this result. The reason why it works is because the proof does not rely on the P-incremental justification of plays ending with an initial $A$-moves. We do not give the details here for conciseness.
\qed
\smallskip

\begin{lemma}[Tensor product]
\label{prop:pijmodulo_tensor}
Let $\sigma :\ A \lingamear B$  and $\tau :\ C\lingamear D$.
Let $\mathfrak{M}_A$ and $\mathfrak{M}_C$ be two sets of moves initial in $A$ and $C$ respectively.
\begin{enumerate}
\item If $\sigma$ and $\tau$ are P-i.j.\ modulo $\mathfrak{M}_A$ and modulo $\mathfrak{M}_C$ respectively
then $\sigma \otimes \tau$ is P-i.j.\ modulo $\mathfrak{M}_A \union \mathfrak{M}_C$;
\item If $\sigma$ and $\tau$ are \emph{closed} P-i.j.\ modulo $\mathfrak{M}_A$ and modulo $\mathfrak{M}_C$ respectively
    then $\sigma \otimes \tau$ is \emph{closed} P-i.j.\ modulo $\mathfrak{M}_A \union \mathfrak{M}_C$.
\end{enumerate}
\end{lemma}
\begin{lemma}[Pairing]
\label{prop:pijmodulo_pairing}
Let $\sigma :\ C \lingamear A$, $\tau :\
C\lingamear B$, and $\mathfrak{M}_C$ be a sets of moves initial in $C$.
\begin{enumerate}
\item If $\sigma$ and $\tau$ are P-i.j.\ modulo $\mathfrak{M}_C$ then so is $\langle \sigma , \tau \rangle$;
\item If $\sigma$ and $\tau$ are closed P-i.j.\ modulo $\mathfrak{M}_C$ then so is $\langle \sigma , \tau \rangle$.
\end{enumerate}
\end{lemma}
The proof of the two previous lemmas is an easy adaptation of the proofs of their counterpart for P-i.j.\ strategies.


\begin{lemma}
\label{lem:cellcomposition_preserve_pijmodulo} Let $\tau : I
\gamear C_2$, $\sigma : C_1 \otimes C_2 \gamear B$  and
$\mathfrak{M}$ be any set of moves initial in $C_1 \otimes
C_2$.
  If $\tau$ is P-i.j. and
  $\sigma$ is P-i.j. (resp. closed P-i.j.) modulo $\mathfrak{M}$
  then $(id_{C_1} \otimes \tau) \fatsemi \sigma$ is P-i.j. (resp. closed P-i.j.) modulo $\mathfrak{M} \inter C_1$.
\end{lemma}
\proof
Let $D = C_1\otimes C_2$.
Let $u \in Int(C_1, D, B)$ be a non-empty interaction play of $\mu = (id_{C_1} \otimes \tau)^\dagger  \| \sigma$, and $m$ denote the last play of $u$. We need to show that if $m$ does not belong to $\mathfrak{M}$ then $u \filter C_1, B$ is P-incrementally justified.

Suppose $m \in C_1 \setminus \mathfrak{M}$. Let $d$ be the initial $D$-move hereditarily justifying $m$, then by definition of $\mu$ we have
$u\filter C_1, D, d \in id_{C_1}$ which implies
that $u\filter C_1, B = u\filter D, B$.
But $u$ is an interaction sequence therefore $u\filter D, B \in \sigma$, and since $\sigma$ is P-i.j.\ modulo $\mathfrak{M}$ this implies that $u\filter C_1, B$ is P-incrementally justified.

Suppose $m\in B$ then necessarily its justifier also occurs in $B$.
By definition of $u$, the play $u\filter D, B$ belongs to $\sigma$ which
is P-i.j.\ modulo $\mathfrak{M}$. Since $m$ belongs to $B$ it cannot be in $\mathfrak{M}$ therefore $u$ is P-i.j. Furthermore, since $\tau$ is P-i.j., so is $(id_{C_1} \otimes \tau)^\dagger$ therefore the play $u\filter C_1, D$ and all its prefixes are P-i.j.
Hence we can  apply Lemma \ref{lem:compos_auxiliary_lemma}
with $X\leftarrow D, B$ and $Y\leftarrow C_1, D$ which shows that $u\filter C_1, B$ is P-i.j. \qed
% end of proof
\bigskip

\emph{Convention:} Given a safe split-term $\Gamma | \Xi \safeentail M : A$, we write $\sem{\Gamma | \Xi \safeentail M : A}$ to refer to $\sem{\Gamma, \Xi \vdash M : A}$, the game denotation of the corresponding \ialgol\ term.

\begin{proposition}
\label{prop:safeia_closedpijmodulo} Let $\Gamma | \Xi
\safeentail M : A $ be a safe \ialgol\ split-terms. Its denotation $\sem{\Gamma | \Xi \safeentail M : A}$ is closed P-i.j. modulo
$\mathfrak{M}_{\Xi}$ where
$\mathfrak{M}_{\Xi}$ is the set of initial moves in
$\Xi$.
\end{proposition}
\begin{remark}
$\mathfrak{M}_{\Xi}$ contains only order-$0$ questions because the context $\Xi$ contains variables of type \iavar\ and \iaexp\ only.
\end{remark}
\proof
We just need to prove the result for the fragment of safe \ialgol\ where the only allowed uses of the $Y$ combinator is in terms of the form $\Omega$. The result is then lifted to the whole of safe \ialgol\ using the technique of syntactic approximants and the continuity of the ``closed P-i.j.'' property.

We proceed by induction on the safe \ialgol\ term. The cases \rulenamet{var}, \rulenamet{var^\ianew}, \rulenamet{wk} and \rulenamet{wk^\ianew} are just trivial adaptations of the proof for the safe lambda calculus (Prop.\ \ref{prop:safe_closepij_sem}).
\begin{asparaitem}[-]
  \item \rulenamet{const}, \rulenamet{succ}, \rulenamet{pred}, \rulenamet{cond},
  \rulenamet{seq}, \rulenamet{assign}, \rulenamet{deref}:
  These constants all have closed P-i.j.\ denotations so the result
  follows from the I.H., Lemma \ref{lem:leftcompos_preserv_pijmodulo},  Proposition \ref{prop:pijmodulo_pairing} and \ref{prop:pijmodulo_tensor}.

    \item \rulenamet{app}: The premise of the rule is an almost safe split-term \ie a consecutive applications of safe terms. By the I.H.\ all these terms have a closed P-i.j.\ modulo $\mathfrak{M}_{\Xi}$ denotation.
        Since the evaluation strategy $ev$ is P-i.j.\ and because of Lemma \ref{lem:leftcompos_preserv_pijmodulo} this implies that the denotation of the split-term being formed is P-i.j.\ modulo $\mathfrak{M}_{\Xi}$. Finally, the side-condition of the rule ensures that it is \emph{closed} P-i.j.\ modulo $\mathfrak{M}_{\Xi}$.

  \item \rulenamet{abs} and \rulenamet{abs_{as}}: It follows from the I.H.\ and because the side condition of the abstraction rules constrains only free variables from the $\Gamma$-context.

  \item \rulenamet{new}: Take the split-term $\Gamma | \Xi \safeentail \ianewin{x}{M}:B$. Let $\sigma = \sem{\Gamma | \Xi, x : \iavar \safeentail M : B}$.  We have $\sem{\Gamma | \Xi \safeentail
\ianewin{x}{M} : B} = (id_{\Gamma,\Xi} \otimes cell)
\fatcompos \sigma$ where $cell$ denotes the memory cell strategy on the game $I \rightarrow !\iavar$. By the I.H.\ $\sigma$ is closed P-i.j.\ modulo $\mathfrak{M}_{\Xi \otimes !\iavar}$. Instancing Lemma
\ref{lem:cellcomposition_preserve_pijmodulo} with $\tau
\leftarrow cell$, $C_1 \leftarrow \Gamma \otimes  \Xi$
and $C_2\leftarrow !\iavar$ gives us the desired result.

\item \rulenamet{mkvar}

Take the split-term $\sigma_1 = \sem{\Gamma | \Xi ,x:\iaexp \safeentail M_1:\iacom}$
 and $\sigma_2 = \sem{\Gamma | \Xi, x : \iaexp \safeentail M_2 : \iaexp}$.
   Then $\sem{\Gamma | \Xi \safeentail
\iamkvar\ (\lambda x.M_1) M_2} = \langle \Delta(\sigma_1), \sigma_2 \rangle ; mkvar$. By the I.H.\ $\sigma_1$ and $\sigma_2$ are closed P-i.j.\ modulo $\mathfrak{M}_{\Xi,x:\iaexp}$.

and \rulenamet{mkvar}
\qed
\end{asparaitem}
\bigskip

By definition, safe \ialgol\ terms are the semi-closed safe split-terms, hence:
\begin{proposition}
\label{prop:safeia_closedpij} Safe \ialgol\ terms are denoted by closed
P-incrementally justified strategies.
\end{proposition}





\section{Full abstraction}

Clearly, the fully-abstract game-model of PCF is also fully-abstract for the
safe fragment of PCF when observational equivalence is defined with
respect to unrestricted (\ie possibly unsafe) PCF contexts.
\smallskip

\emph{Question: What is a fully abstract model of safe PCF with respect to {\rm safe} contexts?}
\smallskip




We show here that the category of game $\mathcal{C}_{Pij.ib}$ gives rise to such a model when quotiented by the usual intrinsic preorder. This results falls out easily from the Full Abstraction result for \pcf.

\subsection*{Soundness}

Clearly, the soundness of the game model $\mathcal{C}_{ib}$ of \pcf\ implies that the game model model $\mathcal{C}_{Pij.ib}$ of safe \pcf\ is also sound. This is because a safe term $M$ is denoted by the empty strategy in $\mathcal{C}_{Pij.ib}$ if and only if it is denoted by the empty strategy in $\mathcal{C}_{ib}$, and  $M\eval_{safe \pcf}$ if and only if $M\eval_\pcf$ where $\eval_{\pcf}$ (resp.\ $\eval_{safe \pcf}$) refers to the big-step operational semantics of \pcf (resp.\ safe \pcf).

\subsection*{The extensional model}

Let $\lesssim_{Pij.ib}$ denote the intrinsic preorder of the category $\mathcal{C}_{inc}$.
\begin{proposition}
$\mathcal{C}_{Pij.ib}/\lesssim_{Pij.ib}$ is a non-cartesian-closed rational category.
\end{proposition}
\proof
\notetoself{proof needed}
\qed

Since safe \pcf\ can be modelled in $\mathcal{C}_{Pij}$, this implies \cite{} that $\mathcal{C}_{Pij}/\lesssim_{Pij}$ is also a model of safe \pcf.

Moreover it is clear that incremental justification is a property preserved by taking the least-upper of a chain (when it exists), and we
Indeed, we have seen in Chapter \ref{chap:syntactic_gamesem} that the definability result for \pcf\ implies the one for safe \pcf.

\subsection*{Full abstraction}
\notetoself{
By the definability results for Safe PCF, it should be possible to
prove that the category $\mathcal{C}_{inc.ib}$ of
OP-incrementally justified well-bracketed innocent strategies is fully abstract
for Safe PCF. We can use the same proof as in the PCF case: we have
a compact test strategy $\alpha:A\rightarrow N$ and by definability,
there must be some context $x:A \vdash C[x] : N$ such that $\sem{x:A
\vdash C[x] : N} = \alpha$. The definability result for Safe PCF
gives us that $\lambda x . C[x] : A \rightarrow N$ is safe which in
turns implies that $x:A \vdash C[x] : N$ is safe since $\ord{N} =
0$.
}


\section{O-incremental justification}

We define \emph{O-incremental justification} as the dual of P-incremental justification:
\begin{definition}
  A play $s m$ of \emph{odd} length is said to be \defname{O-incrementally justified}, or \emph{O-i.j.} for short, if $m$ points to the last unanswered P-question in $\pview{s}$ with order strictly greater than $\ord{m}$.

 A strategy $\sigma$ is said to be \defname{O-incrementally justified}, if all plays in $\sigma$ ending with an O-question are
O-incrementally justified.
\end{definition}

This corresponds to the constraint that needs to
be imposed on the Opponent to reflect the fact that the environment is itself incarnated by a safe term. This duality resembles very much that of O-visibility and P-visibility (see \cite[Sec.~3.6]{Harmer2005}).

The duality can be formally explained as follows: Let $\sigma : A$ and $\mu : A \rightarrow o$ be two strategies, the first
representing the program and the second representing the
environment. Let $q$ be the initial move of the game $A \rightarrow
o$. Then P-views of plays in $A$ correspond to O-views in the game
$A \rightarrow o$. Indeed, for $s\in L_A$ we have $q s \in L_{A
\rightarrow o}$ and due to alternation, $q \pview{s}^A = \oview{q s
}_{A \rightarrow o}$. Consequently, if $\sigma$ is P-i.j.\ then the
play involved in the interaction between $\sigma$ and $\mu$ are all
O-i.j.\ from $\mu$'s perspective. Indeed, let $u \in \sigma \| \mu$
with $|u|\geq1$. Then $u=q v$ and $u\filter A = v \filter A$ is
P-i.j. By the previous remark, this implies that $q (v\filter A) =
(q v)\filter (A \rightarrow o) = u \filter (A \rightarrow o)$ is
O-i.j.
\smallskip

Now if we regard $\sigma$ as the denotation of some closed term
$\vdash M:A$ and $\mu$ as the denotation of some context $x:A \vdash
C[x]:o$ then the previous remark expresses that plays that are not O-i.j.\ are not relevant to the observational equivalence problem.
We can therefore eliminate them from the game denotation. But before doing that, we have to ensure that it does not prevent us from building a category:
\begin{lemma}
\label{lem:oij_decomp}
Let $\sigma : A\rightarrow B$ and $\tau : A\rightarrow B$ be closed P-i.j.\ strategies and suppose
that $u\in \sigma \| \tau$ such that for all external O-moves $o$ of $u$, we have that $u_{\prefixof o} \filter A,C$ satisfies
O-incremental justification. Then, for any generalized O-move $m$ of $u$ in component $X$, we have that
$u_{\prefixof m} \filter X$ satisfies O-incremental justification
\end{lemma}
\notetoself{Proof forthcoming! }

If we write $\mathcal{O}(\sigma)$ to denote the largest subset of plays of $\sigma$ whose odd-length prefixes are all O-i.j. Then the Lemma can be restated equivalently as:
\begin{eqnarray}
     \forall \sigma, \tau\ \mbox{closed P-i.j.}: \mathcal{O}(\sigma) ; \mathcal{O}(\tau) \supseteq \mathcal{O}(\sigma ; \tau)
     \label{eqn:oijdecomp_1}
\end{eqnarray}
which is equivalent to
\begin{eqnarray}
    \forall \sigma, \tau\ \mbox{closed P-i.j.}: \mathcal{O}( \mathcal{O}(\sigma) ; \mathcal{O}(\tau) ) = \mathcal{O}(\sigma ; \tau)
    \label{eqn:oijdecomp_2}
\end{eqnarray}
(Clearly Eq.~\ref{eqn:oijdecomp_1} implies the right-to-left inclusion in Eq.~\ref{eqn:oijdecomp_2}. The converse inclusion holds because $\mathcal{O}(\sigma) ; \mathcal{O}(\tau) \subseteq \sigma;\tau$.)

In other words, Lemma \ref{lem:oij_decomp} states that O-i.j plays cannot be obtained from the interaction of plays that are not O-i.j. In some sense it is the dual of compositionality of closed P-i.j.\ strategies. This duality can be revealed by reformulating compositionality as follows:
\begin{eqnarray}
     \forall \sigma, \tau\ \mbox{closed P-i.j.}: \, \mathcal{P}(\sigma) ; \mathcal{P}(\tau) \subseteq \mathcal{P}(\sigma ; \tau)
     \label{eqn:pijcomp_1}
\end{eqnarray}
where $\mathcal{P}(\sigma)$ denotes the largest even-length-prefix-closed subset of $\sigma$ consisting of closed P-i.j.\ plays.

\subsubsection*{The category of incremental strategies}
We say that a strategy is \defname{incremental} if it is closed P-incrementally justified and O-incrementally justified. Hence a strategy $\sigma$ is incremental if and only if
$\sigma = \mathcal{P}(\sigma)$ and $\sigma = \mathcal{O}(\sigma)$.


\begin{proposition}
We have a category $\mathcal{C}_{inc}$ with games as objects, incremental strategies as morphisms, and composition of $\sigma:A\rightarrow B$ and $\mu : B\rightarrow C$ defined as $\mathcal{O}(\sigma;\mu)$.
\end{proposition}
\proof
The proof is identical to the proof of Proposition 3.6.3 in \cite{Harmer2005}, using Lemma \ref{lem:oij_decomp}. \qed


We write $\mathcal{C}_{inc.ib}$, $\mathcal{C}_{inc.b}$ and
$\mathcal{C}_{inc.i}$ to denote the lluf subcategories of innocent, well-bracketed and innocent and well-bracketed strategies respectively.


\section{Algorithmic game semantics}

There is an important theorem (\cite{AM97a}) in game semantics
which states that two IA terms are equivalent if and only if the set
of complete plays of their game denotations are equal. This result was used in \cite{ghicamccusker00} to show that observational
equivalence for the $IA_2$ fragment of IA is decidable -- the set of
complete plays being representable by regular expressions. In
\cite{Ong02} it was shown that it is still decidable
 for $IA_3+Y_0$. Indeed, for this fragment, the set of complete plays becomes context-free
therefore the problem reduces to the DPDA equivalence problem which
is itself decidable (with an unknown complexity).

Imposing the safety condition should lead to some improvement in
complexity. The complexity of safe $IA_3$ (resp.\ strongly safe $IA_3$) for
instance, must be lower than the complexity of the DPDA equivalence
problem. Moreover the fact that safe $IA_3$ and strongly safe $IA_3$
contain terms whose denotation is context free -- \eg $\lambda f .
f (\lambda x .x )$ -- strongly suggests that its complexity is
strictly higher than the complexity of regular language equivalence.

Murawski \cite{Murawski2003} has shown that observational
equivalence for $\ialgol_4$ is undecidable. The proofs proceeds by
showing that the computations of $\Gamma$-machine -- some variation
of queue machines that are Turing complete -- are representable
using IA terms.

Does this result extend to the safe fragments? For safe \ialgol, it does,
simply because the $IA_4$ term exhibited in \cite{Murawski2003} to
represent computations of the $\Gamma$-machine is also a safe \ialgol\
term. The same argument does not carry over to strongly safe \ialgol\ since
the term is not typable in this language. We do not know whether
observational equivalence is decidable for Strongly Safe $IA_4$.




\torework[Proof that up to order 4, it is conservative to add unsafe contex]
{We recall that \emph{strongly safe \ialgol} $\subseteq$ \emph{safe \ialgol} $\subseteq$ \ialgol.
Up to order $3$, it is conservative, with respect to observational equivalence, to add unsafe context to safe ones.
At order $4$, it is not conservative anymore.
}

\paragraph{Observational equivalence}
\begin{table}
\begin{tabular}{|c|c||c|c|c|c|c|}
    \cline{3-7}
  \multicolumn{2}{c|}{}  & \multicolumn{5}{c|}{Finitary fragments} \\ \hline
  \multirow{2}{*}{$L$} & \multirow{2}{*}{$C[\_]$} &   order 2          &  order 2       & order 3     & order 3 & \multirow{2}{*}{order 4}  \\
                       &                          &    + while         &   + $Y_1$      & + while     & +$Y_0$  &          \\ \hline \hline

  \multirow{4}{*}{IA}  & \multirow{2}{*}{IA}      & \multirow{4}{2cm}{PSPACE$^{(1)}$ \\ {\small $\preccurlyeq$ DFA}} & \multirow{4}{*}{U$^{(2)}$} & \multirow{4}{2.8cm}{EXP-complete$^{(3)}$ \\ {\small $\preccurlyeq$ VPA} }  & \multirow{4}{2cm}{D$^{(4)}$ \\ {\small $\preccurlyeq_{exp}$ DPDA\\ $\succcurlyeq$ DPDA} } & \multirow{2}{*}{U$^{(5)}$}\\
                       &                          &                    &                    &  & & \\
\cline{2-2}\cline{7-7} & \multirow{2}{*}{Safe IA} &                    &                    &  & & \multirow{2}{*}{?} \\
                       &                          &                    &                    &  & & \\ \hline

  \multirow{4}{*}{Safe IA} & \multirow{2}{*}{IA}      & \multirow{4}{2cm}{PSPACE \\ {\small $\preccurlyeq$ DFA}} & \multirow{4}{*}{U} & \multirow{4}{2.3cm}{EXP-complete \\ {\small $\preccurlyeq$ VPA}} & \multirow{4}{2cm}{D \\ {\small $\preccurlyeq_{exp}$ DPDA\\ $\succcurlyeq$ DPDA} } & \multirow{2}{*}{U} \\
                           &                          &                    &                & & & \\
\cline{2-2}\cline{7-7}     & \multirow{2}{*}{Safe IA} &                    &                & & & \multirow{2}{*}{?} \\
                           &                          &                    &                & & & \\ \hline

  \multirow{4}{*}{St. Safe IA} & \multirow{2}{*}{IA}           & \multirow{4}{*}{D} & \multirow{4}{*}{?} & \multirow{4}{*}{D} & \multirow{4}{*}{D} & \multirow{2}{*}{?} \\
                               &                               &                    &                    &                    &                    & \\
\cline{2-2} \cline{7-7}        &  \multirow{2}{*}{St. Safe IA} &                    &                    &                    &                    & \multirow{2}{*}{?} \\
                               &                               &                    &                    &                    &                    & \\ \hline
\end{tabular}
\caption[Complexity of observational equivalence in \ialgol]{Decidability (and complexity) of observational equivalence for some finitary fragments of \ialgol}

U stands for Undecidable and D stands for decidable with unknown complexity, $\preccurlyeq P$ means ``reducible to problem $P$''
and $\succcurlyeq P$ means ``at least as hard as problem $P$''.
\begin{asparaenum}
\item[1.] See \cite{ghicamccusker00}.
\item[2.] Showed by Ong in \cite{OngLics2006}.
\item[3.] See \cite{DBLP:conf/fossacs/MurawskiW05}.
\item[4.] See \cite{DBLP:conf/icalp/MurawskiOW05}.
\item[5.] By encoding of $\Sigma$-machine (turing complete) into IA$_4$, see \cite{murawski03program}.

\end{asparaenum}
\end{table}


\subparagraph*{Observational equivalence for finitary safe $\ialgol_2 + Y_1$}

\begin{theorem}[Ong, LICS 2002 \cite{Ong02}]
Assuming that base types are finite, observational equivalence of 2nd-order IA with $Y_1$ recursion is undecidable.
\end{theorem}

The proof proceeds by reduction of the \textsc{Queue-Halting} problem to the
observational equivalence of two $\ialgol_2 + Y_1$ programs: given a
\textsc{Queue} program $P$, a $IA_2 + Y_1$ term $\entail M_P :\iacom$ is defined such that $M_P$ simulates $P$. $P$ terminates if and only if $M_P$ is equivalent to $\iaskip$. It turns out that the term $M_P$ used in this encoding is safe therefore:
\begin{corollary}
Assuming that base types are finite, observational equivalence of 2nd-order Safe IA with recursion is undecidable.
\end{corollary}

\paragraph{Observational approximation}

Observational approximation has been shown to be undecidable at order $1$ already, for the fragment $IA_1 + Y_0$ (\cite{DBLP:conf/fossacs/MurawskiW05}).


\notetoself{
- Characterization of the set of complete plays for safe \ialgol.
(Easy adaptation of the corresponding result for \ialgol. In the present case however, the proof relies
on the fact that plays of the strategy are O-i.j. (in order for $\alpha$ to be P-i.j.)
}


\section{Expressivity of Safe \ialgol/Strongly Safe \ialgol}

Murawski representability: safe \ialgol\ representable languages are
exactly the context free languages. For strongly safe \ialgol\ however, we
believe that the representable languages are a proper subclass of
the context free languages.


\section{Conclusion and Further work}


What is a model of safe \pcf\ (resp.\ safe \ialgol)?

\torework[model of safe IA]{
- Define the notion of incremental category.

- Show that any incremental category is a model of Safe PCF and that any model of Safe PCF
is an incremental category.

- Show that the category of games and OP-i.j. strategies is an incremental category.

}

