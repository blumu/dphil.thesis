 \label{sec:gamesem}

Game semantics is a very powerful paradigm for giving models of programming languages. It was the first kind of semantics able to provide a \emph{fully abstract model} of the language \pcf, a result which was subsequently extended to other languages. In a nutshell, the term ``full abstraction'' means that the model provides a faithful mathematical characterizations of the language. A natural way to give a semantic account of a language consists therefore in giving a game semantic characterization of it. A question that we will try to answer in this thesis is how does a syntactic restriction such as \emph{safety}
impact on the on the game model of a language? A substantial part of this thesis is devoted to this question (Chapter \ref{chap:concrete_gamesem} and \ref{chap:model}).

This chapter introduces the basic notions of game semantics including the categorical interpretation, the game interpretation of \pcf\ and \ialgol, and the full abstraction results. It concludes by giving a brief summary of some important results in \emph{Algorithmic game semantics}.
For an introduction, we recommend the tutorial by Samson Abramsky  \cite{abramsky:game-semantics-tutorial} on which this chapter is based.
Many details and proofs will be omitted; we refer the reader to \cite{hylandong_pcf, abramsky94full} for a complete description of game semantics. The reader familiar with game semantics may very well consider skipping this chapter altogether as all the definitions and notations introduced here are standard.

\subsection{History}

In the 1950s, Paul Lorenzen invented Game semantics as a new
approach to study semantics of intuitionistic logic \citep{lor61}.
In this setting, the notion of logical truth is modeled using game
theoretic concepts (mainly the existence of winning strategy).

Four decades later, game semantics is used to prove the full completeness of Multiplicative Linear Logic (MLL) \citep{abramsky92games,HO93a}. Shortly after, a connection between games and linear logic was established. Game semantics has then emerged as a new paradigm for the study of formal models for programming languages. The idea is to model the execution of a program as a game played by two protagonists. The Opponent represents the environment and the Proponent represents the system.
The meaning of the program is then modeled by a strategy for the Proponent.


Subsequently, these game-based model have been used to give a solution to the long-standing problem of ``Full abstraction of \pcf'' \citep{abramsky94full, hylandong_pcf,Nickau:lfcs94}.

Based on that major result, and in a more applied direction, games semantics has been used as a new tool for software verification \cite{ghicamccusker00}. This opened-up a new field called Algorithmic Game Semantics \citep{Abr02}.


\subsubsection*{Model of programming languages}

Before the 1980s, there were many approaches to define models for programming languages. Among the successful ones, there were the axiomatic, operational and denotational semantics.
\begin{itemize}
\item Operational semantics gives a meaning to a program by describing the behaviour of a machine executing the program. It is defined formally
by giving a state transition system.
\item Axiomatic semantics defines the behaviour of the program through the use of axioms and is used to prove program correctness
by static analysis of the code of the program.
\item The denotational semantics approach consists in mapping a program to a mathematical structure
having good properties such as compositionality. This mapping is achieved by structural induction on the syntax of the program.
\end{itemize}

In the 1990s, three different independent research groups: Samson
Abramsky, Radhakrishnan Jagadeesan and Pasquale Malacaria
\citep{abramsky94full}, Martin Hyland and Luke Ong
\citep{hylandong_pcf} and Nickau \citep{Nickau:lfcs94} introduced
game semantics, a new kind of semantics, in order to solve a long
standing problem in the semanticists community -- finding a fully
abstract model for \pcf.

\subsubsection*{The problem of full abstraction for \pcf}


The problem of the Full Abstraction for \pcf\ goes back to the
1970s. In \citep{scott93}, Scott gave a model for \pcf\ based on
domain theory. This model gives a sound interpretation of
observational equivalence -- if two terms have the same domain
theoretic interpretation then they are observationally equivalent.
However the converse is not true -- there exist two \pcf\ terms
which are observationally equivalent but have different domain
theoretic denotations. As a result, we say that the model is not
fully abstract.

The key reason why the domain theoretic model of \pcf\ is not fully
abstract is that the parallel-or operator defined by the following
truth table
\begin{center}
\begin{tabular}{l|lll}
p-or  & $\bot$ & tt & ff \\ \hline
$\bot$ & $\bot$ & tt & $\bot$\\
tt & tt & tt & tt\\
ff & $\bot$ & tt & ff\\
\end{tabular}
\end{center}
is not definable as a \pcf\ term. It is possible to create two
different \pcf\ terms that always behave in the same way except when
applied to a term computing p-or. Since p-or is not definable in
\pcf, these two terms will have the same denotation. This implies
that the model is not fully abstract.


It is possible to ``patch'' \pcf\ by adding the operator p-or, the
resulting language ``\pcf+p-or'' becomes fully-abstracted by Scott
domain theoretic model \citep{DBLP:journals/tcs/Plotkin77}. The language we are now dealing with, however,
is strictly more powerful than
\pcf\ since it allows parallel execution of commands whereas \pcf\
only permits sequential execution.

Another approach involves the elimination of the undefinable
elements (like p-or) by strengthening the conditions on the function
used in the model. This approach has been followed by Berry in
\cite{berry-stable,gberry-thesis} where he gives a model based on
stable functions. Stable functions are a class of functions smaller
than the class of strict and continuous function. Unfortunately this
approach did not succeed.

Full abstract models for \pcf\ were found at the same time and independently by three research teams: Abramsky, Jagadeesan and Malacaria \citep{abramsky94full}, Hyland and Ong \citep{hylandong_pcf} and Nickau \citep{Nickau:lfcs94}. These three approaches are all based on game semantics.

The game semantics approach has then been adapted to other varieties of programming paradigms including languages with stores (Idealized Algol), call-by-value \citep{honda99gametheoretic,abramsky98callbyvalue} and call-by-name, general references \citep{DBLP:conf/lics/AbramskyHM98}, polymorphism
\citep{DBLP:journals/apal/AbramskyJ05}, control features
(continuation and exception), non determinism, concurrency. In all these cases, the game semantics model led to a syntax-independent fully abstract model of the corresponding language.

\subsection{Definitions}
\label{sec:catgames}

We now introduce formally the notion of game that will be used in
the following sections to give a model of the programming languages
\pcf\ and Idealized Algol. The definitions are taken from
\cite{abramsky:game-semantics-tutorial, hylandong_pcf,
abramsky94full}.

The games we are interested in are two-players games. The players
are named O for \defname{Opponent} and P for \defname{Proponent}. The game played by O
and P is constrained by the \emph{arena}. The arena defines the
possible moves of the game. By analogy with real board games, the
arena represents the board together with the rules that tell players
how they can make their moves on the board. The analogy with board
game will not go beyond that. Instead, it is better to regard our
games as dialogs between two players: player O interviews player P.
P's goal is to answer the initial question asked by O. P can also
ask questions to O if he needs more precision about O's initial
question. Again, O can ask further question to P. This induces a
flow of questions and answers between O and P that can continue
possibly forever. In game semantics the attention is given to the
study of this flow of questions and answers, the notion of winner of
the game is not a concern.

\subsubsection{Arenas}


Our games have two kinds of moves -- the questions and the answers.
We also distinguish moves played by O and those played by P. An arena is
represented by a directed acyclic graph (DAG) whose nodes correspond
to question moves and leaves correspond to answer moves. It is
formally defined as follows.
\begin{definition}[Arena]
An arena is a structure $\langle M, \lambda, \vdash \rangle$ where:
\begin{itemize}
\item $M$ is the set of possible moves;
\item $(M,\vdash)$ is a directed acyclic graph;

\item $\lambda : M \rightarrow \{ O, P\} \times \{Q, A\}$ is a labelling function indicating whether a given move
    is a question or an answer and whether it can be played by O or P.

    $\lambda = [\lambda^{OP},\lambda^{QA}]$ where $\lambda^{OP} : M \rightarrow  \{ O, P\}$
    and $\lambda^{QA} : M \rightarrow  \{ Q, A\}$.

    \begin{itemize}
    \item If $\lambda^{OP} (m) = O$, we call $m$ an O-move otherwise $m$ is a P-move.
    $\lambda^{QA} (m) = Q$ indicates that $m$ is a question otherwise $m$ is an answer.

    \item a leaf $l$ of the DAG $(M,\vdash)$ satisfies $\lambda^{QA} (l) = A$ and a node
    $n$ satisfies $\lambda^{QA} (n) = Q$.
    \end{itemize}

\item The DAG $(M,\vdash)$ respects the following condition:
    \begin{itemize}
    \item[(e1)] The roots are O-moves: for any root $r$ of $(M,\vdash)$, $\lambda^{OP} (r) =
    O$;
    \item[(e2)] enablers are questions: $m \vdash n  \implies \lambda^{QA}(m) =
    Q$;
    % Or more succinctly, if we write $\dashv$ the relation $\vdash^-1$: $\lambda^{QA} \left( \dashv( (\lambda^{QA})^{-1}(\{A\}) ) \right) = \{ O \}$
    \item[(e3)] a player's move must be justified by a move played by the other player:
         $m\vdash n \implies \lambda^{OP}(m) \neq \lambda^{OP}(n)$.
    \end{itemize}
\end{itemize}
\end{definition}

For will abbreviate the set $\{O,P\} \times \{Q,A\}$ as $\{OQ,OA,PQ,PA\}$. $\overline{\lambda}$ denotes the labelling function obtained from $\lambda$ after swapping players:
\begin{eqnarray*}
\overline{\lambda(m)} &=& OQ \iff \lambda(m) = PQ \\
\mbox{ and } \overline{\lambda(m)} &=& OA \iff \lambda(m) = PA
\end{eqnarray*}

The roots of the DAG $(M,\vdash)$ are called the \emph{initial moves}.
Other moves must be enabled by some other question move. The edges of the DAG induces the enabling relation between moves.

The simplest possible arena, written $\mathbf{1}$, is the arena with an empty set of moves.

\begin{example}[The flat arena]
\label{exmp:flatarena}
 Let $A$ be any countable set, then the flat arena over $A$
is defined to be the arena $\langle M, \lambda, \vdash \rangle$ such
that $M$ has one move $q$ with $\lambda(q) = OQ$ and for each
element in $A$, there is a corresponding move $a_i$ in $M$ with
$\lambda(a_i) = PA$ for some $i \in \nat$. The enabling relation
$\vdash$ is defined to be $\{ q \vdash a_i \ | i \in \nat \}$.
This arena is represented by the tree \begin{tikzpicture}[baseline=(root.base),level distance=7mm,inner ysep=0.5mm,sibling distance=5mm]
\node (root) {$q$}
child {node {$a_0$}}
child {node {$a_1$}}
child {node {$\ldots$}};
\end{tikzpicture}
 whose vertices represent the moves and edges represent the enabling relation. In the rest of this thesis we will just write $\nat$ to mean the flat arena over $\nat$.
\end{example}

Once the arena has been defined, the bases of the game are set and the players have something to play with.
We now need to describe the state of the game, for that purpose
we introduce \emph{justified sequences of moves}:
\begin{definition}[Justified sequence of moves]
A justified sequence is a sequence of moves $s$ together with an
associated sequence of pointers. Any move $m$ in the sequence that
is not initial has a pointer that points to a previous move $n$ that
justifies it (\ie $n \vdash m$).
\end{definition}
Since initial moves are all O-moves, the first move of a justified
sequence is necessarily an O-move

A justified sequence can be encoded as a sequence of pairs -- a pair
encodes an element of the sequence together with an index indicating
the position where the element points to.

The pointers of a justified sequence are represented with arrows.
The following is an example of justified sequence of moves:
$$\Pstr{ (q4){q^4}\ (q3-q4){q^3}\  (q2-q3){q^2}\ (q3b-q4){q^3}\ (q2b-q3b){q^2}\ (q1){q^1}\
}$$

Sequences of moves will be used to record the history of all the
moves that have been played.
\bigskip

\emph{Notation:} we write $s t$ or sometimes $s \cdot
t$ to denote the sequences obtained by concatenating $s$ and $t$.
The empty sequence is written $\epsilon$. Given a sequence $s = m_1
\cdot m_2 \ldots m_n$ we write $s_{\leq m_i}$ for $m_1 \cdot m_2
\ldots m_i$, the prefix sequence of $s$ up to the move $m_i$. We
write $s_{< m_i}$ for $m_1 \cdot m_2 \ldots m_{i-1}$.


A justified sequence has two particular subsequences called the P-view and the O-view
of the sequence. The idea is that a view describes the local context
of the game. Here is the formal definition:
\begin{definition}[View]
\notation{$\pview{s}$}{Proponent view of a justified sequence of move}
Given a justified sequence of moves $s$, the \index{P-view}\defname[view!P-view]{Proponent view} (P-view) written $\pview{s}$ is defined by induction as follows:
\begin{align*}
\pview{\epsilon} &= \epsilon, \\
\pview{s \cdot m} &= \pview{s} \cdot \ m && \mbox{ if $m$ is a P-move}, \\
\pview{s \cdot m} &= m && \mbox{ if $m$ is initial (O-move) }, \\
\pview{ \Pstr{ s \cdot (m){m} \cdot t \cdot (n-m){n}} } &=
     \Pstr{ \pview{s} \cdot (m2){m} \cdot (n2-m2){n}} && \mbox{ if $n$ is a non initial O-move
 }.
\end{align*}
\notation{$\oview{s}$}{Opponent view of a justified sequence of move}
The \index{O-view}\defname[view!O-view]{O-view} $\oview{s}$ is defined similarly:
\begin{align*}
\oview{\epsilon} &= \epsilon, \\
\oview{s \cdot m} &= \oview{s} \cdot \ m && \mbox{ if $m$ is a O-move}, \\
\oview{ \Pstr{ s \cdot (m){m} \cdot t \cdot (n-m){n} } } &=
\Pstr{ \pview{s} \cdot (m2){m} \cdot (n2-m2){n} } && \mbox{ if $n$ is a P-move
 }.
\end{align*}
\end{definition}


\subsubsection{Games}
\label{sec:games}

Not all justified sequences will be of interest for the
games that we will use. We call \emph{legal position} justified
sequences that satisfy two additional conditions: alternation and
visibility. Alternation says that players O and P play
alternatively. Visibility expresses that each non-initial move is
justified by a move situated in the local context at that point.
The visibility condition gives some coherence to the
justification pointers of the sequence.

\begin{definition}[Legal position]
A legal position is a justified sequence of move $s$ respecting the following constraints:
\begin{itemize}
\item \index{alternation}\emph{Alternation}: For any subsequence $m \cdot n$ of $s$, $\lambda^{OP}(m) \neq \lambda^{OP}(n)$.
\item \index{visibility}\emph{Visibility}: For any subsequence $t m$ of $s$ where $m$ is not initial, if $m$ is a P-move then $m$ points to a move in $\pview{s}$
and if $m$ is a O-move then $m$ points to a move in $\oview{s}$.
\end{itemize}
The set of legal position of an arena $A$ is denoted by $L_A$.
\end{definition}

We say that a move $n$ is hereditarily justified by a move $m$ if there is a sequence of move
$m_1, \ldots, m_q$ such that:
$$ m \vdash m_1 \vdash m_2 \vdash \ldots m_q \vdash n$$
If a move has no justification pointer, we says that it is an
\emph{initial move} (in that case it must be a root of the DAG of the arena).

Suppose that $n$ is an occurrence of a move in the sequence $s$ then
$s \filter n$ denotes the subsequence of $s$ containing all
the moves hereditarily justified by $n$. Similarly, $s
\filter I$ denotes the subsequence of $s$ containing all the
moves hereditarily justified by moves in $I$.

\begin{definition}[Game]
A game is a structure $\langle M, \lambda, \vdash, P \rangle$ such that
\begin{itemize}
\item $ \langle M, \lambda, \vdash \rangle$ is an arena;
\item $P$ is called the set of valid positions, it is:
    \begin{itemize}
    \item a non-empty prefix closed subset of the set of legal
    positions,
    \item closed by initial hereditary projection: if $s$ is a valid position then for any set $I$ of occurrences of initial moves
    in $s$, $s\filter I$ is also a valid position.
    \end{itemize}
\end{itemize}
\end{definition}

\begin{example}Consider the flat arena  $\nat$.
The set of valid position $P = \{ \epsilon, q \} \union \{ q \cdot
a_i \ | i \in \nat \}$ defines a game on the arena $\nat$.
\end{example}

\subsubsection{Constructions on games}
\label{sec:gameconstruction}

We now define game constructors that will be useful later on.

Consider the two functions $f : A \rightarrow C$ and $g : B
\rightarrow C$, we write $[f,g]$ to denote the pairing of $f$ and
$g$ defined on the direct sum $A + B$. Given a game $A$ with a set
of moves $M_A$, we use the projection operator $s \filter A$ to
denote the subsequence of $s$ consisting of all moves in $M_A$.
Although this notation conflicts with the hereditary projection
operator, it should not cause any confusion.

\paragraph{Tensor product}
Given two games $A$ and $B$ the tensor product
$A \otimes B$ is defined as:
\begin{eqnarray*}
  M_{A \otimes B} &=& M_A + M_B \\
  \lambda_{A\otimes B} &=& [\lambda_A,\lambda_B] \\
  \vdash_{A\otimes B} & = & \vdash_{A}\ \union\ \vdash_{B} \\
  P_{A\otimes B} & = & \{ s \in L_{A\otimes B} | s \filter A \in P_A \wedge s \filter B \in P_B  \}.
\end{eqnarray*}

In particular,  $n$ is initial in $A\otimes B$ if and only if $n$ is
initial in A or B. And $m \vdash_{A\otimes B} n$  holds if and only if $m
\vdash_{A} n$ or $m \vdash_{B} n$ holds.

\paragraph{Function space}
The game $A \multimap B$ is defined as follows:
\begin{eqnarray*}
  M_{A \multimap B} &=& M_A + M_B \\
  \lambda_{A\multimap B} &=& [\overline{\lambda_A},\lambda_B] \\
  \vdash_{A\multimap B} & = & \vdash_{A}\ \union\ \vdash_{B}\ \union\  \{ (m,n) \ |\ m \mbox{ initial in } B \wedge n \mbox{ initial in } A \} \\
  P_{A\otimes B} & = & \{ s \in L_{A\otimes B} | s \filter A \in P_A \wedge s \filter B \in P_B  \}.
\end{eqnarray*}

%Graphically if we draw a triangle to represent an arena $A$ then the
%arena for $A \multimap B$ is represented as:
%\begin{center}
%\begin{tikzpicture}[baseline=(A.base),inner ysep=0.5mm,shape border rotate=90, isosceles triangle]
%\path  node[draw] (A)  {$B$}
%(-1.5cm,-0.7cm) node[draw] (B) {$A$} ;
%\path (A.north) edge (B.north);
%\end{tikzpicture}
%\end{center}
%


\paragraph{Cartesian product}
The game $A \& B$ is defined as follows:
\begin{eqnarray*}
  M_{A \& B} &=& M_A + M_B \\
  \lambda_{A\& B} &=& [\lambda_A,\lambda_B] \\
  \vdash_{A\& B} & = & \vdash_{A}\ \union\ \vdash_{B} \\
  P_{A\& B} & = & \{ s \in L_{A\otimes B} | s \filter A \in P_A \wedge s \ \filter B = \epsilon  \} \\
        &&   \union \{ s \in L_{A\otimes B} | s \filter A \in P_B \wedge s \ \filter A = \epsilon  \}.
\end{eqnarray*}

Note that a play of the game $A \& B$ is either a play of $A$ or a
play of $B$, whereas a play of the game $A \otimes B$ may be an
interleaving of plays on $A$ and plays on $B$.

\subsubsection{Representation of plays}

Plays of the game are usually represented in a table diagram. The
columns of the table correspond to the different components of the
arena and each row corresponds to one move in the play. The first
row always represents an O-move, this is because O is the only
player who can open a game (since roots of the arena are O-moves).

For example the play
$\Pstr[0.5cm]{ (q1){q}\
 (q2-q1){q}
 \ (a2-q2){8}
\  (a1-q1){12}}$ on the game $\nat \multimap
\nat$ is represented by the following diagram:
$$
\begin{array}{cccc}
\nat & \multimap & \nat & \\
&& q & O\\
q  &&& P\\
8  &&& O\\
&& 12 & P
\end{array}
$$
When necessary, we will also represent the justification pointers on the diagram.


\subsubsection{Strategy}

During a game, the player who has to play may have several choices
for his next move. A strategy is a guide telling the player which move to make when the game is in a given position. There is no notion of winning strategy since this is not relevant for the games that we are considering.
Formally, a strategy is a partial function mapping legal positions
where P has to play to P-moves.
\begin{definition}
\label{dfn:strategy}
A \defname{strategy} for player P on a given game $\langle M, \lambda, \vdash, P \rangle$ is a
non-empty set of even-length positions from $P$ such that:
\begin{enumerate}
\item if $sab \in \sigma$ then $s \in \sigma$ (\emph{no unreachable
position});
\item if $sab, sac \in \sigma$ then $b = c$  and $b$ has the same justifier as
$c$ (\emph{determinacy}).
\end{enumerate}
\end{definition}

The idea is that the presence of the even-length sequence $s a b$ in
$\sigma$ tells the player P that whenever the game is in position
$s$ and player O plays the move $a$ then it must respond by playing
the move $b$. The first condition ensures that the strategy $\sigma$ only
considers positions that the strategy itself could have led to in a
previous move. The second condition in the definition requires that
this choice of move is deterministic (\ie there is a function $f$
from the set of odd length position to the set of moves $M$ such
that $f(s a) = b$).


For any game $A$, the smallest possible strategy is called the
\emph{empty strategy} and written $\bot$. It is formally defined by
$\{ \epsilon \}$, which corresponds to a strategy that never
responds.


\begin{remark}
\label{rem:atlern_strategy} There is an alternative definition for
strategies. If we regard a strategy as an appropriated sub-tree of the game tree then it can be represented as the collection of all paths
in this sub-tree, \ie some prefix-closed set (as opposed to ``\emph{even-length prefix}-closed set'' as in the above
definition).

If $\sigma$ denotes a strategy in the sense of definition \ref{dfn:strategy} then the corresponding strategy in the alternative definition is given by
$\sigma \union \textsf{dom}(\sigma)$ where $\textsf{dom}(\sigma)$ is the domain of $\sigma$ defined as
$$\textsf{dom}(\sigma) = \{ sa \in P_A^{odd} | \exists b . sab \in \sigma \}.$$
\end{remark}


\paragraph{Copy-cat strategy}

For any arena $A$ there is a strategy on the game $A \multimap A$
called the \emphind{copy-cat strategy}. We write $A_1$ and $A_2$ to
denote the first and second copies of the arena $A$ in the game $A
\multimap A$. If $A$ is the arena $A_1$ then $A^\perp$ denotes the
arena $A_2$ and conversely.

Let $A$ be one of the arena $A_1$ or $A_2$. The copy-cat strategy
operates as follows: whenever P has to respond to an O-move played
in $A$, it first replicates this move into the arena $A^{\perp}$.
$O$ then responds in $A^{\perp}$ and finally $P$ replicates O's
response back to $A$.


It is formally defined by:
$$ \textsf{id}_A = \{ s \in P^{\textsf{even}}_{A \multimap A} \ | \ \forall t \prefixof^{\textsf{even}} s\ .\ t \filter A_1 = t \filter A_2 \}$$
where $P^{\textsf{even}}_A$ denotes the set of valid positions of
even length in the game $A$ and $t \prefixof^{\textsf{even}} s$
denotes that $t$ is an even length prefix of $s$.

The copy-cat strategy is also called \emph{identity strategy} since
it is the identity for strategy composition as we will see in the
next paragraph.

\begin{example} The copy-cat strategy on $\nat$ is given by the following generic play:
$$\begin{array}{ccc}
\nat & \multimap & \nat \\
&& q\\
q \\
n \\
&& n
\end{array}
$$
Note that we introduced this type of diagram in the first place in
order to represent plays but, as we can see here, whenever the
represented play is general enough, the diagram can be used to
represent strategies.

The copy-cat strategy on $\nat\multimap\nat$ is given
by the following diagram:
$$\begin{array}{ccccccc}
(\nat & \multimap & \nat) & \multimap & (\nat & \multimap & \nat) \\
&&&& && q\\
&& q\\
q \\
&&&& q \\
&&&& m \\
m\\
&& n \\
&&&& && n
\end{array}$$
\end{example}

\subsubsection{Composition}
\label{sec:strategy_composition}

Game semantics is used to give a model of higher-order functional languages, and in particular of the simply typed lambda calculus.
It is well-known that any such model underlies a cartesian closed category \citep{CroleRL:catt}. The notion of morphism composition in the category
is incarnated by a notion of strategy composition.  This feature is essential as we will see that computing the denotation of a composite program boils down to composing the denotation of its constituent programs.



\begin{definition}[Interaction sequence]
Let $u$ be a sequence of moves from games $A$, $B$ and $C$ together with justification pointers from all moves except those initial in $C$.
The \defname{projection} of $s$ on the game $A \multimap B$, written $u \filter A,B$ is the subsequence of $s$ obtained by removing from $u$ the moves in $C$ and pointers to moves in $C$. The projection on $B \multimap
C$ is defined similarly.

An \defname{interaction sequence} is a sequence of moves with pointers from $A$, $B$ and $C$ such that $u\filter A,B$ and $u\filter B,C$ are legal positions of the game $A\gamear B$ and $B\gamear C$ respectively. We write $Int(A,B,C)$ for the set of all such sequences.
\end{definition}

We define the projection on the game $A \multimap C$ as follows: $u \filter A,C$ is the subsequence of $u$ consisting of the moves from $A$ and $C$ with some additional pointers. We add a pointer from $a \in A$ to $c\in C$ whenever $a$ points to some move $b \in B$ itself pointing to $c$. All the
pointers to moves in $B$ are removed.



%For a given legal position $s$ in the game $A \multimap C$, there is a particular sequence called the \defname{uncovering} of $s$.
%It is formally defined as the the maximal justified sequence of moves $u$
%from the games $A$, $B$ and $C$ such that:
%\begin{itemize}
%\item The sequence $s$, considered as a pointer-less sequence, is a subsequence of
%$u$;
%\item the projection of $u$ on the game $A \multimap B$ belongs to the
%strategy $\sigma$;
%\item the projection of $u$ on the game $B \multimap C$ belongs
%to the strategy $\tau$;
%\item and the projection of $u$ on the game $A \multimap C$ is a subsequence of $s$ (here the term ``subsequence'' refers to the sequence of nodes together with the auxiliary sequence of pointers).
%\end{itemize}
%This uncovering, written $uncover(s, \sigma, \tau)$, is
%defined uniquely for given strategies $\sigma$, $\tau$ and legal
%position $s$ (this is proved in part II of \cite{hylandong_pcf}).

Given two strategies $\sigma : A \multimap B$ and $\tau : B \multimap C$, the \defname{interaction} $\sigma \| \tau $ of $\sigma$ and $\tau$ is defined as
%the set of uncovering of legal positions in $A \multimap C$:
%$$ \sigma \| \tau = \{ uncover(s, \sigma, \tau) \ | \ s \mbox{ is a legal position in } A \multimap C \}$$
$$ \sigma \| \tau = \{ u \in Int(A,B,C) \ | \ u \filter A,B \in \sigma \zand u\filter B,C \in \tau \} \ .$$
%The composition of $\sigma$ and $\tau$ is defined to be the set of
%projections of uncovering of legal positions in $A \multimap C$:
\begin{definition}[Strategy composition\index{strategy composition}\index{composition of strategy}]
Let $\sigma : A \multimap B$ and  $\tau : B \multimap C$ be two
strategies. The \defname{composite} $\sigma ; \tau$ is defined as:
$$ \sigma ; \tau = \{ u \filter A,C \ | \ u \in \sigma \|
\tau \} \ .$$
\end{definition}
This way of composing strategies is often summarized
as performing ``parallel composition plus hiding'' as defined in the trace semantics of CSP \citep{hoare_csp}.

It can be verified that composition is well-defined, associative and that the copy-cat strategy $\textsf{id}_A$ is the identity for composition \citep{hylandong_pcf}.

\subsubsection{Constraint on strategies}

Different classes of strategies will be considered depending on the
features of the language that we want to model. Here is a list of
common restrictions that we will consider:
\begin{itemize}
\item  \index{well-bracketing|see{strategy well-bracketed}}\index{strategy!well-bracketed}\emph{Well-bracketing:}
We call \emphind{pending question} the last question in a sequence that has not been answered.
A strategy $\sigma$ is well-bracketed if for every play $s \cdot m \in \sigma$ where $m$ is an answer, $m$ points to the pending question in $s$.

\item \index{strategy!history-free}\emph{History-free strategies:} a strategy is history-free if the Proponent's move at any position of the game where he has to play
is determined by the last move of the Opponent. In other words, the
history prior to the last move is ignored by the Proponent when
deciding how to respond.

\item \index{strategy!history-sensitive}\emph{History-sensitive strategies:} The Proponent follows a history-sensitive strategy if he needs to have access to the full
history of the moves in order to decide which move to make.

\item \index{innocence|see{strategy innocent}}\index{strategy!innocent}\emph{Innocence:} In these strategies, the Proponent determines his next move based solely on a restricted view of the history of the play, namely the P-view at that point. It always plays the same move when the game is in a given P-view. Innocence plays an important role in the modeling of higher-order functional languages.
\end{itemize}

The formal definition of innocence is:
\begin{definition}[Innocence]
Given positions $sab, ta \in L_A$ where $sab$ has even length and
$\pview{sa} = \pview{ta}$, there is a unique extension of $ta$ by
the move $b$ together with a justification pointer such that
$\pview{sab} = \pview{tab}$. We write this extension
$\textsf{match}(sab,ta)$.

The strategy $\sigma:A$ is \index{innocence}\defname[strategy!innocent]{innocent} if and only if:
$$ \left(
     \begin{array}{c}
       \pview{sa} = \pview{ta} \\
       sab \in \sigma \\
       t\in \sigma \wedge ta \in P_A \\
     \end{array}
   \right)
\quad \imp\quad  \textsf{match}(sab,ta) \in \sigma$$
\end{definition}

Since the next move is determined by the P-view, an innocent strategy induces a partial function mapping P-views to P-moves called the \defname{view function}. Not every partial function from P-views to P-moves gives
rise to an innocent strategy, however. A sufficient condition is given in
\cite{hylandong_pcf}.


\subsection{On the necessity of justification pointers}
\label{subsec:pointer_necessary}

For any legal justified sequence of moves $s$, we write $?(s)$ for
the subsequence of $s$ obtained by keeping only the unanswered
questions in $s$. It is easy to check that if $s$ satisfies
alternation then $?(s)$ also satisfies alternation.

\begin{lemma}
  If $s\cdot q$ is a legal position (\ie justified sequence satisfying visibility and alternation) satisfying well-bracketing where $q$ is a non-initial question then $q$ points in $?(s)$.
\end{lemma}
\begin{proof}
    By induction on the length of $s \cdot q$. The base case $s=\epsilon$ is trivial.
    Let $s = s\cdot q$, where $q$ is not initial.

    Suppose $q$ is a P-move. We prove that $q$ cannot point to an O-question that has been answered.
    Suppose that an O-move $q'$ occurs before $q$ and is answered by the move $a$ also occurring before $q$.
    Then we have $s = s_1 \cdot q'^O \cdot s_2 \cdot a^P \cdot s_3 \cdot q^P$ where $a$ is justified by $q'$.
    $a$ is not in the P-view $\pview{s_{<q}}$. Indeed this would imply that some O-move occurring in $s_3$ points to $a$, but this is impossible
    since answer moves are not enablers. Hence the move $a$ must be situated underneath an O-to-P link. Let us note $m$ the origin of this link,
    the P-view of $s$ has the following form: $\pview{s} = \pview{s_1\cdot q'^O \cdot s_2 \cdot a^P \ldots m^O} \ldots q^P$ where $m$ is an O-move pointing before $a$.

    If $m$ is an answer move then it must point to the last unanswered move -- that is to say the last move in $?(s_{<m})$.
    If $m$ is a question move then it is not initial since there is a link going from $m$. Therefore by the induction hypothesis, $m$ must point
    to a move in $?(s_{<m})$.

    Since $s$ is well bracketed, all the questions in the segment $q'\ldots a$ are answered.
    Therefore since $m$ points to an unanswered question occurring before $a$, $m$ must
    point to a move occurring strictly before $q'$. Consequently $q'$ does not occur in the P-view $\pview{s}$.
    By visibility, $q$ must point in the P-view $\pview{s}$ therefore $q$ does not point to $q'$.

    A similar argument holds if $q$ is an O-move.
\end{proof}

This means that in a well-bracketed legal position $s\cdot m$ where
$m$ is not initial, $m$'s justifier is a question occurring in
$?(s)$. Also if $m$ is an answer then its justifier is precisely the
\emph{last} question in $?(s)$. Furthermore, if $m$ is a P-move then
by visibility it should point to an unanswered question in
$\pview{m}$ therefore it should also point in $?(\pview{m})$.
Similarly, if $m$ is a non initial O-move then it points in
$?(\oview{m})$.

\begin{lemma}
\label{lem:views_and_questionmarkfilter} Let $s$ be a legal
well-bracketed position.
\begin{enumerate}[(i)]
\item If $s=\epsilon$ or if the last move in $s$ is not a P-answer then $?(\pview{s}) = \pview{?(s)}$;
\item If $s=\epsilon$ or if the last move in $s$ is not an O-answer then $?(\oview{s}) = \oview{?(s)}$.
\end{enumerate}
\end{lemma}
\begin{proof}
(i) By induction on the length of $s$. The base case is trivial.
Step case: suppose that $s \cdot m$ is a legal well-bracketed position.

If $m$ is an initial O-question then $?(\pview{s \cdot m}) = ?(m) = m = \pview{?(s) \cdot m} = \pview{?(s \cdot m)}$.

If $m$ is a non initial O-question then
$s \cdot m^O = s' \cdot q^P \cdot s'' \cdot m^O$ where $m$ is justified by $q$.
We have $?(\pview{s}) = ?(\pview{s'} \cdot q \cdot  m) = ?(\pview{s'}) \cdot q \cdot m$.
If $s'$ is not empty then its last move must be an O-move (by alternation), therefore by the induction hypothesis
$?(\pview{s'})= ?(\pview{?(s')})$.
By the previous lemma, the move $m$ must point in $?(s)$ therefore we have
$?(s \cdot m) = ?(s') \cdot q^P \cdot u \cdot m^O$ for some sequence $u$. And therefore
$\pview{?(s \cdot m)} = \pview{?(s')} \cdot q^P \cdot m^O$.

If $m$ is an O-answer then $s \cdot m = s' \cdot q^P \cdot s'' \cdot m^O$ where $m$ is justified by $q$.
Then $?(\pview{s\cdot m}) = ?(\pview{s'} q a) = ?(\pview{s'})$.
Moreover since $s$ is well-bracketed, we have $?(s) = ?(s')$.
Again the induction hypothesis permits us to conclude.

If $m$ is a P-question then $\pview{s \cdot m} = \pview{s} \cdot m$
and $?(\pview{s \cdot m}) = ?(\pview{s}) \cdot m$. Moreover
$\pview{?(s \cdot m)} = \pview{?(s) \cdot m} = \pview{?(s)} \cdot
m$. By alternation if $s$ is not empty it must end with an O-move
and the induction hypothesis permits us to conclude.


(ii) The argument is similar to (i).
\end{proof}

Note that in (i) and (ii), it is important that $s$
does not end with a P-answer. For instance consider the legal
position
    $$\Pstr{s = (q0){q_0^O} \  (q1-q0){q_1^P} \ (q2-q1){q_2^O} \  (q3-q2){q_3^P} \ (q4-q1){q_4^O}
    (a-q4){a^P} }$$
 ending with a P-answer. We have $\pview{?(s)} =
\pview{q_0 \cdot q_1 \cdot q_2 \cdot q_3} = q_0 \cdot q_1 \cdot q_2
\cdot q_3$ but $?(\pview{s}) = ?(q_0 \cdot q_1 \cdot q_4 \cdot a) =
q_0 \cdot q_1 \cdot q_4$.
\bigskip


By the previous remark and lemma we obtain the following corollary:
\begin{corollary}
\label{cor:pendingview}
Let $s \cdot m$ be a legal well-bracketed position.
\begin{enumerate}
\item If $m$ is a P-move then it points in $?(\pview{s}) = \pview{?(s)}$;
\item if $m$ is a non initial O-move then it points in $?(\oview{s}) = \oview{?(s)}$.
\end{enumerate}

\end{corollary}


Let $\langle M, \lambda, \vdash \rangle$ be a game. The \emphind{height} of a move $m$ in $M$ is the length of the longest chain of enabling moves
$m \vdash m_2 \vdash \ldots \vdash m_h$. The \defname[order!move]{order} of a move $m$ written $\ord{M}$ is defined as its height minus two.
The order of a game $\langle M, \lambda, \vdash \rangle$ is defined as $\max_{m \in M} \ord{m}$.

We make the assumption that each question move in the arena enables at least one answer move. Consequently, order-$0$ moves enable answer moves only.

\begin{lemma}[Pointers are superfluous up to order 2]
\label{lem:ptr_superfluous_atorder2} Let $A$ be an arena of order at
most 2. Let $s$ be a justified sequence of moves in the arena $A$
satisfying  alternation, visibility, well-openedness and well-bracketing. If $s$ contains a single initial move then
the pointers of the sequence $s$ can be uniquely reconstructed from the underlying sequence of moves.
\end{lemma}
\proof
Let $A$ be an arena of order $2$ at most and let $s$ be a legal well-bracketed position in $L_A$. W.l.o.g.\ we can assume that the game $A$ has a single initial move $q_0$.
Indeed, since $s$ is well-opened, its first move $m_0$ is the only initial move in the sequence, thus $m_0$ is the root of some sub-arena $A'$ of $A$. Hence $s$ can be seen as a play on the game $A'$ instead of $A$.

Since $A$ is of order $2$ at most, all the moves in $s$ except $q_0$ are of order $1$ at most.
We prove by induction on the length of $s$ that $?(s)$ corresponds to one of the cases 0, A, B, C, D shown on the table below, and that the pointers in
$s$ can be recovered uniquely. Let $L$ denote the language $L = \{\ p q \ | \ q_0 \vdash p \vdash q
\wedge \ord{p}=1 \wedge \ord{q} = 0 \}$.
\begin{center}
\begin{tabular}{c|c|l|l}
Case & $\lambda_{OP}(m)$ & $?(s) \in$ & where... \\ \hline
0 & O & $\{ \epsilon \}$ \\
A & P & $q_0$ \\
B & O & $q_0 \cdot L^* \cdot p$     & $q_0 \vdash p \quad \wedge\quad  \ord{p}=1$ \\ % $j \in I_1$ \\
C & P & $q_0 \cdot L^* \cdot p q$ & $q_0 \vdash p \vdash q \quad \wedge\quad  \ord{p}=1 \quad \wedge\quad  \ord{q} = 0$ \\ % $j \in I_1$ \\
D & O & $q_0 \cdot L^* \cdot q$      & $q_0 \vdash q \quad \wedge\quad  \ord{q} = 0$ \\ % $i \in I_0$
\end{tabular}
\end{center}

\noindent \emph{Base cases:}
If $s$ is the empty play then there is no pointer to recover and $s$ corresponds to case 0.
If $s$ is a singleton then it must be the initial question $q_0$, so
there is no pointer to recover. This corresponds to case A.

\noindent \emph{Step case:}
If $s = u \cdot m$ for some non empty legal well-bracketed position $u$ and move $m \in M_A$
then by the induction hypothesis the pointers in $u$ can all be recovered and $u$ corresponds to one of the
cases 0, A, B, C or D.
We proceed by case analysis:
\begin{asparadesc}
\item[case 0] $?(u) = \epsilon$. By corollary \ref{cor:pendingview}, $m$ points in $\pview{?(u)} = \epsilon$.
                Hence this case is impossible.

\item[case A] $?(u) = q_0$ and the last move $m$ is played by P.
    By corollary \ref{cor:pendingview}, $m$ points to $q_0$.
    If $m$ is an answer to the initial question $q_0$ then $s$ is a complete play and $?(s) = \epsilon$, which corresponds to case 0.
    If $m$ is a first order question then $?(s)= q_0 p$ and it is O's turn to play after $s$ therefore $s$ falls into category B.
    If $m$ is an order 0 question then $s$ falls into category D.

\item[case B] $?(u) \in q_0 \cdot L^* \cdot p$ where $\ord{p} = 1$ and $m$ is an O-move.
By corollary \ref{cor:pendingview}, $m$ points in $\pview{?(u)} = q_0 p$. Since $m$ is an O-move it can only point to $p$.
If $m$ is an answer to $p$ then $?(s) = ?(u \cdot m) \in q_0 \cdot L^*$ which is covered by case A and C.
If $m$ is an order 0 question pointing to $p$ then we have $?(s) = ?(u) \cdot m \in q_0 \cdot L^* \cdot p m$ and $s$ falls into category C.


\item[case C] $?(u) \in q_0 \cdot L^* \cdot p q$ where $\ord{p} = 1$, $\ord{q} = 0$, $q_0$ justifies $p$, $p$ justifies $q$
                 and $m$ is played by $P$.

Suppose that $m$ is an answer, then the well-bracketing condition imposes
$q$ to be answered first. The move $m$ therefore points to $q$ and we have $?(s) = ?(u \cdot m) \in  q_0 \cdot L^* \cdot p$. This corresponds to case B.

Suppose that $m$ is a question. $m$ is a P-move therefore is cannot be justified by $p$.
It cannot be justified by $q$ either because $q$ is an order $0$ question and therefore enables answer moves only.
Similarly $m$ is not justified by any move in $L^*$.
Hence $m$ must point to the initial question $q_0$.
There are two sub-cases, either $m$ is an order $0$ move and then $s$ falls into category D
or $m$ is an order $1$ move and $s$ falls into category B.


\item[case D] $?(u) \in q_0 \cdot L^* \cdot q$ where $\ord{q} = 0$ and $m$ is played by $O$.

Again by corollary \ref{cor:pendingview}, $m$ points in $\oview{?(u)} = q_0 q$. Since $m$ is a P-move it can only point to $q$.
Since $q$ is of order 0, it only enables answer moves therefore $m$ is an answer to $q$.
Hence $?(s) = ?(u\cdot m) \in q_0 \cdot L^* $ and $s$ falls either into category A or C.
\qed
\end{asparadesc}
%%% end of proof
\bigskip

Hence for order-2 games, the plays of a strategy are entirely determined by underlying pointer-less sequence of moves. At order 3, however, eliminating pointers causes ambiguities. Take for instance the game $((\nat^1 \typear \nat^2) \typear \nat^3) \typear \nat^4$ and  sequence of moves $s = q^4 q^3 q^2 q^3 q^2 q^1$, where the superscripts indicate the component of the game in which each move is played. Which valid plays have $s$ as their underlying sequence of moves? By the visibility condition,  the pointers of the first five moves are uniquely determined:
$$s = \Pstr[0.4cm]{ (q4){q^4}\ (q3-q4){q^3}\ (q2-q3){q^2}\
(q3b-q4){q^3}\ (q2b-q3b){q^2}\ (q1){q^1} }$$
For the last move, however, there is an ambiguity: its justifier can be any of the two occurrences of $q^2$. The visibility condition does not eliminate this ambiguity since both occurrences of $q^2$ appear in
the P-view $\pview{s} = s$. These two possibilities correspond to two different strategies for the Proponent.


\subsection{Categorical interpretation}

In this section we recall some results about the categorical
representation of games. These results with complete details and
proofs can be found in \cite{McC96b,hylandong_pcf,abramsky94full}.
We refer the reader to \cite{CroleRL:catt} for more information
about category theory.

We consider the category $\mathcal{G}$ whose objects are games and morphisms are strategies. A morphism from $A$ to $B$ is a strategy on the game $A \multimap B$. Three other sub-categories of $\mathcal{G}$ are considered, each of them corresponds to some restriction on strategies: $\mathcal{G}_i$
is the sub-category of $\mathcal{G}$ whose morphisms are the
innocent strategies, $\mathcal{G}_b$ has only the well-bracketed
strategies and $\mathcal{G}_{ib}$ has the innocent and
well-bracketed strategies.

\begin{proposition}
$\mathcal{G}$, $\mathcal{G}_i$, $\mathcal{G}_b$ and $\mathcal{G}_{ib}$ are categories.
\end{proposition}
In particular this means that composition of strategies is
well-defined, associative, has a unit (the copy-cat strategy),
preserves innocence and well-bracketedness. See \cite{hylandong_pcf,abramsky94full} for a proof.


\subsubsection{Monoidal structure}
\label{sec:monoidal}

We have already defined the tensor product on games in section
\ref{sec:gameconstruction}. We now define the corresponding
transformation on morphisms. Given two strategies $\sigma : A
\multimap B$ and $\tau : C \multimap D$ the strategy $\sigma \otimes
\tau : (A \otimes C) \multimap (B\otimes D)$ is defined by:
$$ \sigma \otimes \tau = \{ s \in L_{A \otimes C \multimap B\otimes D} \ s \filter A,B \in \sigma
\wedge s \filter C,D \in \tau \}$$

It can be shown that the tensor product is associative, commutative
and has $I = \langle \emptyset, \emptyset,\emptyset, \{ \epsilon \}
\rangle $ as identity. Hence the game category $\mathcal{G}$ is a
symmetric monoidal category. Moreover $\mathcal{G}_i$ and
$\mathcal{G}_b$ are sub-symmetric monoidal categories of
$\mathcal{G}$, and $\mathcal{G}_{ib}$ is a sub-symmetric monoidal
category of $\mathcal{G}_i$, $\mathcal{G}_b$ and $\mathcal{G}$.

\subsubsection{Closed structure}

Given the games $A$, $B$ and $C$, we can transform strategies on $A\otimes B \multimap C$ to strategies on $A \multimap (B \multimap C)$ by retagging the moves to the appropriate arenas. This transformation defines an isomorphism written $\Lambda_B$ and called \emphind{currying}. Therefore the hom-set $\mathcal{G}(A\otimes B, C)$ is isomorphic to the hom-set $\mathcal{G}(A,B\multimap C)$ which makes $\mathcal{G}$ an autonomous (\ie symmetric monoidal closed) category.

We write $ev_{A,B} : (A \multimap B) \otimes A \rightarrow B$ to denote the \emph{evaluation strategy} obtained by uncurrying the
identity map on $A \rightarrow B$. $ev_{A,B}$ is in fact the copycat strategy for the game
$(A \multimap B) \otimes A \rightarrow B$.

$\mathcal{G}_i$ and  $\mathcal{G}_b$ are sub-autonomous categories of $\mathcal{G}$,
and $\mathcal{G}_{ib}$ is a sub-autonomous category of $\mathcal{G}_i$, $\mathcal{G}_b$ and
$\mathcal{G}$.

\subsubsection{Cartesian product}
\label{sec:pairing}
The cartesian product defined in section \ref{sec:gameconstruction} is indeed a cartesian product in the category
$\mathcal{G}$, $\mathcal{G}_i$, $\mathcal{G}_b$ and $\mathcal{G}_{ib}$.
The projections $\pi_1:A \& B \rightarrow A$ and $\pi_1:A \& B
\rightarrow B$ are given by the obvious copy-cat strategies. Given
two category morphisms $\sigma :C \rightarrow A$ and $\tau : C
\rightarrow B$, the \defname{pairing} morphism $\langle \sigma, \tau \rangle : C \rightarrow A \& B$ is given by:
\begin{eqnarray*}
\langle \sigma, \tau \rangle &=& \{ s \in L_{C\multimap A\&B} \ | \ s \filter C,A \in \sigma \wedge s \filter B = \epsilon  \} \\
&\union& \{ s \in L_{C\multimap A\&B} \ | \ s \filter C,B \in \tau \wedge s \filter A = \epsilon  \}
\end{eqnarray*}

\subsubsection{Cartesian closed structure}
To obtain a cartesian closed category: we need to define a \emph{terminal} object $I$ and the \emph{exponential} construct $A \expar B$ for any two games $A$ and $B$.

For any game $A$ the exponential game $!A$ is defined as follows:
\begin{eqnarray*}
  M_{!A} &=& M_A \\
  \lambda_{!A} &=& \lambda_A \\
  \vdash_{!A} & = & \vdash_{A} \\
  P_{!A} & = & \{ s \in L_{!A} | \mbox{ for each initial move $m$, } s \filter m \in P_A \}
\end{eqnarray*}
This game can be understood as the game multi-threaded version of the game $A$ where a new ``copy'' of the game can be spawned at any time. Thus plays of $!A$ are made of an interleaving of plays of $A$. We have the following identities:
\begin{eqnarray*}
  !(A \& B) &=& !A \otimes !B\\
  I &=& !I
\end{eqnarray*}

A game $A$ is said to be \defname{well-opened} if for any position $s \in P_A$ the only initial move in $s$ is the first one. In a well-opened game, plays contain a single ``thread'' of moves. Given a strategy on a well-opened game, one can turn it into a ``multi-threaded'' strategy using the \emphind{promotion} operator:
\begin{definition}[Promotion]
Consider a well-opened game $B$. Given a strategy on ${!A} \multimap
B$, its \defname{promotion} $\sigma^\dagger : {!A} \multimap {!B}$
is the strategy which plays several copies of $\sigma$. Formally:
$$ \sigma^\dagger = \{ s \in L_{{!A} \multimap !B} \ | \ \mbox{ for all initial $m$, } s \filter m \in \sigma  \}.$$
\end{definition}
It can be shown that promotion is a well-defined strategy and that it preserves innocence and well-bracketing. We now introduce the category of well-opened games:
\begin{definition}[Category of well-opened games]
The category $\mathcal{C}$ of well-opened games, also called the
\emphind{co-Kleisli category} of $\mathcal{G}$, is defined as
follows:
\begin{enumerate}
\item The objects are the well-opened games,
\item a morphism $\sigma : A \rightarrow B$ is a strategy for the game $!A \multimap B$,
\item the identity map for $A$ is the copy-cat strategy on $!A \multimap A$ (which is well-defined for well-opened games).
It is called dereliction, denoted by
$\textsf{der}_A$ and defined formally by:
$$ \textsf{der}_A = \{ s \in P^{\textsf{even}}_{{!A} \multimap A} \ | \ \forall t \prefixof^{\textsf{even}} s \ . \ t \filter {!A} = t \filter A \},$$
\item composition of morphisms $\sigma : {!A} \multimap B$ and $\tau : {!B} \multimap C$
denoted by $\sigma \fatsemi \tau : {!A} \multimap C$ is defined as $\sigma^\dagger;\tau$.
\end{enumerate}
\end{definition}
$\mathcal{C}$ is a well-defined category and has three sub-categories
$\mathcal{C}_i$, $\mathcal{C}_b$, $\mathcal{C}_{ib}$ corresponding respectively to sub-category of innocent, well-bracketed, and innocent and well-bracketed strategies.


The category $\mathcal{C}$ has a terminal object $I$, and for any two games $A$ and $B$,
a product $A \& B$ and an exponential $A \expar B$ defined as $!A \multimap B$. The hom-sets $\mathcal{C}(A \& B,C)$ and $\mathcal{C}(A,!B \multimap C)$ are isomorphic. Indeed:
\begin{eqnarray*}
\mathcal{C}(A\& B,C) &=& \mathcal{G}(!(A\& B),C) \\
&=& \mathcal{G}({!A}\otimes {!B},C) \\
&\cong& \mathcal{G}({!A}, {!B} \multimap C) \qquad  \mbox{($\mathcal{G}$ is a closed monoidal category)}\\
&=& \mathcal{C}(A, {!B} \multimap C)
\end{eqnarray*}
Hence $\mathcal{C}$ is a cartesian closed category. Furthermore $\mathcal{C}_i$ and $\mathcal{C}_b$ are sub-cartesian closed caterogies of $\mathcal{C}$ and $\mathcal{C}_{ib}$ is as sub-cartesian closed category of each of $\mathcal{C}$, $\mathcal{C}_i$ and $\mathcal{C}_b$.


\subsubsection{Order enrichment}

Strategies can be ordered using the inclusion ordering. Under this
ordering, the set of strategies on a given game $A$ is a pointed
directed complete partial order: the least upper bound is given by
the set-theoretic union and the least element is the empty strategy
$\{ \epsilon \}$.

Moreover all the operators on strategies that we have defined so far
(composition, tensor product, ...) are continuous. Hence the categories $\mathcal{C}$ and $\mathcal{G}$ are cpo-enriched.


\subsubsection{Intrinsic preorder}
\label{sec:intrinsic}

Let $\Sigma$ denote the \emphind{Sierpinski game} with a single question $q$ and single answer $a$. There are only two strategies on $\Sigma$: $\bot = \{
\epsilon \}$ and $\top = \{ \epsilon, q a \}$ which are both innocent and well-bracketed. For any object $A$, the \defname{intrinsic preorder} $\lesssim_A$ on the set of strategies on the game $A$ is defined by:
$$ \sigma \lesssim_A \tau \quad \iff \quad \forall \alpha : A \rightarrow \Sigma.\ \sigma \fatsemi \tau = \top \implies \tau \fatsemi \alpha = \top \ .$$
This indeed defines a preorder \cite{abramsky94full}.
The \defname{quotiented category} $\quotient{\mathcal C}{\lesssim}$ is defined as follows. The objects of $\quotient{\mathcal C}{\lesssim}$ are those of $\mathcal{C}$, and the morphisms are the equivalence classes of morphism in $\mathcal{C}$ modulo the equivalence relation induced by $\lesssim$.


We will consider the quotiented categories
$\quotient{\mathcal{C}_\$}{\lesssim_\$}$ where $\$$ ranges in $\{ i, b, ib \}$. The full abstraction of the game semantic model of \pcf\ will be stated in the quotiented category $\quotient{\mathcal{C}_{ib}}{\lesssim_{ib}}$ rather than  $\mathcal{C}_{ib}$.


\subsection{The fully abstract game model of \pcf}

\label{subsec:pcfgamemodel}
In this section we present the fully abstract game model of \pcf\ introduced in \cite{abramsky94full}.

As we have seen in section \ref{sec:catgames}, games and strategies
form a cartesian closed category, therefore games can model the
simply typed $\lambda$-calculus. We are now about to make this
connection explicit by giving the strategy corresponding
to a given $\lambda$-term. We will then extend the game model to \pcf\ and IA.

\subsubsection{Simply typed lambda calculus fragment}

In the games that we are considering, the Opponent represents the
environment and the Proponent represents the lambda term. Opponent
opens the game by asking a question such as ``What is the output of
the function?''. Then the proponent may ask further information
such that ``What is the input of the function?''. O can provide
$P$ with an answer -- the value of the input -- or can pursue with
another question. The dialog goes on until O gets the answer to his
initial question.

O represents the environment, he is responsible for proving input
values while P plays from the term's point of view: he is
responsible for performing the computation and returning the output
to O. P plays according to the strategy that is associated to the
$\lambda$-term being modeled.

We recall that in the cartesian closed category $\mathcal{C}$, the
objects are the games and the morphisms are the strategies. Given a
simple type $A$, we will model it as a game $\sem{A}$. A context
$\Gamma = x_1 :A_1, \ldots x_n:A_n$ will be mapped to the game
$\sem{\Gamma} = \sem{A_1} \times \ldots \times \sem{A_n}$ and a term
$\Gamma \vdash M : A$ will be modeled by a strategy on the game
$\sem{\Gamma} \rightarrow \sem{A}$. Since $\mathcal{C}$ is cartesian
closed, there is a terminal object $\textbf{1}$ (the empty arena)
that models the empty context ($\sem{\Gamma} = \textbf{1}$).


Let $\omega$ denote the set of natural numbers. Consider the
following flat arena over $\omega$:
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=7mm,inner ysep=0.5mm,sibling distance=5mm]
\node (root) {$q$}
child {node {$0$}}
child {node {$1$}}
child {node {$2$}}
child {node {$\ldots$}};
\end{tikzpicture}
\end{center}

Then the base type \iaexp is interpreted by the flat game
$\nat$ over the previous arena where the set of valid position is:
$$P_N = \{ \epsilon, q \} \union \{ qn \ | \ n \in \omega \}$$


In this game, there is only one question: the initial O-question. P
can then answer by playing a natural number $i \in \omega$. There
are only two kinds of strategies on this arena:
\begin{itemize}
\item the empty strategy where P never answer the initial question. This corresponds to a non terminating computation;
\item the strategies where P answers by playing a number $n$. This models a numerical constant of the language.
\end{itemize}

Given the interpretation of base types, the interpretation
of $A\rightarrow B$ is defined by induction as
$$\sem{A \rightarrow B} = \sem{A} \Rightarrow \sem{B}$$
where the operator $\Rightarrow$ denotes the game construction $!A
\multimap B$ \ie the exponential object of the cartesian closed
category $\mathcal{C}$.



Variables are interpreted by projection:
$$\sem{x_1 : A_1, \ldots, x_n:A_n \vdash x_i : A_i} = \pi_i : \sem{A_i} \times \ldots \times \sem{A_i} \times \ldots \times \sem{A_n} \rightarrow  \sem{A_i}$$

The abstraction $\Gamma \vdash \lambda x^A.M : A \rightarrow B$ is
modeled by a strategy on the arena $\sem{\Gamma} \rightarrow
(\sem{A}\Rightarrow\sem{B})$. This strategy is obtained by using the
currying operator of the cartesian closed category:
$$\sem{\Gamma \vdash \lambda x^A.M : A \rightarrow B} = \Lambda( \sem{\Gamma, x :A \vdash M : B})$$

The application $\Gamma \vdash M N$ is modeled using the evaluation
map $ev_{A,B} : (A\Rightarrow B)\times A \rightarrow B$:

$$\sem{\Gamma \vdash M N} = \langle \sem{\Gamma \vdash M, \Gamma \vdash N} \rangle \fatsemi ev_{A,B}$$

\begin{example}[Kierstead terms]
The two strategies from In section \ref{subsec:pointer_necessary} we
have shown that there are two different strategies on the game
$((\nat^1 \typear \nat^2) \typear \nat^3) \typear \nat^4$ containing
a play whose underlying sequence of move is $s = q^4 q^3 q^2 q^3 q^2
q^1$ but whose justification pointers differ.

These two strategies are precisely the denotation of the \emphind{Kierstead terms} defined as follows:
$$M_1 = \lambda f . f (\lambda x . f (\lambda y .y )) : ((\nat \typear \nat) \typear \nat) \typear \nat$$
$$M_2 = \lambda f . f (\lambda x . f (\lambda y .x )) : ((\nat \typear \nat) \typear \nat) \typear \nat$$

Suppose that $q^1$ is justified by the first
occurrence of $q^2$ then it means that the proponent is requesting
the value of the variable $x$ bound in the subterm $\lambda x . f (
\lambda y. ... )$. If P needs to know the value of $x$, this is
because P is in fact following the strategy of the subterm $\lambda
y . x$. This corresponds to a play of the strategy $\sem{M_2}$.
If $q^1$ is justified by the second occurrence of $q^2$ then it is a play of $\sem{M_1}$.
\end{example}


\subsubsection{\pcf\ fragment}

We now show how to model \pcf\ constructs in the game semantics
setting. In the following, each sub-arena of a game is tagged so that it is possible to distinguish identical arenas
occurring in different components of the game. Moves are also tagged (in the exponent) so that it is possible
to identify the arena component in which the move belongs. We will
omit the pointers in the play when there is no ambiguity.

The successor arithmetic operator is modeled by the following
strategy on the arena $\nat^1 \Rightarrow \nat^0$:
$$\sem{\pcfsucc} = \prefset^{\sf even} \{q^0 \cdot q^1 \cdot n^1 \cdot (n+1)^0\ |\ n \in \nat \}$$
where $\prefset^{\sf even} X$ denotes the set consisting of the prefixes of even length of plays of $X$.

The predecessor arithmetic operator is denoted by the strategy
$$\sem{\pcfpred} = \prefset^{\sf even} \left( \{q^0 \cdot q^1 \cdot n^1 \cdot (n-1)^0\ |\ n >0 \} \union \{ q^0 \cdot q^1 \cdot 0^1 \cdot 0^0 \} \right)$$

Then given a term $\Gamma \vdash \pcfsucc\ M : \iaexp$ we
can define:
$$\sem{\Gamma \vdash \pcfsucc\  M : \iaexp} = \sem{\Gamma \vdash M} \fatsemi \sem{\pcfsucc} $$
$$\sem{\Gamma \vdash \pcfpred\  M : \iaexp} = \sem{\Gamma \vdash M} \fatsemi \sem{\pcfpred} $$

The conditional operator is denoted by the following strategy on the
arena $\nat^3 \times \nat^2 \times \nat ^1 \Rightarrow \nat^0$:
$$\sem{\pcfcond} = \prefset^{\sf even}
    \{ q^0 \cdot q^3 \cdot 0 \cdot q^2 \cdot n^2 \cdot n^0 \ | \ n \in \nat \}
    \union
    \prefset^{\sf even}  \{ q^0 \cdot q^3 \cdot m \cdot q^2 \cdot n^2 \cdot n^0 \ | \ m >0, n \in \nat \}
    $$

Given a term $\Gamma \vdash \pcfcond\ M\ N_1\ N_2$ we define:
$$\sem{\Gamma \vdash \pcfcond\ M\ N_1\ N_2} =
\langle \sem{\Gamma \vdash M}, \sem{\Gamma \vdash N_1}, \sem{\Gamma
\vdash N_2} \rangle \fatsemi \sem{\pcfcond}$$


The interpretation of the \texttt{Y} combinator is a bit more
complicated. Consider the term $\Gamma \vdash M : A \rightarrow A$, its semantics
$f$ is a strategy on $\sem{\Gamma} \times \sem{A} \rightarrow
\sem{A}$. We define the chain $g_n$ of strategies on the arena
$\sem{\Gamma} \rightarrow \sem{A}$ as follows:
\begin{eqnarray*}
g_0 &=& \perp \\
g_{n+1} &=&  F(g_n) = \langle id_{\sem{\Gamma}}, g_n\rangle \fatsemi f
\end{eqnarray*}

where $\perp$ denotes the empty strategy $\{ \epsilon \}$. It is easy to see that the $g_n$ forms a chain. The denotation
$\sem{\texttt{Y} M}$ is defined as the least upper bound of the chain $g_n$
\ie the  least fixed point of $F$. Its existence is guaranteed by
the fact that the category of games is cpo-enriched.

Since all the strategies that we have given are innocent and
well-bracketed, the game model of \pcf\ can be interpreted in any of
the four categories $\mathcal{C}$, $\mathcal{C}_i$, $\mathcal{C}_b$,
$\mathcal{C}_{ib}$. The category $\mathcal{C}_{ib}$ is refered as the \defname{intentional game model} of \pcf.


\subsubsection{Observational preorder}

A context denoted $C[-]$ is a term containing a hole denoted by $-$.
If $C[-]$ is a context then $C[M]$ denotes the term obtained after
replacing the hole by the term $M$. $C[M]$ is well-formed provided
that $M$ has the appropriate type. Note that this substitution is done capture-permitting, as opposed to the capture-avoiding
substitution used to contract beta-redexes in the lambda calculus.

\begin{definition}
The \defname{observational preorder} is a relation $\obspre$ on terms defined as follows: for any two closed terms $M$ and $N$ of the same type,
\begin{eqnarray*}
M \obspre N &\iff& \parbox{10cm}{for all context $C[-]$ such that
                $C[M]$ and $C[N]$ are well-formed closed \pcf\ term of type \iaexp, $C[M] \eval$ implies $C[N] \eval$.}
\end{eqnarray*}
The reflexive closure of $\obspre$, denoted $\obseq$, is called the \defname{observational equivalence} relation.
\end{definition}

The intuition behind this definition is that two terms are observationally equivalent if there is no context that distinguishes them, and therefore they can be safely interchanged in any program context.

\subsubsection{Soundness}
We say that the model is \emphind{sound for evaluation} if
the denotation of a term is preserved by the evaluation
relation $\eval$ of the big-step semantics of the language \ie for any term $M$ and value $V$ we have:
$$M \eval V \quad \implies \quad \sem{M} = \sem{V}.$$

\begin{lemma}[\cite{abramsky:game-semantics-tutorial}]
\label{lem:evalsoundness}
The game model of \pcf\ is sound for evaluation.
\end{lemma}

\begin{definition}[Computable terms\index{computable term}] \hfill
\begin{itemize}
\item A closed term $\vdash M : B$ of base type is computable if $\sem{M} \neq \bot$ implies $M \eval$.
\item A higher-order closed term $\vdash M : A\rightarrow B$ is computable if $M N$ is computable for any computable closed term $\vdash  N:A$.
\item An open term $x_1 : A_1, \ldots, x_n : A_n \vdash M : A\rightarrow B$ is computable if $\vdash M [N_1/x_1, \ldots N_n/x_n]$ is computable
for all computable closed terms $N_1:A_1, \ldots, N_n:A_n$.
\end{itemize}
\end{definition}

A model is \defname{computationally adequate} if all terms are computable.
\begin{lemma}[\cite{abramsky:game-semantics-tutorial}]
\label{lem:computadequacy}
The game model of PCF is computationally adequate.
\end{lemma}


A model of a programming language is said to be \defname{sound} if whenever the denotation of two programs are equal then the two programs are observationally
equivalent \ie if for any closed terms $M$ and $N$ of the same type we have:
$$ \sem{M} = \sem{N} \implies M \obseq N \ .$$
The model is said to be \defname{inequationally sound} if the following stronger condition holds
$$ \sem{M} \subseteq \sem{N} \implies M \obspre N \ .$$

Soundness is the minimum one can require for a model of
programming language: it tells us that we can reason about terms
by manipulating objects in the denotational model.

Inequational soundness of \pcf\ follows from the last two lemmas:
\begin{proposition} \label{prop:ineqsoundness}
The game model of \pcf\ is \emph{inequationally sound}.
\end{proposition}
\begin{proof}
Take two two closed \pcf\ terms $M$ and $N$. Suppose that $\sem{M} \subseteq \sem{N}$ then by compositionality of the model we have $\sem{C[M]} \subseteq \sem{C[N]}$. Suppose that $C[M] \eval$ for some context $C[-]$ then
by soundness (Lemma \ref{lem:evalsoundness}) we have $\sem{C[M]} \neq \bot$, which implies $\sem{C[N]} \neq \bot$.
The adequacy of the model (Lemma \ref{lem:computadequacy}) then gives us $C[N] \eval$. Hence $M \obspre N$.
\end{proof}

\subsubsection{Definability}
\label{sec:pcfdefinability}
We now work in the category $\mathcal{C}_{ib}$ of innocent and well-bracketed strategies.
The \emphind{definability} property is the key to the full-abstraction result. It says that every compact element of the model is the denotation of some term.
In $\mathcal{C}_{ib}$, the \defname{compact morphisms} are the innocent strategies with finite view-function.
Due to its economical syntax, \pcf\ does not verify the definability result: there are strategies that are not the
denotation of any term in \pcf. For instance consider the \emph{ternary conditional} strategy acting as follows: it tests the value of its first parameter, if it is equal to $0$ or $1$ then it returns the value of the second or third parameter respectively, otherwise it returns the value of the fourth parameter.
This is illustrated in the left diagram of Figure \ref{fig:casek_denotation}. Such computation can be operationally simulated in \pcf\ by the term $T_3 = \pcfcond\ M\
N_1 (\pcfcond\ (\pcfpred\  M)\  N_2\ N_3)$. The term $T_3$, however, is not denoted by the ternary conditional strategy. Its denotation
is instead given by the right diagram on Figure \ref{fig:casek_denotation}.
\begin{figure}
$$
\begin{array}{ccccccccc}
!\bf N & \otimes & !\bf N & \otimes & !\bf N & \otimes & !\bf N & \multimap & !\bf N \\
&&&&&&&&q \\
q \\
0 \\
&& q \\
&& n \\
&&&&&&&&n \\
\hline
&&&&&&&&q \\
q \\
1 \\
&&&& q \\
&&&& n \\
&&&&&&&&n \\
\hline
&&&&&&&&q \\
q \\
m>1 \\
&&&&&& q \\
&&&&&& n \\
&&&&&&&&n \\
\end{array}
\hspace{0.3cm}
\begin{array}{ccccccccc}
!\bf N & \otimes & !\bf N & \otimes & !\bf N & \otimes & !\bf N & \multimap & !\bf N \\
&&&&&&&&q \\
q \\
0 \\
&& q \\
&& n \\
&&&&&&&&n \\
\hline
&&&&&&&&q \\
q \\
1 \\
q \\
0 \\
&&&& q \\
&&&& n \\
&&&&&&&&n \\
\hline
&&&&&&&&q \\
q \\
m>1 \\
q \\
m-1>0 \\
&&&&&& q \\
&&&&&& n \\
&&&&&&&&n \\
\end{array}
$$
\label{fig:casek_denotation}
\caption[Strategy denotation of the case construct.]{Strategy denotation of $case_3$ (left) and $T_3$ (right).}
\end{figure}

In $\pcf_c$, however, the ternary conditional strategy is definable by the term $case_3$.
In fact, the definability result holds precisely for $\pcf_c$:
\begin{proposition}[Definability]
\label{prop:definability} Let $A$ be a \pcf\ type and $\sigma$ be a compact innocent and well-bracketed
strategy on $A$. There exists a $\pcf_c$ term $M$ such that $\sem{M} = \sigma$.
\end{proposition}

The definability only holds for $\pcf_c$ but crucially, $\pcf_c$ is a conservative extension of \pcf:
if $M$ and $N$ are terms such that for any \pcf-context $C[-]$, $C[M] \eval
\implies C[N] \eval$ then the same is true for any $\pcf_c$-context. (This
is because the $\pcfcase_k$ constructs can all be simulated by
\pcf\ terms with the same operational semantics.)
This property suffices to prove full abstraction of \pcf.

\subsubsection{Full abstraction}
The converse of soundness is called \emph{completeness}: a model is \defname[complete model]{complete} if:
$$ M \obseq N \ \implies\ \sem{M} = \sem{N} \ .$$
Further, if the stronger relation
$$ M \obspre N \ \implies \ \sem{M} \subseteq \sem{N}$$
holds then the model is said to be \defname{inequationally complete}.

A model is \defname{fully abstract} if it is both sound and complete, and
\defname{inequationally fully abstract} if it is inequationally sound and inequationally complete.


Full abstraction of \pcf\ cannot be stated directly in the category $\mathcal{C}_{ib}$. Instead we need to consider the quotiented category
$\quotient{\mathcal{C}_{ib}}{\lesssim_{ib}}$. But first we need to make sure that $\quotient{\mathcal{C}_{ib}}{\lesssim_{ib}}$ is a
model of \pcf. $\quotient{\mathcal{C}_{ib}}{\lesssim_{ib}}$ is a posset-enriched
cartesian closed category. The denotation of the basic types and
constants of \pcf\ can be transposed from $\mathcal{C}_{ib}$ to
$\quotient{\mathcal{C}_{ib}}{\lesssim_{ib}}$. Although it is not known
whether $\quotient{\mathcal{C}_{ib}}{\lesssim_{ib}}$ is enriched over the
category of CPOs, it can be proved that it verifies a condition called \emph{rationality} \citep{abramsky94full} and this suffices to ensure that
$\quotient{\mathcal{C}_{ib}}{\lesssim_{ib}}$ is indeed a model of \pcf. This category will
be referred as the \defname{extensional game model} of \pcf. The full abstraction of the game model then follows from proposition
\ref{prop:ineqsoundness} and \ref{prop:definability}:
\begin{theorem}[Full abstraction \cite{abramsky94full,hylandong_pcf,Nickau:lfcs94}]
Let $M$ and $N$ be two closed \pcf\ terms.
$$\sem{M} \lesssim_{ib} \sem{N} \ \iff \ M \obspre N$$
where $\lesssim_{ib}$ denotes the intrinsic preorder of the category $\mathcal{C}_{ib}$.
\end{theorem}

\subsection{The fully abstract game model of Idealized Algol}
\label{sec:ia_gamemodel}

We now describe the fully abstract game model of \ialgol\ introduced in \cite{abramsky99full}.

All the strategies used to model \pcf\ are well-bracketed and
innocent. To obtain a model of \ialgol, however we need to
introduce strategies that are not innocent. This is necessary to
model the memory cell variable created with the \ianew\ operator.
The intuition is that a cell needs to remember the last value which
was written in it in order to be able to return it when it is read,
and this can only be done by looking at the whole history of moves,
not only those present in the P-view. We therefore restrict our attention to the categories $\mathcal{C}$ and $\mathcal{C}_b$.

\subsubsection*{Base types}

The type \iacom\ is modeled by the flat game with a single initial question \iarun\ and a single answer
\iadone. The idea is that O can request the execution of a command by playing \iarun, P then executes the command
and if it terminates, acknowledges it by playing \texttt{done}.

The variable type \iavar\ is modeled by the game $\tt{com^{\bf
N} \times exp}$ illustrated below:
\begin{center}
\begin{tikzpicture}[baseline=(root.base),level distance=10mm,inner ysep=0.5mm]%,sibling distance=5mm
 \node{\tt{ok}}  [grow'=up]
    child {node {$\tt{write}_0$}}
    child {node {$\tt{write}_1$}}
    child {node {$\tt{write}_2$}}
    child {node {$\ldots$}}
;
\draw +(5,+10mm) node {\tt{read}}
    child {node {$0$}}
    child {node {$1$}}
    child {node {$2$}}
    child {node {$\ldots$}}
;
\end{tikzpicture}
\end{center}

\subsubsection*{Modelling the constants}

\begin{asparaitem}
\item The constant \iaskip\ is interpreted by the strategy $\{ \epsilon, \iarun \cdot \iadone \}$.
\item Sequential composition $\tt{seq_{exp}}$ is interpreted by the following strategy:
$$
\begin{array}{ccccc}
!\iacom & \otimes & ! \iaexp & \stackrel{\iaseq_{\iaexp}}{\multimap} & \iaexp\\
&&&&q\\
\iarun\\
\iadone\\
&&q\\
&&n\\
&&&&n
\end{array}
$$

\item Assignment \iaassign\ and dereferencing \iaderef\ are denoted  by the
following strategies:
$$
\begin{array}{ccccc}
!\iavar & \otimes & ! \iaexp & \stackrel{\iaassign}{\multimap} & \iacom\\
&&&&q\\
&&q\\
&&n\\
\iawrite_n\\
\iaok\\
&&&&\iadone
\end{array}
\hspace{3cm}
\begin{array}{ccccc}
!\iavar & \stackrel{\iaderef}{\multimap} & \iaexp\\
&&q\\
\iaread\\
n\\
&&n
\end{array}
$$

\item \iamkvar\ is modeled by the paired strategy $\langle \iamkvar_{acc} , \iamkvar_{exp}
\rangle$ where $\iamkvar_{acc}$ and $\iamkvar_{exp}$ are the following strategies:
$$
\begin{array}{ccccccc}
!(!\iaexp & \multimap & \iacom) & \otimes & !\iaexp & \stackrel{\iamkvar_{acc}}{\multimap} & \iacom^\omega\\
&&&&&&\iawrite_n\\
&&\iarun\\
q\\
n\\
&&\iadone \\
&&&&&&\iaok
\end{array}
\hspace{0.2cm}
\begin{array}{ccccccc}
!(!\iaexp & \multimap & \iacom) & \otimes & !\iaexp & \stackrel{\iamkvar_{exp}}{\multimap} & \iaexp\\
&&&&&&\iaread\\
&&&&q\\
&&&&n\\
&&&&&&n \\ \  \\ \
\end{array}
$$

\item Block-allocated variable (\ianew): The strategies introduced until now are all innocent. In order to model
the \ianew\ operator, it is necessary to introduce non-innocent strategies,
also called \emphind{knowing strategies}.
We call \defname{memory-cell strategy} the knowing well-bracketed strategy  written $cell : I \multimap !\iavar$ behaving as follows: it responds to \iawrite\ with \iaok\ and responds to
\iaread\ with the last value written or $0$ if no value has yet been
written. The denotation of a term $\Gamma \vdash \ianewin{x}{M} : A$ is then defined as the strategy:
$$ \sem{\Gamma \vdash \ianewin{x}{M} : A} =
(id_{\sem{\Gamma}} \otimes cell) \fatsemi \sem{\Gamma,x:\iavar \vdash M : A}
: !\Gamma \multimap \iacom \ .$$
\end{asparaitem}


\subsubsection*{Full abstraction}

The inequational soundness result can also be proved for \ialgol.
Proving soundness of the evaluation requires a bit more work than in
the \pcf\ case because the store needs to be made explicit. Also, one
needs to define an appropriate notion of \emph{computable term} that
takes into account the presence of stores in the evaluation
semantics. It is also possible to prove that the model is computational
adequate. This implies:
\begin{proposition}[\cite{abramsky94full}]
\label{prop:ia_ineqsoundness} The game model of \ialgol\ is inequationally sound.
\end{proposition}

A result called the Innocent Factorization Theorem \cite{AM97a}, shows that the strategies in $\mathcal{G}_b$ can all be obtained by composing the
non-innocent strategy $cell$ with an innocent strategy. The strategy $cell$ can therefore be viewed as a generic non-innocent strategy. Using this factorization argument,
it is possible to prove the definability result:
\begin{proposition}[Definability]
\label{prop:ia_definability} For any compact well-bracketed
strategy $\sigma$ on a game $A$ denoting a \ialgol\ type, there exists an \ialgol-term $M$ such that $\sem{M} = \sigma$.
\end{proposition}


Full abstraction for the model $\mathcal{C}_b$ is then a consequence of inequational soundness and definability:
\begin{theorem}[Full abstraction]
Let $M$ and $N$ be two closed IA-terms.
$$\sem{M} \lesssim_b \sem{N} \ \iff \ M \obspre N$$
where $\lesssim_b$ denotes the intrinsic preorder of the category
$\mathcal{C}_b$.
\end{theorem}


\subsection{Algorithmic game semantics}
\label{sec:algogamesem}

Game semantics has proved to be a very successful paradigm in fundamental computer science. Following the resolution of the full abstraction problem for \pcf, game semantics was subsequently used to obtain fully abstract models of a variety of programming languages. More recently, game semantics has emerged as a new approach to program verification and program analysis. In \cite{ghicamccusker00,Ghica2003}, the authors identified a fragment of Idealized Algol for which the game denotation of programs can be expressed using regular expressions. Consequently, the observational equivalence problem for this fragment is decidable. This development opened up a new branch of research called \emph{Algorithmic game semantics} which has interesting applications in program verification \cite{agom2003,DBLP:conf/sas/DimovskiGL05}. This section gives a quick overview of some important results in algorithmic game semantics.

\subsubsection{Effective presentability}
The starting point of Algorithmic game semantics is a result shown by Abramsky and McCusker called the Characterization Theorem \citep[Theorem 25]{AM97a}.
We say that a play is \emph{complete}\index{complete play} if it is maximal and all question have been answered. One can be show that for any \ialgol\ type $T$, the complete plays on the game $\sem{T}$ are precisely those in which the initial question has been answered. A game verifying this condition is said to be \emph{simple}\index{simple game} \cite{AM97a}. The characterization theorem can then be stated as follows:
\begin{theorem}[Characterization Theorem for Simple Game (Abramsky, McCusker \cite{AM97a})]
\label{thm:abramskycusker_charac}
Let $\sigma$ and $\tau$ be strategies on a simple game $A$ then:
$$\sigma \leq \tau \iff \textit{comp}(\sigma) \subseteq \textit{comp}(\tau) \ .$$
\end{theorem}
Thus in the game model of Idealized Algol, observational equivalence is characterized by equality of the set of complete plays.

This result implies that the fully abstract model of Idealized Algol is \emph{effectively presentable}  which means that the denotation of a term can be computed by a Turing Machine (see \cite{loader1998upd} for a definition of effective presentability). The proof crucially relies on the presence of imperative features in \ialgol. Indeed, Loader has shown in \cite{loader2001fpn} that even on compact strategies, observation equivalence of \pcf\ is undecidable. This implies that there is not fully abstract model of \pcf\ that is effectively representable.

Algorithmic game semantics is concerned with deriving decision procedures for the observational equivalence problem for various
fragments of \ialgol. This problem can be stated as follows: \emph{Given two
$\beta$-normal forms $M$ and $N$ in a given fragment of \ialgol, does $M \obseq N$ hold?} By the Characterization theorem \ref{thm:abramskycusker_charac}, this problem reduces to comparing the set of complete plays of two given terms. Observational equivalence is undecidable in the general case, but it becomes decidable when restricted to some lower-order fragments of \ialgol. This question has now been fully investigated and there is now a full classification of decidability results for \ialgol's fragments.

\subsubsection{The order-\texorpdfstring{$2$}{2} fragment of \ialgol}

Ghica and McCusker were the first to show that the observational equivalence problem becomes decidable when
restricting the language \ialgol\ to some finitary fragment.
They showed that for the second-order finitary fragment of Idealized Algol, written $\ialgol_2$,
the set of complete plays of the strategy denotation can be expressed as an extended regular expression \cite{ghicamccusker00}:
\begin{lemma}[Ghica and McCusker, \cite{ghicamccusker00}]
For any IA$_2$-term $\Gamma \vdash M : T$, the set of complete
plays of $\sem{\Gamma \vdash M : T}$ is regular.
\end{lemma}
Since equivalence of regular expression is decidable with complexity PSPACE, by the Characterization Theorem
this result gives a decision procedure for observational equivalence of $\ialgol_2$-terms. In the same paper they show that the same result holds for the
$\ialgol_2 +\textsf{while}$ fragment. At order $2$, this results cannot be extend further as Ong showed that that observational equivalence is undecidable for $\ialgol_2 + \textsf{Y}_1$ \cite{Ong02}.

\subsubsection{Other fragments of IA}

The result by Ghica and McCusker opened up the field of \emph{Algorithmic game semantics}.
Other finitary fragments were subsequently considered. In \cite{Ong02}, Ong considered the order-$3$ finitary fragment, denoted $IA_3$. He showed that the set of complete plays is a context-free language, thus
observational equivalence reduces to the \emph{Deterministic
Push-down Automata Equivalence} (DPDA). This problem was shown to be decidable \citep{DBLP:journals/tcs/Senizergues01} but with an unspecified complexity.
We only know that it is primitive recursive \citep{stirling02}.

Even for $\ialgol_3 + \textsf{while}$ (the fragment obtained by throwing in iteration), the problem remains decidable. Moreover the problem lies in EXPTIME \citep{DBLP:conf/fossacs/MurawskiW05}. For the fragments $\ialgol_i +Y_0$ for $i = 1, 2, 3$, observational equivalence is as difficult as DPDA equivalence (\ie there is a reduction in both directions) \cite{DBLP:conf/icalp/MurawskiOW05}. Finally, Murawski showed in \cite{murawski03program} that the problem becomes undecidable beyond order $3$ ($\ialgol_i$ with $i\geq4$).

The complete classification of complexity results for \ialgol\ is reacpitulated in Table \ref{tab:IAcomplexity_classification}. Undefined fragments are marked with the symbol $\times$.

\begin{table}[htbp]
  \centering
\begin{tabular}{rcccc}
Fragment  & pure & +while & +Y0 & +Y1 \\ \hline \hline
$\ialgol_0$ & PTIME & $\times$ & $\times$ & $\times$  \\
$\ialgol_1$ & coNP & PSPACE & DPDA EQUIV & $\times$ \\
$\ialgol_2$ & PSPACE & PSPACE & DPDA EQUIV & undecidable \\
$\ialgol_3$ &EXPTIME & EXPTIME & DPDA EQUIV & undecidable \\
$\ialgol_i, i \geq 4$  & undecidable & undecidable & undecidable
& undecidable
\end{tabular}
\caption{The complete complexity classification for observational equivalence in \ialgol.}
\label{tab:IAcomplexity_classification}
\end{table}

The coNP and PSPACE results are due to Murawski \citep{Mur04b}.
