%\chapapp{Chapter}
\chapapp{}

\chapter{First-Year work}
%\addcontentsline{toc}{chapter}{First-Year work}

\section{Coursework}
I have attended the following courses: \emph{Automata Logic and
Games} in Hilary term 2005, \emph{Domain theory} in Michaelmas term
2005 and \emph{Categories Proofs and Programs} in Hilary term 2006.

\section{Teaching}

I was the demonstrator for \emph{Network and Operating Systems}
practicals in Hilary term 2005, I tutored two groups of students for
the \emph{Introduction to Specification} classes (Hilary 2006) and I
was the marker for one group.

\section{Meetings and conferences}
\begin{itemize}
\item I attended Bonn spring school on GAMES in March 2005;

\item  I attended BCTCS (British Colloquium in
Theoretical Computer Science) in Nottingham in March 2005 where I
gave a presentation based on my MSc dissertation ``Termination
analysis of a subset of CoreML'';

\item I attended PAT \emph{Program transformation and Analysis} in Copenhagen, July 2005;

\item Marktoberdorf Summer School;
\item CSL (Computer Science Logic) August 2005:
I helped to organise the conference;
\item I visited the Isaac Newton Institute in Cambridge in February
2006.
\end{itemize}
I have also done a presentation during the Computer Laboratory open
days.


\section{Research}

\subsection{Game semantics}

During the past months, I have studied a restriction of
lambda-calculus called ``safe lambda-calculus''. \emph{Safety} is a
syntactic property originally defined in \cite{KNU02} for
higher-order recursion schemes (grammars). In their paper they
proved that the MSO theory of the term tree generated by a safe
recursion scheme of level $n$ is decidable. More recently, Ong
proved in \cite{OngLics2006} that the safety assumption is in fact
not necessary for the decidability of MSO theories.

I am interested in the transposition of the safety property from
grammars to lambda terms. A definition of the safe
$\lambda$-Calculus was first given in a technical report by Aehlig,
de Miranda and Ong in \cite{safety-mirlong2004}. One interesting
property is that performing substitution on safe terms does not
require a renaming of the variable.

I have investigated different possible definitions of a safe lambda
calculus and have proposed a more general notion of safety that does
not assume homogeneity of types while still preserving  the ``no
variable renaming'' property.

I also tried to relate the safety restriction and the
\emph{size-change termination} property defined in
\cite{jones01,jones04}. Jones conjectured that any simply-typed term
is size-change terminating, however Damien Sereni disproved this
conjecture by exhibiting a class of counter-examples
(\cite{serenistypesct05}). It turns out that the simply-typed terms
of this class are all safe (but not necessary of homogeneous type)
and not size-change terminating. This suggests that there is no real
interesting relation between safety and size-change termination.


Recently, inspired by my reading on game semantics
\citep{abramsky:game-semantics-tutorial} and by the techniques
developed by Luke Ong in \citep{OngLics2006}, I have proved a result
on the game semantics of safe terms: the pointers in the game
semantics of safe simply-typed terms can be recovered uniquely from
the sequence of moves. This result is similar to the standard result
in game semantics which says that pointers of strategies can be
recovered uniquely for arena of order 2 at most.


\subsection{Verification}

In parallel, I worked on a separate project with Matthew Hague and
Luke Ong. We developed a SAT-based  model checker for verifying
Linear Temporal Logic (LTL) formulae on programs expressed as finite
state machines. Our approach combines techniques presented in two
papers: \cite{hammer:truly, DBLP:conf/cav/McMillan03}.

In \cite{DBLP:conf/cav/McMillan03}, McMillan describes an
acceleration technique for the SAT-based Bounded Model Checking
problem based on Craig interpolants. His algorithm significantly
improves the performance of the standard SAT-based model checking
method in the case of positive instances.


Languages definable in LTL correspond exactly to those recognised by a certain class of automata called \emph{Linear Weak Alternating Automata} \citep{thomas97languages}, abbreviated LWAA. 
There is a straightforward translation from LTL formulae to LWAAs such that the size of the resulting automaton is linear in the size of the LTL formula. Checking emptiness of a LWAA amounts to searching the configuration graph for a lasso verifying certain conditions. In \citep{hammer:truly}, Hammer \emph{et al.} proposed the notion of ``simple LWAA''. While the ``simple'' condition does not limit the expressiveness of LWAAs, it makes the model checking problem more tractable. The authors have implemented their algorithm in an extension of the SPIN model checker which outperforms the usual SPIN algorithm on non trivial examples.


Our approach can be summarized as follows: we translate the model checking problem into an emptiness checking of a simple LWAA. The automata is empty if and only if the formula is true. The emptiness of the automaton is expressed in term of a reachability problem. As in the
traditional SAT-based bounded-model checking approach
(\cite{biere99symbolic}), we construct a boolean formula which is
satisfiable if and only if the desired configuration is reachable in
at most $k$ steps (i.e. there is a counter-example of length $k$ at
most).

Furthermore, instead of using the traditional SAT-solver technique,
which iterates $k$ until the completeness threshold is reached, we
use the acceleration method described in
\cite{DBLP:conf/cav/McMillan03}. The principle is the following: for
every iteration of $k$, if the formula is not satisfiable then we
perform some over-approximation of the set of initial configuration.

Suppose that the final configuration becomes reachable in $k$ steps
from the over-approximated initial configuration then we are still
uncertain whether the formula has a valid counter-example because
the counter-example obtained may be spuriously created by the
over-approximation. We therefore increase $k$ and move on to the
next iteration. However, if after performing several
over-approximations we reach a fixed point and the formula is still
not satisfiable (not counter-example of length $k$ at most) then we
know that there cannot be any counter-example of any length. We have
therefore reached the completeness threshold and we know that the
formula is true.


There are two reasons why we think that our approach may lead to a
gain of performance. Firstly, although determining emptiness of a
LWAA is more costly than determining emptiness of a B\"uchi
automaton, we save time during the construction of the automaton
because the size of a LWAA is linear in the length of the formula as
opposed to the standard translation which produces a B\"uchi
automaton of size exponential in the length of the formula.
Secondly, in the case where there is no counter-example, McMillan's
acceleration method based on over-approximation permits quick
detection of attaintment of the completeness threshold.


%\cite{ckos2005}
We have produced an experimental implementation in OCaml and C. The
program parses a file in the NuSMV format (\cite{CAV02:nusmv})
containing the Kripke structure of the model and the set of LTL
properties to verify. Our tools can be interfaced with two SAT
solvers: ZChaff \citep{zChaff} and MiniSat \citep{ES03}. We also use
BDD to perform simplification on the propositional formula and to
generate the CNF representation that the SAT solver takes as input.

Compared to the LWAASpin LTL model checker (\cite{hammer:truly}),
our tool performs quite poorly. As soon as a model is taken into
account, our procedure generates increasingly bigger propositional
formulae that the SAT solver struggles to solve. However, for pure
LTL emptiness checking, our tool performs quite well.

It seems disappointing that our approach does not give good results
for model checking, however the reason seems to be that the
SAT-solvers we are using produce bad interpolants. In the future, we
would like to interface our model checking tool with other SAT
solvers and interpolers.

Furthermore, there are optimisations that we have not finished to
implement. These include the optimization of the encoding of the
bounded model checking problem into a propositional formula. We
propose to do some experimental tests to discover the encoding
giving the best performance.

\chapter{Research plan}
%\addcontentsline{toc}{chapter}{Research plan}

My research plan for the coming year is as follows: first I will
continue to work on the safe $\lambda$-calculus. My immediate goal
is to extend the result I obtained about the unique recoverability
of pointers in the game semantics of Safe simply-typed
$\lambda$-calculus to the case of other languages like Safe
Idealized Algol. I also wish to investigate applications in
algorithmic game semantics. There are also further questions about
safe $\lambda$-calculus that have to be addressed: what is the
categorical interpretation of safe $\lambda$-calculus? What kind of
proof theory do we obtain by the Curry-Howard isomorphism? Which
complexity class is characterised by the safe $\lambda$-calculus?

In parallel to that line of research, I will continue to work with
Matthew Hague and Luke Ong on the LTL model checking problem.


%I also want to investigate some application of game semantics to
%program analysis and transformation by trying to extend the work of
%Dimovski \emph{et al.} (\cite{DBLP:conf/sas/DimovskiGL05}) on
%data-absraction refinement based on game semantics.
