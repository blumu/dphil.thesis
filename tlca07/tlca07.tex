% the LaTeX macro package from Springer-Verlag for Lecture Notes in Computer Science,
% version 2.2 for LaTeX2e
\documentclass{llncs}
\usepackage{amsmath, amssymb}
\usepackage{pst-tree}
\usepackage{tabularx}
\usepackage[all]{xy}
\usepackage{stmaryrd}
\usepackage{picins}


\newtheorem{thm}{Theorem}
\newtheorem{lem}{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{cor}{Corollary}
\newtheorem{dfn}{Definition}
%\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}
\newtheorem{exmp}[thm]{Example}


% reduction, substitution
\newcommand\defeq{\stackrel{\textsf{def}}{=}}
\newcommand\betared{\rightarrow_\beta}
\newcommand\betaredtr{\twoheadrightarrow_\beta} % transitive closure of the beta reduction
\newcommand\betasred{\rightarrow_{\beta_s}}
\newcommand\betasredO{\rightarrow_{\beta_s^1}}
\newcommand\betasredT{\rightarrow_{\beta_s^2}}
\newcommand\subst[2]{\left[ #1/#2 \right]}
\newcommand\captsubst[2]{\{1/#2 \}}

% computation tree and eta normal form
\newcommand\aux[1]{\lceil #1\rceil}
\newcommand\etanf[1]{\eta_{\sf nf}(#1)}
\newcommand\etabetanf[1]{\eta\beta_{\sf nf}(#1)}

% lambda calculus
%\newcommand\bot{\perp}
\newcommand\typar{\Rightarrow}
\newcommand\dps{\displaystyle}
\newcommand\rulef[2]{\frac{\dps #1}{#2}}
\newcommand\rulefex[3][5pt]{\frac{\dps #2}{\stackrel{\rule{0pt}{#1}}{#3}}}
\newcommand\axiomf[1]{\frac{\dps}{#1}}
\newcommand\funto{\longrightarrow}
\newcommand\ord[1]{{\sf ord}(#1)}
\newcommand\order[1]{{\sf order}(#1)}
\newcommand{\typear}{\rightarrow}
\newcommand{\rulename}[1]{\mathbf{(#1)}}
\newcommand\textbfit[1]{{\bf\em #1}\index{#1}}
\newcommand\blambda{\hbox{\boldmath $\lambda$}}
\newcommand\lterm[2]{{\blambda{#1}.{#2}}}
\newcommand\terms[2]{{\cal T}^{#1}(#2)}
\newcommand{\funsp}{\rightarrow}
\newcommand\seq[2]{{{#1} \vdash {#2}}}

% semantics
\newcommand{\lsem}{[\![} % \llbracket
\newcommand{\rsem}{]\!]} % \rrbracket
\newcommand{\sem}[1]{{\lsem #1 \rsem}}
\newcommand{\intersem}[1]{{\langle\!\langle #1 \rangle\!\rangle}}

%set theory
\newcommand{\makeset}[1]{\{\,{#1}\,\}}
\newcommand\union{\cup}
\newcommand\Union{\bigcup}
\newcommand\prefset{\textsf{Pref}}
\newcommand{\relimg}[1]{{(\!| #1 |\!)}}
\newcommand\sthat{\ | \ }  % ``such that'' for set defined by comprehension
\newcommand\nat{\mathbb{N}}


%%% game semantics
\newcommand\natbf{\mathbf{N}}
\newcommand\zset{\mathbb{Z}}
\newcommand\eval{\Downarrow}
\newcommand\obspre{\sqsubseteq}
\newcommand\obseq{\approx}
\newcommand\intercomp{\fatsemi{^\|}}

% trees
\newcommand{\SubTree}[2][]{\Tr[ref=t]{\pstribox[#1]{#2}}}
\newcommand{\SubTreeE}[2][]{\Tr[ref=t]{\pstribox[#1]{#2}}}
\def\dedge{\ncline[linestyle=dashed]}
\def\dotedge{\ncline[linestyle=dotted]}
\def\valueedge{\ncline[linestyle=dashed,linewidth=0.5pt]}
\newcommand{\TRV}[1][edge=\valueedge]{\TR[edge=\valueedge,#1]}
\newcommand{\tree}[2][levelsep=4ex]{\pstree[levelsep=4ex,#1]{\TR{#2}}}

% logic
\newcommand\imp{\Rightarrow}
\newcommand\zand{\wedge}


% traversals
\newcommand\travset{\mathcal{T}rav}



% ia
\newcommand\ialgol{\textsf{IA}}
\newcommand\ialgolmnew{\ialgol-$\{\ianew\}$}
\newcommand\iaseqcom{$\tt{seq_{com}}$}
\newcommand\iaseqexp{$\tt{seq_{exp}}$}
\newcommand\iaseq{\texttt{seq}}
\newcommand\iaskip{\texttt{skip}}
\newcommand\iaderef{\texttt{deref}}
\newcommand\iaassign{\texttt{assign}}
\newcommand\iadone{\texttt{done}}
\newcommand\iarun{\texttt{run}}
\newcommand\iawrite{\texttt{write}}
\newcommand\iaread{\texttt{read}}
\newcommand\iaok{\texttt{ok}}
\newcommand\iamkvar{\texttt{mkvar}}
\newcommand\ianew{\texttt{new}}
\newcommand{\ianewin}[1]{\texttt{new}\ #1\ \texttt{in}}
\newcommand\iabool{\texttt{bool}}
\newcommand\iawhile{\texttt{while}}
\newcommand\iado{\texttt{do}}
\newcommand\iacom{\texttt{com}}
\newcommand\iaexp{\texttt{exp}}
\newcommand\iavar{\texttt{var}}

%pcf
\newcommand\pcf{\textsf{PCF}}
\newcommand\pcfcond{\texttt{cond}}
\newcommand\pcfsucc{\texttt{succ}}
\newcommand\pcfpred{\texttt{pred}}


%% justified sequence of moves
\newcommand{\oview}[1]{\llcorner #1 \lrcorner}
\newcommand{\pview}[1]{\ulcorner #1 \urcorner}
%%\newcommand\jseq{\stackrel{\curvearrowleft}{=}} %equality of justseq

% back pointer using psttricks
\newcommand{\bkptr}[2][nodesep=0pt]{\ncarc[offset=-2pt,nodesep=0pt,ncurv=1,arcangleA=-#2, arcangleB=-#2,#1]{->}}
\newcommand{\bklabel}[1]{\mput*{\mbox{{\tiny $#1$}}}}
\newcommand{\bklabelb}[1]{\mput{\mbox{\tiny $#1$}}}
\newcommand{\bklabelc}[1]{\Bput[1pt]{\mbox{{\tiny $#1$}}}}
\newcommand\treelabel[1]{\mput*{\mbox{{\small $#1$}}}}


% model checking
\newcommand\entail{\vdash}



\begin{document}

\frontmatter          % for the preliminaries
\pagestyle{headings}  % switches on printing of running heads
\addtocmark{Hamiltonian Mechanics} % additional mark in the TOC


\mainmatter              % start of the contributions

\title{Game semantics of the Safe $\lambda$-Calculus}

\titlerunning{Game semantics of the Safe $\lambda$-Calculus}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used


\author{William Blum\inst{1} \and C.-H. Luke Ong\inst{2}}
%
\authorrunning{William Blum et al.}   % abbreviated author list (for running head)
%
%%%% modified list of authors for the TOC (add the affiliations)
\tocauthor{William Blum (University of Oxford), C.-H. Luke Ong (University of Oxford)}


\institute{Oxford University Computing Laboratory\\ Wolfson Building, Parks Road, Oxford, OX1 3QD, ENGLAND\\
\email{william.blum@comlab.ox.ac.uk\inst{1} luke.ong@comlab.ox.ac.uk\inst{2}} }

\maketitle              % typeset the title of the contribution

\pagestyle{empty}

% TLCA05:
%    Papers should not exceed 15 pages in Springer LNCS format.
%    An abstract (ASCII text) of no more than 150 words should be sent separately at least a weak before the paper submission deadline.

% LNCS:
%    The abstract should summarize the contents of the paper
%    using at least 70 and at most 150 words. It will be set in 9-point
%    font size and be inset 1.0 cm from the right and left margins.
%    There will be two blank lines before and after the Abstract. \dots

\begin{abstract}
The \emph{safety condition} has been introduced in \cite{KNU02} as a syntactic
restriction for higher-order recursion grammars that constrains the order
of the variables occurring in the grammar equations.

When transposed to the $\lambda$-calculus, the safety condition gives rise to the \emph{Safe $\lambda$-calculus}, a
strict sub-language of the $\lambda$-calculus (\cite{safety-mirlong2004}).

We present a new version of Safe $\lambda$-calculus and give a game-semantic
account of it. In particular we show that pointers are superfluous in the plays
of the game denotation of safe terms.
\end{abstract}

\section{Introduction}

\subsection{Background}

The \emph{Safety restriction} has been introduced in by Knapik, Niwi{\'n}ski and Urzyczyn in \cite{KNU02}
for the purpose of studying infinite trees generated by higher-order grammars.
Safety is very similar to the ``restriction of derived types'' which was introduced
by Damm in \cite{Dam82} however the formulation differs.

Safety is a syntactic restriction for higher-order grammars that
constrains the occurrences of the variables in the grammar
equations according to their order.
The definition of the Safety is a somewhat complex but it has an important algorithmic impact.
In particular, the authors of \cite{KNU02} proved that the Monadic Second
Order (MSO) theory of the term tree generated by a safe recursion
scheme of any order is decidable\footnote{In fact it has been shown
recently in \cite{OngLics2006} that it is also true for unsafe
recursion schemes.}. They also give the following nice automata-theoretic characterization of safety:
an infinite term is generated by a \emph{safe} higher-order grammar if and only if
it is generated by a level-$n$ pushdown automaton.


When transposed to the $\lambda$-calculus, the safety condition
gives rise to the \emph{Safe $\lambda$-calculus}, a strict
sub-language of the $\lambda$-calculus. A first version appeared in
the technical report \cite{safety-mirlong2004}. We propose a more
general and simpler version where term types are not required to be
homogeneous. A noteworthy feature of the Safe
$\lambda$-calculus is that no variable capture can occur when
performing substitution and therefore it is unnecessary to rename
variables when computing $\beta$-reductions.

Little is known about the Safe $\lambda$-calculus and there are many
problems that have yet to be studied concerning its
computational power, the complexity classes that it characterises,
its interpretation under the Curry-Howard isomorphism and its
game-semantic characterisation. This paper contributes to give an
answer to the last problem.


The difficulty in giving a game-semantic account of Safety lies in
the fact that it is a syntactic restriction whereas Game Semantics
is by essence a syntax-independent semantics. The solution consists
in finding a particular syntactical representation of terms on which
the plays of the game denotation can be represented.
To achieve this, we use ideas recently introduced in \cite{OngLics2006}: a term
is canonically represented by the abstract syntax tree of its
$\eta$-long normal form, referred as the \emph{computation tree}. A
computation is described by a justified sequence of nodes of the
computation tree respecting some formation rules and called a
\emph{traversal}. Traversals permit us to model $\beta$-reductions
without altering the structure of the computation tree via
substitution. A notable property is that \emph{P-view} (in the game-semantic sense) of traversals
corresponds to paths in the computation tree.

These notions permit us to establish a correspondence between the game semantics of a term and
the syntactic representation given by its computation tree.
More precisely, we show that traversals are just representations of the
uncovering of plays of the strategy denoting the term.
Then by defining an appropriate \emph{reduction} operation which eliminates traversal
nodes that are ``internal'' to the computation, we obtain an
isomorphism between the strategy denotation of a term and the set of
reductions of traversals of its computation tree.



Using that correspondence and after introducing the notion of \emph{incrementally-justified
strategies}, we are able to show that $\beta$-normal terms are \emph{safe} if and only if
their strategy denotation is incrementally-justified.
A consequence of this is that pointers in the game semantics of safe simply-typed terms can be recovered uniquely from the underlying sequences of moves.

\vspace{1cm}

\subsection{Related work}

De Miranda's forthcoming thesis \cite{demirandathesis} proposes a unified framework for the study of higher-order grammars. The thesis contains a detailed analysis of the safety constraint at level 2. It shows that, when restricted to word languages, safe level $2$ higher-order grammars are as powerful as (non-deterministic) unsafe ones. It also shows that at level $2$, safety is not a requirement to guarantee MSO decidability. The reader is referred to it for a full account of the Safety condition for higher-order grammars.


As we mentioned before, Knapik \emph{et al.} showed in \cite{KNU02} that infinite trees generated by \emph{safe} higher-order grammars
have decidable MSO theories. In \cite{OngLics2006}, Ong generalized the result to any higher-order grammar, whether safe or not.
Using an argument based on innocent game-semantics, he establishes a correspondence between the tree generated by a higher-order grammar called \emph{value tree} and a certain regular tree called \emph{computation tree}. Paths in the value tree correspond to traversals in the computation tree. Decidability is then obtain by reducing the problem to the acceptance of the (annotated) computation tree by a certain alternating parity tree automaton (APT). The approach that we follow in section \ref{sec:correspondence} uses many ingredients introduced in this paper.


\section{The Safe $\lambda$-calculus}
We consider simple types generated by the grammar $A
\, ::= \, o \; | \; A \funsp A$. Any type different from the ground
type $o$ can be written $(A_1, \cdots, A_n, o)$ for some $n \geq 1$,
which is a shorthand for $A_1 \funsp \cdots \funsp A_n \funsp o$ (by
convention, $\rightarrow$ associates to the right). If $T=(A_1,
\cdots, A_n, o)$ then the arity of $T$, written $arity(T)$, is
defined to be $n$.
The order of a type is defined by $\ord{o} = 0$ and
$\ord{A \funsp B} = \max(\ord{A}+1, \ord{B})$.

%Following \cite{KNU02}, we say that a type is homogeneous
%if it is $o$ or if it is $(A_1, \cdots, A_n, o)$ with the condition
%that $\ord{A_1} \geq \ord{A_2}\geq \ord \geq \rank{A_n}$ and
%each $A_1$, \ldots, $A_n$ is homogeneous.





The \textbf{Safe $\lambda$-Calculus} is a sub-system of the simply-typed $\lambda$-calculus formally defined by the definition that follows.
We use a set of sequents of the form $\Gamma \vdash M : A$ to represent
terms-in-context where $\Gamma$ is the context (a typed-alphabet) and $A$ is the type. We assume that a set
of higher-order constants $\Sigma$ is given.

\begin{dfn}[The Safe $\lambda$-calculus]
We call \emph{safe term} any simply-typed lambda term that is typable using the following
formation rules:
$$ \rulename{var} \   \rulef{}{x : A\vdash x : A}
\qquad  \rulename{const} \   \rulef{}{\vdash f : A} \quad f \in \Sigma
\qquad  \rulename{wk} \   \rulef{\Gamma \vdash s : A}{\Delta \vdash s : A} \quad \Gamma \subset \Delta$$

$$ \rulename{app} \  \rulef{\Gamma \vdash s : (A_1,\ldots,A_n,B)
                                        \ \Gamma \vdash t_1 : A_1
                                        \  \ldots\  \Gamma \vdash t_n : A_n }
                                   {\Gamma  \vdash s t_1 \ldots t_n : B}
                                    \
                                   \ord{B} \sqsubseteq \ord{\Gamma}$$

$$ \rulename{abs} \   \rulef{\Gamma, x_1 : A_1 \ldots x_n : A_n \vdash s : B}
                                   {\Gamma  \vdash \lambda x_1 \ldots x_n . s : (A_1, \ldots ,A_n,B)} \
                                   \ord{A_1, \ldots ,A_n,B} \sqsubseteq \ord{\Gamma}$$

where in the side-conditions, $\ord{\Gamma}$ denotes the set $\{ \ord{y} : y \in \Gamma \}$ and $c \sqsubseteq S$ is a notation for
``$c$ is a lower-bound for $S$''.
\end{dfn}

The first deviation from the standard definition of the simply-typed $\lambda$-calculus is the possibility to perform multiple applications at a time using the {\sf (app)} rule and similarly to abstract several variables at a time using the {\sf (abs)} rule.
Of course, this change does not alter the expressivity. However, at the same time, there is an additional condition
which constrains the possible occurrences of variables within a term. More precisely, the side-condition in the application rule and abstraction rules ensures that all variables in the context of the term being formed have order greater than the order of the term itself.



Note that there is no specific constraint on the term type. In particular, the type-homogeneity constraint that is used
in the definition of safe higher-order grammars in \cite{KNU02} is not required here.
In that regard, our formulation of the Safe $\lambda$-calculus differs from the one proposed in \cite{safety-mirlong2004}.
It is possible to reconcile the two definitions by adding the further constraint that each type occurring in our rules is homogeneous, we then obtain a calculus equivalent to the one of \cite{safety-mirlong2004}.




\begin{exmp}[Kierstead terms]
Consider the terms $M_1 = \lambda f . f (\lambda x . f (\lambda y . y ))$ and
$M_2 = \lambda f . f (\lambda x . f (\lambda y .x ))$ where $x,y:o$ and $f:((o,o),o)$.
$M_2$ is not safe because in the subterm $f (\lambda y . x)$, the free variable $x$ has order $0$ which is smaller than $\ord{\lambda y . x} = 1$.
On the other hand, $M_1$ is safe as the following proof tree shows:
$$
 \rulef{
     \rulef{
        \rulef{}{f \vdash f} {\sf(var)}
        \
        \rulef{
             \rulef{
                \rulef{
                    \rulef{}{f \vdash f} {\sf(var)}
                }
                {f , x \vdash f } {\sf(wk)}
                \
                \rulef{
                    \rulef{
                        \rulef{}{y \vdash y} {\sf(var)}
                    }
                    {y \vdash \lambda y . y } {\sf(abs)}
                }
                {f , x \vdash \lambda y .y } {\sf(wk)}
             }
             {f , x \vdash f (\lambda y .y )} {\sf(app)}
        }
        { f  \vdash \lambda x . f (\lambda y .y )} {\sf(abs)}
     }
     {
        f  \vdash f (\lambda x . f (\lambda y .y ))} {\sf(app)}
     }
 { \vdash M_1 = \lambda f . f (\lambda x . f (\lambda y .y )) } {\sf(abs)}
$$
\end{exmp}

The following lemma is an immediate consequence of the definition
\begin{lem}
\label{lem:ordfreevar}
If $\Gamma \vdash M : A$ then every variable in $\Gamma$ occurring free in $M$ has order at least $ord(M)$.
\end{lem}




In the simply typed $\lambda$-calculus, it is necessary to rename
variables when performing substitution on an abstraction in order to
avoid possible variable capture. As a consequence, in order to
implement substitution one needs to have access to an unbound number
of variable names.
In the Safe $\lambda$-Calculus, however, variable capture never happens as the following lemma shows.
Hence substitution can implemented naively by capture-permitting replacement, avoiding any need for variable renaming.


Let us write $M\{N/x\}$ to denote the capture-permitting substitution of $N$ for $x$ in $M$. This substitution is implemented
by textually replacing all free occurrences of $x$ in $M$ by $N$ without performing variable renaming.
In particular for the abstraction case we have:
$$(\lambda \overline{y} . P)\captsubst{N}{x} = \left\{
                                                 \begin{array}{ll}
                                                   \lambda \overline{y} . P\captsubst{N}{x} , & \hbox{if $x\not\in \overline{y}$;} \\
                                                   \lambda \overline{y} . P, & \hbox{if $x\in y$.}
                                                 \end{array}
                                               \right.
$$

\begin{lem}[No variable capture]
\label{lem:homog_nocapture} There is
no variable capture when performing capture-permitting
substitution of $N$ for $x$ in $M$
provided that $\Gamma, x \vdash M$ and $\Gamma \vdash  N$ are valid judgments of the Safe $\lambda$-calculus.
\end{lem}

\begin{proof}
We prove the result by induction. The variable, constant and
application cases are trivial. For the abstraction case, suppose $M
= \lambda \overline{y} : \overline{A}. P$ where $\overline{y} = y_1
\ldots y_p$. If $x \in \overline{y}$ then $M \subst{N}{x} = M$ and there is no variable capture.
Suppose that $x \not\in \overline{y}$ then the capture-permitting substitution gives:
$$M \captsubst{N}{x} = \lambda \overline{y} . P \captsubst{N}{x} \ .$$


By the induction hypothesis there is no variable capture in $P \captsubst{N}{x}$.
Hence variable capture can only happen when for some $i \in 1..p$, the variable $y_i$
occurs freely in $N$ and $x$ occurs freely in $P$. Lemma \ref{lem:ordfreevar} gives:
$$ \ord{y_i} \geq \ord{N} = \ord{x} \ .$$

Since $x \not \in \overline{y}$ and $x$ occurs freely in $P$, $x$ also occurs freely in the safe term
$\lambda \overline{y}. P$ therefore by lemma \ref{lem:ordfreevar} we have:
$$ \ord{x} \geq \ord{\lambda y_1 \ldots y_p . T} \geq 1+ \ord{y_i} > \ord{y_i}$$
which, together with the previous equation, gives a contradiction.
\end{proof}

From now on we will use the standard notation $M\subst{N}{x}$ do denote the substitution of $N$ for $x$ in $M$.
It is understood that, provided that $M$ and $N$ are safe, this substitution
is implemented by the capture-permitting substitution $M\captsubst{N}{x}$.


\begin{lem}[Substitution preserves safety]
\label{lem:subst_preserve_safety}
If $\Gamma, x \vdash M$ and $\Gamma \vdash N$ then $\Gamma \vdash M[N/x]$.
\end{lem}
\begin{proof}
An easy proof by an induction on the structure of the safe term $M$.
\end{proof}

%%%%%%%%%%%%%


It is desirable to have an appropriate notion of reduction for our calculus. However the standard $\beta$-reduction rule is not adequate. Indeed, Safety is not preserved by $\beta$-reduction as the following example shows. Suppose that $x,y,z,y : o$ and $\varphi : (o,o,o)$ then the safe term $(\lambda x y . \varphi x y) z w$ $\beta$-reduces to $(\underline{\lambda y . \varphi z y}) w$ which is unsafe since the underline order-1 subterm  contains a free occurrence of variable $z$ of ground type. However if we perform one more reduction we obtain the safe term
$\varphi z w$. This suggests an alternative notion of reduction that performs simultaneous reduction of consecutive $\beta$-redexes. In order to define this reduction we first introduce an appropriate notion of redex.

In the simply-typed lambda calculus a redex is a term of the form
$(\lambda x . M) N$. In the Safe
lambda calculus, a redex is a succession of several standard redexes:
\begin{dfn}[Safe redex]
We call \emph{safe redex} a safe term whose derivation tree has the following form:
$$   \rulef{
            \rulef{\rulef{\vdots}{\Gamma, \overline{x}\vdash M}}{\Gamma \vdash \lambda \overline{x} . M} (\sf{abs})
            \quad
            \rulef{\vdots}{\Gamma \vdash N_1}  \ \ldots \  \rulef{\vdots}{\Gamma \vdash N_l}
    }
    {
       \Gamma \vdash (\lambda \overline{x} . L) N_1 \ldots N_l
    } (\sf{app})
$$
where $\overline{x}$ denotes the list of variables $x_1\ldots x_n$.
\end{dfn}

In other words a safe redex is a safe term of the form $(\lambda \overline{x} . M) N_1 \ldots N_l$ such that
the variable $\overline{x}$ are abstracted altogether by one occurrence of the rule $(\sf{abs})$ and the terms $(\lambda \overline{x} . M)$, $N_1$, \ldots, $N_l$ are applied together at once using the $(\sf{app})$ rule
(and consequently each $N_i$ must be safe).



%%%%%%%%%%%%%%%%%%

We are now in a position to define a notion of reduction for safe terms.

\begin{dfn}[Safe reduction $\beta_s$] \
\label{dfn:safereduction} The following
abbreviations are used $\overline{x} = x_1 \ldots x_n$,
$\overline{N} = N_1 \ldots N_l$, and when $n\geq l$, $\overline{x_L}
= x_1 \ldots x_l$, $\overline{x_R} = x_{l+1} \ldots x_n$.
\begin{itemize}
\item The relation $\beta_s$ is defined on the set of safe redex as follows:
\begin{eqnarray*}
\beta_s &=&
\{  \ (\lambda \overline{x} : \overline{A} . T) N_1 \ldots N_l \mapsto \lambda \overline{x_R}. T\subst{\overline{N}}{\overline{x_L}}  \\
&& \mbox{ where $(\lambda \overline{x} : \overline{A} . T) N_1 \ldots N_l$ is a safe redex such that $n> l$}
\} \\
&\cup&
\{ \ (\lambda \overline{x} : \overline{A} . T) N_1 \ldots N_l \mapsto T\subst{\overline{N}}{\overline{x}} N_{n+1} \ldots N_l  \\
&& \mbox{ where $(\lambda \overline{x} : \overline{A} . T) N_1 \ldots N_l$ is a safe redex such that $n\leq l$}
\} \ .
\end{eqnarray*}

\item
The safe $\beta$-reduction, written $\betasred$, is the closure of
the relation $\beta_s$ by compatibility with the formation rules of
the Safe $\lambda$-Calculus.
\end{itemize}
\end{dfn}

\noindent \emph{Remark:} The $\beta_s$-reduction is a multi-step $\beta$-reduction i.e. $\betared \subset \betasred \subset \betaredtr$.


\begin{lem}[$\beta_s$ reduction preserves safety]
\label{lem:homoh_safered_preserve_safety}
If $\Gamma \vdash s$ and $s \betasred t$ then $t$ is safe.
\end{lem}

\begin{proof}
It suffices to show that the relation $\beta_s$ preserves safety.
Consider the safe-redex $ s \equiv (\lambda x_1 \ldots x_n . M) N_1 \ldots N_l $ such that
$s\ \beta_s\ t$ for some simply-typed term $t$.
Without lose of generality we can assume that the last rule used to form the term $s$ is {\sf(app)} i.e. not the weakening rule
{\sf(wk)}. Hence we have $\Gamma = fv(s)$.

By lemma \ref{lem:subst_preserve_safety}, $T\subst{\overline{N}}{\overline{x_L}}$ is safe.
By lemma \ref{lem:ordfreevar}, all variables in $\Gamma$ have order greater than $\ord{s} = \ord{t}$. Therefore
if $n>l$ then we can use the {\sf(abs)} rule to form $\Gamma \vdash t \equiv \lambda \overline{x_R}. T\subst{\overline{N}}{\overline{x_L}}$
and if $n \leq l$ we can use the {\sf(app)} rule to form $\Gamma \vdash t \equiv  T\subst{\overline{N}}{\overline{x}} N_{n+1} \ldots N_l$.
\end{proof}



\section{Computation tree and traversals}
\label{sec:correspondence}

In this section we introduce the notion of computation tree of a simply-typed term and
define traversals over the computation tree. These two notions were firstly introduced in \cite{OngLics2006}. Here they
are adapted to the context of the $\lambda$-calculus.

We then prove the \emph{Correspondence Theorem} (theorem \ref{thm:correspondence}), a result similar to the ``Path-Traversal Correspondence'' theorem of \cite{OngLics2006}. We will make use of this result in the next section in order to obtain
a game-semantic characterisation of the Safe $\lambda$-Calculus.

In the following, we work in the general setting of the simply-typed
$\lambda$-calculus extended with a fixed set $\Sigma$ of
higher-order constants.


\subsection{$\eta$-long normal form and computation tree}


The $\eta$-long normal form appeared in
\cite{DBLP:journals/tcs/JensenP76} and
\cite{DBLP:journals/tcs/Huet75} under the names \emph{long reduced
form} and \emph{$\eta$-normal form} respectively. It was then
investigated in \cite{huet76} under the name \emph{extensional
form}.

The $\eta$-expansion of a term $M$ of type $(A_1,\ldots,A_n,o)$ is
$\lambda \varphi_1 \ldots \varphi_l . M \varphi_1 \ldots \varphi_l$
where the $\varphi_i:A_i$ are fresh variables. The $\eta$-normal
form of a term is obtained by hereditarily $\eta$-expanding every
subterm occurring at an operand position.

\begin{dfn}[$\eta$-long normal form]
A simply-typed term is either an abstraction or it can be written uniquely as
$s_0 s_1 \ldots s_m$ where $m\geq0$ and $s_0$ is a variable, a $\Sigma$-constant or an abstraction.
The $\eta$-long normal form of a term $M$, written $\aux{M}$ or sometimes $\etanf{M}$,
is defined as follows:
\begin{align*}
\aux{\lambda x . s } &= \lambda x . \aux{s} \\
\aux{\alpha s_1 \ldots s_m : (A_1,\ldots,A_n,o)} &= \lambda \overline{\varphi} . \alpha \aux{s_1}\ldots \aux{s_m} \aux{\varphi_1} \ldots \aux{\varphi_n} \\
& \mbox{with $m,n\geq0$}\\
\aux{(\lambda x . s) s_1 \ldots s_m : (A_1,\ldots,A_n,o) } &= \lambda \overline{\varphi} . (\lambda x . \aux{s}) \aux{s_1} \ldots \aux{s_m} \aux{\varphi_1} \ldots \aux{\varphi_n} \\
& \mbox{with $m\geq 1,n\geq0$}
\end{align*}
where $x$ and each $\varphi_i : A_i$ are variables and $\alpha$ is
either a variable or a constant.
\end{dfn}

\begin{rem}
\begin{itemize}
\item For $n=0$, the first clause in the definition becomes:
$$\aux{x s_1 \ldots s_m : o} = \lambda . x \aux{s_1} \aux{s_2} \ldots \aux{s_m}.$$
The \textsl{dummy lambda} $\lambda .$ occurring in the right-hand
side of the equation kept deliberately as it will play an important role in the
game-semantic correspondence.

\item A term in $\eta$-normal form is either an abstraction or it is of ground type and can be written uniquely as
$s_0 s_1 \ldots s_m : 0$ where $m\geq0$,  $s_0$ is a variable, a constant or an abstraction and each of the $s_j$ for $j\in 1..m$ is in $\eta$-normal form.
\end{itemize}
\end{rem}

Our version of the $\eta$-long normal form is defined for any simply-typed term, not only for $\beta$-normal terms.
Moreover it is defined in a way that $\beta$-normality is preserved after taking the $\eta$-long normal form:
\begin{lem}
The $\eta$-long normal form of a term in $\beta$-normal form is also in $\beta$-normal form.
\end{lem}
\begin{proof}
By induction on the structure of the term and the order of its type.
\emph{Base case}:
If $M=x:0$ then $\aux{x} = \lambda . x$ is also in $\beta$-nf.
\emph{Step case}:
The case $M = (\lambda x . s_0) s_1 \ldots s_m : (A_1,\ldots,A_n,o)$ with $m>0$ is not possible since $M$ is in
$\beta$-normal form.
Suppose $M = \lambda x . s$ then $s$ is in $\beta$-nf. By the induction hypothesis $\aux{s}$ is also in $\beta$-nf and therefore
so is $\aux{M} = \lambda x . \aux{s}$.

Suppose $M= \alpha s_1 \ldots s_m : (A_1,\ldots,A_n,o)$. Let $i,j$
range over $1..n$ and $1..m$ respectively. The $s_j$ are in
$\beta$-nf and the $\varphi_i$ are variables of order smaller than
$M$, therefore by the induction hypothesis the $\aux{\varphi_i}$ and
the $\aux{s_j}$ are in $\beta$-nf. Hence $\aux{M}$ is also in
$\beta$-nf.
\end{proof}



\emph{Notation:} We introduce the following notations for labelled-trees: $[l](t_1, \ldots, t_n)$ denotes the tree whose root is labelled by $l$ and has $n$ children subtrees $t_1$, \ldots, $t_n$. Single node trees are written $[l]$ for some label $l$. If $t = [l](t')$, i.e. the root has a single child, then $t^-$ denotes the tree $t'$ (the tree obtained after deleting the root).



The computation tree is defined to be the abstract syntax tree of the $\eta$-long normal form of the term.
It provides a canonical representation for the term.

\begin{dfn}[Computation tree]
Let $L$ be the set of node labels defined as follows:
$$ L = \Sigma \union \{ @ \} \union \{ x : x \mbox { is a variable} \}
\union \{ \lambda \overline{x} : \overline{x} = x_1 \ldots x_n \mbox { is a list of variables.} \}
  $$

For terms in $\eta$-normal form, we define the $L$-labelled tree $\tau(M)$ as follows:
\begin{eqnarray*}
  \tau(\lambda x_1 \ldots x_n . s) &=& [\lambda x_1 \ldots x_n](\tau(s)^{-}) \\
    && \mbox{for $n\geq0$ and some term $s$ that is not an abstraction \ ;} \\
  \tau( \alpha s_1 \ldots s_m : o) &=& [ \lambda ]([\alpha](\tau(s_1),\ldots,\tau(s_m))) \\
    && \mbox{for $m\geq0$ and some variable or constant $\alpha$ \ ;} \\
  \tau((\lambda x.s_0) s_1 \ldots s_n :o) &=& [\lambda] ([@](\tau(\lambda x.s),\tau(s_1),\ldots,\tau(s_m))) ) \\
    && \mbox{for $n \geq 1$ \ .}
\end{eqnarray*}

The \emph{computation tree} of a simply-typed term $M$ (not necessarily in $\eta$-normal form) is written $\tau(M)$
and defined as $\tau(M) = \tau(\etanf{M})$.
\end{dfn}

The nodes (and leaves) of the tree are of three kinds:
\begin{itemize}
\item $\lambda$-nodes labelled $\lambda \overline{x}$ representing several consecutive variable abstractions,
\item application nodes labelled @,
\item variable or constant nodes labelled $\alpha$ for some constant or variable $\alpha$.
\end{itemize}
Suppose that a term $M$ has been fixed, then we abbreviate $\tau(M)$ into $\tau$  and we write
$N$ for the set of nodes of $\tau$, $N_\Sigma$ for the set of $\Sigma$-labelled nodes,
$N_@$ for the set of @-labelled nodes, $N_{var}$ for the set of variable nodes and
$N_{fv}$ for the subset of $N_{var}$ constituted of free-variable nodes.


Clearly, each subtree of the computation tree $\tau(M)$ represents a subterm of $\aux{M}$.
There is a function $\kappa$ defined on $N$ that maps each node $n \in N$ to the subterm of $\aux{M}$ corresponding to the subtree of $\tau(M)$ rooted at $n$.
In particular if $\tau(M) = [r](\ldots)$ then we have $\kappa(r) = \aux{M}$.

\begin{dfn}[Node order]
\label{def:nodeorder}
The node-order function $\textsf{ord}$ is defined on nodes as follows:
\begin{eqnarray*}
\ord{n} =& \\
&\left\{
  \begin{array}{ll}
    \ord{T}, & \hbox{if $n$ is a variable or constant of type $T$;} \\
    1 + \max_{z\in \overline{\xi}\union fv(M)} \ord{z}, & \hbox{if $n$ is labelled $\lambda \overline{\xi}$ and is the root of $\tau(M)$;} \\
    1 + \max_{z\in \overline{\xi}} \ord{z}, & \hbox{if $n$ is labelled $\lambda \overline{\xi}$ and is not the root;} \\
    0, & \hbox{if $n$ is labelled @.}
  \end{array}
\right.
\end{eqnarray*}
\end{dfn}

\noindent Some remarks:
\begin{itemize}
\item In a computation tree, nodes at even level are $\lambda$-nodes and nodes at odd level are either application nodes,
variable or constant nodes;

\item for any ground type variable or constant $\alpha$, $\tau(\alpha) = \tau(\lambda . \alpha) =  [\lambda]([\alpha])$;

\item for any higher-order variable or constant $\alpha : (A_1,\ldots,A_p,o)$, the computation tree $\tau(\alpha)$ is of the form
$ [\lambda](
        [\alpha]([\lambda \overline{\xi_1}](\ldots), \ldots, [\lambda \overline{\xi_p}](\ldots))
        )
$;

\item for any computation tree of the form $[\lambda \overline{\varphi}]([n]( \ldots ))$ we have $\ord{\kappa(n)}=0$.
\end{itemize}







\subsection{Pointers and justified sequence of nodes}

\begin{dfn}[Binder]
Let $n$ be a variable node of the computation tree labelled $x$. We
say that a node $n$ is bound by the node $m$, and $m$ is called the
binder of $n$, if $m$ is the closest node in the path from $n$ to
the root of the tree such that $m$ is labelled $\lambda
\overline{\xi}$ with $x\in \overline{\xi}$.
\end{dfn}

\begin{dfn}[Enabling]
The enabling relation $\vdash$ is defined on the set of nodes of the
computation tree. We write $m \vdash n$ and we say that $m$ enables
$n$ if and only if
\begin{itemize}
\item $n$ is a bound variable node and $m$ is the binder of $n$,
\item or $n$ is a free variable node and $r$ is the root of the computation tree,
\item or $n$ is a $\lambda$-node and $m$ is the parent node of $n$.
\end{itemize}
\end{dfn}

We call \emph{input-variable} a variable that is hereditarily justified by the root of the computation tree.
Free variables and variables bound by the root are example of input-variables.

\begin{dfn}[Justified sequence of nodes]
A \emph{justified sequence of nodes} is a sequence of
nodes of the computation tree $\tau(M)$ with pointers attached to the nodes. A node $n$ in the sequence
that is either a variable node or a lambda-node different from the root of the computation tree
has a pointer to a node $m$ occurring before $n$ in the sequence such that $m \vdash n$.
If $n$ points to $m$ then we say that $m$ \emph{justifies} $n$ and we represent the pointer in the sequence as follows:
$$\rnode{m}{m} \cdot \ldots \cdot \rnode{n}{n} \bkptr[nodesep=1pt]{40}{n}{m}$$
\end{dfn}
Note that justified sequences are also defined for open terms:
occurrences of nodes in $N_{fv}$ must point to an occurrence of the
root of the computation tree.


A pointer is sometime labeled with an index $i$: if $m$ is a
$\lambda$-node then it indicates that $n$ is labelled with the $i$th
variable abstracted in $m$; otherwise it indicates that $n$ is the
$i$th child of $m$. A pointer in a justified sequence of nodes has
therefore one of the following forms: \vspace{2pt}
$$
\rnode{m}{r} \cdot \ldots \cdot \rnode{n}{z} \bkptr[nodesep=1pt]{40}{n}{m}
\hspace{1.5cm}
\rnode{m}{\lambda \overline{\xi}} \cdot \ldots \cdot \rnode{n}{\xi_i} \bkptr[nodesep=1pt]{40}{n}{m} \bklabel{i}
\hspace{1.5cm}
\rnode{m}{@ } \cdot \ldots \cdot \rnode{n}{\lambda \overline{\eta}} \bkptr[nodesep=1pt]{40}{n}{m} \bklabel{j}
\hspace{1.5cm}
\rnode{m}{\alpha } \cdot \ldots \cdot \rnode{n}{\lambda \overline{\eta}} \bkptr[nodesep=1pt]{40}{n}{m} \bklabel{k}
$$
where $r$ denotes the root of $\tau(M)$, $z \in N_{fv}$, $\xi_1,
\ldots \xi_n$ are bound variables, $\alpha \in N_{\Sigma} \union
N_{var}$, $i \in 1..n$, $j$ ranges from $0$ to the number of
children nodes of @ minus 1 and $k \in 1 ..arity(\alpha)$.

The following numbering conventions are used:
\begin{itemize}
\item the first child of a @-node is numbered $0$,
\item the first child of a variable or constant node is numbered $1$,
\item variables in $\overline{\xi}$ are numbered from $1$ onward ($\overline{\xi} = \xi_1, \ldots \xi_n$).
\end{itemize}
We use the notation $n.i$ to denote the $i$th child of node $n$.


We write $s = t$ to denote that the justified sequences $t$ and $s$
have same nodes \emph{and} pointers. Justified sequence of nodes can
be ordered using the prefix ordering: $t \sqsubseteq t'$ if and only
if $t=t'$ or the sequence of nodes $t$ is a finite prefix of $t'$
(and the pointers of $t$ are the same as the pointers of the
corresponding prefix of $t'$). Note that with this definition,
infinite justified sequences can also be compared. This ordering
gives rise to a complete partial order.

We say that a node $n_0$ of a justified sequence is hereditarily justified by $n_p$ if there are nodes $n_1, n_2, \ldots n_{p-1}$ in
the sequence such that for all $i\in 0..p-1$, $n_i$ points to $n_{i+1}$.

If $N$ is a set of nodes and $s$ a justified sequence of nodes then
we write $s \upharpoonright N$ to denote the subsequence of $s$
obtained by keeping only the nodes that are hereditarily
justified by nodes in $N$. This subsequence is also a justified
sequence of nodes. If $n$ denotes a node of $\tau(M)$ we
abbreviate $s \upharpoonright \{ n \}$ into $ s\upharpoonright n$.

\begin{lem}
\label{lem:filtercontinous}
For any set of node $N$, the filtering function $\_ \upharpoonright N$ defined on the cpo of justified sequences ordered by the prefix ordering
is continuous.
\end{lem}
\begin{proof}
Clearly $\_ \upharpoonright N$ is monotonous.
Suppose that $(t_i)_{i\in\omega}$ is a chain of justified sequence of nodes. Let $u$ be a finite prefix of $(\bigvee t_i) \upharpoonright r$.
Then $u = s \upharpoonright r$ for some finite prefix $s$ of $\bigvee t_i$. Since $s$ is finite we must have $s \sqsubseteq t_j$ for some $j\in\omega$.
Therefore $u \sqsubseteq t_j \upharpoonright r \sqsubseteq \bigvee (t_j \upharpoonright r)$.
This is valid for any finite prefix $u$ therefore $(\bigvee t_i) \upharpoonright r \sqsubseteq \bigvee (t_j \upharpoonright r)$.
\end{proof}


\begin{dfn}[P-view]
The P-view of a justified sequence of nodes $t$ of $\tau(M)$, written $\pview{t}$, is defined as follows:
\begin{eqnarray*}
 \pview{\epsilon} &=&  \epsilon \\
 \pview{s \cdot n }  &=&  \pview{s} \cdot n \\
 \pview{s \cdot \rnode{m}{m} \cdot \ldots \cdot \rnode{lmd}{\lambda \overline{\xi}}} &=& \pview{s} \cdot \rnode{m2}{m} \cdot \rnode{lmd2}{\lambda \overline{\xi}}
   \bkptr[nodesep=1pt]{30}{lmd}{m}
   \bkptr[nodesep=1pt]{60}{lmd2}{m2} \\
 \pview{s \cdot r }  &=&  r
\end{eqnarray*}
where $r$ is the root of the tree $\tau(M)$ and $n$ ranges over
non-lambda nodes (i.e. $N_\Sigma \union N_@ \union N_{var}$).

In the second clause, the pointer associated to $n$ is preserved
from the left-hand side to the right-hand side i.e. if in the
left-hand side, $n$ points to some node in $s$ that is also present
in $\pview{s}$ then in the right-hand side, $n$ points to this
occurrence of the node in $\pview{s}$.

Similarly, in the third clause the pointer associated to $m$ is preserved.
\end{dfn}

We also define O-view, the dual notion of P-view:
\begin{dfn}[O-view]
The O-view of a justified sequence of nodes $t$ of $\tau(M)$, written $\oview{t}$, is defined as follows:
\begin{eqnarray*}
 \oview{\epsilon} &=&  \epsilon \\
 \oview{s \cdot \lambda \overline{\xi} }  &=&  \oview{s} \cdot \lambda \overline{\xi} \\
 \oview{s \cdot \rnode{m}{m} \cdot \ldots \cdot \rnode{x}{x}} &=& \oview{s} \cdot \rnode{m2}{m} \cdot \rnode{n2}{x} \\
   \bkptr[nodesep=1pt]{30}{x}{m}
   \bkptr[nodesep=1pt]{60}{n2}{m2}
 \oview{s \cdot n }  &=&  n
\end{eqnarray*}
where $x$ ranges over variable nodes and  $n$ ranges over non-lambda
nodes without pointer (i.e. $N_@ \union N_\Sigma$).

The pointer associated to $\lambda \overline{\xi}$ in the second
equality and the pointer associated to $m$ in the third equality are
preserved from the left-hand side to the right-hand side of the
equalities.
\end{dfn}

\begin{dfn}[Alternation and Visibility] \ \\
A justified sequence of nodes $s$ satisfies:
\begin{itemize}
\item \emph{Alternation} if for any two consecutive nodes in $s$, one is a $\lambda$-node
and the other is not;

\item \emph{P-visibility} if every variable node in $s$ points to a node occurring in the P-view a that point;

\item  \emph{O-visibility} if every lambda node in $s$ points to a node occurring in the O-view a that point.
\end{itemize}
\end{dfn}

\begin{property}
\label{proper:pview_visibility}
The P-view (resp. O-view) of a justified sequence verifying P-visibility (resp. O-visibility)
is a well-formed justified sequence verifying P-visibility (resp. P-visibility).
\end{property}

\subsection{Adding value-leaves to the computation tree}
\label{sec:adding_value_leaves}

We now add leaves to the computation tree that has been defined in the previous section.
These leaves, called \emph{value-leaves}, are attached to the nodes of the computation tree. Each
value-leaf corresponds to a possible value of the base type $o$.
We write $\mathcal{D}$ to denote the set of values of the base type
$o$. The values leaves are added as follows: every  %$\lambda$-node or variable
node $n \in \tau(M)$ has a child leaf denoted by $v_n$ for each possible value $v \in \mathcal{D}$.

%@-nodes and $\Sigma$-nodes do not have child leaves.

%If $n$ is a $\lambda$-node then its value-leaves are numbered from $1$ onwards.
%If $n$ is a variable or constant node then its children nodes are numbered from $1$ to $arity(n)$ and
%its value-leaves are numbered from $arity(n)+1$ onwards.
%If $n$ is an application node then its value-leaves are numbered from $1$ onwards.

Everything that we have defined for computation tree can be lifted
to this new version of computation tree. The node order of a
value-leaf is defined to be $0$. The enabling relation $\vdash$ is
extended so that every leaf is enabled by its parent node. The
definition of justified sequence does not change.
When representing a link in a justified sequence going from a value-leaf $v_n$ to a node $n$,
we label the link with $v$:
$$
\rnode{n}{n} \cdot \ldots \cdot \rnode{vn}{v_n} \bkptr[nodesep=1pt]{40}{vn}{n} \bklabel{v}
$$


For the definition
of P-view, O-view and visibility, value-leaves are treated as
$\lambda$-nodes if they are at odd level in the computation tree and
as variable nodes if there at a even level.

From now the term ``computation tree'' refers to this extended
definition.
\vspace{10pt}

Let $n$ be a node of a justified sequence of nodes.
% that is either a $\lambda$-node or a variable node.
If there is an occurrence of a value-leaf $v_n$ in the sequence that points to $n$ we say that
$n$ is \emph{matched} by $v_n$. If there is no value-leaf in the sequence that points to $n$ we
say that $n$ is an \emph{unmatched node}.
The last unmatched node is called the \emph{pending node}.
A justified sequence of nodes is \emph{well-bracketed} if
each value-leaf in the traversal points to the pending node at that point.

If $t$ is a traversal then we write $?(t)$ to denote the subsequence
of $t$ consisting only of unmatched nodes.

\subsection{Traversal of the computation tree}
\label{subsec:traversal} We first define traversals for computation
tree of simply-typed $\lambda$-terms with no interpreted constants.
We will then we show how to extend the definition to the general
setting of $\lambda$-calculus augmented with interpreted constants.

\subsubsection{Traversals for simply-typed $\lambda$-terms}
Intuitively, a \emph{traversal} is a justified sequence of nodes of the computation tree where each node
indicates a step that is taken during the evaluation of the term.

\begin{dfn}[Traversals for pure simply-typed $\lambda$-terms]
\label{def:traversal}
In the simply-typed $\lambda$-calculus with no constants,
a traversal over a computation tree $\tau(M)$
is a justified sequence of nodes defined by induction on the rules
given below. A \emph{maximal-traversal} is a traversal that cannot be
extended by any rule. If $T$ denotes a computation tree then we write $\travset(T)$
to denote the set of traversals of $T$. We also use the abbreviation $\travset(M)$ for $\travset(\tau(M))$.

\emph{Initialization rules}
\begin{itemize}
\item ($\epsilon$) The empty sequence of node $\epsilon$ is a traversal.
\item (Root) The length 1 sequence $r$, where $r$ is denotes the root of $\tau(M)$, is a traversal.
\end{itemize}

\emph{Structural rules}
\begin{itemize}
\item (Lam) Suppose that $t \cdot \lambda \overline{\xi}$ is a traversal and $n$ is the only child node of $\lambda \overline{\xi}$ in
the computation tree then
$$t \cdot \lambda \overline{\xi} \cdot n$$
is also a traversal
where $n$ points to the (only) occurrence of its enabler in $\pview{t \cdot \lambda \overline{\xi}}$.
In particular, if $n$ is a free variable node then $n$ points to the first node of $t$.

\item (App) If $t \cdot @$ is a traversal then so is
$$t \cdot \rnode{m}{@} \cdot
\rnode{n}{n} \bkptr[nodesep=1pt]{60}{n}{m} \bklabelc{0}
$$

i.e. the next visited node is the $0$th child node of @ : the
node corresponding to the operator of the application.
\end{itemize}

\emph{Input-variable rules}
\begin{itemize}
\item (InputVar$^0$) If $t = t_1 \cdot x \cdot t_2$ is a traversal where
$x$ is the pending node in $t$ (i.e. $?(t_2)=\epsilon$)
and $x$ is a ground-type input-variable then for any $v \in \mathcal{D}$ the following is a traversal
$$t_1 \cdot \rnode{x}{x} \cdot t_2 \cdot \rnode{xv}{v_x}
\bkptr[nodesep=1pt]{40}{xv}{x} \bklabelc{v}$$


\item (InputVar$^{\geq 1}$)
If $t = t_1 \cdot x \cdot t_2$ is a traversal where
$x$ is the pending node in $t$ (i.e. $?(t_2)=\epsilon$)
and $x$ is a higher-order input-variable then the following is a traversal:
$$t_1 \cdot \rnode{m}{x} \cdot t_2 \cdot
\rnode{n}{n} \bkptr[nodesep=1pt]{40}{n}{m} \bklabelc{i} \qquad
\mbox{ for } 1 \leq i \leq arity(x).$$
Moreover for any $v\in \mathcal{D}$ the sequence $t_1 \cdot \rnode{x}{x} \cdot t_2 \cdot
\rnode{xv}{v_x} \bkptr[nodesep=1pt]{40}{xv}{x} \bklabelc{v}$ is also a traversal.
\end{itemize}

\emph{Copy-cat rules}
\begin{itemize}
  \item (CCAnswer-@)
%  If $t \cdot \lambda \overline{\xi} \cdot \rnode{app}{@} \cdot \rnode{lz}{\lambda \overline{z}} \cdot \ldots \cdot  \rnode{lzv}{v_{\lambda \overline{z}}}
%              \bkptr[nodesep=1pt]{30}{lzv}{lz} \bklabelc{v}
%              \bkptr[nodesep=1pt]{40}{lz}{app} \bklabelc{0}$
%              is a traversal then so is:
%              $t \cdot \rnode{lmd}{\lambda \overline{\xi}} \cdot \rnode{app}{@} \cdot \rnode{lz}{\lambda \overline{z}} \cdot \ldots \cdot \rnode{lzv}{v_{\lambda \overline{z}}} \cdot
%              \rnode{lmdv}{v_{\lambda \overline{\xi}}}
%              \bkptr[nodesep=1pt]{30}{lzv}{lz} \bklabelc{v}
%              \bkptr[nodesep=1pt]{40}{lz}{app} \bklabelc{0}
%                \bkptr[nodesep=1pt]{30}{lmdv}{lmd} \bklabelc{v}$.
  If $t \cdot \rnode{app}{@} \cdot \rnode{lz}{\lambda \overline{z}} \cdot \ldots \cdot \rnode{lzv}{v_{\lambda \overline{z}}}
              \bkptr[nodesep=1pt]{30}{lzv}{lz} \bklabelc{v}
              \bkptr[nodesep=1pt]{40}{lz}{app} \bklabelc{0}$
              is a traversal then so is:
              $t \cdot \rnode{app}{@} \cdot \rnode{lz}{\lambda \overline{z}} \cdot \ldots \cdot \rnode{lzv}{v_{\lambda \overline{z}}} \cdot \rnode{appv}{v_@}
              \bkptr[nodesep=1pt]{30}{lzv}{lz} \bklabelc{v}
              \bkptr[nodesep=1pt]{40}{lz}{app} \bklabelc{0}
              \bkptr[nodesep=1pt]{30}{appv}{app} \bklabelc{v}$.


  \item (CCAnswer-$\lambda$) If $t \cdot \lambda \overline{\xi} \cdot \rnode{x}{x} \cdot \ldots \cdot  \rnode{xv}{v_x}
              \bkptr[nodesep=1pt]{30}{xv}{x} \bklabelc{v}$
              is a traversal then so is:
              $t \cdot \rnode{lmd}{\lambda \overline{\xi}} \cdot \rnode{x}{x} \cdot \ldots \cdot \rnode{xv}{v_x} \cdot
              \rnode{lmdv}{v_{\lambda \overline{\xi}}}
              \bkptr[nodesep=1pt]{20}{xv}{x} \bklabelc{v}
                \bkptr[nodesep=1pt]{20}{lmdv}{lmd} \bklabelc{v}$.

     \item (CCAnswer-var) If $t \cdot y \cdot \rnode{lmd}{\lambda \overline{\xi}}
                   \cdot \ldots
                   \cdot \rnode{lmdv}{v_{\lambda \overline{\xi}}} \bkptr[nodesep=1pt]{30}{lmdv}{lmd} \bklabelc{v}$ is a traversal,
                   where $y$ is a non input-variable node, then the following is also a traversal:
        $$t \cdot \rnode{y}{y}
            \cdot \rnode{lmd}{\lambda \overline{\xi}}
            \cdot \ldots
            \cdot \rnode{lmdv}{v_{\lambda \overline{\xi}}}
            \cdot \rnode{yv}{v_y}
                \bkptr[nodesep=3pt]{35}{yv}{y} \bklabelc{v}
                \bkptr[nodesep=1pt]{30}{lmdv}{lmd} \bklabelc{v}.$$


\item (Var)
If $t \cdot x_i$ is a traversal where $x_i$ is not an input-variable,
then the rule (Var) permits to visit the node corresponding to the subterm that would be substituted
for $x_i$ if all the $\beta$-redexes occurring in $M$ were reduced.

The binding node $\lambda \overline{x}$ necessarily occur previously
in the traversal. Since $x$ is not hereditarily justified by the
root, $\lambda \overline{x}$ is not the root of the tree and
therefore its justifier $p$ - which is also its parent node - occurs
immediately before itself it in the traversal. We do a case analysis
on $p$:

    \begin{itemize}
    \item Suppose $p$ is an @-node then $\lambda \overline{x}$ is necessarily the first child node of $p$
    and $p$ has exactly $|\overline{x}| + 1$ children nodes:
    $$\pstree[levelsep=7ex]{\TR{\stackrel{\vdots}{@^{[p]}}}}
    {   \pstree[linestyle=dotted,levelsep=4ex]{\TR{\lambda \overline{x}}\treelabel{0}}
            {\TR{x_i }}
        \tree{\lambda \overline{\eta_1}}{\vdots}\treelabel{1}
        \TR[edge=\dotedge]{}
        \tree{\lambda \overline{\eta_i}}{\vdots}\treelabel{i}
        \TR[edge=\dotedge]{}
        \tree{\lambda \overline{\eta_{|x|}}}{\vdots}\treelabel{|x|}
    }
    $$
    In that case, the next step of the traversal is a jump to $\lambda \overline{\eta_i}$ -- the $i$th child of
    @ -- which corresponds to the subterm that would be substituted for $x_i$ if the $\beta$-reduction was
    performed:
    \vspace{0.3cm}
    $$t' \cdot \rnode{n}{@^{[p]}} \cdot
    \rnode{lx}{\lambda \overline{x}} \cdot \ldots \cdot
    \rnode{x}{x_i} \cdot
    \rnode{mi}{\lambda \overline{\eta_i}} \cdot \ldots
    \bkptr[ncurv=0.45]{45}{mi}{n} \bklabel{i}
    \bkptr[ncurv=0.6]{50}{x}{lx} \bklabel{i} \in \travset(M)
    $$

    \item Suppose $p$ is variable node $y$, then
    necessarily the node $\lambda \overline{x}$ has been added to the traversal $t_{\leq y}$ using the (Var) rule
    (this is proved in proposition \ref{prop:pviewtrav_is_path}(i)).
    Therefore $y$ is substituted by the term $\kappa(\lambda \overline{x})$ during the evaluation of the term
    and we have $\ord{y} = \ord{\lambda \overline{x}}$.

    Consequently, during reduction, the variable $x_i$ is substituted by the subterm represented by
    $\lambda \overline{\eta_i}$ -- the $i$th child node of $y$.
    Hence the following justified sequence is also a traversal:
    \vspace{0.2cm}
    $$t' \cdot \rnode{n}{y^{[n]}} \cdot
    \rnode{lx}{\lambda \overline{x}} \cdot \ldots \cdot
    \rnode{x}{x_i} \cdot
    \rnode{mi}{\lambda \overline{\eta_i}} \cdot \ldots
    \bkptr[ncurv=0.6]{50}{x}{lx} \bklabel{i}
    \bkptr[ncurv=0.5]{50}{mi}{n} \bklabel{i}$$
    \end{itemize}
\end{itemize}
Note that a traversal always starts with the root of the tree.
\end{dfn}

\begin{rem}
Our notions of computation tree and traversal differ slightly from
\cite{OngLics2006}.

Firstly, our computation tree do not have nodes labelled with
(uninterpreted) first-order constants. On the other hand, there are
nodes which are labelled by free variables of any order. Since
uninterpreted constants can be regarded as free variables, we do not
lose any expressivity. The traversal rules (InputVar$^0$) and
(InputVar$^\geq 1$) provide a more general version of the (Sig) rule
of \cite{OngLics2006}.

Secondly we have introduced copy-cat rules that permit to visit the
value-leaves of the computation tree. The presence of value-leaves
is necessary to model free variables as well as the interpreted
constants present in extensions of the $\lambda$-calculus such as
\pcf\ or \ialgol.
\end{rem}

\begin{exmp}
Consider the following computation tree:
$$\tree{\lambda}
{
    \tree{@}
    {
        \pstree[levelsep=8ex,linestyle=dotted]{\TR{\lambda y}\treelabel{0} }
        {
            \pstree[levelsep=8ex]{\TR{y}}
            {
                \tree{\lambda \overline{\eta_1}}{\vdots} \treelabel{1}
                \TR[edge=\dotedge]{}
                \tree{\lambda \overline{\eta_i}}{\vdots}\treelabel{i}
                \TR[edge=\dotedge]{}
                \tree{\lambda \overline{\eta_n}}{\vdots}\treelabel{n}
            }
        }
        \pstree[levelsep=6ex,linestyle=dotted]{\TR{\lambda \overline{x}}\treelabel{1}}{ \tree{x_i}{\TR{} \TR{} } }
    }
}
$$
An example of traversal of this tree is:
\vspace{0.3cm}
$$ \lambda \cdot
\rnode{app}{@}  \cdot
\rnode{ly}{\lambda y} \cdot \ldots \cdot
\rnode{y}{y} \cdot
\rnode{lx}{\lambda \overline{x}} \cdot \ldots \cdot
\rnode{x}{x_i} \cdot
\rnode{leta}{\lambda \overline{\eta_i} } \cdot \ldots
\bkptr[ncurv=0.6,nodesep=0]{40}{x}{lx}  \bklabel{i}
\bkptr[ncurv=0.5]{50}{leta}{y}  \bklabel{i}
\bkptr[ncurv=0.6,nodesep=0]{40}{y}{ly}  \bklabel{1}
\bkptr[ncurv=0.5]{50}{lx}{app}  \bklabel{1}$$
\end{exmp}

\subsubsection{Traversals for interpreted constants}

\begin{dfn}[Well-behaved traversal rule]
\label{def:wellbehaved_traversal}
A traversal rule is \emph{well-behaved} if it can be stated under the following form:
$$\rulef{t = t_1\cdot n \cdot t_2 \in \travset \quad ?(t_2) = \epsilon \quad P(t)}
  { \stackrel{  \rule{0pt}{3pt} }{t' = t_1\cdot \rnode{n}{n} \cdot t_2 \cdot \rnode{m}{m} \in \travset} }
   \bkptr[nodesep=1pt]{35}{m}{n}
    \ m\in S(t)
   $$
such that:
\begin{enumerate}
  \item $n$ is a variable or a constant node;
  \item $P$ expresses some condition on $t$;
  \item $S(t)$ is some subset of $E(n)$, the set of children $\lambda$-nodes and value-leaves of $n$.
  If $S(t)$ has more than one element then the rule is non-deterministic.
\end{enumerate}
\end{dfn}
Note that if $t$ is well-bracketed then $t'$ is also well-bracketed
and if $?(t)$ satisfies alternation (resp. visibility) then so does $?(t')$.


The rules (InputVar$^0$) and (InputVar$^{\geq1}$) are two examples of
non-deterministic well-behaved traversal rules for which
$S(t)$ is exactly the set of all children-nodes and value-leaves of $n$:
$S(t) = \{ n.i \ |\ i \in 1..arity(n) \} \union  \{ v_n \ | \ v \in \mathcal{D} \} $.


In the presence of higher-order interpreted constants, additional rules must be specified to indicate how
the constant nodes should be traversed in the computation tree. These rules
are specific to the language that is being studied.
In the last section of this chapter we will define such traversals for the interpreted constants of
\pcf\ and \ialgol.

From now on, we consider a simply-typed $\lambda$-calculus language extended with
higher-order interpreted constants for which some constant traversal rules have been defined
and we take the following condition as a prerequisite:
\begin{center}
  \textbf{Condition (WB) :} the constant traversal rules are well-behaved.
\end{center}


\subsubsection{Some properties of traversals}

\begin{prop}
\label{prop:pviewtrav_is_path}
Let $t$ be a traversal. Then:
\begin{itemize}
\item[(i)] $t$ is a well-defined and well-bracketed justified sequence;
\item[(ii)] $?(t)$ is a well-defined justified sequence verifying alternation, P-visibility and O-visibility;
\item[(iii)] $\pview{?(t)}$ is a path in the computation tree going from the root to the last node in $?(t)$.
\end{itemize}
\end{prop}
This is the counterpart of proposition 6 from
\cite{OngHoMchecking2006} which is proved by induction on the
traversal rules. This proof can be easily adapted to take into
account the constant rules (using the assumption that constants
rules are well-behaved) and the presence of value-leaves in the
traversal.



\begin{dfn}[Traversal reduction]
Let $r$ be the root of the computation tree. We say that the
justified sequence of nodes \emph{$s$ is a reduction of the
traversal $t$} just when $s = t \upharpoonright r$.
\end{dfn}

Since @-nodes and $\Sigma$-constants do not have pointer, the
reduction of traversal contains only nodes in $N_\lambda \union
N_{var}$.


\begin{lem}
\label{lem:var_followedby_child} Let $M$ be a term in $\beta$-normal
form and $t$ be a traversal of $\tau(M)$. If $?(t) = u_1 \cdot
\rnode{m}{m} \cdot u_2 \cdot \rnode{n}{n}
\bkptr[nodesep=1pt]{20}{n}{m}$ where $m$ is a not a $\lambda$-node
then $u_2 = \epsilon$.
\end{lem}
\begin{proof}
By induction on the traversal rules. The only relevant rules are (Var), (CCAnswer-var), (InputVar$^0$), (InputVar$^{\geq 1}$)
and the constant rules.
Since the term is in $\beta$-normal form, there is no @-node in $\tau(M)$ and therefore (Var) cannot be used.
For the rules (CCAnswer-var), (InputVar$^0$) and (InputVar$^{\geq 1})$ we just use the well-bracketedness of traversals.
For the constant rules, the result is a consequence of condition (WB) stating that constant rules are the well-behaved.
\end{proof}

\begin{lem}[View of a traversal reduction]
\label{lem:redtrav_trav} Let $M$ be a term in $\beta$-normal form,
$r$ be the root of $\tau(M)$ and $t$ be a traversal of $\tau(M)$. We
have
\begin{itemize}
\item[(i)] $ \pview{?(t) \upharpoonright  r } = \pview{?(t)} \upharpoonright r$;
\item[(ii)] if the last node in $t$ is hereditarily justified by $r$ then $ \oview{?(t) \upharpoonright r } = \oview{?(t)}$.
\end{itemize}
\end{lem}
The proof is by an easy induction.

\begin{lem}[Traversal of $\beta$-normal terms]
\label{lem:betaeta_trav}
Let $M$ be a $\beta$-normal term, $r$ be the root of the tree $\tau(M)$ and
$t$ be a traversal of $\tau(M)$.
For any node $n$ occurring in $t$:
\begin{eqnarray*}
&& r \mbox{ does not hereditarily justify } n  \  \\
&\iff&  \   n \mbox{ is
hereditarily justified by some node in } N_\Sigma.
\end{eqnarray*}
\end{lem}


\section{Game semantics of simply-typed $\lambda$-calculus with $\Sigma$-constants}
\label{sec:assumptions}

We are working in the general setting of an applied simply-typed $\lambda$-calculus with a given set of higher-order constants $\Sigma$.
The operational semantics of these constants is given by certain reduction rules.
We assume that a fully abstract model of the calculus is provided by mean of a category of well-bracketed games.
For instance, if $\Sigma$ is the set of \pcf\ constants then we work in the category $\mathcal{C}_{b}$
of well-bracketed defined in section \ref{subsec:pcfgamemodel} of the first chapter.

We will use the alternative representation of strategy defined in remark \ref{rem:atlern_strategy}: a
strategy is given by a prefix-closed set instead of an ``even length
prefix''-closed set. In practice this means that we replace the set
of plays $\sigma$ by $\sigma \union \textsf{dom}(\sigma)$. This
permits to avoid considerations on the parity of the length of
traversals when we show the correspondence between traversals and
game semantics. We write $\sem{\Gamma \vdash M : A}$ for the strategy denoting the simply-typed term
$\Gamma \vdash M : A$ and $\prefset(S)$ to denote the
prefix-closure of the set $S$.


\subsection{Relationship between computation trees and arenas}

\subsubsection{Example}
Consider the following term $M \equiv \lambda f z . (\lambda g x . f (f x)) (\lambda y. y) z$ of type $(o \typear o) \typear o \typear o$.
Its $\eta$-long normal form is $\lambda f z . (\lambda g x . f (f x)) (\lambda y. y) (\lambda .z)$.

\newlength{\yNull}
\def\bow{\quad\psarc{->}(0,\yNull){1.5ex}{90}{270}}

The figure below represents the computation tree (left) and the
arena (right). The dashed line defines a partial function $\varphi$
from the set of nodes in the computation tree to the set of moves.
For simplicity, we now omit answers moves when representing arenas.
$$
\tree{ \Rnode{root} {\lambda f z w}^{[1]} }
     {  \tree{@^{[2]}}
        {   \tree{\lambda g x ^{[3]}}
                { \tree{\Rnode{f}{f^{[6]}}}{  \tree{\Rnode{lmd}\lambda^{[7]}}{ \tree{\Rnode{f2}{f^{[8]}}} {\tree{\Rnode{lmd2}\lambda^{[9]}}{\TR{x^{[10]}}}}}  }
                }
            \tree{\lambda y ^{[4]}}{\TR{y}}
            \tree{\lambda ^{[5]}}{\TR{\Rnode{z}z}}
        }
    }
\hspace{3cm}
  \tree[levelsep=12ex]{ \Rnode{q1}q^1 }
    {   \pstree[levelsep=4ex]{\TR{\Rnode{q3}q^3}}{\TR{\Rnode{q4}q^4}}
        \TR{\Rnode{q2}q^2}
        \TR{\Rnode{q5}q^5}
    }
\psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
\ncline{->}{root}{q1} \aput*{:U}{\varphi}
\ncarc{->}{z}{q2}
\ncline{->}{f}{q3}
\ncline{->}{lmd}{q4}
\ncline{->}{f2}{q3}
\ncline{->}{lmd2}{q4}
$$

Consider the justified sequence of moves $s \in \sem{M}$:
\vspace{0.2cm}
 $$s =
\rnode{q1}{q}^1\ \rnode{q3}{q}^3\ \rnode{q4}{q}^4\ \rnode{q3b}{q}^3\ \rnode{q4b}{q}^4\ \rnode{q2}{q}^2
\bkptr[offset=-3pt]{60}{q3}{q1}
\bkptr[offset=-3pt,ncurv=0.5]{60}{q3b}{q1}
\bkptr[offset=-3pt]{60}{q4}{q3}
\bkptr[offset=-3pt]{60}{q4b}{q3b}
\bkptr[offset=-3pt,ncurv=0.5]{60}{q2}{q1}
\in \sem{M}$$

There is a corresponding justified sequence of nodes in the computation tree:
\vspace{0.5cm}
$$r =
\rnode{q1}{\lambda f z} \cdot
\rnode{q3}{f}^{[6]} \cdot
\rnode{q4}{\lambda^{[7]}} \cdot
\rnode{q3b}{f}^{[8]} \cdot
\rnode{q4b}{\lambda^{[9]}} \cdot
\rnode{q2}{z}
\bkptr[ncurv=1]{60}{q3}{q1}
\bkptr[ncurv=1]{60}{q4}{q3}
\bkptr[ncurv=0.5]{75}{q3b}{q1}
\bkptr[ncurv=1]{50}{q4b}{q3b}
\bkptr[ncurv=0.4]{80}{q2}{q1}$$
such that $s_i = \varphi(r_i)$ for all $i < |s|$.

The sequence $r$ is in fact the reduction of the following
traversal: \vspace*{1cm}
$$t = \rnode{q1}{\lambda f
z} \cdot \rnode{n2}{@^{[2]}} \cdot \rnode{n3}{\lambda g x^{[3]}}
\cdot \rnode{q3}{f}^{[6]} \cdot \rnode{q4}{\lambda^{[7]}} \cdot
\rnode{q3b}{f}^{[8]} \cdot \rnode{q4b}{\lambda^{[9]}} \cdot
\rnode{n8}{x^{[10]}} \cdot \rnode{n9}{\lambda^{[5]}} \cdot
\rnode{q2}{z} \bkptr[ncurv=0.6]{60}{q3}{q1}
\bkptr[ncurv=1]{60}{q4}{q3} \bkptr[ncurv=0.4]{75}{q3b}{q1}
\bkptr[ncurv=0.8]{70}{q4b}{q3b} \bkptr[ncurv=0.4]{80}{q2}{q1}
\bkptr[ncurv=0.4]{60}{n3}{n2} \bkptr[ncurv=0.4]{60}{n8}{n3}
\bkptr[ncurv=0.4]{60}{n9}{n2}.
$$

By representing side-by-side the computation tree and the type arena of a term in $\eta$-normal form we have observed
that some nodes of the computation tree can be mapped to question moves of the arena.
In the next section, we show how to define this mapping in a systematic manner.

\subsubsection{Formal definition}

Let us establish precisely the relationship between arenas of the
game semantics and the computation trees. Let $\Gamma \vdash M : A$
be a term in $\eta$-long normal form. The computation tree $\tau(M)$
is represented by a pair $(V,E)$ where $V$ is the set of vertices of
the trees and $E$ is the edges relation. $V = N \union L$ where $N$
is the set of nodes and $L$ is the set of value-leaves.

The relation $E \subseteq V \times V$ gives the parent-child relation on the vertices of the tree.
$E = E_n \union E_l$ where $E_n \subseteq N \times N$ gives the node-node parent relation and $E_l \subseteq N \times L$ gives the node-leaf parent relation.
We write $L_\$$ for $E_l(N_\$)$
and $V_\$$  for $N_\$ \union L_\$$ where $\$$ ranges over $\{@, var, \Sigma, fv \}$.

%$E^+$ denotes the transitive closure of $E$ --
%$E^+(n)$ is the set of nodes $m$ such that there is a path from $n$
%to $m$ in the computation tree.

Let $\mathcal{D}$ be the set of values of the base type $o$. If $n$
is a node in $N$ then the value-leaves in
$E_l(n)$ attached to the node $n$ are written $v_n$ where $v$ ranges in $\mathcal{D}$.
Similarly, if $q$ is a question in $\sem{A}$ then the answer moves
enabled by $q$ are written $v_q$ where $v$ ranges in $\mathcal{D}$.

If $A$ is an arena and $q$ is a move in $A$ then we write $A_q$ to
denote the subarena of $A$ rooted at $q$.

\begin{dfn}[Relation between the arena and the computation tree]
\label{def:phi_procedure}
We consider the computation tree of a simply-typed-term.
For any arena $A$, we define a function $f_A(n,q)$ taking two parameters:
a node $n$ of the computation tree and a question move $q$ of the arena $A$
such that $q$ and $n$ have the same type.
$f_A(n,q)$ returns a partial function from $V$ to $A$. It is defined as follows:
\noindent
\begin{itemize}
\item[case 1] If $n$ is an order $0$ $\lambda$-node (i.e. labelled $\lambda$) or a ground type variable node then
        $$f_A(n,q) = \{ n \mapsto q \} \quad \union \quad  \{ v_n \mapsto v_q \ | \ v \in \mathcal{D} \}$$

\item[case 2] If $n$ is a $\lambda$-node labelled $\lambda \overline{\xi} = \lambda \xi_1 \ldots \xi_p$ with $p\geq 1$ then
    the computation tree and the arena $A_q$ have the following form
    (value-leaves and answer moves are not represented for simplicity):
    $$ \tree[levelsep=6ex]{ \Rnode{r}\lambda \overline{\xi}  ^{[n]}}
        {
            \tree[levelsep=6ex]{\alpha}
            {   \TR{\ldots} \TR{\ldots} \TR{\ldots}
            }
        }
    \hspace{3cm}
    \tree{ \Rnode{q0}q }
        {
            \tree[linestyle=dotted]{q^1}{\TR{} \TR{} }
            \tree[linestyle=dotted]{q^2}{\TR{} \TR{} }
            \TR{\ldots}
            \tree[linestyle=dotted]{q^p}{\TR{} \TR{} }
        }
    \psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
    \ncline{->}{r}{q0}
    \ncarc{->}{q2}{z}
    \ncline{->}{q3}{f}
    \ncline{->}{q4}{lmd}
    \ncline{->}{q3}{f2}
    \ncline{->}{q4}{lmd2}
    $$

    For each of the abstracted variable $\xi_i$ there exists a corresponding question move $q^i$ of the same order
    in the arena.  $f_A(n,q)$ maps each free occurrence of a variable $\xi_i$ to the corresponding move $q^i$:
    $$
    f_A(n,q) =  \{ n \mapsto q \} \quad  \union \quad  \{ v_n \mapsto v_q \ | \ v \in \mathcal{D} \}
                      \quad \union \quad  \Union_{\stackrel{\displaystyle m \in N | n \vdash m}{\displaystyle m \mbox{ labelled } \xi_i}} f_A( m, q^i)
    $$

\item[case 3] If $n$ is a variable node labelled with a higher-order variable $x$ of type $(A_1|\ldots|A_m|o)$ then the computation tree and the arena $A_q$
have the following form:
    $$\tree[levelsep=6ex]{\Rnode{r}{x^{[n]}}}
        {   \tree{\TR{\lambda \overline{\eta}_1}}{\vdots} \TR{\ldots}
        \tree{\TR{\lambda \overline{\eta}_m }}{\vdots}
        }
    \hspace{3cm}
    \tree{ \Rnode{q0}q }
        {
            \tree[linestyle=dotted]{\Rnode{q1}{q^1}}{\TR{} \TR{} }
            \tree[linestyle=dotted]{\Rnode{q2}{q^2}}{\TR{} \TR{} }
            \TR{\ldots}
            \tree[linestyle=dotted]{\Rnode{qm}{q^m}}{\TR{} \TR{} }
        }
    \psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
    \ncline{->}{r}{q0}
    \ncarc{->}{q2}{z}
    \ncline{->}{q3}{f}
    \ncline{->}{q4}{lmd}
    \ncline{->}{q3}{f2}
    \ncline{->}{q4}{lmd2}
    $$

    $f_A(n,q)$ maps each child node of $n$ to the corresponding question move $q^i$ of the same type
    in the arena $A_q$:
    $$f_A(n,q) =
         \{ n \mapsto q \} \quad \union\quad \{ v_n \mapsto v_q \ | \ v \in \mathcal{D}   \} \quad\union\quad     \Union_{i=1..m} f_A( \lambda \overline{\eta}_i, q^i)
    $$
\end{itemize}

Note that $f_A(n,q)$ is only a partial function from $V$ to $A$ since it is defined only
on nodes that are hereditarily justified by the root \emph{and} not hereditarily justified by a free variable node.
In other words, $f_A(n,q)$ is undefined on nodes that are hereditarily justified by $N_{fv} \union N_@ \union N_\Sigma$.
\end{dfn}

Suppose $\Gamma \vdash M  : T$ is a simply-typed term and $N$ denotes the set of nodes of the computation tree.
We write $\mathcal{M}_M$ to denote the following disjoint union of arenas:
$$\mathcal{M}_M = \sem{\Gamma \rightarrow T} \quad \uplus \quad  \biguplus_{n \in E_n \relimg{N_@ \union N_\Sigma} } \sem{type(\kappa(n))}.$$

Moves in $\mathcal{M}_M$ are implicitly tagged so it is possible to recover the arena in which they belong.


\begin{dfn}[Total mapping from nodes to moves]
Let $\Gamma \vdash M : T$ be a simply-typed term
with $\Gamma = x_1:X_1 \ldots x_p : X_p$.
We write $q_{\sem{\Gamma}}^1$, \ldots, $q_{\sem{\Gamma}}^p$ to denote the initial question moves of the
component $\Gamma$ of the arena $\sem{\Gamma \rightarrow T}$ and $q^0_A$ to denote the single initial question of any arena $A$
(arenas involved in the game semantics of pure simply-typed $\lambda$-calculus have only one root).
$r$ denotes the root of the computation tree.

We define the total function $\varphi_M : V_\lambda \union V_{var} \rightarrow \mathcal{M}_M$ as follows:
\begin{align*}
\varphi_M =
        f_{\sem{\Gamma \rightarrow T}}(r, q^0_{\sem{\Gamma \rightarrow T}}) \quad
    & \union \quad
    \Union_{n \in N_{fv} | n \mbox{ {\small labelled} } x_i }  f_{\sem{\Gamma \rightarrow T}}(n, q^i_{\sem{\Gamma}} ) \\
    & \union \quad
        \Union_{n \in E_n \relimg{N_@ \union N_\Sigma}}  f_{\sem{type(\kappa(n))}}(n, q^0_{\sem{type(\kappa(n))}} )
\end{align*}
When there is no ambiguity we just write $\varphi$ instead of $\varphi_M$.
\end{dfn}

Nodes of $\tau(M)$ are either hereditarily justified by the root, by
a @-node or by a $\Sigma$-node, therefore $\varphi_M$ is totally
defined on $V_\lambda \union V_{var} = V\setminus (V_@ \union
V_\Sigma)$.

\begin{exmp}
Consider the term $\lambda x . (\lambda g . g x) (\lambda y . y)$ with $x,y:o$ and $g:(o,o)$.
The diagram below represents the computation tree (middle), the arenas
$\sem{(o,o)\rightarrow o}$ (left), $\sem{o \rightarrow o}$ (right), $\sem{o\rightarrow o}$ (rightmost)
and the function $\varphi = f(\lambda x, q_{\lambda x}) \union f(\lambda g, q_{\lambda g}) \union f(\lambda y, q_{\lambda y})$
(dashed-lines).
$$
\psset{levelsep=4ex}
\pstree{\TR[name=root]{\lambda x}}
{
    \pstree{\TR[name=App]{@}}
    {
            \pstree{\TR[name=lg]{\lambda g}}
                { \pstree{\TR[name=lgg]{g}}{
                        \pstree{\TR[name=lgg1]{\lambda}}
                        { \TR[name=lgg1x]{x}  } } }
            \pstree{\TR[name=ly]{\lambda y}}
                    {\TR[name=lyy]{y}}
    }
}
\rput(5cm,-1cm){
  \pstree{\TR[name=A1lx]{q_{\lambda x}}}
        { \TR[name=A1x]{q_x} }
}
\rput(-6cm,-1.5cm){
    \pstree{\TR[name=A2lg]{q_{\lambda g}}}
    {
        \pstree{\TR[name=A2g]{q_g}}
        {  \TR[name=A2g1]{q_{g_1}}   }
    }}
\rput(2.5cm,-1.5cm){
    \pstree{\TR[name=A3ly]{q_{\lambda y}}}
        { \TR[name=A3y]{q_y}
        }
}
\psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
\ncline{->}{root}{A1lx} \mput*{f(\lambda x, q_{\lambda x})}
\ncarc{->}{lgg1x}{A1x}
\ncline{->}{lg}{A2lg} \mput*{f(\lambda g, q_{\lambda g})}
\ncline{->}{lgg}{A2g}
\ncline{->}{lgg1}{A2g1}
\ncline{->}{ly}{A3ly} \mput*{f(\lambda y, q_{\lambda y})}
\ncline{->}{lyy}{A3y}
$$
\end{exmp}

The following properties are immediate consequences of the definition of the procedure $f$:
\begin{property} \
\label{proper:phi_conserve_order}
\begin{itemize}
\item[(i)] $\varphi$ maps $\lambda$-nodes to O-questions, variable nodes to
P-questions, value-leaves of $\lambda$-nodes to P-answers and
value-leaves of variable nodes to O-answers;
\item[(ii)] $\varphi$ maps nodes of a given order to moves of the same order.
\end{itemize}
\end{property}
Remark: we recall that in definition \ref{def:nodeorder}, the
node-order is defined differently for the root $\lambda$-node and
other $\lambda$-nodes. This convention was chosen to guarantee that
property (ii) holds.

By extension, the function $\varphi$ is also defined on justified
sequences of nodes: if $t = t_0 t_1 \ldots$ is a justified sequence
of nodes in $V_\lambda \union V_{var}$ then $\varphi(t)$ is defined
to be the following sequence of moves:
$$\varphi(t) = \varphi(t_0)\ \varphi(t_1)\  \varphi(t_2) \ldots$$
where the pointers of $\varphi(t)$ are defined to be exactly those
of $t$. This definition implies that $\varphi : (V_\lambda \union
V_{var})^* \rightarrow \mathcal{M}^*$ regarded as a function from
pointer-less sequences of nodes to pointer-less sequences of moves
is a monoid homomorphism.

\begin{property}
\label{proper:phi_pview} Let $t$ be a justified sequence of nodes. The following properties hold:
\begin{itemize}
\item[(i)] $\varphi(t)$ and $t$ have the same pointers;
\item[(ii)] the P-view of $\varphi(t)$ and the P-view of $t$ are computed
identically: the set of indices of elements that must be removed
from both sequences in order to obtain their P-view is the same;
\item[(iii)] the O-view of $\varphi(t)$ and the O-view of $t$ are computed identically;
\item[(iv)] if $t$ is a justified sequence of nodes in $V_\lambda \union V_{var}$ then $?(\varphi(t)) =
\varphi(?(t))$,
\end{itemize}
where $?(\varphi(t))$ denotes the set of unanswered questions in the
justified sequence of moves $\varphi(t)$ and $?(t)$ denotes the set
of unmatched nodes in the justified sequence of nodes $t$ (see the
definition in section \ref{sec:adding_value_leaves}).
\end{property}


\subsection{Category of interaction games}
\label{sec:interaction_semantics}

In game semantics, strategy composition is achieved by performing a
CSP-like ``composition + hiding''. It is possible to define an
alternative semantics where the internal moves are not hidden when
performing composition. This semantics is named \emph{interaction}
semantics in \cite{DBLP:conf/sas/DimovskiGL05} and \emph{revealed
semantics} in \cite{willgreenlandthesis}.

In addition to the moves of the standard semantics, the interaction semantics contains certain
internal moves of the computation.
Consequently, the interaction semantics depends on the syntactical structure of the term and therefore cannot
lead to a full abstraction result. However this semantics will prove to be useful to identify
a correspondence between the game semantics
of a term and the traversals of its computation tree.

We will be interested in the interaction semantics computed from the
$\eta$-normal form of a term. However we do not want to keep all the internal moves. We will only keep the internal
moves that are produced when composing two subterms of the computation tree that are joined by an @-node.
This means that when computing the strategy of
$y N_1 \ldots N_p$ where $y$ is a variable, we keep the internal moves of $N_1$, \ldots, $N_p$, but
we omit the internal moves produced by the copy-cat projection strategy denoting $y$.




Let $T$ be a type-tree. Each leaf or node of type $A$ in $T$ can be mapped to the
(standard) arena $\sem{A}$. By taking the image of $T$ across this mapping we obtain a tree whose leaves and nodes are labelled by arenas.
This tree, written $\intersem{T}$, is called the \emph{interaction arena} of type $T$.
We write $root(\intersem{T})$ to denote the arena located at the root of the interaction arena $\intersem{T}$.

A \emph{revealed strategy} $\Sigma$ on the interaction arena
$\intersem{T}$ is a composition of several standard strategies where
certain internal moves are not hidden. Formally this can be defined
as follows:
\begin{dfn}[Revealed strategy]
A revealed strategy $\Sigma$ on a game $\intersem{T}$, written
$\Sigma: \intersem{T}$, is a tree type $T$ where
\begin{itemize}
\item each leaf $\sem{A}$ of
$\intersem{T}$ is annotated with a (standard) strategy $\sigma$ on the
game $\sem{A}$;
\item each $;$-node is annotated with a set of indices $U \subseteq \nat$.
\end{itemize}
\end{dfn}
A $;$-node with children of type $A\multimap B$ and $B\multimap C$ is annotated with a set of indices $U$ indicating
which components of $B$ should be uncovered when performing composition.



A play of the interaction semantics, called an \emph{uncovered
play}, is a play containing internal moves.
The moves are implicitly tagged so that it is possible to retrieve in which component
of which node or leaf-arenas the move belongs to. Note that a same move can belong to different node/leaf-arenas.
The internal moves of an interaction play on the game $\intersem{T}$ are those which do not
belong to the arena $root(\intersem{T})$.

For any uncovered play $s$ and any interaction arena $\intersem{T}$
we can define the filtering operator $s\upharpoonright \intersem{T}$ to be the
sequence of moves obtained from $s$ by keeping only the moves
belonging to a node or leaf-arena of $\intersem{T}$.


Revealed strategies can be represented by mean of sets
of uncovered plays instead of annotated type-trees. This set is
defined inductively on the structure of the annotated type-tree
$\Sigma$ as follows:
\begin{itemize}
\item for a leaf $\sem{A}$ of $\Sigma$ annotated by $\sigma :\sem{A}$, it is just the set of plays of the standard strategy $\sigma$;
\item for a $\otimes$-node with two children strategies $\Sigma_1$ and $\Sigma_2$, it is the tensor product written $\Sigma_1 \otimes \Sigma_2$;
\item for a $\times$-node, it is the pairing written $\langle \Sigma_1, \Sigma_2 \rangle$;
\item for a $\dagger$-node with a child strategy $\Sigma$, it is the promotion written $\Sigma^\dagger$;
\item for a $\Lambda$-node with a child strategy $\Sigma$, it is the same set of plays with the moves retagged appropriately;

\item for a $;^U$-node, it is the ``uncovered-composition'' of $\Sigma_1 : \intersem{T_1}$ and $\Sigma_2 :\intersem{T_2}$ which is written $\Sigma_1
;^U \Sigma_1$ and defined as follows: suppose that $type(T_1) = A
\multimap B_0 \times \ldots \times B_l$ and $type(T_2) = B_0 \times
\ldots \times B_l \multimap C$ then $\Sigma_1 ;^U \Sigma_1$ is the
set of uncovered plays obtained by performing the usual composition
while ignoring and copying the internal moves from arenas in
$\intersem{T_1}$ or $\intersem{T_2}$ and preserving any internal
move produced by the composition in some component $B_k$ for $k \in
U$. Formally:
$$ \Sigma_1 \| \Sigma_2 = \{ u \in int(\intersem{T}) \ | \ u \upharpoonright \intersem{T_1} \in \Sigma_1 \mbox{ and } u \upharpoonright \intersem{T_2} \in \Sigma_2 \}$$
$$ \Sigma_1 ;^{\{i_0, \ldots i_l\}} \Sigma_2 = \{ u \upharpoonright A, B_{i_0}, \ldots, B_{i_l}, C \ | \ u \in \Sigma_1 \| \Sigma_2 \}$$
where $int(\intersem{T})$ denotes the set of sequences of moves in (some arena of) $\intersem{T}$;
\end{itemize}
where the tensor product, pairing and promotion are defined similarly as in the standard game semantics.

It can be checked that this indeed defines a category. The constructions of the category $\mathcal{C}$ can be transposed to $\mathcal{I}$
making $\mathcal{I}$ a cartesian closed category.



\subsubsection{Modeling the $\lambda$-calculus in $\mathcal{I}$}

It is possible to define a (non fully-abstract) category formalizing the revealed game semantics.

We would like to use the category $\mathcal{I}$ to model terms of
the simply-typed lambda calculus. However there may be several valid
type decomposition tree for a given term $M$ and therefore several
strategies denoting $M$. To fix this problem, we will base our
definition on the computation tree of $M$. Since the computation
tree is unique, the denotation of a term will be uniquely defined.

\begin{dfn}[Revealed denotation of a term]
\label{dfn:interactionstrategy_ofterms} 
The \emph{revealed game denotation of $M$} or \emph{revealed
strategy of $M$} written $\intersem{\Gamma \vdash M : A}$ is the
revealed strategy defined by structural induction on the computation
tree $\tau(M)$ as follows:

Let $\overline{\xi} = \xi_1 : Y_1, \ldots \xi_n : Y_n$.
Let $z$ be a variable ranging in $\Gamma \union \overline{\xi}$. If $z\in \Gamma$ then $\pi_{z}$ denotes
the $i^{th}$ projection copycat strategy $\pi_i : \sem{\Gamma \union \overline{\xi}} \rightarrow \sem{X_i}$. If $z = \xi_j$ then
$\pi_{z}$ denotes the $(n+j)^{th}$ projection $\pi_{n+j} : \sem{\Gamma \union \overline{\xi}} \rightarrow \sem{Y_j}$.
\begin{eqnarray*}
 \intersem{\Gamma \vdash \lambda \xi_1\ldots \xi_n . z } &=& \Lambda^n(\pi_{z})  \\
 \intersem{\Gamma \vdash \lambda \xi_1\ldots \xi_n . z N_1 \ldots N_p} &=& \Lambda^n(\langle \pi_z, \intersem{\Gamma \vdash N_1 : A_1}, \ldots, \intersem{\Gamma \vdash N_p : A_p}  \rangle \fatsemi ^{1..p} ev^p) \\
 \intersem{\lambda \xi_1\ldots \xi_n . N_0 \ldots N_p} &=& \Lambda^n(\langle \intersem{\Gamma \vdash N_0 : A_0}, \ldots, \intersem{\Gamma \vdash N_p : A_p}  \rangle \fatsemi^{0..p} ev^p) 
\end{eqnarray*}
where $\Gamma \vdash N_0 : (A_1,\ldots,A_p,B)$, $\Gamma \vdash z : (A_1,\ldots,A_p,B)$, $\Gamma \vdash N_k : A_k$ for $k\in 1..p$
and $ev^p$ denotes the evaluation strategy with $p$ parameters.

We write $\intersem{\Gamma \rightarrow A}_M$ to denote the interaction arena of the revealed strategy $\intersem{\Gamma \vdash M : A}$.
\end{dfn}



\begin{exmp}
Consider the term $\lambda x . (\lambda f . f x) (\lambda y . y)$ in $\eta$-long normal form.
Its revealed strategy is $\langle \sem{ x:X \vdash \lambda f . f
x} , \sem{ x:X \vdash \lambda y . y} \rangle \fatsemi^{\{0,1\}} ev_2$.
\end{exmp}


\subsubsection{From interaction semantics to standard semantics and vice-versa}

In the standard semantics, given two strategies $\sigma : A \rightarrow B$, $\tau : B \rightarrow C$ and
a sequence $s \in \sigma \fatsemi \tau$, it is possible to (uniquely) recover the internal moves. The uncovered sequence is written
${\bf u}(s, \sigma, \tau)$. The algorithm to obtain this unique uncovering is given in part II of \cite{hylandong_pcf}.

Given a term $M$, we can completely uncover the internal moves of a
sequence $s\in\sem{M}$ by performing the uncovering recursively at
every @-node of the computation tree. This operation is called
\emph{full-uncovering with respect to $M$}.

Conversely, the standard semantics can be recovered from the
interaction semantics by filtering the moves, keeping only those
played in the root arena:
\begin{eqnarray}
 \sem{\Gamma \vdash M : A} = \intersem{\Gamma \vdash M : A} \upharpoonright \sem{\Gamma \rightarrow T} \label{eqn:int_std_gamsem}
\end{eqnarray}






\subsection{The correspondence theorem for the pure simply-typed $\lambda$-calculus}
In this section, we establish a
connection between the interaction semantics of a simply-typed term without constants ($\Sigma = \emptyset$)
and the traversals of its computation tree.

\subsubsection{Removing @-nodes from traversals}

When defining computation trees, it was necessary to introduce
application nodes (labelled @) in order to connect the operator and
the operand of an application. The presence of @-nodes has also
another advantage: it ensures that the lambda-nodes are all at even
level in the computation tree. Consequently a traversal respects
Alternation.

Application nodes are however redundant in the sense that they do
not play any role in the computation of the term. In other words,
the @-nodes occurring in traversals are superfluous. In fact it is
necessary to filter them out if we want to establish the
correspondence with the interaction game semantics.

\begin{dfn}[Filtering @-nodes in traversals]
\label{dfn:appnode_filter}
Let $t$ be a traversal of $\tau(M)$.
We write $t-@$ for the sequence of nodes with pointers obtained by
\begin{itemize}
\item removing from $t$ all @-nodes and value-leaves of a @-node;
\item replacing any link pointing to an @-node by a link pointing to the immediate predecessor of @ in $t$.
\end{itemize}

Suppose $u = t-@$ is a sequence of nodes obtained by applying the
previously defined transformation on the traversal $t$, then $t$ can
be partially recovered from $u$ by reinserting the @-nodes as
follows. For each @-node @ in the computation tree with parent node
denoted by $p$, we perform the following operations:
\begin{enumerate}
\item replace every occurrence of the pattern $p \cdot n$, where $n$ is a $\lambda$-nodes,
by $p \cdot @ \cdot n$;
\item replace any link in $u$ starting from a $\lambda$-node and pointing to $p$ by a link pointing to the inserted @-node;
\item if there is an occurrence in $u$ of a value-leaf $v_p$ pointing to $p$ then insert a value-leaf $v_@$
immediately before $v_p$ and make it points to the node immediately
following $p$ (which is also the $@$-node that we inserted in 1).
\end{enumerate}
We write $u+@$ for this second transformation.
\end{dfn}
These transformations are well-defined because in a traversal, an @-node
always occurs in-between two nodes $n_1$ and $n_2$ such that  $n_1$ is the parent node of @
and $n_2$ is the first child node of @ in the computation tree:
$$      \pstree[levelsep=4ex]{\TR{n_1}\treelabel{0} }
        {
            \pstree[levelsep=3ex]{\TR{@}}
            {
                \tree{n_2}{\vdots}
                \TR[edge=\dedge]{}
                \TR[edge=\dedge]{}
            }
        }
$$
Remark: $t-@$ is not a proper justified sequence
since after removing a @-node, any $\lambda$-node justified by @ will become
justified by the parent of @ which is also a $\lambda$-node.

The following lemma follows directly from the definition:
\begin{lem}
\label{lem:minus_at_plus_at}
For any traversal $t$ we have $(t-@)+@ \sqsubseteq t$ and if $t$ does not end with an @-node then
$(t-@)+@ = t$.
\end{lem}

Let $M$ be a term and $r$ be the root of $\tau(M)$. We introduce the following notations:
\begin{eqnarray*}
\travset(M)^{-@} &=& \{ t - @ \ | \  t \in \travset(M) \} \\
\travset(M)^{\upharpoonright r} &=& \{ t  \upharpoonright r \ | \  t  \in \travset(M) \} .
\end{eqnarray*}

\begin{lem}
Let $M$ be a pure simply-typed term and $r$ be the root of $\tau(M)$.
If $M$ is in $\beta$-normal form then $t = t \upharpoonright r = t - @$ for any $t \in \travset(M)$.
Consequently,
$$\travset(M)^{-@} \cong \travset(M) \cong  \travset(M)^{\upharpoonright r }.$$
\end{lem}
\begin{proof}
This is because the computation tree of a term in $\beta$-normal
does not contain any @-node and therefore all the nodes are
hereditarily justified by the root.
\end{proof}



\begin{lem}[Filtering lemma] Let $\Gamma \vdash M :T$ be a term and $r$ be the root of $\tau(M)$.
\label{lem:varphi_filter}
For any traversal $t$ of the computation tree we have
$\varphi(t-@) \upharpoonright \sem{\Gamma \rightarrow T} = \varphi(t\upharpoonright r)$.
Consequently:
$$ \varphi(\travset^{-@}(M)) \upharpoonright \sem{\Gamma \rightarrow T} = \varphi(\travset^{\upharpoonright r}(M)).$$
\end{lem}
\begin{proof}
    From the definition of $\varphi$, the nodes of the computation tree that are mapped by $\varphi$
    to moves of the arena $\sem{\Gamma \rightarrow T}$ are exactly the nodes that are hereditarily justified by $r$.
    The result follows from the fact that @-nodes are not hereditarily justified by the root.
\end{proof}

The function $\varphi$ regarded as a function from the set of vertices $V_\lambda \union V_{var}$ of the computation tree to moves in arenas is not injective.
For instance the two occurrences of $x$ in the computation tree of the term $\lambda f x. f x x$ are mapped to the same question. However
the function $\varphi$ regarded as a function from sequences of nodes to sequences of moves is injective:
\begin{lem}[$\varphi$ is injective]
\label{lem:varphiinjective}
$\varphi$ regarded as a function defined on the set of
sequences of nodes is injective in the sense that for any two traversals $t_1$ and $t_2$:
\begin{itemize}
\item[(i)] if $\varphi (t_1 - @ ) = \varphi (t_2 - @ )$ then $t_1-@ =t_2 -@$;
\item[(ii)] if $\varphi (t_1 \upharpoonright r ) = \varphi (t_2 \upharpoonright r )$ then $t_1\upharpoonright r = t_2\upharpoonright r$.
\end{itemize}
\end{lem}
\begin{proof}
(i) The set of traversals of a computation tree verifies the following property:
\begin{equation}
\mbox{If } t \cdot n_1, t \cdot n_2 \in \travset,  n_1 \neq n_2 \mbox{ and $n_1, n_2 \not\in N_@$ then } \varphi(n_1) \neq \varphi(n_2) \ . \label{lem:varphiinjective:eq1}
\end{equation}
Indeed, the only possible case where $\varphi$ maps two different
nodes to the same move is when $n_1$ and $n_2$ are two nodes
labelled with the same variable $x$. Hence the two traversals $t
\cdot n_1$ and $t \cdot n_2$ must have been formed using either rule
(Lam) or (App). But these two rules are deterministic and their
domain of definition is disjoint. This contradict the fact that $n_1
\neq n_2$.

Now suppose that $t_1-@\neq t_2-@$ then necessarily $t_1 \neq t_2$. Therefore
 $t_1 = t' \cdot n_1 \cdot u_1$ and $t_2 = t' \cdot n_2 \cdot u_2$ for some sequences $t'$, $u_1$, $u_2$
and some nodes $n_1\neq n_2$. By property \ref{lem:varphiinjective:eq1} we have $\varphi(n_1) \neq \varphi(n_2)$.
If we regard sequences of nodes and moves as \emph{pointer-less} sequences then we are allowed to write the following:
$$ (t' \cdot n_1 \cdot u_1) - @ = (t' - @) \cdot n_1 \cdot (u_1 -@),$$
and since $\varphi_M$ is a monoid homomorphism (provided that we ignore the justification pointers) we have:
$$ \varphi(t_1-@) = \varphi(t'-@) \cdot \varphi(n_1) \cdot \varphi(u_1) \neq \varphi(t'-@) \cdot \varphi(n_2) \cdot \varphi(u_2) = \varphi(t_2-@).$$

(ii) Again, suppose that $t \upharpoonright r \neq t' \upharpoonright r$ then
 $t_1 = t'_1 \cdot n_1 \cdot u_1$ and $t_2 = t_2' \cdot n_2 \cdot u_2$ for some sequences $t_1'$, $t_2'$, $u_1$, $u_2$
 such that $t'_1 \upharpoonright r = t'_2 \upharpoonright r $
and some nodes $n_1 \neq n_2$ both hereditarily justified by the root.
For the same reason as in (i), we must have $\varphi(n_1) \neq \varphi(n_2)$. Hence:
$$ \varphi(t_1\upharpoonright r) =
        \varphi(t'_1\upharpoonright r) \cdot \varphi(n_1) \cdot \varphi(u_1 \upharpoonright r)
    \neq \varphi(t'_1\upharpoonright r) \cdot \varphi(n_2) \cdot \varphi(u_2 \upharpoonright r)
         = \varphi(t_2\upharpoonright r)\ .$$
\end{proof}

\begin{cor} \
\label{cor:varphi_bij}
\begin{itemize}
\item[(i)] $\varphi$ defines a bijection from $\travset(M)^{-@}$
to $\varphi(\travset(M)^{-@})$\ ;
\item[(ii)] $\varphi$ defines a bijection from $\travset(M)^{\upharpoonright r}$ to
$\varphi(\travset(M)^{\upharpoonright r})$\ .
\end{itemize}
\end{cor}

\subsubsection{The correspondence theorem}
We are now going to state and prove the correspondence theorem
for the pure simply-typed $\lambda$-calculus without constants ($\Sigma = \emptyset$).
The result extends immediately to the simply-typed $\lambda$-calculus with \emph{uninterpreted} constants by
considering constants as being free variables.
We use the cartesian closed category of games $\mathcal{C}$ (defined in section \ref{subsec:pcfgamemodel} of the first chapter) as
a model of the simply-typed $\lambda$-calculus. We write $\sem{\Gamma \vdash M : A}$ for the strategy denoting the simply-typed term
$\Gamma \vdash M : A$.

\begin{prop}
\label{prop:rel_gamesem_trav} Let $\Gamma \vdash M : T$ be a term of
the pure simply-typed $\lambda$-calculus and $r$ be the root of
$\tau(M)$. We have:
\begin{itemize}
\item[(i)]  $\varphi_M(\travset(M)^{-@}) = \intersem{M}$
\item[(ii)] $\varphi_M(\travset(M)^{\upharpoonright r}) = \sem{M}$.
\end{itemize}
\end{prop}


\begin{rem} The proof that follows is quite tedious but the idea is simple. Let us give the intuition.
    We start by reducing the problem to the case of closed terms only. Then the proof proceeds by induction on the structure of the computation tree.
    It is straightforward to prove the result for term that are abstraction of a single variable.
    Now consider an application $M$ with the following computation tree $\tau(M)$:
    $$ \tree[levelsep=4ex]{\lambda \overline{\xi}}
        { \tree[levelsep=4ex]{@}
            {   \TR{\tau(N_0)} \TR{\ldots} \TR{\tau(N_p)}}}
    $$

    A traversal of $\tau(M)$ proceeds as follows: it starts at the root $\lambda \overline{\xi}$ of the tree $\tau(M)$ (rule
    (Root)), it then passes the node @ (rule (Lam)).
    After this initialization part, it proceeds by traversing the term $N_0$ (rule (App)).
    At some point, while traversing $N_0$, some variable $y_i$ bound by the root of $N_0$ is visited. The traversal
    of $N_0$ is interrupted and there is a jump (rule (Var)) to the root of $\tau(N_i)$. The process goes on by traversing $\tau(N_i)$.
    When traversing $N_i$, if the traversal encounters a variable bound by the root of $\tau(N_i)$ then the traversal of $N_i$ is interrupted and
    the traversal of $N_0$ resumes.  This schema is repeated until the traversal of $\tau(N_0)$ is completed\footnote{Since we are considering
    simply-typed terms, the traversal does indeed terminate. However this will not be true anymore in the \pcf\ case.}.

    The traversal of $M$ is therefore made of an initialization part followed by an interleaving of a traversal of $N_0$ and
    several traversals of $N_i$ for $i=1..p$. This schema is reminiscent of the way the evaluation copycat map $ev$ works in game semantics.

    The key idea is that every time the traversal pauses the traversal of a subterm and switches to another one,
    the jump is permitted by one of the four copycat rules (Var), (CCAnswer-@), (CCAnswer-$\lambda$) or (CCAnswer-var).
    We show by (a second) induction that these copycat rules defines exactly what the copycat strategy $ev$ performs on sets of moves.

%    In the game semantics, the evaluation map (a copy-cat strategy) copies this opening move to an initial move $m_0$ in the game
%    $B_0$ and the game continues in $B_0$. We reflect this in the traversal : we make $t$ follow
%    the ``script'' given by the traversal $t^0_{m_0}$.
%    The rule (App) allow us to initiate this simulation  by visiting the  first move in $t^0_{m_0}$: the root of $\tau(N_0)$.
%
%    This simulation continues until it reaches a node $\alpha_0$ which is hereditarily justified by the root
%    $\tau(N_0)$: $\alpha_0$ is present in the reduction of traversal of $t^0_{m_0}$ therefore $\varphi_{N_0}(\alpha_0)$ is an un-hidden move played in $A_0$.
%
%    In the game semantics this corresponds to a move played in a component $A_k$ for some $k\in 1..p$ of
%    of the game $B_0$ in which case the evaluation map copies the move to an initial move $m_1$ in the corresponding component $B_k$.
%
%    To reflect this the traversal now opens up a new thread and simulates the traversal $t^k_{m_1}$.  Again, this simulation stops when we reach a node
%    $\alpha_1$ in $t^k_{m_1}$ which is hereditarily justified by the root of $\tau(N_k)$: $\alpha_1$ must be present in the reduction of traversal
%    of $t^k_{m_1}$ therefore $\varphi_{N_k}(\alpha_1)$ is an un-hidden move played in $A_k$.
%    In the game semantics, this move $\alpha$ is copied back to the component $B_k$ of the game $B_0$.
%
%    The traversal now resumes the simulation of $t^0_{m_0}$. And the process goes continuously.
\end{rem}

Let us fix some notation: we write $s\upharpoonright A,B$ for the
sequence obtained from $s$ by keeping only the moves that are in $A$ or $B$ and by removing any link pointing to a move that
has been removed.
If $m$ is an initial move, we write $s \upharpoonright m$ to
denote the thread of $s$ initiated by $m$, i.e. the sequence obtained from $s$ by keeping all the moves
hereditarily justified by $m$.
We also write $s \upharpoonright A,B,m$ where $m$ is an initial move
for the sequence obtained from $s \upharpoonright A,B$ by keeping
all moves hereditarily justified by $m$.



\begin{proof}
(i) Suppose $\Gamma = \xi_1:X_1,\ldots \xi_n:X_n$. Then we have:
\begin{eqnarray*}
\intersem{\Gamma \vdash M:T} &=& \Lambda^n( \intersem{\emptyset \vdash \lambda \xi_1\ldots \xi_n . M: (X_1,\ldots,X_n,T) } ) \\
        &\simeq& \intersem{\emptyset \vdash \lambda \xi_1\ldots \xi_n . M: (X_1,\ldots,X_n,T) }.
\end{eqnarray*}
Similarly the computation tree $\tau(M)$ is isomorphic to
$\tau(\lambda \xi_1\ldots \xi_n . M)$ (up to a renaming of the root
of the computation tree) therefore $\travset(M)$ is also isomorphic
to $\travset(\lambda \xi_1\ldots \xi_n . M)$. Hence we can make the
assumption that $M$ is a closed term. If we prove that the property
is true for all closed terms of a given height then it will be
automatically true for any open term of the same height.


Let us assume that $M$ is already in $\eta$-long normal form. We
proceed by induction on the height of the tree $\tau(M)$ and by
case analysis on the structure of the computation tree:
\begin{itemize}
  \item (abstraction of a variable): $M \equiv \lambda \overline{\xi} .
  x$.  Since $M$ is in $\eta$-long normal form, $x$ must be of ground type and since $M$ is
      closed we have $x = \xi_i \in \overline{\xi}$ for some $i$.
      Hence $\tau(M)$ has the following shape:
        $$ \tree[levelsep=6ex]{ \lambda \overline{\xi}^{[0]} }{\TR{\xi_i^{[1]}}}$$
        The arena is of the following form (only question moves are represented):
        $$ \tree{ q_0 }
        {   \tree[linestyle=dotted]{q^1}{\TR{} \TR{} }
            \tree[linestyle=dotted]{q^2}{\TR{} \TR{} }
            \TR{\ldots}
            \tree[linestyle=dotted]{q^n}{\TR{} \TR{} }
        }$$

        Let $\pi_i$ denote the $i$th projection of the interaction game
        semantics. We have:
        \begin{equation*}
        \intersem{M} = \intersem{\emptyset \vdash \lambda \overline{\xi} . \xi_i}  = \Lambda^n(\pi_i)  \cong \pi_i  = \prefset(\{ q_0 \cdot q^i \cdot v_{q^i} \cdot v_{q_0} \ | \ v\in \mathcal{D}
                     \})\ .
        \end{equation*}

        Since $M$ is in $\beta$-normal we have $\travset(M)^{-@} = \travset(M)$.
        It is easy to see that the set of traversals of $M$ is the set of prefix of
        the traversal $\lambda \overline{\xi} \cdot \xi_i \cdot v_{\xi_i} \cdot v_{\lambda \overline{\xi}}$:
        $$ \travset^{-@}(M) = \travset(M) = \prefset( \lambda \overline{\xi} \cdot \xi_i \cdot v_{\xi_i} \cdot v_{\lambda \overline{\xi}}) \ .
        $$

        The pointers of the traversal $\lambda \overline{\xi} \cdot \xi_i \cdot v_{\xi_i} \cdot
        v_{\lambda \overline{\xi}}$ are the same as the play $q_0 \cdot q^i \cdot v_{q^i} \cdot
        v_{q_0}$, therefore since $\varphi_M(\lambda \overline{\xi}) = q_0$ and $\varphi_M(\xi_i) =
        q^i$ we have:
        $$ \varphi_M(\travset^{-@}(M)) = \intersem{M} \ .$$


    \item (abstraction of an application): we have $M = \lambda \overline{\xi} . N_0 N_1 \ldots N_p$. Let $\Gamma$ be the context
    $\Gamma = \overline{\xi} : \overline{X}$. Then we have the following sequents:
    $\emptyset \vdash M : (X_1,\ldots,X_n,o)$,
    $\Gamma \vdash N_0 N_1 \ldots N_p : o$,
    $\Gamma \vdash N_i : B_i$ for $i\in 0..p$ with $B_0 = (B_1,\ldots,B_p,o)$ and $p\geq 1$.

    There are two subcases, either $N_0 \equiv \xi_i$ where $\alpha$ is a variable in $\overline{\xi}$ and the tree has the following form:
    $$ \tree[levelsep=6ex]{\lambda \overline{\xi}^{[0]}}
        { \tree[levelsep=6ex]{\xi_i^{[1]}}
            {   \TR{\tau(N_1)} \TR{\ldots} \TR{\tau(N_p)}}}
    $$
    or $N_0$ is not a variable and the tree $\tau(M)$ has the following form:
    $$ \tree[levelsep=6ex]{\lambda \overline{\xi}^{[0]}}
        { \tree[levelsep=6ex]{@^{[1]}}
            {
            \tree[levelsep=6ex]{\lambda y_1 \ldots y_p}{\ldots}
            \TR{\tau(N_1)} \TR{\ldots} \TR{\tau(N_p)}}}
    $$

    We only consider the second case since the first one can be treated
    similarly. Moreover we make the assumption that $p=1$. It is
    straightforward to generalize to any $p\geq1$.
    We write $\lambda \overline{z}$ to denote the root of the tree $\tau(N_1)$.


    We have:
    \begin{align*}
    \intersem{M}
        &=  \Lambda^n( \intersem{\Gamma \vdash N_0 N_1 : o} )
            & \mbox{(game semantics for abstraction)}\\
        &\cong  \intersem{\Gamma \vdash N_0 N_1 : o}
            & \mbox{(up to moves retagging)}\\
        &=  \langle \intersem{\Gamma \vdash N_0}, \intersem{\Gamma \vdash N_1} \rangle \fatsemi^{0..1} ev
            & \mbox{(game semantics for application)}\\
        &=  \langle \varphi_{N_0} (\travset^{-@}(N_0)), \varphi_{N_1}(\travset^{-@}(N_1) \rangle \fatsemi^{0..1} ev
            & \mbox{(induction hypothesis)}\\
        &=  \langle \varphi_{M} (\travset^{-@}(N_0)), \varphi_{M}(\travset^{-@}(N_1)) \rangle \fatsemi^{0..1} ev
            & \mbox{($\varphi_M = f(0,q_0) \union \varphi_{N_0} \union \varphi_{N_1}$)} \\
        &=  \underbrace{\langle \varphi_{M} (\travset^{-@}(N_0)), \varphi_{M}(\travset^{-@}(N_1)) \rangle}_{\sigma} \parallel ev
            & \mbox{($\fatsemi^{0..1}$ and $\parallel$ are the same operator)}
    \end{align*}


    The strategies $\sigma$ and $ev$ are defined on the arena $!A \multimap B$ and $!B \multimap C$ respectively where:
    \begin{eqnarray*}
        A &=& \intersem{\Gamma} = \intersem{X_1} \times \ldots \times \intersem{X_n}\\
        B &=& \intersem{B_0} \times \intersem{B_1} = \intersem{B_1' \rightarrow o'} \times \intersem{B_1} \\
        C &=& \intersem{o}
    \end{eqnarray*}

    We have $u \in \intersem{M} \cong \sigma^{\dag} \parallel ev$ if and only if
    \begin{eqnarray*}
      &&      \left\{
            \begin{array}{ll}
                u \in int(!A,!B,C)\\
                u \upharpoonright !A,!B  \in \sigma^\dagger \\
                u \upharpoonright !B,C  \in  ev
            \end{array}
            \right. \\
    & \mbox{or equivalently} & \left\{
    \begin{array}{ll}
        u \in int(!A,!B,C) \\
        \hbox{for any initial $m$ in $u \upharpoonright !A,!B$ there is $j \in 0..p$ such that } \\
        \left\{\begin{array}{ll}
            u \upharpoonright !A,B_j, m \in \varphi_{M} (\travset^{-@}(N_j)) \label{eq:def_z} \\
            u \upharpoonright !A, B_k,m = \epsilon \quad \mbox{ for every } k\neq j \label{eq:b}
        \end{array}
        \right.
    \end{array}
    \right.
    \end{eqnarray*}


    We first prove that $\intersem{M} \subseteq \varphi_{M}( \travset^{-@}(M)
    )$.


    Suppose $u \in \intersem{M}$. We give a constructive proof that
    there exists a sequence of nodes $t$ in $N$ such that $\varphi_M(t-@) = u$ by induction on the length of $u$.
    Let $q_o$ be the initial question of the arena $\sem{M}$ and $q_1$ the initial question of $\sem{N_0}$.

    Base cases:
    \begin{itemize}
    \item $u=\epsilon$ then $\varphi(\epsilon) = u$ where the traversal $\epsilon$ is formed with the rule ($\epsilon$).
    \item If $|u|=1$ then $u=q_0$ is the initial move in $C$ and $\varphi(\lambda \overline{\xi}) = u$. The traversal
    $\lambda \overline{\xi}$ is formed with the rule (Root).
    \end{itemize}

    Step cases: Suppose that $u' = \varphi_M(t'-@)$ and $u = u' \cdot m \in \intersem{M}$ with $|u|>1$ for some traversal $t'$ of $\tau(M)$.
    Let us write $m^1$ for the last move in $u'$.

    \begin{enumerate}
    \item Suppose $m \in C$. In $C$ there are no internal moves, the only moves of $C$ are therefore $q_0$ and
    $v_{q_0}$ for some $v\in\mathcal{D}$. But $q_0$ can occur only once in $u$, therefore since $|u|>1$ we must have $m = v_{q_0}$
    for some $v\in \mathcal{D}$.  Since $m$ is an answer move to the initial question, it must be
    the duplication  (performed by the copy-cat evaluation strategy) of the move $m^1$ played in $o'$.
    Hence $m^1=v_{q_1}$. By the induction hypothesis, $n'$ -- the last move in $t'$ -- is equal to
    $\varphi(m^1) = v_{\lambda y_1}$.

    By property \ref{proper:phi_pview}(iv), $?(u') = \varphi(?(t'-@))$ and
    since $q_0$ is the pending question in $u'$, the first node of $t'$ is also the pending node in $t'$.
    This permits us to use the rule (CCAnswer-$\lambda$) to produce the traversal $t = t' \cdot v_{\lambda \overline{\xi}}$
    where $v_{\lambda \overline{\xi}}$ points to the first node in $t'$. Clearly, $\varphi(t-@) = u$.



    \item Suppose that $m,m^1 \in A \union B_0$.
    The strategy $ev$ is responsible for switching thread in $B_0$ therefore, in the interaction semantics,
    there must be a copycat move in-between two moves belonging to two different threads.
    Since $m$ and $m^1$ are consecutive moves in the sequence $u$, they must belong to the same thread i.e. there are
    hereditarily justified  by the same initial $m_0$ in $B_0$.


    We then have $(u \upharpoonright !A, !B)\upharpoonright m_0 = \varphi_{N_0}(t_0-@)$ for some traversal $t_0$ of $N_0$.
    Consequently  $\varphi_{N_0}(n^1) = m^1$ and $\varphi_{N_0}(n) = m$
    where $n^1 \cdot n$ are the last two moves in $t_0-@$.

    $n$ points to some node in $t_0$ that also occurs in $t'$. Let us call $n^2$ this node.
    Since $(u \upharpoonright !A, !B)\upharpoonright m_0 = \varphi_{N_0}(t_0-@)$,
    $n_2$ must have the same position in $t'$ as the node justifying $m$ in $u'$.
    Hence we just need to take $t = t' \cdot n$ where $n$ points to $n^2$ in $t'$.

    The sequence $t$ is indeed a valid traversal of $\tau(M)$
    because the rule used by the traversal $t_0$
    of $\tau(N_0)$ to visit the node $n$ after $n^1$ can also be used by the traversal $t'$ of $\tau(M)$
    to visit $n$ after $n^1$.
    This can be checked formally by inspecting all the traversal rules. The key reason is that
    all the nodes in $t_0-@$ are present in $t'$ with the same pointers but with some nodes interleaved in between.
    However these interleaved nodes are inserted in a way that still permits to use the traversal rule.

    \item Suppose that $m,m^1 \in A \union B_1$.
    The proof is similar to the previous case.

    \item Suppose that $m \in A \union B_0$ and $m^1 \in A \union B_1$.

    $t$ is obtained from $t-@$ using the transformation $+@$. We apply the same transformation to $u$ in order
    to make $O$-questions and $P$-questions in $u$ match with $\lambda$-nodes and variable nodes in $t'$ respectively.
    We write this sequence $u+@$.
    The $+@$ operation inserts nodes in the sequence but not at the end,
    therefore $m^1$, the last move in $u'$, is also the last move in $u'+@$.
    Let us note $n^1$ for the last move in $t'$.

        \begin{enumerate}
        \item If $n^1$ is the application node @ then it must be the parent of the node $\lambda y_1$ since it
        is the only non-internal @-node present in $t'$.
        Therefore $t'=\lambda \overline{\xi} \cdot @$ and $u= q_0 \cdot m$.
        But $m$ is the copy of $q_0$ replicated by $ev$ in $o'$ therefore $m=q_1$.
        Applying the (App) rule on $t'$ produces the traversal $\lambda \overline{\xi} \cdot @ \cdot \lambda y_1$
        with $\varphi((\lambda \overline{\xi} \cdot @ \cdot \lambda y_1)-@ ) = q_0 \cdot q_1 = u$.

        \item If $n^1$ is a variable node then $m^1$ is a P-move and $m$ is an O-move
            and therefore $m$ is the copy of $m^1$ duplicated in $B_1$ by the evaluation strategy.
            Consequently, $m^1$ points to some $m^2$ and $m$ points to the node preceding $m^2$ denoted by $m^3$.
            The diagram below shows an example of such sequence:
                $$
                \begin{array}{cccccccc}
                & (B_1' &\rightarrow & o') & \times & B_1 & \rightarrow & o' \\
                O & &&&&&& \rnode{q0}{q_0 (\lambda \overline{\xi})} \\
                P & &&&&& \\
                O & && \rnode{q1}{q_1 (\lambda \overline{y})} \\
                P & \rnode{m3}{m^3 (y_1)} \\
                O & &&&& \rnode{m2}{m^2 (\lambda \overline{z})} \\
                P & &&&& \rnode{m1}{m^1 (z_i)} \\
                O & \rnode{m}{m} \\
                \end{array}
                \ncline[nodesep=3pt]{->}{q1}{q0} \mput*{@}
                \nccurve[nodesep=3pt,ncurv=2,angleA=180,angleB=180]{->}{m1}{m2}
                \ncarc[nodesep=3pt,ncurv=1,angleA=90,angleB=180]{->}{m3}{q1}
                \ncarc[nodesep=3pt,ncurv=1,angleA=90,angleB=180]{->}{m}{m3}
                \ncline[nodesep=3pt]{->}{m2}{q0}
                $$

        $t'$  and $u+@$ have the following forms:
        \begin{eqnarray*}
                t'&=& \ldots \cdot n^3 \cdot \rnode{n2}{n^2} \cdot \ldots \cdot \rnode{n1}{n^1} \\ \\
                u+@ &=& \ldots \cdot \rnode{m3}{m^3} \cdot \rnode{m2}{m^2} \cdot \ldots \cdot \rnode{m1}{m^1} \cdot \rnode{m}{m}
            \bkptr{30}{m1}{m2} \bkptr{30}{m}{m3}
            \bkptr{30}{n1}{n2}
        \end{eqnarray*}

        Since $n^1$ is a variable node, $n^2$ must be a $\lambda$-node.
        $n^3$ could be either a variable node or an @-node. In fact $n^3$ is necessarily a variable node. Indeed,
        $n^3$ is mapped to $m^3$ by $\varphi_{N_0}$ and $m^3$ belongs to $\sem{B_i'}$ (i.e. it is not
        an internal move of $\intersem{B_i'}$). The function $\varphi_{N_0}$ is defined in such a way that
        only nodes which are hereditarily justified by the root of $\tau(N_0)$ are mapped to nodes in $\sem{B_1'}$.
        Hence $n^3$ is hereditarily justified by the root and consequently it cannot be an @-node.

        Hence $n^1$ is a variable node, $n^2$ is a $\lambda$-node and $n^3$ is a variable node. We
        can therefore apply the (Var) rule to $t'$ and we obtain a traversal of the following form:

        \begin{eqnarray*}
            t&=& \ldots \cdot \rnode{n3}{n^3} \cdot \rnode{n2}{n^2} \cdot \ldots \cdot \rnode{n1}{n^1} \cdot \rnode{n}{n}
            \bkptr{30}{n1}{n2} \bkptr{30}{n}{n3}
        \end{eqnarray*}

        We have $\varphi(t'-@) = u'$ by the induction hypothesis and $\varphi(n) = m$ by definition of $\varphi$.
        Therefore since $m$ and $n$ point to the same position we have $\varphi(t-@) = u$.

        \item If $n^1$ is the value-leaf of a variable node then we proceed the same way as in the previous case:
        $n^1$ is a value-leaf of the variable node $n^2$ and we can use the
        (CCAnswer-$\lambda$) rule to extend the traversal $t'$.

        \item Suppose that $n^1$ is a lambda node, in which case $m^1$ is an O-move, then
        necessarily, $m^1$ is a move copied by the evaluation strategy
         from $B_1'$ to $B_1$. The move following $m^1$ should also be played in $B_1$ before being copied
         back to $B_1'$ by the evaluation strategy. But since $m \in B_0$, this case does not happen.


        \item If $n^1$ is a value-leaf of a lambda node then $n^2$ is a lambda node and $n^3$ is a variable node.
        We can therefore use the rule (CCAnswer-var) or (CCAnswer-@) to extend the traversal $t'$.
        \end{enumerate}

    \item Suppose $m \in A \union B_1$ and $m^1 \in A \union B_0$ then
    the proof is similar to the previous case.
    \end{enumerate}


  For the converse, $\varphi_{M}( \travset^{-@}(M) ) \subseteq \intersem{M}$, it is an easy induction
  on the traversal rules. We omit the details here.
\end{itemize}

(ii) is an immediate consequence of (i):
\begin{align*}
\sem{M} &= \intersem{M} \upharpoonright \sem{\Gamma \rightarrow T} & \mbox{(eq. \ref{eqn:int_std_gamsem})} \\
        &= \varphi_M(\travset^{-@}(M)) \upharpoonright \sem{\Gamma \rightarrow T} & \mbox{(by (i))}\\
        &= \varphi_M(\travset^{\upharpoonright r}(M)) & \mbox{(lemma \ref{lem:varphi_filter})}
\end{align*}
\end{proof}


Putting corollary \ref{cor:varphi_bij} and proposition
\ref{prop:rel_gamesem_trav} together we obtain the following theorem
which establish a correspondence between the game-denotation of a
term and the set of traversals of its computation tree:

\begin{thm}[The Correspondence Theorem]
\label{thm:correspondence}
 For any pure simply-typed term $\Gamma \vdash M$,
$\varphi_M$ defines a bijection from $\travset(M)^{\upharpoonright
r}$ to $\sem{M}$ and a bijection from $\travset(M)^{-@}$ to
$\intersem{M}$:
\begin{eqnarray*}
 \varphi_M  &:& \travset(\Gamma \vdash M)^{\upharpoonright r} \stackrel{\cong}{\longrightarrow} \sem{\Gamma \vdash M} \\
 \varphi_M  &:& \travset(\Gamma \vdash M)^{-@} \stackrel{\cong}{\longrightarrow} \intersem{\Gamma \vdash M}
\end{eqnarray*}

Moreover if $M$ is in $\beta$-normal form and $s$ is a
\emph{maximal} play then  $t$ is a \emph{maximal} traversal.
\end{thm}

\begin{proof}
The first part is an immediate consequence of corollary
\ref{cor:varphi_bij} and proposition
\ref{prop:rel_gamesem_trav}.

Finally, if $M$ is in $\beta$-normal form then
$\travset(M)^{\upharpoonright r} = \travset(M)$
therefore $\varphi$ is a bijection from $\travset(M)$ to
$\sem{M}$. Suppose $s$ is a maximal play and suppose $t' \sqsubseteq
t$ then since $\varphi$ is monotonous we have $s = \varphi(t) \sqsubseteq
\varphi(t')$. But $s$ is maximal therefore $s = \varphi(t') =
\varphi(t)$ and because $\varphi$ is injective we have $t'=t$.
\end{proof}

The following diagram recapitulates the main results of this section:
$$
\xymatrix @C=6pc{
                                           & \travset(M)^{-@} \ar@/_/[dl]_{+@}  \ar[r]^{\varphi_M}_\cong & \intersem{M} \ar@/_/[dd]_{\_ \upharpoonright \sem{\Gamma\rightarrow T}} \\
\travset(M) \ar@/_/[ur]_{-@}^{} \ar[dr]^{\_ \upharpoonright r}  \\
                                           & \travset(M)^{\upharpoonright r} \ar[r]^{\varphi_M}_\cong & \sem{M} \ar@/_/[uu]^{\cong}_{\mbox{full uncovering}}
}
$$



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Game-semantic characterisation of safety}

Safety has been defined as a syntactical constraint. Since Game
Semantics is by essence syntax-independent, it seems difficult at
first sight to characterise Safety in a game-semantic manner.
However, with the help of the tools developed in the previous
chapter and using the Correspondence Theorem, we can interpret plays
of a strategy as sequences of nodes of some AST of the term.
Therefore it is now possible to investigate the impact of the Safety
restriction on Game Semantics.


The main theorem of this chapter (theorem
\ref{thm:safe_ptr_recoverable}) states that pointers in a play of
the strategy denotation of a safe term can be uniquely recovered
from the underlying sequence of moves. The proof is in several
steps. We start by introducing the notion of
\emph{incrementally-justified strategies} and prove that for plays
of such strategies, pointers can be reconstructed uniquely from the
underlying sequences of moves. We then introduce the notion of
\emph{incrementally-bound computation trees} and prove that
incremental-binding coincides with incremental-justification
(proposition \ref{prop:incrbound_imp_incrjustified}). Finally, we
show that safe simply-typed terms in $\beta$-normal form have
incrementally-bound computation trees, consequently the pointers in
their game denotation are superfluous.


The first section of this chapter is concerned only with the pure
Safe $\lambda$-Calculus without interpreted constants. In the next
section we extend the result by taking into account the interpreted
constants of \pcf\ and \ialgol. We define the language Safe \ialgol\
(resp. Safe \pcf) to be the fragment of \ialgol\ (resp. \pcf) where
the application and abstraction rules are constrained the same way
as in the Safe $\lambda$-Calculus. We show that Safe \pcf\ terms are
denoted by incrementally-justified strategies and we give the key
elements for a possible extension of the result to Safe Idealized
Algol.

\section{Safe $\lambda$-Calculus}
Let us consider the Safe $\lambda$-Calculus without interpreted
constants. Our aim is to prove that pointers in the game semantics
of safe terms can be uniquely recovered.

The example of section \ref{subsec:pointer_necessary} gives a good
intuition: in order to distinguish the terms $M_1 = \lambda f . f
(\lambda x . f (\lambda y .y ))$ and $M_2 = \lambda f . f (\lambda x
. f (\lambda y .x ))$ we have to keep the pointers in the plays of
strategies. However, if we limit ourselves to the safe
$\lambda$-Calculus then the ambiguity disappears because $M_1$ is
safe whereas $M_2$ is not (in the subterm $f (\lambda y . x)$, the
free variable $x$ has the same order as $y$ but $x$ is not
abstracted together with $y$).

\begin{dfn}[Incrementally-justified strategy]
A strategy $\sigma : A$ is said to be \emph{incrementally-justified}
if for any sequence of moves $s q \in P_A$ where $q$ is a question
move in $M_A$ we have:
\begin{eqnarray*}
s q \in \sigma \wedge |s| \mbox{ even } &\implies& \parbox[t]{8cm}{$q$ points to the last P-move in $\oview{?(s)}$ with order strictly greater than $\ord{q}$;} \\
s q \in \sigma \wedge |s| \mbox{ odd } &\implies&
\parbox[t]{8cm}{$q$  points to the last O-move in $\pview{?(s)}$
with order strictly greater than $\ord{q}$.}
\end{eqnarray*}
\end{dfn}

\begin{lem}
\label{lem:incrjustified_pointers_uniqu_recover} Pointers are
superfluous for incrementally-justified strategies.
\end{lem}
\begin{proof}
Suppose $\sigma$ is an incrementally-justified strategy. We prove
that pointers in a play $s\in \sigma$ are uniquely recoverable by
induction on the length of $s$. \noindent \emph{Base case}: if $s
\in \sigma$ with $|s| \leq 1$ then there is no pointer to recover.
\noindent \emph{Step case}: suppose $s m \in \sigma$. If $m$ is an
answer move then thanks to the well-bracketing condition $m$ points
to the last unanswered question in $s$. Suppose $m$ is a question
move. If $m$ is a P-move then $|s|$ is odd and since $\sigma$ is
incrementally-justified, $m$ points to the last O-move in
$\pview{?(s)}$ with order strictly greater than $\ord{q}$.
Similarly, if $m$ is an O-move then $|s|$ is even and by
incremental-justification $m$ points to the last P-move in
$\oview{?(s)}$ with order strictly greater than $\ord{q}$. By the
induction hypothesis the pointers in $s$ are recoverable, this
ensures that the P-view $\pview{?(s)}$ and the O-view $\oview{?(s)}$
can be computed. Consequently the pointer for $m$ is uniquely
recoverable.
\end{proof}

\begin{exmp}
The denotation of the evaluation map $ev$ is not
incrementally-justified. Indeed consider the play $s = q_0 q_1 q_2
q_3 \in \sem{ev}$ shown on the diagram below:
$$\begin{array}{cccccccc}
(A & \implies & B) & \times  & A & \stackrel{ev}{\longrightarrow} & B \\
&&&&&& q_0 \\
&& q_1 \\
 q_2 \\
 &&&&q_3
\end{array}$$
The order of the moves are as follows:  $\ord{q_3} = \ord{A}$,
$\ord{q_2} = \ord{A}$, $\ord{q_1} = \max( 1+\ord{A}, \ord{B})$ and
$\ord{q_0} = 1 + \ord{q_1}$. The last O-move in $?(\pview{s})= s$
with order strictly greater than $\ord{q_3}$ is $q_1$.
 But since $q_3$ points to $q_0$, $\sem{ev}$ is not incrementally-justified.
\end{exmp}


In a computation tree a binder node always occurs in the path from
the bound node to the root. We now introduce a class of computation
tree in which binder nodes can be uniquely recovered from the order
of the nodes. We write $[n_1,n_2]$ to denote the path from node
$n_1$ to node $n_2$ if it exists and $]n_1,n_2]$ for the sequence of
nodes obtained by removing $n_1$ from $[n_1,n_2]$.

\begin{dfn}[Incrementally-bound computation tree]
A variable node $x$ of a computation tree is said to be
\emph{incrementally-bound} if either:
\begin{enumerate}
\item $x$ is \emph{bound} by the first $\lambda$-node in the path to the root that has
order strictly greater than $\ord{x}$. Formally:
\begin{align*}
 x \mbox{ bound by } n \quad \imp & \quad n \in [r,x] \wedge \ord{n} > \ord{x} \\
                                  & \wedge \forall \lambda\mbox{-node } n' \in ]n,x] . \ord{n'} \leq \ord{x} \ ;
\end{align*}

\item $x$ is a \emph{free variable} and all the $\lambda$-nodes in the path to the root except the root have order
smaller or equal to $\ord{x}$. Formally:
$$ x \mbox{ free } \quad \imp \quad  \forall \lambda\mbox{-node } n' \in ]r,x] . \ord{n'} \leq \ord{x}$$
\end{enumerate}
where $r$ denotes the root of the computation tree.

A computation tree is said to be \emph{incrementally-bound} if all
the variable nodes are incrementally-bound.
\end{dfn}

\begin{prop}[Incremental-binding coincides with incremental-justification] \
\label{prop:incrbound_imp_incrjustified}
\begin{enumerate}
\item[(i)] If a term in $\beta$-normal form has an incrementally-bound computation tree then it is denoted by an incrementally-justified strategy.
\item[(ii)] In the pure $\lambda$-calculus ($\Sigma=\emptyset$), reciprocally, if a term is denoted by an incrementally-justified strategy then
the computation tree of its $\beta$-normal is incrementally-bound.
\end{enumerate}
\end{prop}

\begin{proof}
Let $\Gamma \vdash M : A$ be a simply-typed term in $\beta$-normal
form and $r$ denotes the root of $\tau(M)$.

\noindent (i) Suppose that $\tau(M)$ is incrementally-bound.
Consider a justified sequence of move $s \in \sem{\Gamma \vdash M}$
ending with a question move $q$ (note that $q$ is also the last
question in $?(s)$). By proposition \ref{prop:rel_gamesem_trav},
there is a traversal $t$ of $\tau(M)$ such that $\varphi_{M}(t
\upharpoonright r) = s$. We assume that the last node $n$ of $t$ is
hereditarily justified by $r$ (otherwise we replace $t$ by its
longest prefix verifying this condition). Then $n$ is also the last
node in $?(t \upharpoonright r)$ and $t \upharpoonright r$.

\begin{itemize}
\item If $|s|$ is even then $q$ is a P-move:
\begin{itemize}
\item Suppose that $n$ is a variable node $x$ bound by a node $m$ occurring in $t$.
Since $M$ is in $\beta$-normal form, lemma \ref{lem:redtrav_trav}(i)
gives: $ \pview{?(t \upharpoonright r)} = \pview{?(t)}
\upharpoonright  r$. By proposition \ref{prop:pviewtrav_is_path},
$\pview{?(t)} = [r,n]$ and because $\tau(M)$ is incrementally-bound,
$m$ is the last $\lambda$-node in $[r,n]$ of order strictly greater
than $\ord{n}$. Since $n$ is hereditarily justified by the root, so
is $m$ and therefore $m$ occurs in $\pview{?(t \upharpoonright r)}$.
But $\pview{?(t \upharpoonright r)}$ is a subsequence of
$\pview{?(t)}$ therefore $m$ is also the last $\lambda$-node in
$\pview{?(t \upharpoonright  r)}$ that has order strictly greater
than $\ord{n}$.

By property \ref{proper:phi_pview} (ii), the P-view of $?(s)$ and
the P-view of $?(t \upharpoonright r)$ are computed similarly and
have the same pointers. This means that node $n$ and  move $q$ both
point to the same position in the justified sequence
$\pview{?(t\upharpoonright r)}$ and $\pview{?(s)}$ respectively.

Finally, since $\varphi$ maps nodes of a given order to moves of the
same order (property \ref{proper:phi_conserve_order}), $q$ must
point to the last O-move in $\pview{?(s)}$ whose order is strictly
greater than $\ord{q}$.


\item If $n$ is a free variable node $x$ then $n$ is enabled by the root which is the first node in $t$.
By definition of $\varphi$, $\varphi(n) = x$ must be a move enabled
by the initial move $q_0 = \varphi(r)$ in the arena $\sem{\Gamma
\rightarrow A}$. Therefore $\ord{q_0} > \ord{x}$. Since the
computation tree is incrementally-bound, all the $\lambda$-nodes in
$]r,n]$ have order smaller than $\ord{n}$. Therefore by the
correspondence theorem, all the O-moves in $\pview{?(s)}$ have order
smaller than $\ord{x}$.
\end{itemize}



\item If $|s|$ is odd then $q$ is an O-move:

$M$ is in $\beta$-normal form and $t$ is a traversal of $\tau(M)$
whose last node $n$ is hereditarily justified by $r$. Therefore by
lemma \ref{lem:redtrav_trav} (ii), $ \oview{?(t \upharpoonright r)}
= \oview{?(t)}$.

A lambda-node always points to its parent node in the computation
tree. For terms in $\beta$-normal form, this parent node must be a
variable node of order strictly greater than $\ord{n}$.

By inspecting the formation rules for traversals (definition
\ref{def:traversal}) we remark that a lambda-node occurring in a
traversal always points to the last node with order strictly greater
that $\ord{n}$ in the O-view of the sequence of unmatched nodes at
that point (there are just two cases, $n$ points either to the
preceding node or to the third previous node in $\oview{?(t)}$).

Similarly, as in the P-move case, we conclude that $q$ points to the
last question move in $\oview{?(s)}$ of order strictly greater than
$\ord{q}$.
\end{itemize}

\noindent (ii) Suppose that $M$ is $\beta$-normal and the strategy
$\sem{M}$ is incrementally-justified. Let $x$ be a variable node of
$\tau(M)$. Since $M$ is $\beta$-normal, by lemma
\ref{lem:betaeta_trav}, $x$ is either hereditarily justified by the
root $r$ or by a constant in $N_\Sigma$. In the pure simply-typed
$\lambda$-calculus we have $\Sigma=\emptyset$, therefore $x$ is
hereditarily justified by $r$.


We remark that for terms in $\beta$-normal form, every variable node
occurring in the computation tree can be visited by some traversal
i.e. there exists a traversal of the form $t \cdot x$ in
$\travset(M)$. The correspondence theorem gives $\varphi((t \cdot x)
\upharpoonright r) = \varphi((t \upharpoonright r) \cdot x) \in
\sem{M}$. Since $\sem{M}$ is incrementally-justified, $\varphi(x)$
must point to the last move in $\pview{?(\varphi(t \upharpoonright
r))}$ with order strictly greater than $\ord{\varphi(x)}$.
Consequently $x$ points to the last node in $\pview{?(t
\upharpoonright r)}$ with order strictly greater than $\ord{x}$. We
have:
\begin{align*}
\pview{?(t \upharpoonright r)} &= \pview{?(t) \upharpoonright r} = \pview{?(t)} \upharpoonright r & (\mbox{by lemma \ref{lem:redtrav_trav}}) \\
& = \pview{?(t)} & (\mbox{$M$ is a $\beta$-nf and $N_\Sigma = \emptyset$}) \\
& = [r,x[ & (\mbox{by proposition \ref{prop:pviewtrav_is_path}}).
\end{align*}
Therefore if $x$ is a bound variable node then it is bound by the
last $\lambda$-node in $[r,x[$ with order strictly greater than
$\ord{x}$ and if $x$ is a free variable then it points to $r$ and
therefore all the $\lambda$-node in $]r,x[$ have order smaller than
$\ord{x}$. Hence $\tau(M)$ is incrementally-bound.
\end{proof}


\parpic[r]{
    \psset{levelsep=4ex}
    \pstree{\TR{$\lambda x^3$}}{\pstree{\TR{$f^2$}}{ \pstree{\TR{$\lambda y^1$}}{ \TR{$x^0$} }}}
}

\noindent \emph{Examples:} Consider the $\beta$-normal term $\lambda
x . f (\lambda y .x)$ where $x,y:o$ and $f:(o,o),o$. The figure on
the right represents the computation tree with the order of each
node in the exponent part. Since node $x$ of order $0$ is not bound
by the order 1 node $\lambda y$, $\tau(M)$ is not
incrementally-bound and by proposition
\ref{prop:incrbound_imp_incrjustified} $\sem{\lambda x . f (\lambda
y .x)}$ is not incrementally-justified. Similarly we can check that
the denotation of $f (\lambda y .x)$ is not incrementally-justified
whereas $\lambda y. x$ has an incrementally-justified denotation.
Also for any higher-order variable $x:A$, the computation tree
$\tau(x)$ is incrementally-bound, therefore the projection
strategies $\pi_i$ are incrementally-justified. From these examples
we observe that application does not preserve
incremental-justification: $\sem{f}$ and $\sem{\lambda y. x}$ are
incrementally-justified whereas $\sem{f (\lambda y .x)}$ is not.

%In fact incremental-justification is not preserved by composition. Indeed,
%$\sem{f (\lambda y . x) \cong \langle id_{\Gamma}, \sem{\lambda y . x} \rangle} $
%$\sem{f (\lambda y .x)} = \langle \sem{f}, \sem{\lambda y. x} \rangle \fatsemi ev$ is not.


\begin{lem}[Safe terms have incrementally-bound computation trees]
\label{lem:safe_imp_incrbound} Let $\Gamma \vdash M$ be a
simply-typed term.
\begin{itemize}
\item[(i)] If $M$ is a safe term then $\tau(M)$ is incrementally-bound ;
\item[(ii)] reciprocally, if $M$ is \emph{closed} and $\tau(M)$ is incrementally-bound then the $\eta$-normal form of $M$ is safe.
\end{itemize}
\end{lem}
\begin{proof}
(i) Suppose that $M$ is safe. The safety property is preserved after
taking the $\eta$-normal form, therefore $\etanf{M}$ is also safe.
Hence $\tau(M)$ is the tree representation of a safe term.

When applying the abstraction rule in the Safe $\lambda$-Calculus,
the variables in the lowest partition (smallest order) of the
context must all be abstracted together. Moreover in the computation
tree, consecutive abstractions are merged into a single node,
therefore the safety of $\etanf{M}$ implies that for each
$\lambda$-node $\lambda \overline{\xi}$, any variable $x$ occurring
free in $\kappa(\lambda \overline{\xi})$ has order greater or equal
to $\ord{\lambda \overline{\xi}}$. Reciprocally, if a lambda node
$\lambda \overline{\xi}$ binds a variable node $x$ then
$\ord{\lambda \overline{\xi}} = 1+\max_{z\in\overline{\xi}} \ord{z}
> \ord{x}$.

Let $x$ be a bound variable node. In a computation tree, a binder
node always occurs in the path from the bound node to the root,
therefore, according to the previous observation, $x$ must be bound
by the first $\lambda$-node occurring in $[r,x]$ with order strictly
greater than $\ord{x}$. Similarly, let $x$ be a free variable node
in $\tau$ then $x$ is not bound by any of the $\lambda$-nodes
occurring in $[r,x]$. Once again, by the previous observation, all
these $\lambda$-nodes have order smaller than $\ord{x}$. Hence
$\tau$ is incrementally-bound.

(ii) We assume that $M$ is already in $\eta$-normal form. Suppose
$M$ is closed and $\tau(M)$ is incrementally-bound, we prove that
$M$ is safe by induction on its structure: \emph{Base case:} $M =
\lambda \overline{\xi} . \alpha$ for some variable or constant
$\alpha$. This term is obviously safe.

\emph{Step case:} If $M = \lambda \overline{\xi} . N_1 \ldots N_p$.
Let $i$ range over $1..p$. $N_i$ can be written $\lambda
\overline{\eta_i} . N'_i$ where $N'_i$ is not an abstraction. By the
induction hypothesis, $\lambda \overline{\xi} . N_i = \lambda
\overline{\xi} \overline{\eta_i} . N'_i$ is safe. We observe from
the formation rules of Safe $\lambda$-Calculus that the typing
judgment for $\lambda \overline{\xi} \overline{\eta_i} . N'_i$ can
only be derived using the (abs) rule on the term $N'_i$. Hence
$N'_i$ is necessarily safe. Let $z$ be a variable occurring free in
$N'_i$. Since $M$ is closed, $z$ is either bound by $\lambda
\overline{\eta_1}$ or $\lambda \overline{\xi}$. If it is bound by
$\lambda \overline{\xi}$ then because $\tau(M)$ is
incrementally-bound we have $\ord{z} \geq \ord{\lambda
\overline{\eta_1}} = \ord{N_i}$. Hence we can abstract the variables
$\overline{\eta_1}$ using the (abs) rule and we obtain that $N_i$ is
safe.

Because $M$ is in $\eta$-normal form, the application $N_1 \ldots
N_p$ is total (i.e. $N_1$ is a function taking $p-1$ parameters and
it is applied to $p-1$ arguments), therefore since the $N_i$s are
safe, by the (app) rule of the Safe $\lambda$-Calculus $N_1 \ldots
N_p$ is also safe. Finally, using the (abs) rule we conclude that $M
= \lambda \overline{\xi} . N_1 \ldots N_p$ is safe.
\end{proof}

Note that the hypothesis that $M$ is closed in (ii) is necessary.
For instance, the two terms $\lambda x y .x$ and $\lambda y . x$,
where $x,y:o$, have (isomorphic) incrementally-bound computation
trees. However $\lambda x y .x$ is safe whereas $\lambda y . x$ is
not.



Putting proposition \ref{prop:incrbound_imp_incrjustified} and lemma
\ref{lem:safe_imp_incrbound} together we obtain a game-semantic
characterisation of safe terms:
\begin{cor}[Incrementally-justified strategies characterise closed safe terms]
Let $M$ be a closed pure simply-typed term (with no constants) then:
$$ \sem{M} \mbox{ is incrementally-justified if and only if $\etabetanf{M}$ is safe,} $$
where $\etabetanf{M}$ denotes the $\eta$-normal form of the
$\beta$-normal form of $M$.
\end{cor}



\begin{thm}[Pointers are superfluous for safe terms]
\label{thm:safe_ptr_recoverable} Pointers in the game semantics of
safe terms are uniquely recoverable.
\end{thm}
\begin{proof}
Let $M$ be a safe simply-typed term. The $\beta$-normal form of $M$
denoted by $M'$ is also safe. By lemma \ref{lem:safe_imp_incrbound}
(i), $\tau(M')$ is incrementally-bound and by proposition
\ref{prop:incrbound_imp_incrjustified}, $\sem{M'}$ is an
incrementally-justified strategy. By lemma
\ref{lem:incrjustified_pointers_uniqu_recover}, the pointers in
$\sem{M'}$ are uniquely recoverable. Finally, the soundness of the
game model gives $\sem{M} = \sem{M'}$.
\end{proof}


\section{Safe PCF and Safe Idealized Algol}

Safe Idealized Algol, or Safe \ialgol\ for short, is Idealized Algol
where the application and abstraction rules are restricted the same
way as in the Safe $\lambda$-Calculus (see rules of section
\ref{sec:safe_nonhomog}).

The properties of the Safe $\lambda$-Calculus can be transposed
straightforwardly to Safe \ialgol. In particular, it can be shown
that safety is preserved by $\beta$-reduction and that no variable
capture occurs when performing substitution on a safe term.

A natural question to ask is whether we can extend the result about
game semantics of safe $\lambda$-terms to safe \ialgol-terms. In
this section we lay out the key elements permitting to prove that
the pointers in the game semantics of safe IA terms can be recovered
uniquely.

Such result has potential application in algorithmic game semantics.
For instance, by following the framework of \cite{ghicamccusker00},
it may be possible to give a characterisation of the game semantics
of some higher-order fragments of Safe \ialgol\ using extended
regular expressions. Subsequently, this would lead to the
decidability of program equivalence for the considered fragment.


\subsection{Formation rules of Safe \ialgol}
We call safe \ialgol\ term any term that is typable within the
following system of formation rules:
$$ \rulename{var} \   \rulef{}{x : A\vdash x : A}
%\qquad  \rulename{const} \   \rulef{}{\vdash f : A} \quad f \in \Sigma
\qquad  \rulename{wk} \   \rulef{\Gamma \vdash M : A}{\Delta \vdash
M : A} \quad  \Gamma \subset \Delta$$

$$ \rulename{app} \  \rulef{\Gamma \vdash M : (A,\ldots,A_l,B)
                                        \qquad \Gamma \vdash N_1 : A_1
                                        \quad \ldots \quad \Gamma \vdash N_l : A_l  }
                                   {\Gamma  \vdash M N_1 \ldots N_l : B}
                                    \quad
                                   \forall y \in \Gamma : \ord{y} \geq \ord{B}$$

$$ \rulename{abs} \   \rulef{\Gamma \union \overline{x} : \overline{A} \vdash M : B}
                                   {\Gamma  \vdash \lambda \overline{x} : \overline{A} . M : (\overline{A},B)} \qquad
                                   \forall y \in \Gamma : \ord{y} \geq \ord{\overline{A},B}$$

$$ \rulename{num} \rulef{}{\Gamma \vdash n :\texttt{exp}}
\qquad \rulename{succ} \rulef{\Gamma \vdash M:\texttt{exp} }{\Gamma
\vdash \texttt{succ}\ M:\texttt{exp}} \qquad \rulename{pred}
\rulef{\Gamma \vdash M:\texttt{exp} }{\Gamma \vdash \texttt{pred}\
M:\texttt{exp}}$$

$$
\rulename{cond} \rulef{\Gamma \vdash M : \texttt{exp} \qquad \Gamma
\vdash N_1 : \texttt{exp} \qquad \Gamma \vdash N_2 : \texttt{exp}
}{\Gamma \vdash \texttt{cond}\ M\ N_1\ N_2} \qquad  \rulename{rec}
\rulef{\Gamma \vdash M : A\rightarrow A }{ \Gamma \vdash Y_A M :
A}$$

$$ \rulename{seq} \rulef{\Gamma \vdash M : \texttt{com} \quad \Gamma \vdash N :A}
    {\Gamma \vdash \texttt{seq}_A \ M\ N\ : A} \quad A \in \{ \texttt{com}, \texttt{exp}\}$$

$$ \rulename{assign} \rulef{\Gamma \vdash M : \texttt{var} \quad \Gamma \vdash N : \texttt{exp}}
    {\Gamma \vdash \texttt{assign}\ M\ N\ : \texttt{com}}
\qquad
 \rulename{deref} \rulef{\Gamma \vdash M : \texttt{var}}
    {\Gamma \vdash \texttt{deref}\ M\ : \texttt{exp}}$$

$$ \rulename{new} \rulef{\Gamma, x : \texttt{var} \vdash M : A}
    {\Gamma \vdash \texttt{new } x \texttt{ in } M} \quad A \in \{ \texttt{com}, \texttt{exp}\}$$

$$ \rulename{mkvar} \rulef{\Gamma \vdash M_1 : \texttt{exp} \rightarrow \texttt{com} \quad \Gamma \vdash M_2 : \texttt{exp}}
    {\Gamma \vdash \texttt{mkvar } M_1\ M_2\ : \texttt{var}}$$

\subsection{Small-step semantics of Safe \ialgol}
In the first chapter we defined the operational semantics of
\ialgol\ using a big step semantics. The operational semantics of
\ialgol\ can be defined equivalently using a small-step semantics.
The reduction rules of the small-step semantics are of the form $s,e
\rightarrow s',e'$ where $s$ and $s'$ denotes the stores and $e$ and
$e'$ denotes \ialgol\ expressions.

Let us give the rules that tell how to reduce redexes:
\begin{itemize}
\item the reduction of safe-redex (relation $\beta_s$ from definition \ref{dfn:safereduction});
\item reduction rules for \pcf\ constants:
\begin{eqnarray*}
\pcfsucc\ n &\rightarrow& n+1 \\
\pcfpred\ n+1 &\rightarrow& n \\
\pcfpred\ 0 &\rightarrow& 0 \\
\pcfcond\ 0\ N_1 N_2 &\rightarrow& N_1 \\
\pcfcond\ n+1\ N_1 N_2 &\rightarrow& N_2 \\
Y\ M &\rightarrow& M (Y M)
\end{eqnarray*}
\item reduction rules for \ialgol\ constants:
\begin{eqnarray*}
\iaseq\ \iaskip\  M &\rightarrow& M \\
s, \ianewin{x}\ M &\rightarrow& (s|x\mapsto 0), M \\
s, \iaassign\ x\ n &\rightarrow& (s|x\mapsto n), \iaskip \\
s, \iaderef\ x &\rightarrow& s, s(x) \\
\iaassign\ (\iamkvar M N)\ n &\rightarrow& M n \\
\iaderef\ (\iamkvar M N) &\rightarrow& N
\end{eqnarray*}
\end{itemize}

Redex can also be reduced when they occur as subexpressions within a
larger expression. We make use of evaluation contexts to indicate
when such reduction can happen. Evaluation contexts are given by the
following grammar:
\begin{eqnarray*}
E[-] &::=& - |\ E N\ |\ \pcfsucc\ E\ |\ \pcfpred\ E\ |\ \pcfcond\ E\ N_1\ N_2\ |\ \\
&&    \iaseq\ E\ N\ |\ \iaderef\ E\ |\ \iaassign\ E\ n\ |\ \iaassign\ M\ E \ |\ \\
&&    \iamkvar\ M\ E\ |\ \iamkvar\ E\ M\ |\ \ianewin{x}\ E  .
\end{eqnarray*}

The small-step semantics is completed with following rule:
$$ \rulef{M \rightarrow N}{E[M] \rightarrow E[N]} $$

\begin{lem}[Reduction preserves safety]
\label{lem:ia_safety_preserved} Let $M$ be a safe \ialgol\ term. If
$M \rightarrow N$ then $N$ is also a safe term.
\end{lem}
This can be proved easily by induction on the structure of M.


\subsection{Safe \pcf\ fragment}
In this section, we show how to extend the results obtained for the
Safe $\lambda$-Calculus to the \pcf\ fragment of Safe \ialgol.

The $Y$ combinator needs a special treatment. In order to deal with
it, we follow the idea of \cite{abramsky:game-semantics-tutorial}:
we consider the sublanguage $\pcf_1$ of \pcf\ in which the only
allowed use of the $Y$ combinator is in terms of the form $Y(
\lambda x:A .x )$ for some type $A$. We will write $\Omega_A$ to
denote the non-terminating term $Y(\lambda x:A .x)$ for a given type
$A$.

We introduce the \emph{syntactic approximants} to $Y_A M$:
\begin{eqnarray*}
Y^0_A M &=& \Gamma \vdash \Omega_A : A\\
Y^{n+1}_A M &=& M( Y^n M )
\end{eqnarray*}
For any \pcf\ term $M$ and natural number $n$, we define $M_n$ to be
the $\pcf_1$ term obtained from $M$ by replacing each subterm of the
form $Y N$ with $Y^n N_n$. We have $\sem{M} = \Union_{n\in\omega}
\sem{M_n}$ (\cite{abramsky:game-semantics-tutorial}, lemma 16).


\subsubsection{Computation tree}

We would like to define a unique computation tree for terms that use
the $Y$ combinator.

Let us first define the computation tree for $\pcf_1$ terms. We
introduce a special $\Sigma$-constant $\bot$ representing the
non-terminating computation of ground type $\Omega_o$. Given any
type $A = (A_1, \ldots, A_n, o)$, the computation tree
$\tau(\Omega_A)$ is defined to be the tree representation of
$\lambda x_1:A_1 \ldots x_n:A_n . \bot$. The computation tree of a
$\pcf_1$ term is then computed inductively in the standard way.

We now introduce a partial order on the set of computation trees.

A \emph{tree} $t$ is a labelling function $t:T\rightarrow L$ where
$T$, called the domain of $t$ and written $dom(t)$, is a non-empty
prefix-closed subset of some free monoid $X^*$ and $L$ denotes the
set of possible labels. Intuitively, $T$ represents the structure of
the tree (the set of all paths) and $t$ is the labelling function
mapping paths to labels. Trees can be ordered using the
\emph{approximation ordering} defined in \cite{KNU02}, section 1: we
write $t' \sqsubseteq t$ if the tree $t'$ is obtained from $t$ by
replacing some of its subtrees by $\bot$. Formally:
$$t' \sqsubseteq t \quad \iff dom(t') \subseteq dom(t) \wedge \forall  w \in dom(t'). (t'(w) = t(w) \vee t'(w) = \bot).$$
The set of all trees together with the approximation ordering is a
complete partial order.

We now consider a strict subset of the set of all trees: the set of
computation trees. A computation tree is a tree which represents the
$\eta$-normal form of some (potentially infinite) \pcf\ term. In
other words a tree is a computation tree if it can be written
$\tau(M)$ for some infinite \pcf\ term $M$. The set $L$ of labels is
constituted of the $\Sigma$-constants, @, the special constant
$\bot$, variables and abstractions of any sequence of variables. We
will write $(CT, \sqsubseteq)$ to denote the set of computation
trees ordered by the approximation ordering $\sqsubseteq$ defined
above. $(CT, \sqsubseteq)$ is also a complete partial order.

It is easy to check that the sequence of computation trees
$(\tau(M_n))_{n\in\omega}$ is a chain. We can therefore define the
computation tree of a \pcf\ term $M$ to be the least upper-bound of
the chain of computation trees of its approximants:
$$\tau(M) = \Union_{n\in\omega}(\tau(M_n))_{n\in\omega}.$$

In other words, we construct the computation tree by expanding
infinitely any subterm of the form $Y M$. For instance consider the
term $M = Y (\lambda f x. f x)$ where $f:(o,o)$ and $x:o$. Its
computation tree $\tau(M)$ is 
$$\tau(M) = \tree{\lambda y}{
                \tree{@}{
                   \tree{\lambda f x} {\TR{x}}
                   \TR{\tau(M)} \TR{y}
                }
            }
$$
which is a tree representation of the $\eta$-normal form of the infinite term
$$(\lambda f x. f x) ((\lambda f x. f x) ((\lambda f x. f x)  (
\ldots \ .$$

The remaining operators of \ialgol\ are treated as standard
constants and the corresponding computation tree is constructed from
the $\eta$-normal form of the term in the standard way. For instance
the diagram below shows the computation tree for $\pcfcond\ b\ x\ y$
(left) and $\lambda x . 5$ (right):
$$
\tree{\lambda b x y}
     {  \tree{\pcfcond}
        {   \tree{\lambda} {\TR{b}}
            \tree{\lambda} {\TR{x}}
            \tree{\lambda} {\TR{y}}
        }
    }
\hspace{2cm} \tree{\lambda x}{  \TR{5} }
$$
The node labelled $5$ has, like any other node, children
value-leaves which are not represented on the diagram above for
simplicity.

\subsubsection{Traversal}

New traversal rules accompany the additional constants of \ialgol.
There is one additional rule for natural number constants:
\begin{itemize}
\item (Nat) If $t \cdot n$ is a traversal where $n$ denotes a node labelled with some numeral constant $i\in \nat$ then
            $t \cdot \rnode{n}{n} \cdot \rnode{in}{i_n} \bkptr[nodesep=0pt]{40}{in}{n}$
            is also a traversal where $i_n$ denotes the value-leaf of $m$ corresponding to the value $i\in \nat$.
\end{itemize}

\noindent The traversals rules for \pcfpred\ and \pcfsucc\ are
defined similarly. For instance, the rules for \pcfsucc\ are:
\begin{itemize}
\item (Succ) If $t \cdot \pcfsucc$ is a traversal and $\lambda$ denotes the only child node of \pcfsucc\ then
$t \cdot \rnode{succ}{\pcfsucc} \cdot \rnode{l}{\lambda}
\bkptr[nodesep=1pt]{60}{l}{succ} \bklabel{1}$ is also a traversal.

\item (Succ') If
$t_1 \cdot \rnode{succ}{\pcfsucc} \cdot \rnode{l}{\lambda} \cdot t_2
\cdot \rnode{lv}{i_{\lambda}} \bkptr[nodesep=1pt]{60}{l}{succ}
\bklabel{1} \bkptr[nodesep=1pt]{40}{lv}{l}$ is a traversal for some
$i \in \nat$ then $t_1 \cdot \rnode{succ}{\pcfsucc} \cdot
\rnode{l}{\lambda} \cdot t_2 \cdot \rnode{lv}{i_{\lambda}} \cdot
\rnode{succv}{(i+1)_{\pcfsucc}} \bkptr[nodesep=1pt]{60}{l}{succ}
\bklabel{1} \bkptr[nodesep=1pt]{25}{succv}{succ}
\bkptr[nodesep=1pt]{40}{lv}{l} $ is also a traversal.
\end{itemize}

\noindent In the computation tree, nodes labelled with \pcfcond\
have three children nodes numbered from $1$ to $3$ corresponding to
the three parameters of the operator \pcfcond. The traversal rules
are:
\begin{itemize}
\item (Cond-If) If $t_1 \cdot \pcfcond$ is a traversal and $\lambda$ denotes the first child of \pcfcond\ then
$t_1 \cdot \rnode{cond}{\pcfcond} \cdot \rnode{l}{\lambda}
\bkptr[nodesep=1pt]{60}{l}{cond} \bklabel{1}$ is also a traversal.

\item (Cond-ThenElse) If
$t_1 \cdot \rnode{cond}{\pcfcond} \cdot \rnode{l}{\lambda} \cdot t_2
\cdot \rnode{lv}{i_{\lambda}} \bkptr[nodesep=1pt]{60}{l}{cond}
\bklabel{1} \bkptr[nodesep=1pt]{40}{lv}{l}$ then $t_1 \cdot
\rnode{cond}{\pcfcond} \cdot \rnode{l}{\lambda} \cdot t_2 \cdot
\rnode{lv}{i_{\lambda}} \cdot \rnode{condthenelse}{\lambda}
\bkptr[nodesep=1pt]{60}{l}{cond} \bklabel{1}
\bkptr[nodesep=1pt]{40}{lv}{l}
\bkptr[nodesep=1pt]{35}{condthenelse}{cond} \bklabelc{2+[i>0]} $ is
also a traversal.



\item (Cond') If
$t_1 \cdot \rnode{cond}{\pcfcond} \cdot t_2 \cdot \rnode{l}{\lambda}
\cdot t_3 \cdot \rnode{lv}{i_{\lambda}}
\bkptr[nodesep=1pt]{40}{l}{cond} \bklabel{k}
\bkptr[nodesep=1pt]{40}{lv}{l}$ for $k=2$ or $k=3$ then $t_1 \cdot
\rnode{cond}{\pcfcond} \cdot t_2 \cdot \rnode{l}{\lambda} \cdot t_3
\cdot \rnode{lv}{i_{\lambda}} \cdot \rnode{condv}{i_{\pcfcond}}
\bkptr[nodesep=1pt]{40}{l}{cond} \bklabel{k}
\bkptr[nodesep=1pt]{40}{lv}{l} \bkptr[nodesep=1pt]{20}{condv}{cond}
$ is also a traversal.
\end{itemize}
It is easy to verify that these traversal rules are all well-behaved
and therefore condition (WB) of section \ref{subsec:traversal} is
met. This completes the definition of traversal for the \pcf\ subset
of \ialgol.

\subsubsection{Interaction semantics}
We need to complete the interaction semantics of section
\ref{sec:interaction_semantics} to take into account the constants
of the language. Let $f : (A_1,\ldots,A_p) \in \Sigma$ be a
higher-order constant denoted by the strategy $\sem{f}$ in the
standard semantics. We complete definition
\ref{dfn:interactionstrategy_ofterms} by defining the revealed
strategy of a term of the form $\lambda \overline{\xi}. f N_1 \ldots
N_p$ as follows:
$$ \intersem{\lambda \overline{\xi}. f N_1 \ldots N_p} = \langle \intersem{N_1}, \ldots, \intersem{N_p} \rangle \fatsemi^{0..p-1} \sem{f}.$$


\subsubsection{Removing $\Sigma$-nodes from the traversals}

To establish the correspondence with the interaction semantics, we
need to remove the superfluous nodes from the traversals. These
nodes are the @-nodes and the constant nodes. We will use the
operation $-@$ (definition \ref{dfn:appnode_filter}) to filter out
the @-nodes and we introduce a similar operation $-\Sigma$ to
eliminate the $\Sigma$-nodes.

\begin{dfn}[Hiding $\Sigma$-constants in the traversals]
Let $t$ be a traversal of $\tau(M)$. We write $t-\Sigma$ for the
sequence of nodes with pointers obtained by
\begin{itemize}
\item removing from $t$ all nodes labelled with a $\Sigma$-constant or value-leaf justified by a $\Sigma$-constant,
\item replacing any link pointing to a $\Sigma$-constant $f$
by a link pointing to the predecessor of $f$ in $t$.
\end{itemize}

Suppose $u = t-\Sigma$ is a sequence of nodes obtained by applying
the previously defined transformation on the traversal $t$, then $t$
can be partially recovered from $u$ by reinserting the
$\Sigma$-nodes as follows. For each $\Sigma$-node $f$, where $p$
denotes the parent node of $f$, do the following:
    \begin{enumerate}
    \item replace every occurrence of the pattern $p \cdot n$ in $u$ where
    $n$ is a $\lambda$-node by $p \cdot f \cdot n$;

    \item replace any link in $u$ starting from a $\lambda$-node and pointing to $p$ by a link pointing to the inserted node $f$;

    \item for each occurrence in $u$ of a value-leaf $v_p$ pointing to $p$, add the value-leaf $v_f$
    immediately before $v_p$. The links of $v_f$ points to the node immediately following $p$.
    \end{enumerate}
We write $u+\Sigma$ for this second transformation.
\end{dfn}
These transformations are well-defined since in a traversal, a
$\Sigma$-node $f$ always follows immediately its parent
$\lambda$-node $p$, and an occurrence of a value-node $v_p$ always
follows immediately a value-node $v_f$. In other words, if $f$
occurs in $t$ then $t$ must be a prefix of a traversal of the
following form for some $v \in \mathcal{D}$:
$$ \ldots \cdot \rnode{p}{p} \cdot \rnode{f}{f} \cdot \ldots \cdot \rnode{vf}{v_f} \cdot \rnode{vp}{v_p} \cdot \ldots
\bkptr[offset=-4pt]{20}{vf}{f} \bkptr[offset=-4pt]{20}{vp}{p}
$$

Remark: $t-\Sigma$ is not a proper traversal since it does not
satisfy alternation. It is not a proper justified sequence either
since after removing a $\Sigma$-node $f$, any $\lambda$-node
justified by $f$ will become justified by the parent of $f$ which is
also a $\lambda$-node.

The following lemma follows directly from the definition:
\begin{lem}
\label{lem:minus_sig_plus_sig} For any traversal $t$ we have
$(t-\Sigma)+\Sigma \sqsubseteq t$ and if $t$ does not end with an
$\Sigma$-node or a value-leaf of a $\Sigma$-node then
$(t-\Sigma)+\Sigma = t$.
\end{lem}

The operations $-@$ and $-\Sigma$ are commutative: $(t-@)-\Sigma =
(t-\Sigma)-@$. We write $t^*$ to denote $(t-@)-\Sigma$ i.e. the
sequence obtained from $t$ by removing all the @-nodes as well as
the constant nodes together with their associated value-leaves. We
introduce the notation $\travset(M)^{*} = \{ t^* \ | \  t \in
\travset(M) \}$.

\begin{lem}[Filtering lemma]
\label{lem:SIGMACONST:varphi_filter} Let $\Gamma \vdash M :T$ be a
term and $r$ be the root of $\tau(M)$. For any traversal $t$ of the
computation tree we have $ \varphi(\travset^*(M)) \upharpoonright
\sem{\Gamma \rightarrow T} = \varphi(\travset^{\upharpoonright
r}(M)) $.
 Consequently,
$$\varphi(t^*) \upharpoonright \sem{\Gamma \rightarrow T} = \varphi(t\upharpoonright r).$$
\end{lem}
\begin{proof}
    From the definition of $\varphi$, the nodes of the computation tree that $\varphi$ maps
    to moves in the arena $\sem{\Gamma \rightarrow T}$ are exactly the nodes that are hereditarily justified by $r$.
    The result follows from the fact that @-nodes, constant nodes and value-leaves of constant nodes
    are not hereditarily justified by the root.
\end{proof}

The following lemma is the counterpart of lemma
\ref{lem:varphiinjective} and it is proved identically.
\begin{lem}[$\varphi$ is injective]
\label{lem:SIGMACONST:varphiinjective} $\varphi$ regarded as a
function defined on the set of sequences of nodes is injective in
the sense that for any two traversals $t_1$ and $t_2$:
\begin{itemize}
\item[(i)] if $\varphi (t_1^* ) = \varphi (t_2^* )$ then $t_1^* =t_2^*$;
\item[(ii)] if $\varphi (t_1 \upharpoonright r ) = \varphi (t_2 \upharpoonright r )$ then $t_1\upharpoonright r = t_2\upharpoonright r$.
\end{itemize}
\end{lem}

\begin{cor} \
\label{cor:SIGMACONST:varphi_bij}
\begin{itemize}
\item[(i)] $\varphi$ defines a bijection from $\travset(M)^*$
to $\varphi(\travset(M)^*)$;
\item[(ii)] $\varphi$ defines a bijection from $\travset(M)^{\upharpoonright r}$ to
$\varphi(\travset(M)^{\upharpoonright r})$.
\end{itemize}
\end{cor}


\subsubsection{Correspondence theorem}
We would like to prove the counterpart of proposition
\ref{prop:rel_gamesem_trav} in the context of the simply-typed
$\lambda$-calculus \emph{with interpreted \pcf\ constants}. The game
model of the language \pcf\ is given by the category $\mathcal{C}_b$
of well-bracketed strategies. Hence the well-bracketing assumption
stated in section \ref{sec:assumptions} is satisfied.

We first prove that $\travset^{\upharpoonright r}$ is continuous.
\begin{lem}
\label{lem:travred_continuous} Let $(S,\subseteq)$ denote the set of
sets of justified sequences of nodes ordered by subset inclusion.
The function $\travset^{\upharpoonright r} : (CT,\sqsubseteq)
\rightarrow (S,\subseteq)$ is continuous.
\end{lem}
\begin{proof} \
    \begin{description}
    \item[Monotonicity:] Let $T$ and $T'$ be two computation trees such that $T \sqsubseteq T'$
    and let $t$ be some traversal of $T$.
    Traversals ending with a node labelled $\bot$ are maximal therefore $\bot$ can only occur
    at the last position in a traversal. Let us prove the following two properties:
        \begin{itemize}
            \item[(i)]  If $t = t \cdot n$ with $n\neq \bot$ then $t$ is a traversal of $T'$;
            \item[(ii)] if $t= t_1 \cdot \bot$ then $t_1\in \travset(T')$.
        \end{itemize}

        (i) By induction on the length of $t$. It is trivial for the empty traversal.
            Suppose that $t = t_1 \cdot n$ is a traversal with $n \neq \bot$.
            By the induction hypothesis, $t_1$ is a traversal of $T'$.

            We observe that for all traversal rules, the traversal produced is of the form $t_1 \cdot n$ where
            $n$ is defined to be a child node or value-leaf of some node $m$ occurring in $t_1$.
            Moreover, the choice of the node $n$ only depends on the traversal $t_1$
            (for the constant rules, this is guaranteed by assumption (WB)).

            Since $T \sqsubseteq T'$, any node $m$ occurring in $t_1$ belongs
            to $T'$ and the children nodes and leaves of $m$ in $T$ also belong to the tree $T'$.
            Hence $n$ is also present in $T'$ and the rule used to produce the traversal $t$ of $T$
            can be used to produce the traversal $t$ of $T'$.

        (ii) $\bot$ can only occur at the last position in a traversal
        therefore $t_1$ does not end with $\bot$ and by (i) we have $t_1\in \travset(T')$.
\vspace{6pt}

        Hence we have:
        \begin{align*}
        \travset(T)^{\upharpoonright r} &= \{ t \upharpoonright r \ | \ t \in \travset(T)     \} \\
        & = \{ (t\cdot n) \upharpoonright r \ | \ t\cdot n \in \travset(T) \wedge n \neq \bot \}
            \union \{ (t \cdot \bot ) \upharpoonright r \ | \ t \cdot \bot \in \travset(T)  \} \\
\mbox{(by (i) and (ii))} \quad        & \subseteq  \{ (t\cdot n)
\upharpoonright r \ | \ t\cdot n \in \travset(T') \wedge n \neq \bot
\}
            \union \{ t \upharpoonright r \ | \ t \in \travset(T')  \} \\
        & = \travset(T')^{\upharpoonright r}
        \end{align*}

        \item[Continuity:] Let $t \in \travset \left( \Union_{n\in\omega} T_n \right)$.
        We write $t_i$ for the finite prefix of $t$ of length $i$.
        The set of traversals is prefix-closed therefore $t_i \in \travset \left( \Union_{n\in\omega} T_n \right)$ for any $i$.
        Since $t_i$ has finite length we have $t_i \in \travset(T_{j_i})$ for some $j_i \in \omega$.
        Therefore we have:
        \begin{align*}
          t \upharpoonright r &= (\bigvee_{i\in\omega} t_i ) \upharpoonright r   & (\mbox{the sequence $(t_i)_{i\in\omega}$ converges to $t$}) \\
          &= \Union_{i\in\omega} ( t_i \upharpoonright r )   & (\_ \upharpoonright r \mbox{ is continuous, lemma \ref{lem:filtercontinous}}) \\
          &\in \Union_{i\in\omega} \travset^{\upharpoonright r}(T_{j_i})   & (t_i \in \travset(T_{j_i})) \\
          &\subseteq \Union_{i\in\omega} \travset^{\upharpoonright r}(T_i)   & (\mbox{since } \{ j_i \sthat i \in \omega \} \subseteq \omega)
        \end{align*}

        Hence $\travset^{\upharpoonright r} (\Union_{n\in\omega} T_n ) \subseteq \Union_{n\in\omega} \travset^{\upharpoonright r}(T_n).$

    \end{description}
\end{proof}

\begin{prop}
Let $\Gamma \vdash M : T$ be a \pcf\ term and $r$ be the root of
$\tau(M)$. Then:
\begin{align*}
(i)  \quad\varphi_M(\travset(M)^*) = \intersem{M},  \\
(ii) \quad \varphi_M(\travset(M)^{\upharpoonright r}) = \sem{M}.
\end{align*}
\end{prop}
\begin{proof}
We first prove the result for $\pcf_1$: (i) The proof is an
induction identical to the proof of proposition
\ref{prop:rel_gamesem_trav}. However we need to complete the case
analysis with the $\Sigma$-constant cases:
\begin{itemize}
\item The cases \pcfsucc, \pcfpred, \pcfcond\ and numeral constants are straightforward.

\item Suppose $M = \Omega_o$ then $\travset(\Omega_o) = \prefset ( \{ \lambda \cdot \bot \} )$ therefore
$\travset(\Omega_o)^{\upharpoonright r} = \prefset( \{ \lambda \} )$
and $\sem{\Omega_o} = \prefset( \{ q \})$ with $\varphi(\lambda) =
q$. Hence $\sem{\Omega_o} = \varphi
(\travset(\Omega_o)^{\upharpoonright r})$.
\end{itemize}
(ii) is a direct consequence of (i) and the filtering lemma (lemma
\ref{lem:SIGMACONST:varphi_filter}). \vspace{10pt}

\noindent We now extend the result to \pcf. Let $M$ be a \pcf\ term,
we have:
\begin{align*}
\sem{M} &= \Union_{n\in\omega} \sem{M_n} & (\mbox{\cite{abramsky:game-semantics-tutorial}, lemma 16})\\
&= \Union_{n\in\omega} \travset^{\upharpoonright r}(\tau(M_n)) & (M_n \mbox{ is a $\pcf_1$ term}) \\
&= \travset^{\upharpoonright r}(\Union_{n\in\omega} \tau(M_n) ) & (\mbox{by continuity of $\travset^{\upharpoonright r}$, lemma \ref{lem:travred_continuous}}) \\
&= \travset^{\upharpoonright r}(\tau(M)) & (\mbox{by definition of } \tau(M)) \\
&= \travset^{\upharpoonright r}(M) & (\mbox{abbreviation}).
\end{align*}
\end{proof}

Hence by corollary \ref{cor:SIGMACONST:varphi_bij}, $\varphi$
defines a bijection from $\travset(M)^{\upharpoonright r}$ to
$\sem{M}$:
$$\varphi : \travset(M)^{\upharpoonright r} \stackrel{\cong}{\longrightarrow} \sem{M}.$$

\subsubsection{Example: \pcfsucc}

Consider the term $M = \pcfsucc\ 5$ whose computation tree is
represented below. The value-leaves are also represented on the
diagram, they are the vertices attached to their parent node with a
dashed line.
$$
\psmatrix[colsep=3ex,rowsep=2ex]
\lambda^0 \\
\pcfsucc & 0 & 1 & \ldots \\
\lambda^1 & 0 & 1 & \ldots \\
5 & 0 & 1 & \ldots \\
  & 0 & 1 & \ldots
\endpsmatrix
\ncline{1,1}{2,1} \ncline{2,1}{3,1} \ncline{3,1}{4,1}
\valueedge{1,1}{2,2} \valueedge{1,1}{2,3} \valueedge{1,1}{2,4}
\valueedge{2,1}{3,2} \valueedge{2,1}{3,3} \valueedge{2,1}{3,4}
\valueedge{3,1}{4,2} \valueedge{3,1}{4,3} \valueedge{3,1}{4,4}
\valueedge{4,1}{5,2} \valueedge{4,1}{5,3} \valueedge{4,1}{5,4}
$$

The following sequence of nodes is a traversal of $\tau(M)$:
\vspace{18pt}
$$ t = \rnode{l0}{\lambda^0} \cdot \rnode{succ}{\pcfsucc} \cdot \rnode{l1}{\lambda^1} \cdot \rnode{c5}{5} \cdot \rnode{55}{5_5} \cdot \rnode{5l1}{5_{\lambda^1}} \cdot \rnode{6succ}{6_\pcfsucc} \cdot \rnode{6l0}{6_{\lambda^0}}.
\bkptr[offset=-4pt]{20}{6l0}{l0} \bkptr[offset=-4pt]{20}{5l1}{l1}
\bkptr[offset=-4pt]{20}{55}{c5} \bkptr[offset=-4pt]{20}{6succ}{succ}
$$
The subsequences $t^*$ and $t \upharpoonright r$ are given by:
$$
t^* = \rnode{l0}{\lambda^0} \cdot \rnode{l1}{\lambda^1} \cdot
\rnode{5l1}{5_{\lambda^1}} \cdot \rnode{6l0}{6_{\lambda^0}}.
\bkptr[offset=-4pt]{20}{6l0}{l0} \bkptr[offset=-4pt]{20}{5l1}{l1}
\bkptr[offset=-4pt]{20}{l1}{l0} \qquad  \mbox{ and } \qquad t
\upharpoonright r = \rnode{l0}{\lambda^0} \cdot
\rnode{6l0}{6_{\lambda^0}}. \bkptr[offset=-4pt]{20}{6l0}{l0}
$$
We have $\varphi(t^*) = q_0 \cdot q_5 \cdot 5_{q_5} \cdot 5_{q_0}$
and $\varphi(t\upharpoonright r) = q_0 \cdot 5_{q_0}$ where $q_0$
and $q_5$ denote the roots of two flat arenas over $\nat$. These two
sequences of moves correspond to some play of the interaction
semantics and the standard semantics respectively. The interaction
play is represented below:
$$\begin{array}{ccccc}
  \textbf{1} & \stackrel{5}{\multimap} & !\nat & \stackrel{\pcfsucc}{\multimap} & \nat \\
&&&&  \rnode{q0}{q_0} \\
&&  \rnode{q5}{q_5} \\
&&  \rnode{a5}{5_{q_5}} \\
&&&&  \rnode{a6}{6_{q_0}}
\end{array}
\nccurve[nodesep=2pt,ncurv=0.9,angleA=180,angleB=180]{->}{a5}{q5}
\nccurve[nodesep=2pt,ncurv=0.9,angleA=180,angleB=210]{->}{a6}{q0}
\ncarc[nodesep=2pt,ncurv=0.9,angleA=180,angleB=180]{->}{q5}{q0}
$$

\subsubsection{Another example : \pcfcond}

Consider the term $M = \lambda x y . \pcfcond\ 1\ x\ y$. Its
computation tree is represented below (without the value-leaves):
    $$ \tree{\lambda x y}
       {
          \tree{\pcfcond}
          {
            \tree{\lambda^1}{ \TR{0} }
            \tree{\lambda^2}{ \TR{x} }
            \tree{\lambda^3}{ \TR{y} }
          }
      }
    $$
For any value $v \in\mathcal{D}$ the following sequence of nodes is
a traversal of $\tau(M)$: \vspace{18pt}
$$ t = \rnode{lxy}{\lambda x y} \cdot \rnode{cond}{\pcfcond} \cdot \rnode{l1}{\lambda^1} \cdot \rnode{1}{1} \cdot \rnode{11}{1_1}
    \cdot \rnode{l2}{\lambda^2} \cdot \rnode{x}{x} \cdot \rnode{vx}{v_x}  \cdot \rnode{vl2}{v_{\lambda^2}} \cdot \rnode{vcond}{v_{\pcfcond}}
    \cdot \rnode{vlxy}{v_{\lambda x y}}.
\bkptr[offset=-4pt]{20}{vlxy}{lxy}
\bkptr[offset=-4pt]{20}{vcond}{cond}
\bkptr[offset=-4pt]{20}{vl2}{l2} \bkptr[offset=-4pt]{20}{vx}{x}
\bkptr[offset=-4pt]{20}{x}{vxy} \bkptr[offset=-4pt]{20}{l2}{cond}
\bkptr[offset=-4pt]{20}{11}{1} \bkptr[offset=-4pt]{20}{l1}{cond}
$$
The subsequences $t^*$ and $t \upharpoonright r$ are given by:
\vspace{13pt}
$$
t^* =  t = \rnode{lxy}{\lambda x y} \cdot
        \rnode{l1}{\lambda^1} \cdot
        \rnode{l2}{\lambda^2} \cdot
        \rnode{x}{x} \cdot
        \rnode{vx}{v_x}  \cdot
        \rnode{vl2}{v_{\lambda^2}} \cdot
        \rnode{vlxy}{v_{\lambda x y}}
\bkptr[offset=-4pt]{20}{vlxy}{lxy} \bkptr[offset=-4pt]{20}{vl2}{l2}
\bkptr[offset=-4pt]{20}{vx}{x} \bkptr[offset=-4pt]{20}{x}{vxy}
\bkptr[offset=-4pt]{20}{l2}{lxy} \bkptr[offset=-4pt]{20}{l1}{lxy}
\qquad  \mbox{ and } \qquad t \upharpoonright r =
\rnode{lxy}{\lambda x y} \cdot \rnode{x}{x} \cdot \rnode{vx}{v_x}
\cdot \rnode{vlxy}{v_{\lambda x y}}.
\bkptr[offset=-4pt]{20}{vlxy}{lxy} \bkptr[offset=-4pt]{20}{vx}{x}
\bkptr[offset=-4pt]{20}{x}{vxy}
$$
The sequence of moves $\varphi(t^*)$ corresponds to some play of the
interaction semantics and the sequence $\varphi(t\upharpoonright r)$
is a play of the standard semantics obtained by hiding the internal
moves of $\varphi(t^*)$. The interaction play $\varphi(t^*)$ is
represented below:
$$\begin{array}{ccccccccccc}
!\nat & \otimes & !\nat & \stackrel{ \langle \sem{1}, \pi_1,
\pi_2\rangle }{\multimap} & !\nat & \otimes & !\nat & \otimes &
!\nat
& \stackrel{ \pcfcond}{\multimap} & \nat \\
&&&&&&&&&&  \rnode{q0}{q_0} \\
&&&&  \rnode{qa}{q_a} \\
&&&&  \rnode{1}{1} \\
&&&&&&  \rnode{qb}{q_b} \\
  \rnode{qx}{q_x} \\
  \rnode{vqx}{v_{q_x}} \\
&&&&&&  \rnode{vqb}{v_{q_b}} \\
&&&&&&&&&& \rnode{vq0}{v_{q_0}}
\end{array}
\ncarc[nodesep=2pt,ncurv=0.9,angleA=180,angleB=180]{->}{vq0}{q0}
\ncarc[nodesep=2pt,ncurv=0.9,angleA=180,angleB=180]{->}{vqb}{qb}
\nccurve[nodesep=2pt,ncurv=0.9,angleA=180,angleB=180]{->}{vqx}{qx}
\ncarc[nodesep=2pt,ncurv=0.9,angleA=180,angleB=180]{->}{qx}{qb}
\ncarc[nodesep=2pt,ncurv=0.9,angleA=90,angleB=180]{->}{qb}{q0}
\nccurve[nodesep=2pt,ncurv=0.9,angleA=180,angleB=180]{->}{1}{qa}
\ncarc[nodesep=2pt,ncurv=0.9,angleA=90,angleB=180]{->}{qa}{q0}
$$


\subsubsection{Game characterisation of safe terms}

A difficulty arises because of the presence of the Y combinator :
computation trees of \pcf\ terms are potentially infinite. Despite
this particularity, lemma \ref{lem:safe_imp_incrbound} still holds
in the \pcf\ setting:
\begin{lem}[Safe terms have incrementally-bound computation tree]
\label{lem:pcf_safe_imp_incrbound} If $\Gamma \vdash M$ is a safe
\pcf\ term then $\tau(M)$ is incrementally-bound.
\end{lem}
\begin{proof}
Suppose that a variable node $z$ belongs to $\tau(M) =
\Union_{k\in\omega} \tau(M_k)$, then there exists $k\in \omega$ such
that $z$ belongs to $\tau(M_k) \sqsubseteq \tau(M)$. Moreover if we
write $r_k$ to denote the root of the tree $\tau(M_k)$ then the path
$[r_k,z]$ in $\tau(M_k)$ is equal to the path $[r,z]$ in $\tau(M)$.

Let $i$ denote the number of occurrences of the Y combinator in $M$.
We prove by induction on $i$ that $M_k$ is safe for any $k\in
\omega$. \emph{Base case:} $i=0$ then $M_k = M$. \emph{Step case:}
$i>0$. Let $Y_A N$ be a subterm of $M$. Since $M$ is safe, $N$ is
also safe. The number of occurrences of the Y combinator in $N$ is
smaller than $i$ therefore by the induction hypothesis $N_k$ is
safe. Consequently the term $Y_A^k N_k = \underbrace{N_k ( \ldots (
N_k}_{k \mbox{ times}} \Omega ) \ldots )$ is also safe and by
compositionality so is $M_k$.

Clearly, lemma \ref{lem:safe_imp_incrbound} is still valid in
$\pcf_1$ (the subterms of the form $\Omega$ are just represented by
the constant $\bot$ in the computation tree), therefore since $M_k$
is in $\pcf_1$, $\tau(M_k)$ must be incrementally-bound.
Consequently the node $z$ is incrementally-bound in $\tau(M_k)$ and
since $[r,z]=[r_k,z]$, the corresponding node $z$ in the tree
$\tau(M)$ is also incrementally-bound.

Hence $\tau(M)$ is incrementally-bound.
\end{proof}

\begin{thm}[Pointers are superfluous for Safe \pcf]
Pointers in the game denotation of safe \pcf\ terms are uniquely
recoverable.
\end{thm}
\begin{proof}
Since condition (WB) is verified, lemma \ref{lem:redtrav_trav} holds
in the Safe \pcf\ setting. Therefore proposition
\ref{prop:incrbound_imp_incrjustified}(i) also holds: terms in
$\beta$-nf with an incrementally-bound computation tree are denoted
by incrementally-justified strategies.

Safety is preserved by reduction (lemma
\ref{lem:ia_safety_preserved}), therefore by lemma
\ref{lem:pcf_safe_imp_incrbound} and soundness of the game
denotation, any Safe \pcf\ term must be denoted by an
incrementally-justified strategy.

Hence pointers are superfluous in the game denotation of safe \pcf\
terms.
\end{proof}

\subsection{Safe \ialgol}

We are now in a position to consider the full Safe Idealized Algol
language. The general idea is the same as for Safe \pcf, however
there are some difficulties caused by the presence of the two new
base types \iavar\ and \iacom. We just give indications on how to
adapt our framework to the particular case of Safe \ialgol\ without
giving the complete proofs. However we believe that enough
indications are given to convince the reader that the argument used
in the \pcf\ case can be easily adapted to \ialgol.

\subsubsection{Computation DAG}
In \pcf, arenas have a single initial move, therefore they can be
regarded as trees. In \ialgol, on the other hand, the base type
\iavar\ is represented by the infinite product of games
$\iacom^{\nat} \times \iaexp$ which has an infinite number of
initial moves. In order to preserve the relationship established
between arenas and computation trees, we need to accommodate the
definition of computation tree to reflect this property. The
consequence is that in \ialgol, ``computation trees'' become
``computation directed acyclic graphs (DAG)'': a computation DAG may
have (possibly infinitely) many roots and two nodes of a given level
can share children at the next level.

A term of type \iavar\ has a computation DAG with an infinite number
of root $\lambda$-nodes. Suppose that $M$ is a term of type \iavar,
then the computation DAG for $\lambda \overline{\xi} . M$ is
obtained by relabelling the root $\lambda$-nodes $\lambda^r$,
$\lambda^{w_0}$, $\lambda^{w_1}$, $\lambda^{w_2}$, \ldots into
$\lambda^r \overline{\xi}$, $\lambda^{w_0} \overline{\xi}$,
$\lambda^{w_1} \overline{\xi}$, $\lambda^{w_2} \overline{\xi}$,
\ldots. For a term $M$  of type \iaexp\ or \iacom, the computation
DAG for $\lambda \overline{\xi} . M$ is computed in the same way as
in the Safe $\lambda$-Calculus.


\subsubsection{Game semantics correspondence}
The properties that we proved for computation trees and traversals
of the Safe $\lambda$-Calculus with constants can easily be lifted
to computation DAGs of \ialgol. In particular:
\begin{itemize}
\item constant traversal rules are well-behaved;
\item P-view of traversals are paths in the computation DAG;
\item the P-view of the reduction of a traversal is the reduction of the P-view,
and the O-view of a traversal is the O-view of its reduction (lemma
\ref{lem:redtrav_trav});
\item there is a mapping from vertices of the computation DAG to moves in the interaction game semantics;
\item there is a correspondence between traversals of the computation tree and plays in interaction game semantics;
\item consequently, there is a correspondence between the standard game semantics and
the set of justified sequences of nodes $\travset^{\upharpoonright
r}$.
\end{itemize}

\subsubsection{Game-semantic characterisation of safe terms}
Clearly, the computation DAG of a safe term is incrementally-bound.
By using the correspondence between traversals and plays, it is easy
to prove that incrementally-bound computation trees are denoted by
incrementally-justified strategies. Consequently, by lemma
\ref{lem:incrjustified_pointers_uniqu_recover}, the pointers in the
game semantics of Safe \ialgol\ terms are superfluous.

Since the game denotation of an \ialgol\ term is fully determined by
the set of complete plays, this pointer economy suggests that the
game denotation of a Safe \ialgol\ can be represented in a compact
way. This raises the question of the decidability of observational
equivalence for Safe \ialgol.










%%%%%%%%%%%%%%%%%




A traversal is a justified sequence of nodes of the computation tree respecting some
formation rules. Traversals are used to describe computations. An
interesting property is that the \emph{P-view} of a traversal
(computed in the same way as P-view of plays in Game Semantics) is a
path in the computation tree.

The main result that we will prove in this chapter is called the
\emph{Correspondence Theorem} (theorem \ref{thm:correspondence}). It
states that traversals over the computation tree are just
representations of the uncovering of plays in the
strategy-denotation of the term. Hence there is an isomorphism
between the strategy denotation of a term and its revealed game
denotation (i.e. its strategy denotation where internal moves are
not hidden after composition). This theorem permits us to explore
the effect that a given syntactic restriction has on the strategy
denotating a term.

To really make use of the Correspondence Theorem, it will be
necessary to restate it in the standard game-semantic framework in
which internal moves are hidden. For that purpose, we will define a
\emph{reduction} operation on traversals responsible of eliminating
the ``internal nodes'' of the computation. This leads to a
correspondence between the standard game denotation of a term and
the set of reductions of traversals over its computation tree.
Fortunately, the reduction process preserves the good properties of
traversals. This is guaranteed by the facts that the P-view of the
reduction of a traversal is equal to the reduction of the P-view of
the traversal, and the O-view of a traversal is the same as the
O-view of its reduction (lemma \ref{lem:redtrav_trav}). \vspace{8pt}

\emph{Related works}: Traversals of a computation tree provide a way
to perform \emph{local computation} of $\beta$-reductions as opposed
to a global approach where the $\beta$-reduction is implemented by
performing substitutions. A notion of local computation of
$\beta$-reduction has been investigated in
\cite{DanosRegnier-Localandasynchronou} through the use of special
graphs called ``virtual nets'' that embed the lambda-calculus.

In \cite{DBLP:conf/lics/AspertiDLR94}, a notion of graph based on
Lamping's graphs \cite{lamping} is introduced to represent
$\lambda$-terms. The authors unify different notions of paths
(regular, legal, consistent and persistent paths) that have appeared
in the literature as ways to implement graph-based reduction of
lambda-expressions. We can regard a traversal as an alternative
notion of path adapted to the graph representation of
$\lambda$-expressions given by computation trees.



%%%%%%%%%%%%%%%%%%%%

%\begin{thm}[Correspondence theorem]
%\label{thm:corresp} The set of traversals of the computation tree is
%isomorphic to the set of uncovered plays of the game denotation of
%the term.
%\end{thm}

%\begin{thm}[Game-semantic characterisation of safety]
%\label{thm:gamesem_charact} Safe simply-typed terms in
%$\beta$-normal form have incrementally-bound computation trees.
%Reciprocally, a closed term in $\eta$-long normal form with an
%incrementally-bound computation trees is safe.
%\end{thm}

%\begin{cor}
%\label{cor:safeptrrecover} The pointers in the game semantics of
%safe simply-typed terms can be recovered uniquely from the
%underlying sequences of moves.
%\end{cor}

\section{Further work}

\subsection{Extension to Safe Idealized Algol}

%We define Safe \textsf{IA} to be the Safe $\lambda$-calculus
%augmented with the constants of Idealized Algol (\textsf{IA})
%\cite{Reynolds81} as well as a family of combinators $Y_A$ for every
%type $A$. We show that terms of the Safe \textsf{PCF}
%\cite{DBLP:journals/tcs/Plotkin77} fragment are denoted by
%incrementally-justified strategies and we give the key elements for
%a possible extension to full Safe \textsf{IA}.

\subsection{Open problems}

However the nature of the Safe $\lambda$-Calculus is still not well known. We propose the following possible
roadmap for further research:
\begin{enumerate}
\item prove or disprove that observational equivalence is decidable for Safe \ialgol;
\item find a categorical interpretation of the Safe $\lambda$-Calculus;
\item study the proof theory obtained by the Curry-Howard isomorphism and determine whether it has nice properties that can be helpful in theorem proving;
\item in \cite{DBLP:conf/tlca/LeivantM93}, the $\lambda$-calculus is used to
give several characterisations of the complexity class P. We would
like to investigate whether, by following similar techniques, we can
obtain a characterisation of a different complexity class using the
Safe $\lambda$-Calculus.
\end{enumerate}


More generally, we would like to study the class of languages for
which pointers are uniquely recoverable. We name this class PUR for
``Pointer Uniquely Recoverable''.

We proved that Safe $\lambda$-Calculus is a PUR-language. Another
example is the Serially Re-entrant Idealized Algol (SRIA) proposed
by Abramsky  in \cite{abramsky:mchecking_ia}. This language allows
multiple occurrences or uses of arguments, as long as they do not
overlap in time. In the game semantics denotation of a SRIA term
there is at most one pending occurrence of a question at any time.
Each move has therefore a unique justifier and consequently
justification pointers may be ignored. Safe \ialgol\ is not a
sublanguage of SRIA. One reason for this is that none of the two
Kierstead terms $\lambda f . f (\lambda x . f (\lambda y .y ))$ and
$\lambda f . f (\lambda x . f (\lambda y .x ))$ are Serially
Re-entrant whereas the first one is safe. Conversely, SRIA is not a
sublanguage of Safe \ialgol\ since the term $\lambda f g. f (\lambda
x . g (\lambda y .x ))$ where $f,g:((o,o),o)$ belongs to SRIA but
not to Safe \ialgol. SRIA and Safe \ialgol\ are therefore two
different examples of languages with pointer-less game semantics.

Finitary $\ialgol_2$ is also an example of PUR-language for which
observational equivalence is decidable. Decidability of observational equivalence is a very
appealing property which has immediate applications in the domain of
program verification. Intuitively, PUR-languages seem to be good
candidates of languages for which observational equivalence is
decidable. It would be interesting to discover classes of PUR
languages having this appealing property.

Another possible way to generate PUR-languages may be to constrain
the types of an existing language. In \cite{DBLP:conf/tlca/Joly01},
a notion of ``complexity'' is defined for $\lambda$-terms. It is
proved that a type $T$ can be generated from a finite set of
combinators if and only if there is a constant bounding the
complexity of every closed normal $\lambda$-term of type $T$;
consequently, the only inhabited finitely generated types are the
type of rank $\leq 2$ and the types $(A_1, A_2, \ldots, A_n, o)$
such that for all $i = 1..n$: $A_i = o$ , $A_i = o \rightarrow o$ or
$A_i = (o^k \rightarrow o) \rightarrow o$. We know that imposing the
first of these two type restrictions to Finitary \ialgol\ leads to a
PUR language. Is it also the case when imposing the second type
restriction?




\bibliographystyle{splncs}
\bibliography{../transfer/higherorder,../transfer/gamesem,../transfer/modelchecking,../transfer/proganalys}

\end{document}
