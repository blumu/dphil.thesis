% the LaTeX macro package from Springer-Verlag for Lecture Notes in Computer Science,
% version 2.2 for LaTeX2e
\documentclass{llncs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{pst-tree}
\usepackage[all]{xy}
\usepackage{stmaryrd}
\usepackage{picins}


\newcommand\defname[1]{{\bf\em #1}\index{#1}}

% reduction, substitution
\newcommand\betared{\rightarrow_\beta}
\newcommand\betasred{\rightarrow_{\beta_s}}
\newcommand\betaredtr{\twoheadrightarrow_\beta} % transitive closure of the beta reduction
\newcommand\subst[2]{\left[ #1/#2 \right]}
\newcommand\captsubst[2]{\{#1/#2 \}}

% computation tree, eta normal form, traversals
\newcommand\aux[1]{\lceil #1\rceil}
\newcommand\etanf[1]{\eta_{\sf nf}(#1)}
\newcommand\travset{\mathcal{T}rav}

% lambda calculus
%\newcommand\bot{\perp}
\newcommand\dps{\displaystyle}
\newcommand\rulef[2]{\frac{\dps #1}{#2}}
\newcommand\ord[1]{{\sf ord}(#1)}
\newcommand\typar{\Rightarrow}
\newcommand\typear{\rightarrow}
\newcommand{\rulename}[1]{\mathbf{(#1)}}

% semantics
\newcommand{\lsem}{[\![} % \llbracket
\newcommand{\rsem}{]\!]} % \rrbracket
\newcommand{\sem}[1]{{\lsem #1 \rsem}}
\newcommand{\intersem}[1]{{\langle\!\langle #1 \rangle\!\rangle}}

%set theory
\newcommand{\makeset}[1]{\{\,{#1}\,\}}
\newcommand\union{\cup}
\newcommand\Union{\bigcup}
\newcommand\prefset{\textsf{Pref}}
\newcommand{\relimg}[1]{{(\!| #1 |\!)}}
\newcommand\sthat{\ | \ }  % ``such that'' for set defined by comprehension
\newcommand\nat{\mathbb{N}}


%%% game semantics
\newcommand\natbf{\mathbf{N}}
\newcommand\zset{\mathbb{Z}}
\newcommand\eval{\Downarrow}
\newcommand\obspre{\sqsubseteq}
\newcommand\obseq{\approx}
\newcommand\intercomp{\fatsemi{^\|}}

% trees
\newcommand{\SubTree}[2][]{\Tr[ref=t]{\pstribox[#1]{#2}}}
\newcommand{\SubTreeE}[2][]{\Tr[ref=t]{\pstribox[#1]{#2}}}
\def\dedge{\ncline[linestyle=dashed]}
\def\dotedge{\ncline[linestyle=dotted]}
\def\valueedge{\ncline[linestyle=dashed,linewidth=0.5pt]}
\newcommand{\TRV}[1][edge=\valueedge]{\TR[edge=\valueedge,#1]}
\newcommand{\tree}[2][levelsep=3.5ex]{\pstree[levelsep=3.5ex,#1]{\TR{#2}}}

% logic
\newcommand\imp{\Rightarrow}
\newcommand\zand{\wedge}
\newcommand\entail{\vdash}

% ia
\newcommand\ialgol{\textsf{IA}}
\newcommand\ialgolmnew{\ialgol-$\{\ianew\}$}
\newcommand\iaseqcom{$\tt{seq_{com}}$}
\newcommand\iaseqexp{$\tt{seq_{exp}}$}
\newcommand\iaseq{\texttt{seq}}
\newcommand\iaskip{\texttt{skip}}
\newcommand\iaderef{\texttt{deref}}
\newcommand\iaassign{\texttt{assign}}
\newcommand\iadone{\texttt{done}}
\newcommand\iarun{\texttt{run}}
\newcommand\iawrite{\texttt{write}}
\newcommand\iaread{\texttt{read}}
\newcommand\iaok{\texttt{ok}}
\newcommand\iamkvar{\texttt{mkvar}}
\newcommand\ianew{\texttt{new}}
\newcommand{\ianewin}[1]{\texttt{new}\ #1\ \texttt{in}}
\newcommand\iabool{\texttt{bool}}
\newcommand\iawhile{\texttt{while}}
\newcommand\iado{\texttt{do}}
\newcommand\iacom{\texttt{com}}
\newcommand\iaexp{\texttt{exp}}
\newcommand\iavar{\texttt{var}}

%pcf
\newcommand\pcf{\textsf{PCF}}
\newcommand\pcfcond{\texttt{cond}}
\newcommand\pcfsucc{\texttt{succ}}
\newcommand\pcfpred{\texttt{pred}}

%% justified sequence of moves
\newcommand{\oview}[1]{\llcorner #1 \lrcorner}
\newcommand{\pview}[1]{\ulcorner #1 \urcorner}

% back pointer using psttricks
\newcommand{\bkptr}[2][nodesep=0pt]{\ncarc[linewidth=0.4pt,offset=-2pt,nodesep=0pt,ncurv=1,arcangleA=-#2, arcangleB=-#2,#1]{->}}
\newcommand{\bklabel}[1]{\mput*{\mbox{{\tiny $#1$}}}}
\newcommand{\bklabelc}[1]{\Bput[1pt]{\mbox{{\tiny $#1$}}}}
\newcommand\treelabel[1]{\mput*{\mbox{{\small $#1$}}}}


\begin{document}

\frontmatter          % for the preliminaries
\pagestyle{headings}  % switches on printing of running heads
%\addtocmark{} % additional mark in the TOC

\mainmatter              % start of the contributions

\title{The Safe $\lambda$-Calculus}

\titlerunning{The Safe $\lambda$-Calculus}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used


\author{William Blum\inst{1} \and C.-H. Luke Ong\inst{2}}
%
\authorrunning{William Blum et al.}   % abbreviated author list (for running head)
%
%%%% modified list of authors for the TOC (add the affiliations)
\tocauthor{William Blum (University of Oxford), C.-H. Luke Ong (University of Oxford)}


\institute{Oxford University Computing Laboratory\\ Wolfson Building, Parks Road, Oxford, OX1 3QD, ENGLAND\\
\email{william.blum@comlab.ox.ac.uk\inst{1} luke.ong@comlab.ox.ac.uk\inst{2}} }

\maketitle              % typeset the title of the contribution

\pagestyle{empty}

% TLCA05:
%    Papers should not exceed 15 pages in Springer LNCS format.
%    An abstract (ASCII text) of no more than 150 words should be sent separately at least a weak before the paper submission deadline.

% LNCS:
%    The abstract should summarize the contents of the paper
%    using at least 70 and at most 150 words. It will be set in 9-point
%    font size and be inset 1.0 cm from the right and left margins.
%    There will be two blank lines before and after the Abstract. \dots

\begin{abstract}
The \emph{safety condition} has been introduced in \cite{KNU02} as a syntactic
restriction for higher-order grammars that constrains occurrences
of variables in the grammar equations according to their order.
When transposed to the $\lambda$-calculus, the safety condition gives rise to the \emph{Safe $\lambda$-calculus}, a
strict sub-language of the $\lambda$-calculus (\cite{safety-mirlong2004}).

We present a new version of Safe $\lambda$-calculus and give a game-semantic
account of it. In particular we show that pointers are superfluous in the plays
of the game denotation of safe terms.
\end{abstract}


\section{Introduction}

\subsection{Background}

The \emph{Safety restriction} has been introduced in by Knapik, Niwi{\'n}ski and Urzyczyn in \cite{KNU02}
for the purpose of studying infinite trees generated by higher-order grammars.
It is very similar to the ``restriction of derived types'' which was introduced
by Damm in \cite{Dam82} however the formulation differs.
Safety is a syntactic restriction for higher-order grammars that
constrains the occurrences of the variables in the grammar
equations according to their order. Safety imposes a further restriction called \emph{homogeneity} on the type of the grammar equations.
The formal definition is intricate and seems a bit odd but the Safety restriction has important algorithmic impacts.

In particular, the authors of \cite{KNU02} proved that the Monadic Second
Order (MSO) theory of the term tree generated by a safe recursion
scheme of any order is decidable\footnote{In fact it has been shown
recently in \cite{OngLics2006} that it is also true for unsafe
recursion schemes.}. They also give the following nice automata-theoretic characterisation of safety:
an infinite term is generated by a \emph{safe} higher-order grammar if and only if
it is generated by a level-$n$ pushdown automaton.


When transposed to the $\lambda$-calculus, the safety condition
gives rise to the \emph{Safe $\lambda$-calculus}, a strict
sub-language of the $\lambda$-calculus. A first version appeared in
the technical report \cite{safety-mirlong2004}. We propose a more
general and simpler version where term types are not required to be
homogeneous. A noteworthy feature of the Safe
$\lambda$-calculus is that no variable capture can occur when
performing substitution and therefore it is unnecessary to rename
variables when computing $\beta$-reductions.

Little is known about the Safe $\lambda$-calculus and there are many
problems that have yet to be studied concerning its
computational power, the complexity classes that it characterises,
its interpretation under the Curry-Howard isomorphism and its
game-semantic characterisation. This paper contributes to give an
answer to the last problem.


The difficulty in giving a game-semantic account of Safety lies in
the fact that it is a syntactic restriction whereas Game Semantics
is by essence a syntax-independent semantics. The solution consists
in finding a particular syntactical representation of terms on which
the plays of the game denotation can be represented.
To achieve this, we use ideas recently introduced in \cite{OngLics2006}: a term
is canonically represented by the abstract syntax tree of its
$\eta$-long normal form, referred as the \emph{computation tree}. A
computation is described by a justified sequence of nodes of the
computation tree respecting some formation rules and called a
\emph{traversal}. Traversals permit us to model $\beta$-reductions
without altering the structure of the computation tree via
substitution. A notable property is that \emph{P-view} (in the game-semantic sense) of traversals
corresponds to paths in the computation tree.

These notions permit us to establish a correspondence between the game semantics of a term and
the syntactic representation given by its computation tree.
More precisely, we show that traversals are just representations of the
uncovering of plays of the strategy denoting the term.
Then by defining an appropriate \emph{reduction} operation which eliminates traversal
nodes that are ``internal'' to the computation, we obtain an
isomorphism between the strategy denotation of a term and the set of
reductions of traversals of its computation tree.



Using that correspondence and after introducing the notion of \emph{incrementally-justified
strategies}, we are able to show that $\beta$-normal terms are \emph{safe} if and only if
their strategy denotation is incrementally-justified.
A consequence of this is that pointers in the game semantics of safe simply-typed terms can be recovered uniquely from the underlying sequences of moves.

\vspace{1cm}

\subsection{Related work}

\subsubsection{Safety}

De Miranda's forthcoming thesis \cite{demirandathesis} proposes a unified framework for the study of higher-order grammars. The thesis contains a detailed analysis of the safety constraint at level 2. It shows that, when restricted to word languages, safe level $2$ higher-order grammars are as powerful as (non-deterministic) unsafe ones. It also shows that at level $2$, safety is not a requirement to guarantee MSO decidability. The reader is referred to it for a full account of the Safety condition for higher-order grammars.


As we mentioned before, Knapik \emph{et al.} showed in \cite{KNU02} that infinite trees generated by \emph{safe} higher-order grammars
have decidable MSO theories. In \cite{OngLics2006}, Ong generalized the result to any higher-order grammar, whether safe or not.
Using an argument based on innocent game-semantics, he establishes a correspondence between the tree generated by a higher-order grammar called \emph{value tree} and a certain regular tree called \emph{computation tree}. Paths in the value tree correspond to traversals in the computation tree. Decidability is then obtain by reducing the problem to the acceptance of the (annotated) computation tree by a certain alternating parity tree automaton (APT). The approach that we follow in section \ref{sec:correspondence} uses many ingredients introduced in this paper.


\subsubsection{Computation trees and traversals}

In \cite{DBLP:conf/lics/AspertiDLR94}, a notion of graph based on
Lamping's graphs \cite{lamping} is introduced to represent
$\lambda$-terms. The authors unify different notions of paths
(regular, legal, consistent and persistent paths) that have appeared
in the literature as ways to implement graph-based reduction of
lambda-expressions. We can regard a traversal as an alternative
notion of path adapted to the graph representation of
$\lambda$-expressions given by computation trees.

Traversals of a computation tree provide a way
to perform \emph{local computation} of $\beta$-reductions as opposed
to a global approach where the $\beta$-reduction is implemented by
performing substitutions. A notion of local computation of
$\beta$-reduction has been investigated in
\cite{DanosRegnier-Localandasynchronou} through the use of special
graphs called ``virtual nets'' that embed the lambda-calculus.


\section{The Safe $\lambda$-calculus}
We consider simple types generated by the grammar $A
\, ::= \, o \; | \; A \typear A$. Any type different from the ground
type $o$ can be written $(A_1, \cdots, A_n, o)$ for some $n \geq 1$,
which is a shorthand for $A_1 \typear \cdots \typear A_n \typear o$ (by
convention, $\rightarrow$ associates to the right). If $T=(A_1,
\cdots, A_n, o)$ then the arity of $T$, written $arity(T)$, is
defined to be $n$.
The order of a type is defined by $\ord{o} = 0$ and
$\ord{A \typear B} = \max(\ord{A}+1, \ord{B})$.

The \textbf{Safe $\lambda$-Calculus} is a sub-system of the simply-typed $\lambda$-calculus formally defined by the definition that follows.
We use a set of sequents of the form $\Gamma \vdash M : A$ to represent
terms-in-context where $\Gamma$ is the context (a typed-alphabet) and $A$ is the type. We assume that a set
of higher-order constants $\Sigma$ is given.

\begin{definition}[The Safe $\lambda$-calculus]
We call \emph{safe term} any simply-typed lambda term that is typable using the following
formation rules:
$$ \rulename{var} \   \rulef{}{x : A\vdash x : A}
\qquad  \rulename{const} \   \rulef{}{\vdash f : A} \quad f \in \Sigma
\qquad  \rulename{wk} \   \rulef{\Gamma \vdash s : A}{\Delta \vdash s : A} \quad \Gamma \subset \Delta$$

$$ \rulename{app} \  \rulef{\Gamma \vdash s : (A_1,\ldots,A_n,B)
                                        \ \Gamma \vdash t_1 : A_1
                                        \  \ldots\  \Gamma \vdash t_n : A_n }
                                   {\Gamma  \vdash s t_1 \ldots t_n : B}
                                    \
                                   \ord{B} \sqsubseteq \ord{\Gamma}$$

$$ \rulename{abs} \   \rulef{\Gamma, x_1 : A_1 \ldots x_n : A_n \vdash s : B}
                                   {\Gamma  \vdash \lambda x_1 \ldots x_n . s : (A_1, \ldots ,A_n,B)} \
                                   \ord{A_1, \ldots ,A_n,B} \sqsubseteq \ord{\Gamma}$$

where in the side-conditions, $\ord{\Gamma}$ denotes the set $\{ \ord{y} : y \in \Gamma \}$ and $c \sqsubseteq S$ is a notation for
``$c$ is a lower-bound for $S$''.
\end{definition}

The first deviation from the standard definition of the simply-typed $\lambda$-calculus is the possibility to perform multiple applications at a time using the {\sf (app)} rule and similarly to abstract several variables at a time using the {\sf (abs)} rule.
Of course this single change would not alter expressivity if there were not at the same time the additional condition
constraining the occurrences of variables within a term:  the side-condition in the application rule and abstraction rules ensures that all variables in the context of the term being formed have order greater than the order of the term itself.



Note that there is no specific constraint on the term type. In particular, the type-homogeneity constraint that is used
in the definition of safe higher-order grammars in \cite{KNU02} is not required here.\footnote{ We say that a type is homogeneous
if it is $o$ or if it is $(A_1, \cdots, A_n, o)$ with $\ord{A_1} \geq \ord{A_2}\geq \cdots \geq \ord{A_n}$ and
each $A_1$, \ldots, $A_n$ is homogeneous.} Another difference is that we allow $\Sigma$-constants to be of any higher-order types whereas
\cite{KNU02} focuses on the restricted case of first-order $\Sigma$-constants.
In these regards, our formulation of the Safe $\lambda$-calculus differs from the one proposed in \cite{safety-mirlong2004}.
It is possible to reconcile the two definitions by adding the further constraint that each type occurring in our rules is homogeneous, we then obtain a calculus equivalent to the one of \cite{safety-mirlong2004}.




\begin{example}[Kierstead terms]
Consider the terms $M_1 = \lambda f . f (\lambda x . f (\lambda y . y ))$ and
$M_2 = \lambda f . f (\lambda x . f (\lambda y .x ))$ where $x,y:o$ and $f:((o,o),o)$.
$M_2$ is not safe because in the subterm $f (\lambda y . x)$, the free variable $x$ has order $0$ which is smaller than $\ord{\lambda y . x} = 1$.
On the other hand, $M_1$ is safe as the following proof tree shows:
$$
 \rulef{
     \rulef{
        \rulef{}{f \vdash f} {\sf(var)}
        \
        \rulef{
             \rulef{
                \rulef{
                    \rulef{}{f \vdash f} {\sf(var)}
                }
                {f , x \vdash f } {\sf(wk)}
                \
                \rulef{
                    \rulef{
                        \rulef{}{y \vdash y} {\sf(var)}
                    }
                    {y \vdash \lambda y . y } {\sf(abs)}
                }
                {f , x \vdash \lambda y .y } {\sf(wk)}
             }
             {f , x \vdash f (\lambda y .y )} {\sf(app)}
        }
        { f  \vdash \lambda x . f (\lambda y .y )} {\sf(abs)}
     }
     {
        f  \vdash f (\lambda x . f (\lambda y .y ))} {\sf(app)}
     }
 { \vdash M_1 = \lambda f . f (\lambda x . f (\lambda y .y )) } {\sf(abs)}
$$
\end{example}

The following lemma is an immediate consequence of the definition:
\begin{lemma}
\label{lem:ordfreevar}
If $\Gamma \vdash M : A$ then every variable in $\Gamma$ occurring free in $M$ has order at least $ord(M)$.
\end{lemma}




In the simply typed $\lambda$-calculus, it is necessary to rename
variables when performing substitution on an abstraction in order to
avoid possible variable capture. As a consequence, in order to
implement substitution one needs to have access to an unbound number
of variable names.
In the Safe $\lambda$-Calculus, however, variable capture never happens as the following lemma shows.
Hence substitution can implemented naively by capture-permitting replacement, avoiding any need for variable renaming.


Let us write $M\captsubst{N}{x}$ to denote the capture-permitting substitution of $N$ for $x$ in $M$. This substitution is implemented
by textually replacing all free occurrences of $x$ in $M$ by $N$ without performing variable renaming.
In particular for the abstraction case we have:
$$(\lambda \overline{y} . P)\captsubst{N}{x} = \left\{
                                                 \begin{array}{ll}
                                                   \lambda \overline{y} . P\captsubst{N}{x} , & \hbox{if $x\not\in \overline{y}$;} \\
                                                   \lambda \overline{y} . P, & \hbox{if $x\in y$.}
                                                 \end{array}
                                               \right.
$$

\begin{lemma}[No variable capture]
\label{lem:homog_nocapture} There is
no variable capture when performing capture-permitting
substitution of $N$ for $x$ in $M$
provided that $\Gamma, x \vdash M$ and $\Gamma \vdash  N$ are valid judgments of the Safe $\lambda$-calculus.
\end{lemma}

\begin{proof}
We prove the result by induction. The variable, constant and
application cases are trivial. For the abstraction case, suppose $M
= \lambda \overline{y} : \overline{A}. P$ where $\overline{y} = y_1
\ldots y_p$. If $x \in \overline{y}$ then $M \subst{N}{x} = M$ and there is no variable capture.
Suppose that $x \not\in \overline{y}$ then the capture-permitting substitution gives:
$$M \captsubst{N}{x} = \lambda \overline{y} . P \captsubst{N}{x} \ .$$


By the induction hypothesis there is no variable capture in $P \captsubst{N}{x}$.
Hence variable capture can only happen when for some $i \in 1..p$, the variable $y_i$
occurs freely in $N$ and $x$ occurs freely in $P$. Lemma \ref{lem:ordfreevar} gives:
$$ \ord{y_i} \geq \ord{N} = \ord{x} \ .$$

Since $x \not \in \overline{y}$ and $x$ occurs freely in $P$, $x$ also occurs freely in the safe term
$\lambda \overline{y}. P$ therefore by lemma \ref{lem:ordfreevar} we have:
$$ \ord{x} \geq \ord{\lambda y_1 \ldots y_p . T} \geq 1+ \ord{y_i} > \ord{y_i}$$
which, together with the previous equation, gives a contradiction.
\end{proof}

From now on we will use the standard notation $M\subst{N}{x}$ do denote the substitution of $N$ for $x$ in $M$.
It is understood that, provided that $M$ and $N$ are safe, this substitution
is implemented by the capture-permitting substitution $M\captsubst{N}{x}$.


\begin{lemma}[Substitution preserves safety]
\label{lem:subst_preserve_safety}
If $\Gamma, x \vdash M$ and $\Gamma \vdash N$ then $\Gamma \vdash M[N/x]$.
\end{lemma}
\begin{proof}
An easy proof by an induction on the structure of the safe term $M$.
\end{proof}


It is desirable to have an appropriate notion of reduction for our calculus. However the standard $\beta$-reduction rule is not adequate. Indeed, Safety is not preserved by $\beta$-reduction as the following example shows. Suppose that $x,y,z,y : o$ and $\varphi : (o,o,o)$ then the safe term $(\lambda x y . \varphi x y) z w$ $\beta$-reduces to $(\underline{\lambda y . \varphi z y}) w$ which is unsafe since the underline order-1 subterm  contains a free occurrence of variable $z$ of ground type. However if we perform one more reduction we obtain the safe term
$\varphi z w$. This suggests an alternative notion of reduction that performs simultaneous reduction of consecutive $\beta$-redexes. In order to define this reduction we first introduce an appropriate notion of redex.

In the simply-typed lambda calculus a redex is a term of the form
$(\lambda x . M) N$. In the Safe
lambda calculus, a redex is a succession of several standard redexes:
\begin{definition}[Safe redex]
We call \emph{safe redex} a safe term whose derivation tree has the following form:
$$   \rulef{
            \rulef{\rulef{\vdots}{\Gamma, \overline{x}\vdash M}}{\Gamma \vdash \lambda \overline{x} . M} (\sf{abs})
            \quad
            \rulef{\vdots}{\Gamma \vdash N_1}  \ \ldots \  \rulef{\vdots}{\Gamma \vdash N_l}
    }
    {
       \Gamma \vdash (\lambda \overline{x} . L) N_1 \ldots N_l
    } (\sf{app})
$$
where $\overline{x}$ denotes the list of variables $x_1\ldots x_n$.
\end{definition}

In other words a safe redex is a safe term of the form $(\lambda \overline{x} . M) N_1 \ldots N_l$ such that
the variable $\overline{x}$ are abstracted altogether by one occurrence of the rule $(\sf{abs})$ and the terms $(\lambda \overline{x} . M)$, $N_1$, \ldots, $N_l$ are applied together at once using the $(\sf{app})$ rule
(and consequently each $N_i$ must be safe).



We are now in a position to define a notion of reduction for safe terms.

\begin{definition}[Safe reduction $\beta_s$] \
\label{dfn:safereduction} The following
abbreviations are used $\overline{x} = x_1 \ldots x_n$,
$\overline{N} = N_1 \ldots N_l$, and when $n\geq l$, $\overline{x_L}
= x_1 \ldots x_l$, $\overline{x_R} = x_{l+1} \ldots x_n$.
\begin{itemize}
\item The relation $\beta_s$ is defined on the set of safe redex as follows:
\begin{eqnarray*}
\beta_s &=&
\{  \ (\lambda \overline{x} : \overline{A} . T) N_1 \ldots N_l \mapsto \lambda \overline{x_R}. T\subst{\overline{N}}{\overline{x_L}}  \\
&& \mbox{ where $(\lambda \overline{x} : \overline{A} . T) N_1 \ldots N_l$ is a safe redex such that $n> l$}
\} \\
&\cup&
\{ \ (\lambda \overline{x} : \overline{A} . T) N_1 \ldots N_l \mapsto T\subst{\overline{N}}{\overline{x}} N_{n+1} \ldots N_l  \\
&& \mbox{ where $(\lambda \overline{x} : \overline{A} . T) N_1 \ldots N_l$ is a safe redex such that $n\leq l$}
\} \ .
\end{eqnarray*}

\item
The safe $\beta$-reduction, written $\betasred$, is the closure of
the relation $\beta_s$ by compatibility with the formation rules of
the Safe $\lambda$-Calculus.
\end{itemize}
\end{definition}

\noindent \emph{Remark:} The $\beta_s$-reduction is a multi-step $\beta$-reduction i.e. $\betared \subset \betasred \subset \betaredtr$.


\begin{lemma}[$\beta_s$ reduction preserves safety]
\label{lem:homoh_safered_preserve_safety}
If $\Gamma \vdash s$ and $s \betasred t$ then $t$ is safe.
\end{lemma}

\begin{proof}
It suffices to show that the relation $\beta_s$ preserves safety.
Consider the safe-redex $ s \equiv (\lambda x_1 \ldots x_n . M) N_1 \ldots N_l $ such that
$s\ \beta_s\ t$ for some simply-typed term $t$.
Without lose of generality we can assume that the last rule used to form the term $s$ is {\sf(app)} i.e. not the weakening rule
{\sf(wk)}. Hence we have $\Gamma = fv(s)$.

By lemma \ref{lem:subst_preserve_safety}, $T\subst{\overline{N}}{\overline{x_L}}$ is safe.
By lemma \ref{lem:ordfreevar}, all variables in $\Gamma$ have order greater than $\ord{s} = \ord{t}$. Therefore
if $n>l$ then we can use the {\sf(abs)} rule to form $\Gamma \vdash t \equiv \lambda \overline{x_R}. T\subst{\overline{N}}{\overline{x_L}}$
and if $n \leq l$ we can use the {\sf(app)} rule to form $\Gamma \vdash t \equiv  T\subst{\overline{N}}{\overline{x}} N_{n+1} \ldots N_l$.
\end{proof}


\subsection{Safe $\lambda$-calculus and Safe Higher-order grammars}
It is possible to show equivalence of the $\lambda$-calculus formulation of Safety and the
safety restriction for higher-order grammars from \cite{KNU02}.
\begin{definition}[Higher-order grammar]
A \emph{higher-order grammar} is a tuple $G =
\langle \Sigma, \mathcal{N}, V, \mathcal{R}, S \rangle$, where
\begin{itemize}
\item $\Sigma$ is a ranked alphabet of terminals of order at most 1,
\item $V$ is a finite set of typed variables,
\item $\mathcal{N}$ is a finite set of non-terminals,
\item $S$ a distinguished symbol of $\mathcal{N}$ of ground type, called the start symbol,
\item $\mathcal{R}$ is a finite set of production rules, one for each $F : (A_1, \ldots, A_n, o) \in N$, of the form
    $$ F z_1 \ldots z_m \rightarrow e$$
where $z_i$ is a variable of type $A_i$ and $e$ is an applicative
term of type $o$ in $\mathcal{N}(\Sigma \union \mathcal{N} \union
\{z_1 \ldots z_m \} )$. The $z_i$s are called the \emph{parameters}
of the rule.
\end{itemize}
\end{definition}
The order of a rewrite rule is the order of the non-terminal symbol
appearing on the left hand side of the rule. The order of a grammar
is the highest order of its non-terminals.
The grammar is homogenous if the non-terminals in $\mathcal{N}$ have all homogeneous types.


The original notion of safety introduced in \cite{KNU02} is defined as follows:
\begin{definition}[Safe higher-order grammars]
  A rewrite rule $F z_1 \ldots z_m \rightarrow e$ is said to be \emph{unsafe} if $e$ has a subterm $t$ such that:
  \begin{enumerate}
    \item $t$ occurs in an operand position in $e$,
    \item $t$ is of order $k>0$,
    \item $t$ contains a parameter of order strictly less than $k$.
  \end{enumerate}
An homogeneous grammar is \emph{safe} if all its production rules are safe.
\end{definition}


The equivalence of this definition of Safety and the formulation via the Homogeneous $\lambda$-calculus is shown in \cite{demirandathesis}:
\begin{proposition} Let $G = \langle \Sigma, \mathcal{N}, V, \mathcal{R}, S \rangle$ be a grammar.
A rule $F z_1 \ldots z_m \rightarrow e$ in $\mathcal{R}$ is safe if and only if
$ z_1 \ldots z_m \vdash r : o$
is a valid typing judgement (without abstraction) of the \emph{homogeneous} Safe $\lambda$-calculus.
\end{proposition}


The reader is referred to \cite{KNU02,demirandathesis,safety-mirlong2004}
for details about the safety restriction for higher-order grammars.









\section{Computation tree and traversals}
\label{sec:correspondence}

In this section we introduce the notion of computation tree of a term and
define traversals over the computation tree. These two notions were firstly introduced in \cite{OngLics2006}. Here they
are adapted to the context of the $\lambda$-calculus.

We then state the \emph{Correspondence Theorem} (theorem \ref{thm:correspondence}) which is the counterpart of the ``Path-Traversal Correspondence''
of \cite{OngLics2006}. We will make use of this result in the next section in order to obtain
a game-semantic characterisation of the Safe $\lambda$-Calculus.

In the following, we work in the general setting of the simply-typed
$\lambda$-calculus extended with a fixed set $\Sigma$ of
higher-order constants.


\subsection{$\eta$-long normal form and computation tree}

The $\eta$-long normal form appeared in
\cite{DBLP:journals/tcs/JensenP76} and
\cite{DBLP:journals/tcs/Huet75} under the names \emph{long reduced
form} and \emph{$\eta$-normal form} respectively. It was then
investigated in \cite{huet76} under the name \emph{extensional
form}. The $\eta$-normal form of a term is obtained by hereditarily $\eta$-expanding every
subterm occurring at an operand position.

\begin{definition}[$\eta$-long normal form]
A simply-typed term is either an abstraction or it can be written uniquely as
$s_0 s_1 \ldots s_m$ where $m\geq0$ and $s_0$ is a variable, a $\Sigma$-constant or an abstraction.
The $\eta$-long normal form of $M$, written $\aux{M}$ or sometimes $\etanf{M}$,
is defined as follows:
\begin{align*}
\aux{\lambda x . s } &= \lambda x . \aux{s} \\
\aux{\alpha s_1 \ldots s_m : (A_1,\ldots,A_n,o)} &= \lambda \overline{\varphi} . \alpha \aux{s_1}\ldots \aux{s_m} \aux{\varphi_1} \ldots \aux{\varphi_n} \\
& \mbox{with $m,n\geq0$}\\
\aux{(\lambda x . s) s_1 \ldots s_m : (A_1,\ldots,A_n,o) } &= \lambda \overline{\varphi} . (\lambda x . \aux{s}) \aux{s_1} \ldots \aux{s_m} \aux{\varphi_1} \ldots \aux{\varphi_n} \\
& \mbox{with $m\geq 1,n\geq0$}
\end{align*}
where $x$ and each $\varphi_i : A_i$ are variables and $\alpha$ is
either a variable or a constant.
\end{definition}

\begin{remark}
\begin{itemize}
\item For $n=0$, the first clause in the definition becomes:
$\aux{x s_1 \ldots s_m : o} = \lambda . x \aux{s_1} \aux{s_2} \ldots \aux{s_m}.$
The \textsl{dummy lambda} $\lambda .$ is kept deliberately as it will play an important role in the
game-semantic correspondence.

\item A term in $\eta$-normal form is either an abstraction or it is of ground type and can be written uniquely as
$s_0 s_1 \ldots s_m : 0$ where $m\geq0$,  $s_0$ is a variable, a constant or an abstraction and each of the $s_j$ for $j\in 1..m$ is in $\eta$-normal form.

\item Converting a term to its $\eta$-long normal form does not introduce new redex and therefore
the $\eta$-long normal form of $\beta$-normal term is a $\beta$-normal term.
\end{itemize}
\end{remark}

Computation trees were proposed in \cite{OngHoMchecking2006} for the purpose of studying the infinite tree structures
generated by higher-order grammars. The computation tree of a grammar is defined as the unravelling of a finite graph representing the long transform of a grammar. Converting this to the context of the $\lambda$-calculus, we define the computation tree of a $\lambda$-term to be the abstract syntax tree of its $\eta$-long normal form.

\emph{Notation for labelled-trees:} We write $[l](t_1, \ldots, t_n)$ to denote the tree with a root labelled $l$ and with $n$ children subtrees $t_1$, \ldots, $t_n$. We write $[l]$ for the single node tree labelled $l$. If $t = [l](t')$, i.e. the root has a single child, then $t^-$ denotes the tree $t'$ (the tree obtained after deleting the root).

\begin{definition}[Computation tree]
Let $L$ be the following set of node labels:
$$ L = \Sigma \union \{ @ \} \union \{ x : x \mbox { is a variable} \}
\union \{ \lambda \overline{x} : \overline{x} = x_1 \ldots x_n \mbox { is a list of variables.} \}
  $$

For terms in $\eta$-normal form, we define the $L$-labelled tree $\tau$ as follows:
\begin{eqnarray*}
  \mbox{for $n\geq0$, } \tau(\lambda x_1 \ldots x_n . s) &=& [\lambda x_1 \ldots x_n](\tau(s)^{-}) \\
  \mbox{for $m\geq0$, } \tau( \alpha s_1 \ldots s_m : o) &=& [ \lambda ]([\alpha](\tau(s_1),\ldots,\tau(s_m)))\\
  \mbox{for $m \geq 1$, } \tau((\lambda x.s_0) s_1 \ldots s_m :o) &=& [\lambda] ([@](\tau(\lambda x.s),\tau(s_1),\ldots,\tau(s_m))) )
\end{eqnarray*}
where $s$ is not an abstraction and $\alpha$ is a variable or a constant.

The \emph{computation tree} of a simply-typed term $M$, written $\tau(M)$, is defined as $\tau(\etanf{M})$.
\end{definition}

The nodes occurring at odd levels are the $\lambda$-nodes which represent several consecutive variable abstractions.
At odd levels, there are the application nodes labelled @ and the variable and constant nodes labelled by some constant or variable $\alpha$.

We say that a node $n$ is bound by the node $m$, and $m$ is called the
\defname{binder} of $n$, if $m$ is the closest node in the path from $n$ to
the root of the tree such that $m$ is labelled $\lambda
\overline{\xi}$ with $x\in \overline{\xi}$.


Suppose that a term $M$ has been fixed, then we abbreviate $\tau(M)$ into $\tau$  and we write
$N$ for the set of nodes of $\tau$, $N_\Sigma$ for the set of $\Sigma$-labelled nodes,
$N_@$ for the set of @-labelled nodes, $N_{var}$ for the set of variable nodes and
$N_{fv}$ for the subset of $N_{var}$ constituted of free-variable nodes.


Clearly, each subtree of the computation tree $\tau(M)$ represents a subterm of $\aux{M}$.
There is a function $\kappa$ defined on $N$ that maps each node $n \in N$ to the subterm of $\aux{M}$ corresponding to the subtree of $\tau(M)$ rooted at $n$.
In particular if $\tau(M) = [r](\ldots)$ then we have $\kappa(r) = \aux{M}$.

The \defname{order} function $\textsf{ord}$ is defined on nodes as follows:
\begin{align*}
    \ord{\lambda \overline{\xi}} &=
\left\{
  \begin{array}{ll}
    1 +  \max_{z\in \overline{\xi}\union fv(M)} \ord{z}, & \hbox{if $\lambda \overline{\xi}$ is the root of $\tau(M)$;} \\
    1 + \max_{z\in \overline{\xi}} \ord{z}, & \hbox{elsewhere;}
  \end{array}
\right. \\
    \ord{\alpha:T} &= \ord{T}, \quad \hbox{where $\alpha$ is a variable or constant of type $T$;} \\
    \ord{@} &= 0 \ .
\end{align*}

\subsection{Pointers and justified sequence of nodes}

We define the \defname{enabling relation} $\vdash$ on the set of nodes of the
computation tree. We write $m \vdash n$ and we say that $m$ enables
$n$ if and only if
\begin{itemize}
\item $n$ is a bound variable node and $m$ is the binder of $n$,
\item or $n$ is a free variable node and $r$ is the root of the computation tree,
\item or $n$ is a $\lambda$-node and $m$ is the parent node of $n$.
\end{itemize}

We call \defname{input-variable} a variable that is hereditarily justified by the root of the computation tree.
Free variables and variables bound by the root are example of input-variables.

A \defname{justified sequence of nodes} is a sequence of
nodes with pointers such that each variable node $n$ lambda-node $n$ different from the root
has a pointer to a node $m$ occurring before it the sequence such that $m \vdash n$.
We represent the pointer in the sequence as follows \raisebox{0cm}[0.6cm]{$\rnode{m}{m} \cdot \ldots \cdot \rnode{n}{n} \bkptr[nodesep=1pt]{35}{n}{m}$}.

A pointer is sometime labeled with an index $i$: if $m$ is a
$\lambda$-node then it indicates that $n$ is labelled with the $i$th
variable abstracted in $m$; otherwise it indicates that $n$ is the
$i$th child of $m$. A pointer in a justified sequence of nodes has
therefore one of the following forms: \vspace{2pt}
$$
\rnode{m}{r} \cdot \ldots \cdot \rnode{n}{z} \bkptr[nodesep=1pt]{40}{n}{m}
\hspace{1.5cm}
\rnode{m}{\lambda \overline{\xi}} \cdot \ldots \cdot \rnode{n}{\xi_i} \bkptr[nodesep=1pt]{40}{n}{m} \bklabel{i}
\hspace{1.5cm}
\rnode{m}{@ } \cdot \ldots \cdot \rnode{n}{\lambda \overline{\eta}} \bkptr[nodesep=1pt]{40}{n}{m} \bklabel{j}
\hspace{1.5cm}
\rnode{m}{\alpha } \cdot \ldots \cdot \rnode{n}{\lambda \overline{\eta}} \bkptr[nodesep=1pt]{40}{n}{m} \bklabel{k}
$$
where $r$ denotes the root of $\tau(M)$, $z \in N_{fv}$, $\xi_1,
\ldots \xi_n$ are bound variables, $\alpha \in N_{\Sigma} \union
N_{var}$, $i \in 1..n$, $j$ ranges from $0$ to the number of
children nodes of @ minus 1 and $k \in 1 ..arity(\alpha)$.

We use the following numbering conventions: the first child of a @-node is numbered $0$,
the first child of a variable or constant node is numbered $1$ and variables in $\overline{\xi}$ are numbered from $1$ onward ($\overline{\xi} = \xi_1, \ldots \xi_n$).

We use the notation $n.i$ to denote the $i$th child of node $n$.
We write $s = t$ to denote that the justified sequences $t$ and $s$
have same nodes \emph{and} pointers.

We say that a node $n_0$ of a justified sequence is hereditarily justified by $n_p$ if there are nodes $n_1, n_2, \ldots n_{p-1}$ in
the sequence such that for all $i\in 0..p-1$, $n_i$ points to $n_{i+1}$.

If $N$ is a set of nodes and $s$ a justified sequence of nodes then
we write $s \upharpoonright N$ to denote the subsequence of $s$
obtained by keeping only the nodes that are hereditarily
justified by nodes in $N$. This subsequence is also a justified
sequence of nodes. If $n$ denotes a node of $\tau(M)$ we
abbreviate $s \upharpoonright \{ n \}$ into $ s\upharpoonright n$.

The notions of P-view and O-view of justified sequences of nodes
are defined the same way as their game-semantic counterparts for justified sequences of moves.
\begin{definition}[P-view]
The P-view of a justified sequence of nodes $t$ of $\tau$, written $\pview{t}$, is defined as follows: \footnote{
The equalities in the definition determine pointers implicitly. For instance in the second clause, if in the
left-hand side, $n$ points to some node in $s$ that is also present
in $\pview{s}$ then in the right-hand side, $n$ points to this
occurrence of the node in $\pview{s}$.}
\begin{align*}
\pview{\epsilon} &=  \epsilon
& \pview{s \cdot n }  &=  \pview{s} \cdot n  \\
\pview{s \cdot \rnode{m}{m} \cdot \ldots \cdot \rnode{lmd}{\lambda \overline{\xi}}} &= \pview{s} \cdot \rnode{m2}{m} \cdot \rnode{lmd2}{\lambda \overline{\xi}}   \bkptr[nodesep=1pt]{30}{lmd}{m}    \bkptr[nodesep=1pt]{60}{lmd2}{m2}
& \pview{s \cdot r }  &=  r
\end{align*}
where $r$ is the root of the tree $\tau$ and $n$ ranges over
non-lambda nodes (i.e. $N_\Sigma \union N_@ \union N_{var}$).
\end{definition}

The O-view is defined to be the dual notion of P-view.
We borrow the game semantic terminology to qualify justified sequences of nodes:
$s$ satisfies \emph{alternation} if for any two consecutive nodes in $s$, one is a $\lambda$-node
and the other is not and \emph{P-visibility} if every variable node in $s$ points to a node occurring in the P-view a that point.

\subsection{Adding value-leaves to the computation tree}
\label{sec:adding_value_leaves}

We now add \defname{value-leaves} to the computation tree. Each
value-leaf corresponds to a possible value of the base type $o$.
We write $\mathcal{D}$ to denote the set of values of the base type
$o$. The values leaves are added as follows: every
node $n \in \tau(M)$ has a child leaf denoted by $v_n$ for each possible value $v \in \mathcal{D}$.

Everything that we have defined for computation tree can be lifted
to this new version of computation tree. The node order of a
value-leaf is defined to be $0$. The enabling relation $\vdash$ is
extended so that every leaf is enabled by its parent node. The
definition of justified sequence does not change.
When representing a link in a justified sequence going from a value-leaf $v_n$ to a node $n$,
we label the link with $v$:
$$
\rnode{n}{n} \cdot \ldots \cdot \rnode{vn}{v_n} \bkptr[nodesep=1pt]{40}{vn}{n} \bklabel{v}
$$

For the definition of P-view, O-view and visibility, value-leaves are treated as
$\lambda$-nodes if they are at odd level in the computation tree and
as variable nodes if there at a even level.

If there is an occurrence of a value-leaf $v_n$ in the sequence that points to $n$ we say that
$n$ is \emph{matched} by $v_n$. If there is no value-leaf in the sequence that points to $n$ we
say that $n$ is an \emph{unmatched node}.
The last unmatched node is called the \emph{pending node}.
A justified sequence of nodes is \emph{well-bracketed} if each value-leaf in the traversal points to the pending node at that point.

If $t$ is a traversal then we write $?(t)$ to denote the subsequence of $t$ consisting only of unmatched nodes.

\subsection{Traversal of the computation tree}
\label{subsec:traversal}

A \emph{traversal} is a justified sequence of nodes of the computation tree where each node
indicates a step that is taken during the evaluation of the term.
For computation tree of simply-typed $\lambda$-terms without interpreted constants,
traversals are defined as follows:
\begin{definition}[Traversals]
\label{def:traversal}
We define the set $\travset(M)$ of traversals over a computation tree $\tau(M)$ by induction
over the following rules.

\noindent $\mathbf (\epsilon)$ The empty sequence $\epsilon$ is a traversal.

\noindent {\bf (Root)} The length 1 sequence constituted of the root of $\tau(M)$ is a traversal.

\noindent {\bf (Lam)} If $t \cdot \lambda \overline{\xi}$ is a traversal then so is
$t \cdot \lambda \overline{\xi} \cdot n$
where $n$ is the only child of $\lambda \overline{\xi}$ and $n$ points to the only occurrence of its enabler in $t$ that is still present in $\pview{t \cdot \lambda \overline{\xi}}$.

\noindent {\bf (App)} If $t \cdot @$ is a traversal then so is $t \cdot \rnode{m}{@} \cdot \rnode{n}{n} \bkptr[nodesep=1pt]{60}{n}{m} \bklabelc{0}$.

\noindent {\bf (InputVar$^0$)} If $t = t_1 \cdot x \cdot t_2$ is a traversal where
$x$ is the pending node in $t$ (i.e. $?(t_2)=\epsilon$)
and $x$ is a ground-type input-variable then for any $v \in \mathcal{D}$,
\raisebox{0cm}[0.6cm]{$t_1 \cdot \rnode{x}{x} \cdot t_2 \cdot \rnode{xv}{v_x}
\bkptr[nodesep=1pt]{40}{xv}{x} \bklabelc{v}$} is also a traversal.

\noindent {\bf (InputVar$^{\geq 1}$)} If $t = t_1 \cdot x \cdot t_2$ is a traversal where
$x$ is the pending node in $t$ (i.e. $?(t_2)=\epsilon$)
and $x$ is a higher-order input-variable then
for $1 \leq i \leq arity(x)$,
\raisebox{0cm}[0.6cm]{$t_1 \cdot \rnode{m}{x} \cdot t_2 \cdot
\rnode{n}{n} \bkptr[nodesep=1pt]{40}{n}{m} \bklabelc{i}$} is a traversal.

Moreover for any $v\in \mathcal{D}$ the sequence \raisebox{0cm}[0.6cm]{$t_1 \cdot \rnode{x}{x} \cdot t_2 \cdot
\rnode{xv}{v_x} \bkptr[nodesep=1pt]{40}{xv}{x} \bklabelc{v}$} is also a traversal.

\noindent {\bf (CCAnswer-@)}
  If $t \cdot \rnode{app}{@} \cdot \rnode{lz}{\lambda \overline{z}}  \ldots  \rnode{lzv}{v_{\lambda \overline{z}}}
              \bkptr[nodesep=1pt]{30}{lzv}{lz} \bklabelc{v}
              \bkptr[nodesep=1pt]{40}{lz}{app} \bklabelc{0}$
              is a traversal then so is
              \raisebox{0cm}[0.6cm]{$t \cdot \rnode{app}{@} \cdot \rnode{lz}{\lambda \overline{z}}  \ldots  \rnode{lzv}{v_{\lambda \overline{z}}} \cdot \rnode{appv}{v_@}
              \bkptr[nodesep=1pt]{25}{lzv}{lz} \bklabelc{v}
              \bkptr[nodesep=1pt]{40}{lz}{app} \bklabelc{0}
              \bkptr[nodesep=1pt]{25}{appv}{app} \bklabelc{v}$}.

\noindent {\bf (CCAnswer-$\lambda$)} If \raisebox{0cm}[0.5cm]{$t \cdot \lambda \overline{\xi} \cdot \rnode{x}{x}  \ldots   \rnode{xv}{v_x}
              \bkptr[nodesep=1pt]{30}{xv}{x} \bklabelc{v}$}
              is a traversal then so is
              \raisebox{0cm}[0.6cm]{$t \cdot \rnode{lmd}{\lambda \overline{\xi}} \cdot \rnode{x}{x}  \ldots  \rnode{xv}{v_x} \cdot
              \rnode{lmdv}{v_{\lambda \overline{\xi}}}
              \bkptr[nodesep=1pt]{20}{xv}{x} \bklabelc{v}
                \bkptr[nodesep=1pt]{20}{lmdv}{lmd} \bklabelc{v}$}.

\noindent {\bf (CCAnswer-var)} If \raisebox{0cm}[0.5cm]{$t \cdot y \cdot \rnode{lmd}{\lambda \overline{\xi}}
                   \ldots \rnode{lmdv}{v_{\lambda \overline{\xi}}} \bkptr[nodesep=1pt]{30}{lmdv}{lmd} \bklabelc{v}$} is a traversal,
                   where $y$ is a non input-variable node, then so is
        \raisebox{0cm}[0.8cm]{$t \cdot \rnode{y}{y}
            \cdot \rnode{lmd}{\lambda \overline{\xi}}
             \ldots
             \rnode{lmdv}{v_{\lambda \overline{\xi}}}
            \cdot \rnode{yv}{v_y}
                \bkptr[nodesep=3pt]{25}{yv}{y} \bklabelc{v}
                \bkptr[nodesep=1pt]{25}{lmdv}{lmd} \bklabelc{v}$}.

\noindent {\bf (Var)}
If  \raisebox{0cm}[0.5cm]{$t' \cdot \rnode{n}{n} \cdot
    \rnode{lx}{\lambda \overline{x}}  \ldots
    \rnode{x}{x_i}  \bkptr[ncurv=0.6]{50}{x}{lx} \bklabel{i}$} is a traversal where $x_i$ is not an input-variable then so is
\raisebox{0cm}[0.6cm]{
    $t' \cdot \rnode{n}{n} \cdot
    \rnode{lx}{\lambda \overline{x}}  \ldots
    \rnode{x}{x_i} \cdot
    \rnode{letai}{\lambda \overline{\eta_i}}
    \bkptr[ncurv=0.45]{45}{letai}{n} \bklabelc{i}
    \bkptr[ncurv=0.5]{45}{x}{lx} \bklabelc{i}$}.

This rule permits to visit the node corresponding to the subterm that would be substituted
for $x_i$ if all the $\beta$-redexes occurring in $M$ were reduced.

Note that a traversal always starts with the root of the tree.
\end{definition}

\begin{remark}
Our notions of computation tree and traversal differ slightly from \cite{OngLics2006}.
Firstly, in our setting, there is no special treatment for uninterpreted constants since we can just regard them as free variables. Consequently, there is no restriction on the order of these constants. This differs with \cite{OngLics2006} which deals with computations generating tree structures and therefore requires the order of higher-order constants to be at most $1$.
Secondly our computation trees have value-leaves that can be visited by the traversals using the copy-cat rules.
\end{remark}

\begin{example}
The sequence $ \lambda \cdot
\rnode{app}{@}  \cdot
\rnode{ly}{\lambda y} \cdot \ldots \cdot
\rnode{y}{y} \cdot
\rnode{lx}{\lambda \overline{x}} \cdot \ldots \cdot
\rnode{x}{x_i} \cdot
\rnode{leta}{\lambda \overline{\eta_i} } \cdot \ldots
\bkptr[ncurv=0.6,nodesep=0]{40}{x}{lx}  \bklabel{i}
\bkptr[ncurv=0.5]{50}{leta}{y}  \bklabel{i}
\bkptr[ncurv=0.6,nodesep=0]{40}{y}{ly}  \bklabel{1}
\bkptr[ncurv=0.5]{50}{lx}{app}  \bklabel{1}$ is a traversal of the following computation tree:
$$\tree{\lambda} {
    \tree{@}
    {
        \pstree[linestyle=dotted]{\TR{\lambda y}\treelabel{0} }
        {
            \tree{y}
            {
                \tree{\lambda \overline{\eta_1}}{\vdots} \treelabel{1}
                \TR[edge=\dotedge]{}
                \tree{\lambda \overline{\eta_i}}{\vdots}\treelabel{i}
                \TR[edge=\dotedge]{}
                \tree{\lambda \overline{\eta_n}}{\vdots}\treelabel{n}
            }
        }
        \pstree[linestyle=dotted]{\TR{\lambda \overline{x}}\treelabel{1}}{ \tree{x_i}{\TR{} \TR{} } }
    }
}
$$
\end{example}

\begin{proposition}
\label{prop:pviewtrav_is_path}
Let $t$ be a traversal. Then:
\begin{itemize}
\item[(i)] $t$ is a well-defined and well-bracketed justified sequence;
\item[(ii)] $?(t)$ is a well-defined justified sequence verifying alternation, P-visibility and O-visibility;
\item[(iii)] $\pview{?(t)}$ is a path in the computation tree going from the root to the last node in $?(t)$.
\end{itemize}
\end{proposition}
This is the counterpart of proposition 6 from
\cite{OngHoMchecking2006} which is proved by induction on the
traversal rules.

The \defname{reduction} of a traversal $t$ is defined as $s = t \upharpoonright r$
where $r$ is the root of the computation tree.

\begin{lemma}[View of a traversal reduction]
\label{lem:redtrav_trav} Let $M$ be a term in $\beta$-normal form,
$r$ be the root of $\tau(M)$ and $t$ be a traversal of $\tau(M)$. We
have
\begin{itemize}
\item[(i)] $ \pview{?(t) \upharpoonright  r } = \pview{?(t)} \upharpoonright r$;
\item[(ii)] if the last node in $t$ is hereditarily justified by $r$ then $ \oview{?(t) \upharpoonright r } = \oview{?(t)}$.
\end{itemize}
\end{lemma}
The proof is by an easy induction.


\section{Correspondence between traversals and Game semantics}
\label{sec:assumptions}


Let us consider the general setting of an applied simply-typed $\lambda$-calculus with a set of higher-order constants $\Sigma$. The operational semantics of these constants is given by certain reduction rules.
We assume that a fully abstract model of the calculus is provided by mean of a category of well-bracketed games.
A strategy will be represented by a prefix-closed set instead of an ``even length
prefix''-closed set. In practice this means that we replace the set
of plays $\sigma$ by $\sigma \union \textsf{dom}(\sigma)$. This
permits to avoid considerations on the parity of the length of
traversals when we show the correspondence between traversals and
game semantics. We write $\sem{\Gamma \vdash M : A}$ for the strategy denoting the simply-typed term
$\Gamma \vdash M : A$ and $\prefset(S)$ to denote the
prefix-closure of the set $S$.


The main result that we will prove in this section is called the
\emph{Correspondence Theorem} (theorem \ref{thm:correspondence}). It
states that traversals over the computation tree are just
representations of the uncovering of plays in the
strategy-denotation of the term. Hence there is an isomorphism
between the strategy denotation of a term and its revealed game
denotation (i.e. its strategy denotation where internal moves are
not hidden after composition). This theorem permits us to explore
the effect that a given syntactic restriction has on the strategy
denotating a term.

To really make use of the Correspondence Theorem, it will be
necessary to restate it in the standard game-semantic framework in
which internal moves are hidden. For that purpose, we will define a
\emph{reduction} operation on traversals responsible of eliminating
the ``internal nodes'' of the computation. This leads to a
correspondence between the standard game denotation of a term and
the set of reductions of traversals over its computation tree.
Fortunately, the reduction process preserves the good properties of
traversals. This is guaranteed by the facts that the P-view of the
reduction of a traversal is equal to the reduction of the P-view of
the traversal, and the O-view of a traversal is the same as the
O-view of its reduction (lemma \ref{lem:redtrav_trav}). \vspace{8pt}


\subsection{Relationship between computation trees and arenas}

\subsubsection{Example}
Consider the following term $M \equiv \lambda f z . (\lambda g x . f (f x)) (\lambda y. y) z$ of type $(o \typear o) \typear o \typear o$.
Its $\eta$-long normal form is $\lambda f z . (\lambda g x . f (f x)) (\lambda y. y) (\lambda .z)$.

\newlength{\yNull}
\def\bow{\quad\psarc{->}(0,\yNull){1.5ex}{90}{270}}

The figure below represents the computation tree (left) and the
arena (right). The dashed line defines a partial function $\varphi$
from the set of nodes in the computation tree to the set of moves.
For simplicity, we now omit answers moves when representing arenas.
$$
\tree{ \Rnode{root} {\lambda f z w}^{[1]} }
     {  \tree{@^{[2]}}
        {   \tree{\lambda g x ^{[3]}}
                { \tree{\Rnode{f}{f^{[6]}}}{  \tree{\Rnode{lmd}\lambda^{[7]}}{ \tree{\Rnode{f2}{f^{[8]}}} {\tree{\Rnode{lmd2}\lambda^{[9]}}{\TR{x^{[10]}}}}}  }
                }
            \tree{\lambda y ^{[4]}}{\TR{y}}
            \tree{\lambda ^{[5]}}{\TR{\Rnode{z}z}}
        }
    }
\hspace{3cm}
  \tree[levelsep=11ex]{ \Rnode{q1}q^1 }
    {   \pstree[levelsep=4ex]{\TR{\Rnode{q3}q^3}}{\TR{\Rnode{q4}q^4}}
        \TR{\Rnode{q2}q^2}
        \TR{\Rnode{q5}q^5}
    }
\psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
\ncline{->}{root}{q1} \aput*{:U}{\varphi}
\ncarc{->}{z}{q2}
\ncline{->}{f}{q3}
\ncline{->}{lmd}{q4}
\ncline{->}{f2}{q3}
\ncline{->}{lmd2}{q4}
$$

\raisebox{0cm}[0.6cm]{$t = \rnode{q1}{\lambda f
z} \cdot \rnode{n2}{@^{[2]}} \cdot \rnode{n3}{\lambda g x^{[3]}}
\cdot \rnode{q3}{f}^{[6]} \cdot \rnode{q4}{\lambda^{[7]}} \cdot
\rnode{q3b}{f}^{[8]} \cdot \rnode{q4b}{\lambda^{[9]}} \cdot
\rnode{n8}{x^{[10]}} \cdot \rnode{n9}{\lambda^{[5]}} \cdot
\rnode{q2}{z} \bkptr[ncurv=0.6]{60}{q3}{q1}
\bkptr[ncurv=1]{60}{q4}{q3} \bkptr[ncurv=0.4]{75}{q3b}{q1}
\bkptr[ncurv=0.8]{70}{q4b}{q3b} \bkptr[ncurv=0.4]{70}{q2}{q1}
\bkptr[ncurv=0.4]{60}{n3}{n2} \bkptr[ncurv=0.4]{60}{n8}{n3}
\bkptr[ncurv=0.4]{60}{n9}{n2}$} is a traversal of the tree. Its
reduction is \raisebox{0cm}[0.8cm]{$\rnode{q1}{\lambda f z} \cdot
\rnode{q3}{f}^{[6]} \cdot \rnode{q4}{\lambda^{[7]}} \cdot
\rnode{q3b}{f}^{[8]} \cdot \rnode{q4b}{\lambda^{[9]}} \cdot
\rnode{q2}{z} \bkptr[ncurv=1]{60}{q3}{q1} \bkptr[ncurv=1]{60}{q4}{q3} \bkptr[ncurv=0.5]{75}{q3b}{q1} \bkptr[ncurv=1]{50}{q4b}{q3b}
\bkptr[ncurv=0.4]{80}{q2}{q1}$}
which is mapped by $\varphi$ to the play
\raisebox{0cm}[0.6cm]{$\rnode{q1}{q}^1\ \rnode{q3}{q}^3\ \rnode{q4}{q}^4\ \rnode{q3b}{q}^3\ \rnode{q4b}{q}^4\ \rnode{q2}{q}^2
\bkptr[offset=-3pt]{60}{q3}{q1}
\bkptr[offset=-3pt,ncurv=0.5]{60}{q3b}{q1}
\bkptr[offset=-3pt]{60}{q4}{q3}
\bkptr[offset=-3pt]{60}{q4b}{q3b}
\bkptr[offset=-3pt,ncurv=0.5]{60}{q2}{q1}
\in \sem{M}$}.

This examples shows that we can map nodes of the computation tree to question moves of the game arena.
We now give a formal definition of this mapping.

\subsubsection{Formal definition}

Let $\Gamma \vdash M : A$ be a term in $\eta$-long normal form. The computation tree $\tau(M)$
is represented by a pair $(V,E)$ where $V$ is the set of vertices of
the trees and $E$ is the edges relation. $V = N \union L$ where $N$
is the set of nodes and $L$ is the set of value-leaves.

The relation $E \subseteq V \times V$ gives the parent-child relation on the vertices of the tree.
$E = E_n \union E_l$ where $E_n \subseteq N \times N$ gives the node-node parent relation and $E_l \subseteq N \times L$ gives the node-leaf parent relation.
We write $L_\$$ for $E_l(N_\$)$
and $V_\$$  for $N_\$ \union L_\$$ where $\$$ ranges over $\{@, var, \Sigma, fv \}$.


Let $\mathcal{D}$ be the set of values of the base type $o$. If $n$
is a node in $N$ then the value-leaves in
$E_l(n)$ attached to the node $n$ are written $v_n$ where $v$ ranges in $\mathcal{D}$.
Similarly, if $q$ is a question in $\sem{A}$ then the answer moves
enabled by $q$ are written $v_q$ where $v$ ranges in $\mathcal{D}$.

If $A$ is an arena and $q$ is a move in $A$ then we write $A_q$ to
denote the subarena of $A$ rooted at $q$.

\begin{definition}[Relation between the arena and the computation tree]
\label{def:phi_procedure}
We consider the computation tree of a simply-typed-term.
For any arena $A$, we define a function $f_A(n,q)$ taking two parameters:
a node $n$ of the computation tree and a question move $q$ of the arena $A$
such that $q$ and $n$ have the same type.
$f_A(n,q)$ returns a partial function from $V$ to $A$. It is defined as follows:

\noindent {\bf case 1} If $n$ is labelled $\lambda$ or is a ground type variable node then
        $$f_A(n,q) = \{ n \mapsto q \} \quad \union \quad  \{ v_n \mapsto v_q \ | \ v \in \mathcal{D} \}$$

\noindent {\bf case 2} If $n$ is a $\lambda$-node labelled $\lambda \overline{\xi} = \lambda \xi_1 \ldots \xi_p$ with $p\geq 1$ and with a child node
labelled $\alpha$ and $\vdash( q ) = \{ q^1, \ldots, q^m \} \union \{  v_q : v \in \mathcal{D} \} $ then
    $$
    f_A(n,q) =  \{ n \mapsto q \} \quad  \union \quad  \{ v_n \mapsto v_q \ | \ v \in \mathcal{D} \}
                      \quad \union \quad  \Union_{\stackrel{\displaystyle m \in N | n \vdash m}{\displaystyle m \mbox{ labelled } \xi_i}} f_A( m, q^i)
    $$

\noindent {\bf case 3} If $n$ is a variable node $x$ of higher-order type $(A_1,\ldots,A_m,o)$
with children nodes $\lambda \overline{\eta}_1$, \ldots, $\lambda \overline{\eta}_m$ and
$\vdash( q ) = \{ q^1, \ldots, q^m \} \union \{  v_q : v \in \mathcal{D} \} $ then
    $$f_A(n,q) =
         \{ n \mapsto q \} \quad \union\quad \{ v_n \mapsto v_q \ | \ v \in \mathcal{D}   \} \quad\union\quad     \Union_{i=1..m} f_A( \lambda \overline{\eta}_i, q^i) \ .
    $$

Note that $f_A(n,q)$ is a partial function from $V$ to $A$ since it is defined only
on nodes that are hereditarily justified by the root \emph{and} not hereditarily justified by a free variable node.
In other words, $f_A(n,q)$ is undefined on nodes that are hereditarily justified by $N_{fv} \union N_@ \union N_\Sigma$.
\end{definition}

We write $\mathcal{M}_M$ to denote the following disjoint union of arenas:
$$\mathcal{M}_M = \sem{\Gamma \rightarrow T} \quad \uplus \quad  \biguplus_{n \in E_n \relimg{N_@ \union N_\Sigma} } \sem{type(\kappa(n))}.$$

Moves in $\mathcal{M}_M$ are implicitly tagged so it is possible to recover the arena in which they belong.


\begin{definition}[Total mapping from nodes to moves]
Let $\Gamma \vdash M : T$ be a simply-typed term
with $\Gamma = x_1:X_1 \ldots x_p : X_p$.
We write $q_{\sem{\Gamma}}^1$, \ldots, $q_{\sem{\Gamma}}^p$ to denote the initial question moves of the
component $\Gamma$ of the arena $\sem{\Gamma \rightarrow T}$ and $q^0_A$ to denote the single initial question of any arena $A$.
\footnote{Arenas involved in the game semantics of pure simply-typed $\lambda$-calculus have a single root.}
$r$ denotes the root of the computation tree.

We define the total function $\varphi_M : V_\lambda \union V_{var} \rightarrow \mathcal{M}_M$ as follows:
\begin{align*}
\varphi_M =
        f_{\sem{\Gamma \rightarrow T}}(r, q^0_{\sem{\Gamma \rightarrow T}}) \quad
    & \union \quad
    \Union_{n \in N_{fv} | n \mbox{ {\small labelled} } x_i }  f_{\sem{\Gamma \rightarrow T}}(n, q^i_{\sem{\Gamma}} ) \\
    & \union \quad
        \Union_{n \in E_n \relimg{N_@ \union N_\Sigma}}  f_{\sem{type(\kappa(n))}}(n, q^0_{\sem{type(\kappa(n))}} )
\end{align*}
When there is no ambiguity we just write $\varphi$ instead of $\varphi_M$.
\end{definition}

Nodes of $\tau(M)$ are either hereditarily justified by the root, by
a @-node or by a $\Sigma$-node, therefore $\varphi_M$ is totally
defined on $V_\lambda \union V_{var} = V\setminus (V_@ \union
V_\Sigma)$.

\begin{example}
Consider the term $\lambda x . (\lambda g . g x) (\lambda y . y)$ with $x,y:o$ and $g:(o,o)$.
The diagram below represents the computation tree (middle), the arenas
$\sem{(o,o)\rightarrow o}$ (left), $\sem{o \rightarrow o}$ (right), $\sem{o\rightarrow o}$ (rightmost)
and the function $\varphi = f(\lambda x, q_{\lambda x}) \union f(\lambda g, q_{\lambda g}) \union f(\lambda y, q_{\lambda y})$
(dashed-lines).
$$\psset{levelsep=3.5ex}
\pstree{\TR[name=root]{\lambda x}}
{
    \pstree{\TR[name=App]{@}}
    {
            \pstree{\TR[name=lg]{\lambda g}}
                { \pstree{\TR[name=lgg]{g}}{
                        \pstree{\TR[name=lgg1]{\lambda}}
                        { \TR[name=lgg1x]{x}  } } }
            \pstree{\TR[name=ly]{\lambda y}}
                    {\TR[name=lyy]{y}}
    }
}
\rput(5cm,-1cm){
  \pstree{\TR[name=A1lx]{q_{\lambda x}}}
        { \TR[name=A1x]{q_x} }
}
\rput(-6cm,-1.5cm){
    \pstree{\TR[name=A2lg]{q_{\lambda g}}}
    {
        \pstree{\TR[name=A2g]{q_g}}
        {  \TR[name=A2g1]{q_{g_1}}   }
    }}
\rput(2.5cm,-1.5cm){
    \pstree{\TR[name=A3ly]{q_{\lambda y}}}
        { \TR[name=A3y]{q_y}
        }
}
\psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
\ncline{->}{root}{A1lx} \mput*{f(\lambda x, q_{\lambda x})}
\ncarc{->}{lgg1x}{A1x}
\ncline{->}{lg}{A2lg} \mput*{f(\lambda g, q_{\lambda g})}
\ncline{->}{lgg}{A2g}
\ncline{->}{lgg1}{A2g1}
\ncline{->}{ly}{A3ly} \mput*{f(\lambda y, q_{\lambda y})}
\ncline{->}{lyy}{A3y}
$$
\end{example}

\begin{remark}
\begin{itemize}
\item $\varphi$ maps $\lambda$-nodes to O-questions, variable nodes to
P-questions, value-leaves of $\lambda$-nodes to P-answers and
value-leaves of variable nodes to O-answers;
\item $\varphi$ maps nodes of a given order to moves of the same order.
\end{itemize}
\end{remark}
If $t = t_0 t_1 \ldots$ is a justified sequence
of nodes in $V_\lambda \union V_{var}$ then $\varphi(t)$ is defined
to be the sequence of moves $\varphi(t) = \varphi(t_0)\ \varphi(t_1)\  \varphi(t_2) \ldots$
where the pointers of $\varphi(t)$ are defined to be those
of $t$.

%where $?(\varphi(t))$ denotes the set of unanswered questions in the
%justified sequence of moves $\varphi(t)$ and $?(t)$ denotes the set
%of unmatched nodes in the justified sequence of nodes $t$ (see the
%definition in section \ref{sec:adding_value_leaves}).


\subsection{Interaction semantics}
\label{sec:interaction_semantics}

In game semantics, strategy composition is achieved by performing a
CSP-like ``composition + hiding''. If the internal moves are not hidden
then we obtain an alternative semantics called \emph{interaction}
semantics in \cite{DBLP:conf/sas/DimovskiGL05} and \emph{revealed
semantics} in \cite{willgreenlandthesis}.
The \defname{revealed strategy} of a term $\Gamma \vdash M$ is written $\intersem{\Gamma \vdash M}$ and
can be obtained by uncovering the \emph{full-uncovering with respect to $M$} of the internal moves of $\sem{M}$ i.e.
by performing the uncovering algorithm described in part II of \cite{hylandong_pcf} at every @-node of the computation tree.
The standard semantics can be recovered from the interaction semantics by filtering out the internal moves.


\subsection{The correspondence theorem for the pure simply-typed $\lambda$-calculus}

Let us consider the pure simply-typed $\lambda$-calculus without constants ($\Sigma = \emptyset$).\footnote{To handle the case of a $\lambda$-calculus with \emph{uninterpreted} constants, it suffices to
consider constants as being free variables.}
We establish a correspondence between the interaction semantics of a term
and the traversals of its computation tree.

It was necessary to introduce application nodes (labelled @) in order to connect the operator and
the operand of an application in the computation tree. However, application nodes do not play
any role in the computation of the term, and therefore
they can be removed from the traversals.
We write $t-@$ for the sequence of nodes with pointers obtained by
removing from $t$ all @-nodes and value-leaves of a @-node and
replacing any link pointing to an @-node by a link pointing to the immediate predecessor of @ in $t$.
Note that $t-@$ is not necessarily a proper justified sequence of nodes.
We introduce the following notations:
\begin{eqnarray*}
\travset(M)^{-@} &=& \{ t - @ \ | \  t \in \travset(M) \} \\
\travset(M)^{\upharpoonright r} &=& \{ t  \upharpoonright r \ | \  t  \in \travset(M) \}
\end{eqnarray*}
where $r$ denotes the root of $\tau(M)$.

\begin{remark}
The computation tree of a $\beta$-normal term does not contain any @-node, therefore all the nodes are
hereditarily justified by the root and we have $\travset(M)^{-@} \cong \travset(M) \cong  \travset(M)^{\upharpoonright r }$.
\end{remark}

We have the following theorem which establishes a correspondence between the game denotation of a
term and the set of traversals of its computation tree:
\begin{theorem}[The Correspondence Theorem]
\label{thm:correspondence}
\begin{eqnarray*}
 \varphi_M  &:& \travset(M)^{\upharpoonright r} \stackrel{\cong}{\longrightarrow} \sem{\Gamma \vdash M} \\
 \varphi_M  &:& \travset(M)^{-@} \stackrel{\cong}{\longrightarrow} \intersem{\Gamma \vdash M} \ .
\end{eqnarray*}
\end{theorem}

\section{Game-semantic characterisation of the Safe $\lambda$-Calculus}

Safety has been defined as a syntactical constraint. Since Game
Semantics is by essence syntax-independent, it seems difficult at
first sight to characterise Safety in a game-semantic manner.
However, using the Correspondence Theorem, we can interpret plays
of a strategy as sequences of nodes of some AST of the term.
Therefore it is now possible to investigate the impact of the Safety
restriction on Game Semantics.

The main theorem of this section (theorem
\ref{thm:safe_ptr_recoverable}) states that pointers in a play of
the strategy denotation of a term of the Safe $\lambda$-Calculus without interpreted
constants can be uniquely recovered
from the underlying sequence of moves. The proof is in several
steps. We start by introducing the notion of
\emph{incrementally-justified strategies} and prove that for plays
of such strategies, pointers can be reconstructed uniquely from the
underlying sequences of moves. We then introduce the notion of
\emph{incrementally-bound computation trees} and prove that
incremental-binding coincides with incremental-justification
(proposition \ref{prop:incrbound_imp_incrjustified}). Finally, we
show that safe simply-typed terms in $\beta$-normal form have
incrementally-bound computation trees, consequently the pointers in
their game denotation are superfluous.


\begin{definition}[Incrementally-justified strategy]
A strategy $\sigma : A$ is said to be \emph{incrementally-justified}
if for any sequence of moves $s q \in P_A$ where $q$ is a question
move in $M_A$ we have:
\begin{eqnarray*}
s q \in \sigma \wedge |s| \mbox{ even } &\implies& \parbox[t]{8cm}{$q$ points to the last P-move in $\oview{?(s)}$ with order strictly greater than $\ord{q}$;} \\
s q \in \sigma \wedge |s| \mbox{ odd } &\implies&
\parbox[t]{8cm}{$q$  points to the last O-move in $\pview{?(s)}$
with order strictly greater than $\ord{q}$.}
\end{eqnarray*}
\end{definition}

\begin{lemma}
\label{lem:incrjustified_pointers_uniqu_recover} Pointers are
superfluous for incrementally-justified strategies.
\end{lemma}

\begin{example}
Consider the evaluation map $ev : (A^1 \Rightarrow B^2) \times  A^1 \rightarrow B^1$.
The play $s = q_0^{B^1} q_1^{B^2} q_2^{A^1} q_3^{A^2}$ is in $\sem{ev}$. We have $\ord{q_3} = \ord{A}$,
$\ord{q_2} = \ord{A}$, $\ord{q_1} = \max( 1+\ord{A}, \ord{B})$ and
$\ord{q_0} = 1 + \ord{q_1}$. Since the last O-move in $?(\pview{s})= s$
with order strictly greater than $\ord{q_3}$ is $q_1$ and $q_3$ points to $q_0$, $\sem{ev}$ is not incrementally-justified.
\end{example}


In a computation tree a binder node always occurs in the path from
the bound node to the root. We now introduce a class of computation
tree in which binder nodes can be uniquely recovered from the order
of the nodes. We write $[n_1,n_2]$ to denote the path from node
$n_1$ to node $n_2$ if it exists and $]n_1,n_2]$ for the sequence of
nodes obtained by removing $n_1$ from $[n_1,n_2]$.

\begin{definition}[Incrementally-bound computation tree]
A variable node $x$ of a computation tree is said to be
\emph{incrementally-bound} if either:
\begin{enumerate}
\item $x$ is \emph{bound} by the first $\lambda$-node in the path to the root that has
order strictly greater than $\ord{x}$.
\item $x$ is a \emph{free variable} and all the $\lambda$-nodes in the path to the root except the root have order
smaller or equal to $\ord{x}$.
\end{enumerate}
where $r$ denotes the root of the computation tree.

A computation tree is said to be \emph{incrementally-bound} if all
the variable nodes are incrementally-bound.
\end{definition}

\begin{proposition}[Incremental-binding and incremental-justification coincide]
\label{prop:incrbound_imp_incrjustified}
\begin{enumerate}
\item[(i)] A term in $\beta$-normal form with an incrementally-bound computation tree is denoted by an incrementally-justified strategy.
\item[(ii)] Reciprocally, in the pure $\lambda$-calculus ($\Sigma=\emptyset$), if a term is denoted by an incrementally-justified strategy then the computation tree of its $\beta$-normal is incrementally-bound.
\end{enumerate}
\end{proposition}

\parpic[r]{
    \tree{$\lambda x^3$}{\tree{$f^2$}{ \tree{$\lambda y^1$}{ \TR{$x^0$} }}}
}

\begin{example}
Consider the $\beta$-normal term $\lambda
x . f (\lambda y .x)$ where $x,y:o$ and $f:(o,o),o$. The figure on
the right represents the computation tree with the order of each
node in the exponent part. Since node $x$ of order $0$ is not bound
by the order 1 node $\lambda y$, $\tau(M)$ is not
incrementally-bound and by proposition
\ref{prop:incrbound_imp_incrjustified}, $\sem{\lambda x . f (\lambda
y .x)}$ is not incrementally-justified. Similarly we can check that
the denotation of $f (\lambda y .x)$ is not incrementally-justified
whereas $\lambda y. x$ has an incrementally-justified denotation.
Note that incremental-justification is not preserved by application since $\sem{f}$ 
and $\sem{\lambda y. x}$ are both incrementally-justified whereas $\sem{f (\lambda y .x)}$ is not.
\end{example}

\begin{example}
In order to distinguish the terms $M_1 = \lambda f . f
(\lambda x . f (\lambda y .y ))$ and $M_2 = \lambda f . f (\lambda x
. f (\lambda y .x ))$ we have to keep the pointers in the plays of
strategies. However, in the Safe $\lambda$-Calculus then the ambiguity disappears because $M_1$ is
safe whereas $M_2$ is not (in the subterm $f (\lambda y . x)$, the
ground type variable $x$ occurs free in $(\lambda y . x)$ of order $1$).
\end{example}



\begin{lemma}[Safe terms have incrementally-bound computation trees]
\label{lem:safe_imp_incrbound}

(i) If $\Gamma \vdash M$ is a safe simply-typed term then $\tau(M)$ is incrementally-bound ;

(ii) If $M$ is \emph{closed} simply-typed term and $\tau(M)$ is incrementally-bound then the $\eta$-normal form of $M$ is safe.
\end{lemma}
\begin{proof}
(i) Suppose that $M$ is safe. The safety property is preserved after
taking the $\eta$-normal form, therefore $\etanf{M}$ is also safe.
Hence $\tau(M)$ is the tree representation of a safe term.

When applying the abstraction rule in the Safe $\lambda$-Calculus,
the variables in the lowest partition (smallest order) of the
context must all be abstracted together. Moreover in the computation
tree, consecutive abstractions are merged into a single node,
therefore the safety of $\etanf{M}$ implies that for each
$\lambda$-node $\lambda \overline{\xi}$, any variable $x$ occurring
free in $\kappa(\lambda \overline{\xi})$ has order greater or equal
to $\ord{\lambda \overline{\xi}}$. Reciprocally, if a lambda node
$\lambda \overline{\xi}$ binds a variable node $x$ then
$\ord{\lambda \overline{\xi}} = 1+\max_{z\in\overline{\xi}} \ord{z}
> \ord{x}$.

Let $x$ be a bound variable node. In a computation tree, a binder
node always occurs in the path from the bound node to the root,
therefore, according to the previous observation, $x$ must be bound
by the first $\lambda$-node occurring in $[r,x]$ with order strictly
greater than $\ord{x}$. Similarly, let $x$ be a free variable node
in $\tau$ then $x$ is not bound by any of the $\lambda$-nodes
occurring in $[r,x]$. Once again, by the previous observation, all
these $\lambda$-nodes have order smaller than $\ord{x}$. Hence
$\tau$ is incrementally-bound.

(ii) We assume that $M$ is already in $\eta$-normal form. Suppose
$M$ is closed and $\tau(M)$ is incrementally-bound, we prove that
$M$ is safe by induction on its structure: \emph{Base case:} $M =
\lambda \overline{\xi} . \alpha$ for some variable or constant
$\alpha$. This term is obviously safe.

\emph{Step case:} If $M = \lambda \overline{\xi} . N_1 \ldots N_p$.
Let $i$ range over $1..p$. $N_i$ can be written $\lambda
\overline{\eta_i} . N'_i$ where $N'_i$ is not an abstraction. By the
induction hypothesis, $\lambda \overline{\xi} . N_i = \lambda
\overline{\xi} \overline{\eta_i} . N'_i$ is safe. We observe from
the formation rules of Safe $\lambda$-Calculus that the typing
judgment for $\lambda \overline{\xi} \overline{\eta_i} . N'_i$ can
only be derived using the (abs) rule on the term $N'_i$. Hence
$N'_i$ is necessarily safe. Let $z$ be a variable occurring free in
$N'_i$. Since $M$ is closed, $z$ is either bound by $\lambda
\overline{\eta_1}$ or $\lambda \overline{\xi}$. If it is bound by
$\lambda \overline{\xi}$ then because $\tau(M)$ is
incrementally-bound we have $\ord{z} \geq \ord{\lambda
\overline{\eta_1}} = \ord{N_i}$. Hence we can abstract the variables
$\overline{\eta_1}$ using the (abs) rule and we obtain that $N_i$ is
safe.

Because $M$ is in $\eta$-normal form, the application $N_1 \ldots
N_p$ is total (i.e. $N_1$ is a function taking $p-1$ parameters and
it is applied to $p-1$ arguments), therefore since the $N_i$s are
safe, by the (app) rule of the Safe $\lambda$-Calculus $N_1 \ldots
N_p$ is also safe. Finally, using the (abs) rule we conclude that $M
= \lambda \overline{\xi} . N_1 \ldots N_p$ is safe.
\end{proof}

Note that the hypothesis that $M$ is closed in (ii) is necessary.
For instance, the two terms $\lambda x y .x$ and $\lambda y . x$,
where $x,y:o$, have (isomorphic) incrementally-bound computation
trees. However $\lambda x y .x$ is safe whereas $\lambda y . x$ is
not.



Putting proposition \ref{prop:incrbound_imp_incrjustified} and lemma
\ref{lem:safe_imp_incrbound} together we obtain a game-semantic
characterisation of safe terms:
\begin{corollary}[Incrementally-justified strategies characterise closed safe terms]
Let $M$ be a closed pure simply-typed term (with no constants) then
$\sem{M}$  is incrementally-justified  if and only the $\eta$-normal form of the
$\beta$-normal form of $M$ is safe.
\end{corollary}



\begin{theorem}[Pointers are superfluous for safe terms]
\label{thm:safe_ptr_recoverable} Pointers in the game semantics of
safe terms are uniquely recoverable.
\end{theorem}
\begin{proof}
Let $M$ be a safe simply-typed term. Its $\beta$-normal form $M'$
is also safe. By lemma \ref{lem:safe_imp_incrbound}
(i), $\tau(M')$ is incrementally-bound and by proposition
\ref{prop:incrbound_imp_incrjustified}, $\sem{M'}$ is an
incrementally-justified strategy. By lemma
\ref{lem:incrjustified_pointers_uniqu_recover}, the pointers in
$\sem{M'}$ are uniquely recoverable. Finally, the soundness of the
game model gives $\sem{M} = \sem{M'}$.
\end{proof}


\section{Safe \pcf}

\pcf\ is the $\lambda$-calculus augmented with integer constants of ground type, first-order arithmetic operators, if-then-else branching
and a family of recursion combinator $Y_A : (A \typar A) \typar A$ for any type $A$.
Safe \pcf\ is \pcf\ where the application and abstraction rules are restricted as in the Safe $\lambda$-Calculus.
It inherits the good properties of the Safe $\lambda$-Calculus: no variable capture occurs when performing substitution on a safe term and Safety is preserved by the reduction rules of the small-step semantics of \pcf\ constants.

It is possible to extend the game-semantics characterisation result to Safe \pcf.
To handle the $Y$ combinators, we use the \emph{syntactic approximants} technique described in \cite{abramsky:game-semantics-tutorial}.
We define the computation tree of a \pcf\ term $M$ to be the least upper-bound of
the chain of computation trees of its approximants.
In other words, the computation tree is obtained by expanding
infinitely any subterm of the form $Y M$. For instance the computation tree
of $M = Y (\lambda f x. f x)$ where $f:(o,o)$ and $x:o$ is
the tree representation of the $\eta$-normal form of the infinite term
$(\lambda f x. f x) ((\lambda f x. f x) ((\lambda f x. f x)  (
\ldots$.


It is straightforward to define the traversal rules modeling the \pcf\ arithmetic constants in a way that
preserve the Correspondence Theorem. Moreover, these traversal rules are \defname{well-behaved} in
the sense that they can all be stated under the form:
$$\rulef{t = t_1\cdot n \cdot t_2 \in \travset \quad ?(t_2) = \epsilon \quad P(t)}
  { \stackrel{  \rule{0pt}{3pt} }{t' = t_1\cdot \rnode{n}{n} \cdot t_2 \cdot \rnode{m}{m} \in \travset} }
   \bkptr[nodesep=1pt]{35}{m}{n}
    \ m\in S(t)
   $$
where:
\begin{enumerate}
  \item $n$ is a variable or a constant node;
  \item $P$ expresses some condition on $t$;
  \item $S(t)$ is a subset of $E(n)$, the set of children $\lambda$-nodes and value-leaves of $n$.
\end{enumerate}


Just as in the Safe $\lambda$-calculus we had to remove @-nodes in order to make the
game-semantic Correspondence explicit, in the presence of higher-order constants, it is necessary to filter out the constant nodes from the traversals. This operation, defined similarly as the -@ operation, permits to prove the correspondence theorem for term approximants.

To lift up the result to any \pcf\ term, it suffices to observe that the
the function $\travset^{\upharpoonright r} : (CT,\sqsubseteq) \rightarrow (S,\subseteq)$ is continuous, where 
$(S,\subseteq)$ denotes the set of sets of justified sequences of nodes ordered by subset inclusion
and $(CT,\sqsubseteq)$ denote the set of computation trees ordered by the approximation ordering. 


Despite the fact that \pcf\ computation trees are potentially infinite,
lemma \ref{lem:safe_imp_incrbound} still holds: Safe \pcf\ terms have incrementally-bound computation trees.
Moreover the well-behaviour of the constant rules guarantees that lemma \ref{lem:redtrav_trav} remains true even in the presence of
\pcf\ constants. Consequently the analysis of the game-semantic of Safe $\lambda$-terms is still valid for \pcf:
\begin{theorem}[Pointers are superfluous for Safe \pcf]
Pointers in the game denotation of safe \pcf\ terms are uniquely
recoverable.
\end{theorem}


%%%%%%%%%%%%%%%%%%%%

%\begin{theorem}[Correspondence theorem]
%\label{thm:corresp} The set of traversals of the computation tree is
%isomorphic to the set of uncovered plays of the game denotation of
%the term.
%\end{theorem}

%\begin{theorem}[Game-semantic characterisation of safety]
%\label{thm:gamesem_charact} Safe simply-typed terms in
%$\beta$-normal form have incrementally-bound computation trees.
%Reciprocally, a closed term in $\eta$-long normal form with an
%incrementally-bound computation trees is safe.
%\end{theorem}

%\begin{cor}
%\label{cor:safeptrrecover} The pointers in the game semantics of
%safe simply-typed terms can be recovered uniquely from the
%underlying sequences of moves.
%\end{cor}

\section{Further work}

\subsection{Extension to Safe Idealized Algol}

Safe \ialgol\ is Safe \pcf\ augmented with the constants of Idealized Algol
\cite{Reynolds81}. It seems that the correspondence with game semantics and the game-semantic characterisation
of safety can easily be adapted to full Safe \textsf{IA}
although there are some difficulties caused by the presence of the two new
base types \iavar\ and \iacom.
For instance in \ialgol, the base type \iavar\ is represented by the infinite product $\iacom^{\nat} \times \iaexp$ which has an infinite number of
initial moves. Consequently we cannot use trees anymore to have a syntactical representation the term on which the game semantics can be expressed.
Instead we need to use ``computation directed acyclic graphs (DAG)'': a computation DAG may
have possibly infinitely many roots and two nodes at a given level can share children at the next level. For instance, a term of type \iavar\ will have a computation DAG with an infinite number
of root $\lambda$-nodes.

\subsection{Open problems}

The nature of the Safe $\lambda$-Calculus is still not well known. Let us list some open problems:
\begin{enumerate}
\item prove/disprove whether observational equivalence decidable for Safe \ialgol;
\item find a categorical interpretation of the Safe $\lambda$-Calculus;
\item study the proof theory obtained by the Curry-Howard isomorphism and determine whether it has nice properties that can be helpful in theorem proving;
\item in \cite{DBLP:conf/tlca/LeivantM93}, the $\lambda$-calculus is used to
give several characterisations of the complexity class P. We would
like to investigate whether, by following similar techniques, we can
obtain a characterisation of a different complexity class using the
Safe $\lambda$-Calculus.
\end{enumerate}

More generally, it would be nice to have a better understanding of the class of languages for
which pointers are uniquely recoverable. We name this class PUR for
``Pointer Uniquely Recoverable''.

We showed that Safe $\lambda$-Calculus is a PUR-language. Another
example is the Serially Re-entrant Idealized Algol (SRIA) proposed
by Abramsky  in \cite{abramsky:mchecking_ia}. This language allows
multiple occurrences or uses of arguments, as long as they do not
overlap in time. In the game semantics denotation of a SRIA term
there is at most one pending occurrence of a question at any time.
Each move has therefore a unique justifier and consequently
justification pointers may be ignored. Safe \ialgol\ is not a
sublanguage of SRIA. One reason for this is that none of the two
Kierstead terms $\lambda f . f (\lambda x . f (\lambda y .y ))$ and
$\lambda f . f (\lambda x . f (\lambda y .x ))$ are Serially
Re-entrant whereas the first one is safe. Conversely, SRIA is not a
sublanguage of Safe \ialgol\ since the term $\lambda f g. f (\lambda
x . g (\lambda y .x ))$ where $f,g:((o,o),o)$ belongs to SRIA but
not to Safe \ialgol. SRIA and Safe \ialgol\ are therefore two
different examples of languages with pointer-less game semantics.

Finitary $\ialgol_2$ is also an example of PUR-language for which
observational equivalence is decidable. Decidability of observational equivalence is a very
appealing property which has immediate applications in the domain of
program verification. Intuitively, PUR-languages seem to be good
candidates of languages for which observational equivalence is
decidable. It would be interesting to discover classes of PUR
languages having this appealing property.

Another possible way to generate PUR-languages may be to constrain
the types of an existing language. In \cite{DBLP:conf/tlca/Joly01},
a notion of ``complexity'' is defined for $\lambda$-terms. It is
proved that a type $T$ can be generated from a finite set of
combinators if and only if there is a constant bounding the
complexity of every closed normal $\lambda$-term of type $T$;
consequently, the only inhabited finitely generated types are the
type of rank $\leq 2$ and the types $(A_1, A_2, \ldots, A_n, o)$
such that for all $i = 1..n$: $A_i = o$ , $A_i = o \rightarrow o$ or
$A_i = (o^k \rightarrow o) \rightarrow o$. We know that imposing the
first of these two type restrictions to Finitary \ialgol\ leads to a
PUR language. Is it also the case when imposing the second type
restriction?


\bibliographystyle{splncs}
\bibliography{../transfer/current/higherorder,../transfer/current/gamesem,../transfer/current/modelchecking,../transfer/current/proganalys}

\end{document}
