\chapter{Game semantics}

The aim of this chapter is to introduce game semantics. It starts
with a history of game semantics and a presentation of the full
abstraction problem for PCF which has been solved using game
semantics. It then goes on by introducing the basic notions of game
semantics and by giving a categorical interpretation of games.
Finally we show how games are used to define a syntax-independent
model of programming languages like PCF and Idealized Algol (IA).

This chapter is largely based on the tutorial by Samson Abramsky tutorial on Game Semantics \cite{AM98a}.
Most of the proof will be omitted and we refer the reader to
\cite{hylandong_pcf, abramsky94full} for a deeper description
of game semantics with complete proofs.

\section{History}

\subsection{Game semantics}

In the 1950s, Paul Lorenzen invented Game semantics as a tool to
study semantics of intuitionistic logic \citep{lor61}.

Four decade later, Abramsky proved the full completeness of
Multiplicative Linear Logic (MLL) using game semantics
\citep{abramsky92games}. Shortly after, game semantics has been used
as tool to study models of programming languages. In game semantics,
the meaning of a program is given by a strategy in a two-player
game. One player, the Opponent, represents the environment while the
other, the Proponent, represents the system.


\subsection{Model of programming languages}

Before the 1980s, there were many approaches to define models for
programming languages. Among the successful ones, there were the
axiomatic, operational and denotational semantics:
\begin{itemize}
\item Operational semantics gives a meaning to a program by describing the
behaviour of a machine executing the program. It is defined formally
by giving a state transition system.
\item Axiomatic semantics defined the behaviour of the program
with axioms and is used to prove program correctness by static
analysis of the code of the program.
\item The denotational semantics approach consists in mapping a program to a mathematical structure
having good properties such as compositionality. This mapping is
achieved by structural induction on the syntax of the program.
\end{itemize}

In the 1990s, three different independent research groups: Samson
Abramsky, Radhakrishnan Jagadeesan and Pasquale Malacaria
\citep{abramsky94full}, Martin Hyland and Luke Ong
\citep{hylandong_pcf} and Nickau \citep{Nickau:lfcs94} have
introduced game semantics, a new kind of semantics, in order to
solve a long standing problem in the semanticists community :
finding a fully abstract model for PCF.

\subsection{The problem of full abstraction for PCF}

PCF is a simple programming language introduced in a classical paper
by Plotkin ``LCF considered as a programming language''
(\cite{DBLP:journals/tcs/Plotkin77}). PCF is based on LCF, the Logic
of Computable Functions devised by Dana Scott in \cite{scott_lcf}.
It is a simply typed lambda calculus extended with arithmetic
operators, conditional and recursion.

The problem of the Full Abstraction for PCF goes back to the 1970s.
In \citep{scott93}, Scott gave a model for PCF based on domain
theory. This model gives a sound interpretation of observational
equivalence: if two terms have the same domain theoretic
interpretation then they are observationally equivalent. However the
converse is not true: there exist two PCF terms which are
observationally equivalent but have different domain theoretic
denotation. We say that the model is not fully abstract.

The key reason why the domain theoretic model of PCF is not fully
abstract is that the parallel-or operator defined by the following
truth table
\begin{center}
\begin{tabular}{l|lll}
p-or  & $\bot$ & tt & ff \\ \hline
$\bot$ & $\bot$ & tt & $\bot$\\
tt & tt & tt & tt\\
ff & $\bot$ & tt & ff\\
\end{tabular}
\end{center}
is not definable as a PCF term! It is possible to create two
different PCF terms that always behave the same except when they are
apply to a term computing p-or. Since p-or is not definable in PCF,
these two terms will have the same denotation. This implies that the
model is not fully abstract.

One can patch PCF by adding the operator $p-or$, the resulting
language ``PCF+p-or'' now becomes fully-abstracted by Scott domain
theoretic model \citep{DBLP:journals/tcs/Plotkin77}. However the
language we are now dealing with is strictly more powerful than PCF,
it allows parallel execution of commands whereas PCF only permits
sequential execution.

Another approach consists in getting rid of the undefinable elements
(like p-or) by strengthening the conditions on the function used in
the model (a condition stronger than strictness and continuity) but
unfortunately this approach did not succeed.

The only successful approaches to obtain a fully abstract model for
PCF were the ones taken by Ambramsky, Jagadeesan and Malacaria
\citep{abramsky94full}, Hyland and Ong \citep{hylandong_pcf} and
Nickau \citep{Nickau:lfcs94}, all based on game semantics.

This result has then been adapted to other varieties of programming
paradigm including languages with stores (Idealized Algol),
call-by-value \citep{honda99gametheoretic, abramsky98callbyvalue}
and call-by-name, general referencees
\citep{DBLP:conf/lics/AbramskyHM98}, polymorphism
\citep{DBLP:journals/apal/AbramskyJ05}, control features
(continuation and exception), non determinism, concurrency. In all
these cases, the game semantics model led to a syntax-independent
fully abstract model of the corresponding language.

\section{Games}
\label{sec:catgames}

We now introduce formally the notion of game that will be used in
the following section to give a model of the programming languages
PCF and Idealized Algol. The definitions are taken from
\cite{abramsky:game-semantics, hylandong_pcf, abramsky94full}.


\subsection{Arenas and Games}

The games we are interested in are two-players games. The players are named O for Opponent and P for Proponent.

The game played by O and P is constraint by something called
\emph{arena}. The arena defines the possible moves of the game. By
analogy with real board games, the arena represents the board
together with the rules that tell how players can make their moves
on the board. In fact the analogy with board game stops here. Our
games can be thought as dialog games: one person O interviews
another person P, P tries to answer the initial O-question by
possibly asking O some precisions about its initial question.
Moreover, the notion of winner and winning strategy will not be
relevant in our setting.


More formally, the arena can be seen as a forest of trees whose nodes are possible questions and leaves are possible answers.
The arena is partitioned into two kinds of moves: the moves that can be played by P and the ones that can be played by O.
A move is either a question to the other player or an answer to a question previously asked by the other player.

Each move of the game must be justified by another move that has already been played by the other player. This justification relation
is induced by the edges of the forest arena. Moreover, an answer must always be justified by the question that it answers and a question
is always justified by another question.

\begin{dfn}[Arena]
An arena is a structure $\langle M, \lambda, \vdash \rangle$ where:
\begin{itemize}
\item $M$ is the set of possible moves;
\item $(M,\vdash)$ is a forest of trees;

\item $\lambda : M \rightarrow \{ O, P\} \times \{Q, A\}$ is a labeling functions indicating whether a given move
    is a question or an answer and whether it can be played by O or by P.

    $\lambda = [\lambda^{OP},\lambda^{QA}]$ where $\lambda^{OP} : M \rightarrow  \{ O, P\}$
    and $\lambda^{QA} : M \rightarrow  \{ Q, A\}$.

    \begin{itemize}
    \item If $\lambda^{OP} (m) = O$, we call $m$ and O-move otherwise $m$ is a P-move.
    $\lambda^{QA} (m) = Q$ indicates that $m$ is a question otherwise $m$ is an answer.

    \item For any leaf $l$ of the tree $(M,\vdash)$, $\lambda^{QA} (l) = A$ and for any node
    $n \in (M,\vdash)$, $\lambda^{QA} (n) = Q$.
    \end{itemize}

\item The forest of tree $(M,\vdash)$ respect the following condition:
    \begin{itemize}
    \item[(e1)] The roots are O-moves: for any root $r$ of $(M,\vdash)$, $\lambda^{OP} (r) = O$.
    \item[(e2)] Answers are enabled by questions: $m \vdash n  \zand \lambda^{QA}(n) = A \imp \lambda^{QA}(m) = Q$.
    % Or more succinctly, if we write $\dashv$ the relation $\vdash^-1$: $\lambda^{QA} \left( \dashv( (\lambda^{QA})^{-1}(\{A\}) ) \right) = \{ O \}$
    \item[(e3)] A player move must be justified by a move played by the other player:
         $m\vdash n \imp \lambda^{OP}(m) \neq \lambda^{OP}(n)$.
    \end{itemize}
\end{itemize}
\end{dfn}

For commodity we write the set $\{O,P\} \times \{Q,A\}$ as $\{OQ,OA,PQ,PA\}$.
$\overline{\lambda}$ denotes the labeling function $\lambda$ with the question and answer swapped. For instance:
$$\overline{\lambda(m)} = OQ \iff \lambda(m) = PQ$$

The roots of the forest of tree $(M,\vdash)$ are the \emph{initial moves}.

For example, the simplest possible arena is written $\mathbf{1}$ and
denotes the arena which set of moves $M$ is empty.

\begin{exmp}[The flat arena]
\label{exmp:flatarena}

 Let $A$ be any countable set then the flat arena over $A$
is defined to be the arena $\langle M, \lambda, \vdash \rangle$ such
that $M$ has one move $q$ with $\lambda(q) = OQ$ and for each
element in $A$, there is a corresponding move $a_i$ in $M$ with
$\lambda(a_i) = PA$ for some $i \in \nat$. The enabling relation
$\vdash$ is defined to be $\{ q \vdash a_i \ | i \in \nat \}$.

This arena is represented by the following tree:
\begin{center}
  \pstree[levelsep=6ex]
    { \TR{$q$} }
    {    \TR{$a_1$} \TR{$a_2$} \TR{\ldots} }
\end{center}
The vertices represent the moves and the edges represent the
enabling relation.

The flat arena over $\nat$ and $\mathbb{B}$ is written
$\mathbf{int}$ and  $\mathbf{bool}$ respectively.

\end{exmp}

Once the arena has been defined, the bases of the game are set and the players have something to play with.
We now need to describe the state of the game, for that purpose
we introduced \emph{justified sequences of moves}. Sequence of moves are used to record the history of all the moves that have been
played.

\begin{dfn}[Justified sequence of moves]
A justified sequence is a sequence of moves $s$ together with an associated sequence of pointers. Any
move $m$ in the sequence that is not initial has as pointer that points to a previous move $n$ that justifies it (i.e. $n \vdash m$).
\end{dfn}

The pointers of a justified sequences are represented with arrows.
This is an example of justified sequence of moves:
$$\rnode{q4}{q}^4
\rnode{q3}{q}^3 \rnode{q2}{q}^2 \rnode{q3b}{q}^3 \rnode{q2b}{q}^2
\rnode{q1}{q}^1 \bkptrc{q3}{q4} \bkptrc{q2}{q3}
\bkptrc[ncurv=0.6]{q3b}{q4} \bkptrc{q2b}{q3b}$$

The first move of a justified sequence must be an O-move since
initial moves are all O-moves.

Notation: we write $s t$ or sometimes $s \cdot t$ do denote the
sequences obtain by concatenating $s$ and $t$. The empty sequence is
written $\epsilon$.

 A justified sequence has two particular subsequences which
will be of particular interest later on when we introduce
strategies. These subsequences are called the P-view and the O-view
of the sequence. The idea is that a view describes the local context
of the game. Here is the formal definition:

\begin{dfn}[View]
Given a justified sequence of moves $s$. We define the proponent view (P-view) noted $\pview{s}$ by induction:
\begin{align*}
\pview{\epsilon} &= \epsilon \\
\pview{s \cdot m} &= \pview{s} \cdot \ m && \mbox{ if $m$ is a P-move} \\
\pview{s \cdot m} &= m && \mbox{ if $m$ is initial (O-move) } \\
\pview{ s \cdot \rnode{m}{m} \cdot t \cdot \rnode{n}{n} \bkptra{50}{n}{m} } &=
 \pview{s} \cdot \rnode{mm}{m} \cdot \rnode{nn}{n} \bkptra{70}{nn}{mm} && \mbox{ if $n$ is a non initial O-move }
\end{align*}
The O-view $\oview{s}$ is defined similarly:
\begin{align*}
\oview{\epsilon} &= \epsilon \\
\oview{s \cdot m} &= \oview{s} \cdot \ m && \mbox{ if $m$ is a O-move} \\
\oview{ s \cdot \rnode{m}{m} \cdot t \cdot \rnode{n}{n} \bkptra{50}{n}{m} } &=
 \pview{s} \cdot \rnode{mm}{m} \cdot \rnode{nn}{n} \bkptra{70}{nn}{mm} && \mbox{ if $n$ is a P-move }
\end{align*}
\end{dfn}

In fact not all justified sequences will be of interest for the
games that we will use. We call \emph{legal position} any justified
sequence verifying two additional conditions: alternation and
visibility. Alternation says that players O and P plays
alternatively. Visibility expresses that each non-initial move is
justified by a move situated in the local context at that point.
Intuitively, the visibility condition gives some coherence to the
justification pointers of the sequence.

\begin{dfn}[Legal position]
A legal position is a justified sequence of move $s$ respecting the following constraint:
\begin{itemize}
\item Alternation: For any subsequence $m \cdot n$ of $s$, $\lambda^{OP}(m) \neq \lambda^{OP}(n)$.
\item Visibility: For any subsequence $t m$ of $s$ where $m$ is not initial, if $m$ is a P-move then $m$ points to a move in $\pview{s}$
and if $m$ is a O-move then $m$ points to a move in $\oview{s}$.
\end{itemize}

The set of legal position of an arena $A$ is noted $L_A$.
\end{dfn}

We say that a move $n$ is hereditarily justified by a move $m$ if there is a sequence of move
$m_1, \ldots, m_q$ such that:
$$ m \vdash m_1 \vdash m_2 \vdash \ldots m_q \vdash n$$
If a move has no justification pointer, we says that it is an
\emph{initial move} (in that case it must be a root of the forest
arena).

Suppose that $n$ is an occurrence of a move in the sequence $s$ then
$s \upharpoonright n$ denotes the subsequence of $s$ containing all the moves hereditarily justified by $n$.
Similarly, $s \upharpoonright I$ denotes the
subsequence of $s$ containing all the moves hereditarily justified by the moves in $I$.

\begin{dfn}[Game]
A game is a structure $\langle M, \lambda, \vdash, P \rangle$ such that
\begin{itemize}
\item $ \langle M, \lambda, \vdash \rangle$ is an arena.
\item $P$ is called the set of valid positions, it is:
    \begin{itemize}
    \item a non-empty prefix closed subset of the set of legal position
    \item closed by initial hereditary filtering: if $s$ is a valid position then for any set $I$ of occurrences of initial moves
    in $s$, $s\upharpoonright I$ is also a valid position.
    \end{itemize}
\end{itemize}
\end{dfn}

\begin{exmp}  Consider the flat arena  $\mathbf{int}$.
The set of valid position $P = \{ \epsilon, q \} \union \{ q \cdot
a_i \ | i \in \nat \}$ defines a game on the arena $\mathbf{int}$.
\end{exmp}

\subsection{Constructions on games}
\label{sec:gameconstruction}

We now define game constructors that will be useful later on.

Consider the two functions $f : A \rightarrow C$ and $g : B
\rightarrow C$, we write $[f,g]$ to denote the pairing of $f$ and
$g$ defined on the direct sum $A + B$. Given a game $A$ with a set
of moves $M_A$, we use the filtering operator $s \upharpoonright A$
do denote the subsequence of $s$ consisting of all moves in $M_A$.
Although this notation conflicts with the hereditarily filtering
operator, it should not cause any confusion.

\subsubsection{Tensor product}
Given two games $A$ and $B$ we define the tensor product constructor
$A \otimes B$ as follows:
\begin{eqnarray*}
  M_{A \otimes B} &=& M_A + M_B \\
  \lambda_{A\otimes B} &=& [\lambda_A,\lambda_B] \\
  \vdash_{A\otimes B} & = & \vdash_{A}\ \union\ \vdash_{B} \\
  P_{A\otimes B} & = & \{ s \in L_{A\otimes B} | s \upharpoonright A \in P_A \wedge s \ \upharpoonright B \in P_B  \}.
\end{eqnarray*}

In particular,  $n$ is initial in $A\otimes B$ if and only if $n$ is
initial in A or B. And $m \vdash_{A\otimes B} n$  holds if and only if $m
\vdash_{A} n$ or $m \vdash_{B} n$ holds.

\subsubsection{Function space}
The game $A \otimes B$ is defined as follows:
\begin{eqnarray*}
  M_{A \multimap B} &=& M_A + M_B \\
  \lambda_{A\multimap B} &=& [\overline{\lambda_A},\lambda_B] \\
  \vdash_{A\multimap B} & = & \vdash_{A}\ \union\ \vdash_{B}\ \union\  \{ (m,n) \ |\ m \mbox{ initial in } B \wedge n \mbox{ initial in } A \} \\
  P_{A\otimes B} & = & \{ s \in L_{A\otimes B} | s \upharpoonright A \in P_A \wedge s \ \upharpoonright B \in P_B  \}.
\end{eqnarray*}

\subsubsection{Cartesian product}
The game $A \& B$ is defined as follows:
\begin{eqnarray*}
  M_{A \& B} &=& M_A + M_B \\
  \lambda_{A\& B} &=& [\lambda_A,\lambda_B] \\
  \vdash_{A\& B} & = & \vdash_{A}\ \union\ \vdash_{B} \\
  P_{A\& B} & = & \{ s \in L_{A\otimes B} | s \upharpoonright A \in P_A \wedge s \ \upharpoonright B = \epsilon  \} \\
        &&   \union \{ s \in L_{A\otimes B} | s \upharpoonright A \in P_B \wedge s \ \upharpoonright A = \epsilon  \}.
\end{eqnarray*}

A play of the game $A \& B$ is either a play of $A$ or a play of $B$ whether a play
of the game $A \otimes B$ may be an interleaving of plays on $A$ and plays on $B$.

\subsection{Representation of plays}

Plays of the game are usually represented in a table diagram. The
columns of the table correspond to the different components of the
arena and each row corresponds to one move in the play. The first
row always represents an O-move, this is because O is the only
player who can open a game (since roots of the arena are O-moves).

As an example the play
$$\rnode{q1}{q}\
 \rnode{q2}{q}
 \ \rnode{a2}{8}
\  \rnode{a1}{12}
  \bkptrc{a1}{q1}
\bkptrc{a2}{q2} $$
on the
game $\textbf{int} \multimap \textbf{int} $ can be represented by
the following diagram:

\begin{center}
\begin{tabular}{cccc}
\textbf{int} & $\imp$ & \textbf{int} & \\
&& q & O\\
q  &&& P\\
8  &&& O\\
&& 12 & P
\end{tabular}
\end{center}

When it is necessary, the justification pointers of the play can also
be shown on the diagram.


\subsection{Strategy}

\subsubsection{Definition}

During a game, the player who has to play may have several choices
for his next move. The move that he makes is chosen according to a
given strategy.

A strategy is a rule telling the player which move to make when the
game is in a given position. More abstractly, a strategy is a
partial function mapping legal position where Proponent has to move
to P-moves.

\begin{dfn}[Strategy]
A strategy for player P on a given game $\langle M, \lambda, \vdash, P \rangle$ is a
non-empty set of even-length positions from $P$ such that:
\begin{enumerate}
\item (\emph{no unreachable position}) $sab \in \sigma \imp s \in \sigma$
\item (\emph{determinacy}) $sab, sac \in \sigma \quad \imp \quad  b = c$  and $b$ has the same justifier as
$c$.
\end{enumerate}
\end{dfn}

The idea is that the presence of the even-length sequence $s a b$ in
$\sigma$ tells the player P that whenever the game is in position
$s$ and player O plays the move $a$ then it must respond by playing
the move $b$.

The first condition ensures that the strategy $\sigma$ only
considers positions that the strategy itself could have led to in a
previous move. The second condition in the definition requires that
this choice of move is deterministic (i.e. there is a function $f$
from the set of odd length position to the set of moves $M$ such
that $f(s a) = b$).


For any game $A$, the smallest possible strategy is the strategy
that never respond given by $\{ \epsilon \}$. It is called the
\emph{empty strategy} and denoted $\bot$.

\subsubsection{Copy-cat strategy}

For any arena $A$ there is a strategy on the game $A \multimap A$
called the \emph{copy-cat strategy}. We write $A_1$ and $A_2$ to
denote the first and second copy of the arena $A$ in the game $A
\multimap A$. If $A$ is the arena $A_1$ then $A^\perp$ denotes the
arena $A_2$ and reciprocally.

Let $A$ be one of the arena $A_1$ or $A_2$. The copy-cat strategy
operates as follows: whenever P has to respond to an O-move played
in $A$, it replicates the move played by O in the arena $A^{\perp}$
after that $O$ has to respond in $A^{\perp}$ and $P$ replicates this
response in $(A^\perp)^\perp = A$ and so on and so forth.


More formally, the copy-cat strategy is defined by:
$$ \textsf{id}_A = \{ s \in P^{\textsf{even}}_{A \multimap A} \ | \ \forall t \sqsubseteq^{\textsf{even}} s\ .\ t \upharpoonright A_1 = t \upharpoonright A_2 \}$$
where $P^{\textsf{even}}_A$ denotes the valid position of even
length in the game $A$ and $t \sqsubseteq^{\textsf{even}} s$ denotes
that $t$ is an even length prefix of $s$.

The copy-cat strategy is also called \emph{identity strategy} since
it is the identity for strategy composition as we will see in the
next paragraph.

\begin{exmp} The copy-cat strategy on $\textbf{int}$ is:
$$\begin{array}{ccc}
\textbf{int} & \imp & \textbf{int} \\
&& q\\
q \\
n \\
&& n
\end{array}
$$
Note that we introduced this type of diagram to represent plays of
games but, as we can see here, the same diagrams can be used to
represent strategies when the play represented is general enough.

The copy-cat strategy on $\textbf{int} \typar \textbf{int}$ is given
by the following diagram:
$$\begin{array}{ccccccc}
(\textbf{int} & \imp & \textbf{int}) & \imp & (\textbf{int} & \imp & \textbf{int}) \\
&&&& && q\\
&& q\\
q \\
&&&& q \\
&&&& m \\
m\\
&& n \\
&&&& && n
\end{array}$$
\end{exmp}

\subsubsection{Composition}

It is well-known that any model of the simply typed lambda-calculus
is a cartesian closed category \citep{CroleRL:catt}. Games are used
to give a fully-abstract model of PCF, an extended simply typed
lambda calculus, therefore the game model should fit into a
cartesian closed category. This category will have games as objects
and strategies as morphisms. In a category, morphisms should be able
to compose together, therefore there should be an appropriate notion
of strategy composition.

Composition of strategies is an essential feature of game semantics.
As we will see in the following section, in the game model of PCF,
strategies represent programs. Therefore, strategy composition will
prove to be very useful : obtaining the model of a composed program
boils down to composing the strategies of the composing programs.

The way composition is defined for strategies is similar to
``parallel composition plus hiding'' in the trace semantics of CSP
\citep{hoare_csp}. Consider two strategies $\sigma : A \multimap B$
and $\tau : B \multimap C$ that we wish to compose.

For any sequence of moves $u$ on three arenas $A$, $B$, $C$, we call
projection of $s$ on the game $A \multimap B$ and we note $u
\upharpoonright A,B$ the subsequence of $s$ obtained by removing
from $u$ the moves in $C$ and pointers to moves in $C$. The
projection on $B \multimap C$ is defined similarly.

The definition of the projection on $A \multimap B$ differs
slightly: $u \upharpoonright A,C$ is the subsequence of $u$
consisting of the moves from $A$ and $C$ with some additional
pointers: we add a pointer from $a \in A$ to $c\in C$ whenever $a$
points to some move $b \in B$ itself pointing to $c$. All the
pointers to moves in $B$ are removed.


First we remark that for a given legal position $s$ in the game $A
\multimap C$, there is what is called an \emph{uncovering} of $s$.
The uncovering of $s$ is the maximal justified sequence of moves $u$
from the games $A$, $B$ and $C$ such that:
\begin{itemize}
\item The sequence $s$, considered as a pointer-less sequence, is a subsequence of
$u$;
\item the projection of $u$ on the game $A \multimap B$ lies in the
strategy $\sigma$;
\item the projection of $u$ on the game $B \multimap C$
lies in the strategy $\tau$;
\item and the projection of $u$ on the game $A \multimap C$ is a subsequence of $s$ (here the term ``subsequence'' refers to the sequence of nodes together with the auxiliary sequence of pointers).
\end{itemize}
This uncovering, noted $uncover(s, \sigma, \tau)$, is
defined uniquely for given strategies $\sigma$, $\tau$ and legal
position $s$ (this is proved in part II of \cite{hylandong_pcf}).

We define $\sigma \| \tau $ to be the set of uncovering of legal
positions in $A \multimap C$:
$$ \sigma \| \tau = \{ uncover(s, \sigma, \tau) \ | \ s \mbox{ is a legal position in } A \multimap C \}$$

The composition of $\sigma$, $\tau$ is defined to be the set of
projections of uncovering of legal positions in $A \multimap C$:

\begin{dfn}[Strategy composition]
Consider $\sigma : A \multimap B$ and  $\tau : B \multimap C$ two
strategies. We define $\sigma ; \tau$ to be:
$$ \sigma ; \tau = \{ u \upharpoonright A,C \ | \ u \in \sigma \|
\tau \}$$
\end{dfn}

It can be verified that composition is well-defined and associative
\citep{hylandong_pcf} and that the copy-cat strategy $\textsf{id}_A$ is the identity for composition.

\subsubsection{Constraint on strategies}

Different classes of strategies will be considered depending on the
features of the language that we want to model. Here is a list of
common restrictions that we will consider:
\begin{itemize}
\item \emph{Well-bracketing:} In a well-bracketed strategies the players always answer the last unanswered question (called the pending question) first.
If we represent Opponent's question as ``['', Proponent's answer as
``]'', Proponent's question as ``('' and Opponent's answers as ``)''
then requiring that the last pending question is answered first is
the same as requiring that the string representing the play is a
prefix of a well-bracketed sequence.

\item \emph{History-free strategies:} A strategy is history-free if the Proponent's move at any position of the game where he has to play
is determined by the last move of the Opponent. In other words, the
history prior to the last move is ignored by the Proponent when
deciding how to respond.

\item \emph{History-sensitive strategies:} The Proponent follows a history-sensitive strategy if he needs to have access to the full
history of the moves in order to decide which move to make.

\item \emph{Innocence:} a strategy is innocent if it determines Proponent's moves based on a restricted view of the history of the play, mainly the P-view
at that point. Such strategies can be specified by a partial
function mapping P-views to P-moves. However not every partial
function from P-views to P-moves gives rise to an innocent strategy
(a sufficient condition is given in \cite{hylandong_pcf}).
\end{itemize}

The formal definition of innocence follows:
\begin{dfn}[Innocence]
Given positions $sab, ta \in L_A$ where $sab$ has even length and
$\pview{sa} = \pview{ta}$, there is a unique extension of $ta$ by
the move $b$ together with a justification pointer such that
$\pview{sab} = \pview{sa}$. We write this extension
$\textsf{match}(sab,ta)$.

The strategy $\sigma:A$ is \emph{innocent} if and only if:
$$ \left(
     \begin{array}{c}
       \pview{sa} = \pview{ta} \\
       sab \in \sigma \\
       t\in \sigma \wedge ta \in P_A \\
     \end{array}
   \right)
\quad \imp\quad  \textsf{match}(sab,ta) \in \sigma$$

\end{dfn}


\subsection{Categorical interpretation of games}

In this section we recall some results about the categorical representation of Games.
These results with complete details and proofs can be found in \cite{McC96b,hylandong_pcf,abramsky94full}.
We refer the reader to \cite{CroleRL:catt} for more information about category theory.

We consider the category $\mathcal{G}$ whose objects are games and morphisms are
strategies. A morphism from $A$ to $B$ is a strategy on the game $A \multimap B$.

Three other sub-categories of $\mathcal{G}$ are considered: each of them correspond to some restriction on strategies:
$\mathcal{G}_i$ is the sub-category
of $\mathcal{G}$ whose morphisms are the innocent strategies,
$\mathcal{G}_b$ has only the well-bracketed strategies and $\mathcal{G}_{ib}$ has the innocent and well-bracketed strategies.

\begin{prop}
$\mathcal{G}$, $\mathcal{G}_i$, $\mathcal{G}_b$ and $\mathcal{G}_{ib}$ are categories.
\end{prop}

Proving this requires to prove that composition of strategies is well-defined, associative, has a unit (the copy-cat strategy), preserves innocence and
well-bracketedness. See \cite{hylandong_pcf,abramsky94full} for a proof.


\subsubsection{Monoidal structure}

We have already defined the tensor product on games in section \ref{sec:gameconstruction}.
We now define the corresponding transformation on morphisms:
given two strategies $\sigma : A \multimap B$ and $\tau : C \multimap D$ the strategy
$\sigma \otimes \tau : (A \otimes C) \multimap (B\otimes D)$ is defined by:
$$ \sigma \otimes \tau = \{ s \in L_{A \otimes C \multimap B\otimes D} \ s \upharpoonright A,B \in \sigma
\wedge s \upharpoonright C,D \in \tau \}$$

It can be shown that the tensor product is associative, commutative and has
$I = \langle \emptyset, \emptyset,\emptyset, \{ \epsilon \} \rangle $ as identity.
Hence the game categories $\mathcal{G}$ is a symmetric monoidal categories. Moreover
$\mathcal{G}_i$ and  $\mathcal{G}_b$ are sub-symmetric monoidal categories of $\mathcal{G}$,
and $\mathcal{G}_{ib}$ is a sub-symmetric monoidal category of $\mathcal{G}_i$, $\mathcal{G}_b$ and
$\mathcal{G}$.

\subsubsection{Closed structure}

For any game $A$, $B$ and $C$,
to any strategy $\sigma : A\otimes B \multimap C$, there is a corresponding strategy
$\tau : A\otimes B \multimap C$ obtained by relabeling the moves in $\sigma$. This transformation
is in fact an isomorphism: the hom-set $\mathcal{G}(A\otimes B, C)$ is isomorphic to the hom-set
$\mathcal{G}(A,B\multimap C)$. Hence $\mathcal{G}$ is an autonomous (i.e. symmetric monoidal closed) category.

$\mathcal{G}_i$ and  $\mathcal{G}_b$ are sub-autonomous categories of $\mathcal{G}$,
and $\mathcal{G}_{ib}$ is a sub-autonomous category of $\mathcal{G}_i$, $\mathcal{G}_b$ and
$\mathcal{G}$.

\subsubsection{Cartesian product}
The cartesian product defined in section \ref{sec:gameconstruction} is indeed a cartesian product in the category
$\mathcal{G}$, $\mathcal{G}_i$, $\mathcal{G}_b$ and $\mathcal{G}_{ib}$.

The projections $\pi_1:A \& B \rightarrow A$ and $\pi_1:A \& B \rightarrow B$ are given by the obvious copy-cat strategies.
Given two category morphisms $\sigma :C \rightarrow A$ and $\tau : C \rightarrow B$ the pairing function
$\langle \sigma, \tau \rangle : C \rightarrow A \& B$ is given by:
\begin{eqnarray*}
\langle \sigma, \tau \rangle &=& \{ s \in L_{C\multimap A\&B} \ | \ s \upharpoonright C,A \in \sigma \wedge s \upharpoonright B = \epsilon  \} \\
&\union& \{ s \in L_{C\multimap A\&B} \ | \ s \upharpoonright C,A \in \sigma \wedge s \upharpoonright B = \epsilon  \}
\end{eqnarray*}

\subsubsection{Cartesian closed structure}
Having defined the cartesian product is not enough to turn $\mathcal{G}$ into a cartesian closed category :
we also need to define a terminal object $I$ and the exponential construct $A \imp B$ for any two games $A$ and $B$.
In fact, this cannot be done in the current categories $\mathcal{G}$ and we have to move on to another category
of games noted $\mathcal{C}$ whose objects and morphisms are certain sub-classes of games and strategies.

Before introducing the category $\mathcal{C}$ we need some new definitions:


For any game $A$ we define the exponential game noted $!A$.
The game $!A$ corresponds to a repeated version of the game $A$. Plays of $!A$ are interleaving of plays of
$A$. It is defined as follows:
\begin{eqnarray*}
  M_{!A} &=& M_A \\
  \lambda_{!A} &=& \lambda_A \\
  \vdash_{!A} & = & \vdash_{A} \\
  P_{!A} & = & \{ s \in L_{!A} | \mbox{ for each initial move $m$, } s \upharpoonright m \in P_A \}
\end{eqnarray*}
The following equalities hold:
\begin{eqnarray*}
  !(A \& B) &=& !A \otimes !B\\
  I &=& !I
\end{eqnarray*}

\begin{dfn}[Well-opened games]
A game $A$ is well-opened if for any position $s \in P_A$ the only initial move is the first
one.
\end{dfn}

Well-opened games have single thread of dialog. Then can be turned into games with multiple-thread of dialog
using the promotion operator:

\begin{dfn}[Promotion]
Consider a well-opened game $B$.
Given a strategy on ${!A} \multimap B$, we define it promotion $\sigma^\dagger : {!A} \multimap {!B}$ to be the
strategy which plays several copies of $\sigma$. It is formally defined by:
$$ \sigma^\dagger = \{ s \in L_{{!A} \multimap !B} \ | \ \mbox{ for all initial $m$, } s \upharpoonright m \in \sigma  \}.$$
\end{dfn}

It can be shown that promotion is well-defined (it is indeed a strategy) and that it preserves innocence and
well-bracketedness.


We now introduce the category of well-opened games:
\begin{dfn}[Category of well-opened games]
The category $\mathcal{C}$ of well-opened games is defined as follow:
\begin{enumerate}
\item The objects are the well-opened games,
\item a morphism $\sigma : A \rightarrow B$ is a strategy for the game $!A \multimap B$,
\item the identity map for $A$ is the copy-cat strategy on $!A \multimap A$ (which is well-defined for well-opened games).
It is called dereliction, noted
$\textsf{der}_A$ and defined formally by:
$$ \textsf{der}_A = \{ s \in P^{\textsf{even}}_{{!A} \multimap A} \ | \ \forall t \sqsubseteq^{\textsf{even}} s \ . \ t \upharpoonright {!A} = t \upharpoonright A \},$$
\item composition of morphisms $\sigma : {!A} \multimap B$ and $\tau : {!B} \multimap C$ is defined to be
the strategy $\sigma^\dagger;\tau$ on the game ${!A} \multimap C$.
\end{enumerate}
\end{dfn}
$\mathcal{C}$ is a well-defined category and the three sub-categories
$\mathcal{C}_i$, $\mathcal{C}_b$, $\mathcal{C}_{ib}$ corresponding to sub-category
with innocent strategies, well-bracketed strategies and innocent and well-bracketed strategies respectively.


The category $\mathcal{C}$ has a terminal object $I$, for any two games $A$ and $B$ a product $A \& B$ and
an exponential $A \imp B$. Moreover the hom-sets $\mathcal{C}(A \& B,C)$ and
$\mathcal{C}(A,!B \multimap C)$ are isomorphic. Indeed:
\begin{eqnarray*}
\mathcal{C}(A\& B,C) &=& \mathcal{G}(!(A\& B),C) \\
&=& \mathcal{G}({!A}\otimes {!B}),C) \\
&\cong& \mathcal{G}({!A}, {!B} \multimap C) \qquad  \mbox{($\mathcal{G}$ is a closed monoidal category)}\\
&=& \mathcal{C}(A, {!B} \multimap C)
\end{eqnarray*}
Hence $\mathcal{C}$ is a cartesian closed category. Moreover $\mathcal{C}_i$ and $\mathcal{C}_b$
are sub-cartesian closed caterogies of $\mathcal{C}$ and $\mathcal{C}_{ib}$ is as sub-cartesian closed category
of each of $\mathcal{C}$, $\mathcal{C}_i$ and $\mathcal{C}_b$.



\subsubsection{Order enrichment}

Strategies can be ordered using the inclusion ordering.
The set of strategies on a given game $A$ is a pointed directed complete partial order under this ordering: the
least upper bounds is the union of two strategies and the least element is the empty strategy $\{ \epsilon \}$.

The category  $\mathcal{C}$ and  $\mathcal{G}$ are cpo-enriched.





directe It is possible to define an order on strategies


\subsection{Arena of order at most 2}
In this section, we consider a restricted class of arena and prove a
property on the games played on these arenas.

The height of the arena is the length of the longest sequence of moves
$m_1 \ldots m_h$ in $M$ such that $m_1 \vdash m_2 \vdash \ldots \vdash m_h$.

The order of an arena $\langle M, \lambda, \vdash \rangle$ is defined to be
$h-2$ where $h$ is the height of the forest of trees $(M, \vdash)$.


\begin{lem}[Pointers are superfluous up to order 2]
Let $A$ be the arena of order at most 2. Let $s$ be a justified sequence of moves in the arena $A$ satisfying
 alternation, visibility and well-bracketing then
the pointers of the sequence $s$ can be reconstructed uniquely.
\end{lem}



\begin{proof}
In the graphic representation of the arena, we display the sub-arena by decreasing order of sub-arena order.
It is safe to do so since in the definition of the forest of tree of an arena, the children nodes
are not ordered.

Let $A$ be an arena of order 2. We assume that $A$ has only one root. The arena $A$ has therefore the following shape:
\begin{center}
\
  \pstree[levelsep=6ex]
    { \TR{$q$} }
    {
\SubTree{$T_1$} \SubTree[linestyle=none]{$\ldots$} \SubTree{$T_n$}
    \TR{$a_1$} \TR{$a_2$} \TR{\ldots} }
\end{center}

where each triangle $T_i$ represents an arena of order 0 or 1.

We will see that the following proof can easily be adapted to take into account the general case of forest arenas (multiple roots).

We write $I_k$, for $k=0$ or $1$, the set of indices $i$ such that the arena $T_i$ has order $k$:
$$I_k = \{ i \in 1.. n\ |\ \order{T_i} = k \}$$

Here is a graphic representation of the arenas $T_i$ for $i \in I_0$ and $T_j$ for $j \in I_1$:
\begin{center}
\
  \pstree[levelsep=6ex]
    {\TR{$q^i$}}
    { \TR{$a_1^i$} \TR{$a_2^i$} \TR{\ldots} }
\hspace{2cm}
  \pstree[levelsep=6ex]
    { \TR{$p^j$} }
    {
      \pstree[levelsep=6ex]
        { \TR{$q^j$} }
        { \TR{$a_1^j$} \TR{$a_2^j$} \TR{\ldots} }
      \TR{$b_1^j$} \TR{$b_2^j$} \TR{\ldots}
    }
\end{center}



For any justified sequence of moves $u$, we write $?(u)$ for the
subsequence of $u$ consisting of the questions in the sequence $u$
that are still pending at the end of the sequence.

Let $L$ be the following language $L = \{\ p^i q^i\ | \ i \in I_1
\}$. We consider the following cases:

\begin{center}
\begin{tabular}{c|c|l|l}
Case & $\lambda_{OP}(m)$ & $?(u) \in$ & condition \\ \hline
0 & O & $\{ \epsilon \}$ \\
A & P & $q$ \\
B & O & $q \cdot L^* \cdot p^i$     & $i \in I_1$ \\
C & P & $q \cdot L^* \cdot p^i q^i$ & $i \in I_1$ \\
D & O & $q \cdot L^* \cdot q^i$      & $i \in I_0$ \\
\end{tabular}
\end{center}

We use the notation $\hat{s}$ to denote a legal and well-bracketed
\emph{justified} sequence of moves and $s$ to denote the same
sequence of moves with pointers removed.

Note that the well-bracketing condition already tells us how to
uniquely recover the pointers for P answer moves: a P-answers points
to the last pending question having the same tag. However for O
answers, we will see that the visibility condition already ensures
the unique recoverability of the pointer and that the
well-bracketing condition is not needed.


We prove by induction on the sequence of moves $u$ that $?(u)$
corresponds to either case 0, A, B, C or D and that the pointers in
$u$ can be recovered uniquely.

\textbf{Base cases:}

If $u$ is the empty sequence $\epsilon$ then there is no pointer to
recover and it corresponds to case 0.

If $u$ is a singleton then it must be the initial question $q$ and
there is not pointer to recover. This corresponds to case A.

\textbf{Step case:}

Consider a legal well-bracketed justified sequence $\hat{s}$ where
$s = u \cdot m$ and $m \in M_A$. The induction hypothesis tells us
that the pointers of $u$ can be recovered (and therefore the P-view
or O-view at that point can be computed) and that $u$ corresponds to
one of the cases 0,A,B,C or D.

We proceed by case analysis on $u$:

\begin{description}

\item[case 0] This case cannot happen because $?(u) = \epsilon$ ($u$ is a complete play) implies that there cannot be any further move $m$.

Indeed the visibility condition implies that $m$ must point to a
P-question in the O-view at that point. But since $u$ is a complete
play, the O-view is $\oview{\hat{u}} = q a$ which does not contain
any P-question. Hence the move $m$ cannot be justified and is not
valid.


\item[case A] $?(u) = q$ and the last move $m$ is played by P.
    There are several cases:
    \begin{itemize}
    \item $m$ is an answer $a_k$ (to the initial question
    $q$) for some $k$, then $m$ points to $q$:

    $\hat{s} = \justseq{ q & \ldots & m \pointto{ll}}$

    and $?(s) = \epsilon$ therefore $s$ correspond to the case 0 (complete play).

    \item $m = q^i$ where $q^i$ is an order 0 question ($i \in I_0$).
    Then $q^i$ points to the initial question $q$ and $s$ falls into category D.

    \item $m = p^i$, a first order question, then $p^i$ points to $q$,

    $?(s)= q p^i$ and it is O's turn after $s$ therefore $s$ falls into category B.

    \end{itemize}


\item[case B] $?(u) \in q \cdot L^* \cdot p^i$ where $i \in I_1$ and O plays the move $m$.

We now analyse the different possible O-moves:
\begin{itemize}
\item Suppose that O gives the (tagged) answer $b^j$ for some $j \in I_1$ then
the visibility condition constraints it to point to a question in
the O-view at that point.

We remark that the last move in $\hat{u}$ must be $p^i$. Indeed,
suppose that there is a move $x \in M_A$ such that $\hat{u} =
\justseq{q & \ldots & p^i\ x \pointto{ll}}$ then by visibility, the
O-move $x$ should points to a move in the O-view a that point. The
O-view is $q p^i$, therefore $x$ can only points to $p^i$. But then,
$p^i$ is not a pending question in $s$ which is a contradiction.


Therefore $\oview{\hat{u}} = \oview{ \justseq{ q & \ldots & p^i
\pointto{ll}} } = q p^i$.

Hence $b^j$ can only point to $p^i$ (and therefore $i=j$).

We then have $?(s) = ?(u \cdot b^i) \in  q \cdot L^*$ which is
covered by case A and C.

\item The only other possible O-move is $q^i$ which, again by the visibility condition, points necessarily
to the previous move $p^i$. We then have $?(s) = ?(u \cdot q^i) \in
q \cdot L^* \cdot p^i q^i$. This falls into category C.

\end{itemize}

\item[case C] $?(u) \in q \cdot L^* \cdot p^i q^i$ where $i \in I_1$ and the move $m$ is played by $P$.

Suppose $m$ is an answer, then the well-bracketing condition imposes
to answer to $q^i$ first. The move $m$ is therefore an integer $a^i$
pointing to $q^i$. We then have $?(s) = ?(u \cdot a^i) \in  q \cdot
L^* \cdot p^i$. This correspond to case B.


Suppose $m$ is a question then there are two cases:
\begin{itemize}
\item $m = q^j$ with $j \in I_0$, the pointer goes to the initial question $q$ and $s$ falls into category D.
\item $m = p^j$ with $j \in I_1$, the pointer goes to the initial question $q$ and $s$ falls into category B.
\end{itemize}

\item[case D] $?(u) \in q \cdot L^* \cdot q^i$ where $i \in I_0$ and the move $m$ is played by $O$.

    The same argument as in case B holds. However there is now another possible move:
    the answer $m = a^i_k$ for some $k$.  This moves can only points to
    $q^i$ (this is the only pending question tagged by $i \in I_0$).

    Then $?(\hat{s}) = ?(\hat{u}\cdot a^i_k) = ?(\justseq{ q & \ldots & q^i \pointto{ll} & \ldots & a^i_k \pointto{ll}}) \in q \cdot L^* $ therefore $s$ falls either into category A or C.

\end{description}

This completes the induction.

How to generalize the proof to arenas that have multiple roots
(forest arenas)? In fact there is no ambiguity since all the moves
are implicitly tagged according to the arena that they belong to.
Therefore in the induction, it suffices to ignore the moves that
belong to another tree (as if they were part of a different game
played in parallel).


\end{proof}


\subsection{Pointer-less strategies}
\label{subsec:ptrless_strat}

Up to order 2, the semantics of PCF terms is entirely defined by
pointer-less strategies. In other words, the pointers can be
uniquely reconstructed from any non justified sequence of moves
satisfying the visibility and well-bracketing condition.

At level 3 however, pointers cannot be omitted in general. Here is an example
taken from \cite{abramsky:game-semantics} illustrating this. Consider the
following two terms of type $((\nat \typar \nat) \typar \nat) \typar
\nat$:

$$M_1 = \lambda f . f (\lambda x . f (\lambda y .y ))$$
$$M_2 = \lambda f . f (\lambda x . f (\lambda y .x ))$$

We assign tags to the types in order to identify in which arena the
questions are asked: $((\nat^1 \typar \nat^2) \typar \nat^3) \typar
\nat^4$. Consider now the following pointer-less sequence of moves
$s = q^4 q^3 q^2 q^3 q^2 q^1$. It is possible to retrieve the
pointers of the first five moves but there is an ambiguity for the
last move: does it point to the first or second occurrence of $q^2$
in the sequence $s$?

Note that the visibility condition does not eliminate the ambiguity,
since the two occurrences of $q^2$ both appear in the P-view at that
point (after recovering the pointers of $s$ up to the second last
move we get:
$$s = \rnode{q4}{q}^4
\rnode{q3}{q}^3
\rnode{q2}{q}^2
\rnode{q3b}{q}^3
\rnode{q2b}{q}^2
\rnode{q1}{q}^1
\bkptrc{q3}{q4}
\bkptrc{q2}{q3}
\bkptrc[ncurv=0.6]{q3b}{q4}
\bkptrc{q2b}{q3b}$$

 therefore the P-view of $s$ is $s$ itself.)

In fact these two different possibilities correspond to two
different strategies. Suppose that the link goes to the first
occurrence of $q^2$ then it means that the proponent is requesting
the value of the variable $x$ bound in the subterm $\lambda x . f (
\lambda y. ... )$. If P needs to know the value of $x$, this is
because P is in fact following the strategy of the subterm $\lambda
y . x$. And the entire play is part of the strategy $\sem{M_2}$.

Similarly, if the link points to the second occurrence of $q^2$ then
the play belongs to the strategy $\sem{M_1}$.

\section{Game model for PCF}
\subsection{Syntax of the PCF language}
PCF is a simply-type $\lambda$-calculus with the following
additions: integer constants  (of ground type), first-order
arithmetic operators, if-then-else branching, and the recursion
combinator $Y_A : (A\rightarrow A)\rightarrow A$ for any type $A$.

The types of PCF are given by the following grammar:
$$ T ::= \texttt{exp}\ |\ T \rightarrow T$$

The following grammar gives the structure of terms:
\begin{eqnarray*}
 M ::= x\ |\ \lambda x :A . M \ |\ M M \ |\ \\
\ |\ n \ |\ \texttt{succ } M \ |\  \texttt{pred } M \\
\ |\ \texttt{cond } M M M \ |\ \texttt{Y}_A\ M
\end{eqnarray*}

where $x$ ranges over a set of countably many variables and $n$
ranges over the set of natural numbers.

Terms are generated according to the formation rules given in table
\ref{tab:pcf_formrules} where the judgement is of the form $ \Gamma  \vdash M : A$.

\begin{table}[htbp]
$$ (var) \rulef{}{x_1:A_1, x_2:A_2, \ldots x_n : A_n  \vdash x_i : A_i}\ i \in 1..n$$
$$ (app) \rulef{\Gamma \vdash M : A\rightarrow B \qquad \Gamma \vdash N:A}{\Gamma \vdash M\ N : B}
\qquad (abs) \rulef{\Gamma, x:A \vdash M : B}{\Gamma \vdash \lambda x :A . M : A\rightarrow B}$$

$$ (const) \rulef{}{\Gamma \vdash n :\texttt{exp}}
\qquad (succ) \rulef{\Gamma \vdash M:\texttt{exp} }{\Gamma \vdash \texttt{succ}\ M:\texttt{exp}}
\qquad (pred) \rulef{\Gamma \vdash M:\texttt{exp} }{\Gamma \vdash \texttt{pred}\ M:\texttt{exp}}$$

$$
(cond) \rulef{\Gamma \vdash M : exp \qquad \Gamma \vdash N_1 : exp \qquad \Gamma \vdash N_2 : exp }{\Gamma \vdash \texttt{cond}\ M\ N_1\ N_2}
\qquad  (rec) \rulef{\Gamma \vdash M : A\rightarrow A }{ \Gamma \vdash Y_A M : A}$$

\caption{Formation rules for PCF terms}
\label{tab:pcf_formrules}
\end{table}

\subsection{Operational semantics of PCF}

We give the big-step operational semantics of PCF. The notation $M \eval V$ means
that the closed term $M$ evaluates to the canonical form $V$. The canonical forms are given by the following
grammar:
$$V ::= n\ |\ \lambda x. M$$
In other word, a canonical form is either a number or a function.

The operational semantics is given for closed terms therefore the context $\Gamma$ is not present in
the evaluation rules.

The full operational semantics is given in table \ref{tab:bigstep_pcf}.

\begin{table}[htbp]
$$\rulef{}{V \eval V} \quad \mbox{ provided that $V$ is in canonical form.} $$

$$ \rulef{M \eval \lambda x. M' \quad M'\subst{x}{N}}{M N \eval V}$$

$$\rulef{M \eval n}{\texttt{succ}\ M \eval n+1}
\qquad \rulef{M \eval n+1}{\texttt{pred}\ M \eval n}
\qquad \rulef{M \eval 0}{\texttt{pred}\ M \eval 0}$$

$$\rulef{M \eval 0 \quad N_1 \eval V}{\texttt{cond}\ M N_1 N_2  \eval V}
\qquad
 \rulef{M \eval n+1 \quad N_2 \eval V}{\texttt{cond}\ M N_1 N_2  \eval V}$$

$$\rulef{M (\mathrm{Y} M) \eval V }{\texttt{Y} M \eval V}$$
\label{tab:bigstep_pcf}
\caption{Big-step operational semantics of PCF}
\end{table}



\section{Idealized Algol (IA)}
\label{sec:ia}

\subsection{The syntax of IA}
IA is an extension of PCF introduced by J.C. Reynold in
\cite{Reynolds81}. It adds imperative features such as local variables and sequential composition.

The description of the language that we give here follows the one of \cite{abramsky:game-semantics}.

On top of \texttt{exp}, PCF has the following two new types:
 \texttt{com} for commands and \texttt{var} for variables.

There is a constant \texttt{skip} of type \texttt{com} which corresponds to the command that do
nothing. Commands can be composed using the sequential composition operator \texttt{seq}.
Local variable are declared using the \texttt{new} operator, variable content is written
using \texttt{assign} and retrieved using \texttt{deref}.

The new formations rules are given in table \ref{tab:ia_formrules}.

\begin{table}[htbp]
$$ \rulef{\Gamma \vdash M : \texttt{com} \quad \Gamma \vdash N :A}
    {\Gamma \vdash \texttt{seq}_A \ M\ N\ : A} \quad A \in \{ \texttt{com}, \texttt{exp}\}$$

$$ \rulef{\Gamma \vdash M : \texttt{var} \quad \Gamma \vdash N : \texttt{exp}}
    {\Gamma \vdash \texttt{assign}\ M\ N\ : \texttt{com}}
\qquad
 \rulef{\Gamma \vdash M : \texttt{var}}
    {\Gamma \vdash \texttt{deref}\ M\ : \texttt{exp}}$$

$$ \rulef{\Gamma, x : \texttt{var} \vdash M : A}
    {\Gamma \vdash \texttt{new } x \texttt{ in } M} \quad A \in \{ \texttt{com}, \texttt{exp}\}$$

$$ \rulef{\Gamma \vdash M_1 : \texttt{exp} \rightarrow \texttt{com} \quad \Gamma \vdash M_2 : \texttt{exp}}
    {\Gamma \vdash \texttt{mkvar } M_1\ M_2\ : \texttt{var}}$$

\caption{Formation rules for IA terms}
\label{tab:ia_formrules}
\end{table}

If $\vdash M : A$ (i.e. $M$ can be formed with an empty context), we say that $M$ is a close term.

\subsection{Operational semantics}

In IA the semantics is given in a slightly different form from PCF.
In PCF, the evaluation rules were given for closed terms only. Suppose that we
proceed the same way for IA and consider the evaluation rule for the $\texttt{new}$ construct:
the conclusion is $\texttt{new } x:=0 \texttt{ in } M$ and the premise
is an evaluation for a certain term constructed from $M$, more precisely the term $M$
where \emph{some} occurrences of $x$ are replaced by the value $0$.
Because of the presence of the \texttt{assign} operator, we cannot simply replace all
the occurrences of $x$ in $M$ (the required substitution is  more complicated
than the substitution used for beta-reduction).


Therefore, instead of giving the semantics for closed term we consider terms
whose free variables are all of type \texttt{var}. These free variables are ``closed'' by mean of
stores. A store is a function mapping free variables of type \texttt{var} to natural numbers.
Suppose $\Gamma$ is a context containing only variable of type \texttt{var}, then we say that
$\Gamma$ is a \texttt{var}-context. A store whose domain $\Gamma$ is called a $\Gamma$-store.

The notation $s\ |\ x \mapsto n$ refers to the store that maps $x$ to $n$
and otherwise maps variables according to the store $s$.


The canonical forms for IA are given by the grammar:
$$ V ::= n\ |\ \lambda x. M\ |\ x\ |\  \texttt{mkvar} M N$$

where $n \in \nat$ and $x:var$.


A program is now defined by a term together with a $\Gamma$-store such that $\Gamma \vdash M : A$.
The evaluation semantics is expressed by the judgment form
$$s,M \eval s', V$$
where $s$ and $s'$ are $\Gamma$-stores,
$\Gamma \vdash M : A$ and $\Gamma \vdash V : A$ where $V$ is in canonical form.

The operational semantics for IA is given by the rule of PCF (table \ref{tab:bigstep_pcf})
together with the rules of table \ref{tab:bigstep_ia} where the following abbreviation is used:
$$ \rulef{M_1 \eval V_1 \quad M_2 \eval V_2}{M \eval V} \qquad \mbox{for} \qquad
  \rulef{s,M_1 \eval s',V_1 \quad s', M_2 \eval s'',V_2 }{s,M \eval s'',V}
$$


\begin{table}[htbp]
$$\mbox{\textbf{Sequencing }}
    \rulef{M \eval \iaskip \quad N \eval V}{\texttt{seq } M\ N \eval V}
$$

$$\mbox{\textbf{Variables }}
    \rulef{s,N \eval s',n \quad s',M \eval s'',x}{s, \assign\ M\ N \eval (s''\ |\ x \mapsto n),\iaskip}
\qquad
    \rulef{s,M \eval s',x }{s, \deref\ M \eval s',s'(x)}$$

$$\mbox{\texttt{\textbf{mkvar}}}
    \rulef{N \eval n \quad M \eval \texttt{mkvar } M_1\ M_2 \quad M_1\ n \eval \iaskip}
    {\assign\ M\ N \eval \iaskip}
\qquad
    \rulef{N \eval \texttt{mkvar } M_1\ M_2 \quad M_2\ \eval n}
    {\deref\ M \eval n}
$$

$$\mbox{\textbf{Block}}
    \rulef{(s\ |\ x \mapsto 0),M \eval (s'\ |\ x \mapsto n),V }
    {s, \texttt{new } x \texttt{ in } M \eval s',V}
$$

\label{tab:bigstep_ia}
\caption{Big-step operational semantics of IA}
\end{table}

\subsection{Game semantics}

As we have seen in section \ref{sec:catgames}, games and strategies
form a cartesian closed category, therefore games can model the simply-typed $\lambda$-calculus. Let us first
explain how this is achieved before extending the model to PCF and IA.

\subsubsection{Simply typed $\lambda$-calculus}

In the cartesian closed category $\mathcal{C}$, the objects are the arenas and the morphisms are the strategies.

In the games that we describe here, the Opponent represents the environment while
the Proponent plays according to a strategy imposed by the program itself.


Given a simple type $A$, we will model it as an arena $\sem{A}$.
A context $\Gamma = x_1 :A_1, \ldots x_n:A_n$ will be mapped to the arena
$\sem{\Gamma} = \sem{A_1} \times \ldots \times \sem{A_n}$ and a term $\Gamma \vdash M : A$
will be modeled by a strategy on the arena $\sem{\Gamma} \rightarrow \sem{A}$.
Since $\mathcal{C}$ is cartesian closed, there is is a terminal object $\textbf{1}$ (the empty arena) that
models the empty context ($\sem{\Gamma} = \textbf{1}$).


The base type \texttt{exp} is interpreted by the following flat arena of natural numbers noted $\nat$:
$$  \pstree[levelsep=6ex]
    {\TR[name=R]{q}}
    { \TR{1} \TR{2} \TR{\ldots}
    }
$$
In this arena, there is only one question: the initial O-question, P can then answer it by playing a natural number $i \in \nat$.
There are only two kinds strategy on this arena:
\begin{itemize}
\item the empty strategy where P never answer the initial question. This corresponds to a non terminating computation;
\item the strategies where P answers by playing a number $n$. This models the constants of the language.
\end{itemize}

Given the interpretation of base types, we define the interpretation of $A\rightarrow B$ by induction:
$$\sem{A \rightarrow B} = \sem{A} \Rightarrow \sem{B}$$

where the operator $\Rightarrow$ denotes the arena construction $!A
\multimap B$ which exists because $\mathcal{C}$ is cartesian closed.

Graphically if we represent the arena $A$ and $B$ by two triangles, the arena for $A \rightarrow B$ would be represented by:
\begin{center}
\psset{xunit=.5pt,yunit=.5pt,runit=.5pt}
\begin{pspicture}(150,80)
\rput[tr](150,80){ \pnode(27,40){a} \pstribox{A} }
\rput[bl](0,0){ \pnode(27,40){b} \pstribox{B} }
\ncline{->}{a}{b}
\end{pspicture}
\end{center}


Variables are interpreted by projection:
$$\sem{x_1 : A_1, \ldots, x_n:A_n \vdash x_i : A_i} = \pi_i : \sem{A_i} \times \ldots \times \sem{A_i} \times \ldots \times \sem{A_n} \rightarrow  \sem{A_i}$$

The abstraction $\Gamma \vdash \lambda x :A.M : A \rightarrow B$ is modeled by a strategy on the arena
$\sem{\Gamma} \rightarrow (\sem{A}\Rightarrow\sem{B})$. This strategy is obtain by using the currying operator of the
cartesian closed category:
$$\sem{\Gamma \vdash \lambda x :A.M : A \rightarrow B} = \Lambda( \sem{\Gamma, x :A \vdash M : B})$$

The application $\Gamma \vdash M N$ is modeled using the evaluation map $ev_{A,B} : (A\Rightarrow B)\times A \rightarrow B$:

$$\sem{\Gamma \vdash M N} = \langle \sem{\Gamma \vdash M, \Gamma \vdash N} \rangle; ev_{A,B}$$


\subsubsection{PCF}

We now show how to model the PCF constructs in the game semantics setting.
In the following, the sub-arena of a game are tagged in order to distinguish identical arenas that are present in different components of the game.
Moves are also tagged in the exponent in order to identify the sub-arena in which moves are played. We will omit the pointers in the play
when they are not essential for the understanding of the model (moreover we will see later on that under certain assumptions
up to order 2, pointers can be recovered uniquely).

The successor arithmetic operator is modeled by the following strategy on the arena $\nat^1 \Rightarrow \nat^0$:
$$\sem{\texttt{succ}} = \{q^0 \cdot q^1 \cdot n^1 \cdot (n+1)^0\ |\ n \in \nat \}$$

The predecessor arithmetic operator is denoted by the strategy
$$\sem{\texttt{pred}} = \{q^0 \cdot q^1 \cdot n^1 \cdot (n-1)^0\ |\ n >0 \} \union \{ q^0 \cdot q^1 \cdot 0^1 \cdot 0^0 \} $$

Then given a term $\Gamma \vdash \texttt{succ} M : \texttt{exp}$ we define:
$$\sem{\Gamma \vdash \texttt{succ } M : \texttt{exp}} = \sem{\Gamma \vdash M} ; \sem{\texttt{succ}} $$
$$\sem{\Gamma \vdash \texttt{pred } M : \texttt{exp}} = \sem{\Gamma \vdash M} ; \sem{\texttt{pred}} $$


The conditional operator is denoted by the following strategy on the arena $\nat^3 \times \nat^2 \times \nat ^1 \Rightarrow \nat^0$:
$$\sem{\texttt{cond}} =
    \{ q^0 \cdot q^3 \cdot 0 \cdot q^2 \cdot n^2 \cdot n^0 \ | \ n \in \nat \}
    \union
    \{ q^0 \cdot q^3 \cdot m \cdot q^2 \cdot n^2 \cdot n^0 \ | \ m >0, n \in \nat \}
    $$


Given a term $\Gamma \vdash \texttt{cond} M\ N_1\ N_2$ we define:
$$\sem{\Gamma \vdash \texttt{cond} M\ N_1\ N_2} =
\langle \sem{\Gamma \vdash M}, \sem{\Gamma \vdash N_1}, \sem{\Gamma \vdash N_2} \rangle ; \sem{\texttt{cond}}$$


The interpretation of the \texttt{Y} combinator is a bit more complicated.

Consider the term $\Gamma \vdash M : A \rightarrow A$, its semantics $f$ is a strategy on $\sem{\Gamma} \times \sem{A} \rightarrow \sem{A}$.
We define the chain $g_n$ of strategies on the arena $\sem{\Gamma} \rightarrow \sem{A}$ as follows:
\begin{eqnarray*}
g_0 &=& \perp \\
g_{n+1} &=&  F(g_n) = \langle id_{\sem{\Gamma}}, g_n\rangle ; f
\end{eqnarray*}

where $\perp$ denotes the empty strategy $\{ \epsilon \}$.

It is easy to see that indeed the $g_n$ forms a chain.
We define $\sem{\texttt{Y } M}$ to be the least upper bound of the chain $g_n$
(i.e. the  least fixed point of $F$). Its existence is guaranteed by the fact that
the category of games is cpo-enriched.

\subsubsection{IA}

It is easy to check that all the strategies given until now are well-bracketed and innocent.
From now on, we will only require well-bracketing and we will introduce strategies that are
not innocent. This is a necessity if we want to give a model of memory cells that correspond
to variables. The intuition behind this fact is that a cell needs to remember what was the last value written in it
in order to be able to return it when it is read, and this can only be done by looking at the whole history of moves,
not only those present in the P-view.





\subsection{Full-abstraction}
In this section we recall the standard full abstraction result proved in  \cite{abramsky94full}
and \cite{hylandong_pcf}.

A context noted $C[-]$ is a term containing a hole denoted by $-$. If $C[-]$ is a context then $C[A]$ denotes the term obtained
after replacing the hole by the term $A$.

\begin{dfn}[Observational preorder]
Let $\vdash M : A$ and $\vdash N : A$ be two closed terms. We define the relation $\sqsubseteq$ as follows:


$M \sqsubseteq N$ if and only if for all context $C[-]$ such that $C[M]$ and $C[M]$ are well-formed terms if
$C[M] \eval$ then $C[N] \eval$.
\end{dfn}


\begin{lem}[Soundness for PCF terms] Let $M$ be a PCF term.
If $M \eval V$ then $\sem{M} = \sem{V}$.
\end{lem}

\begin{lem}[Soundness for IA terms] Let $\Gamma \vdash M : A$ be an IA term and a $\Gamma$ store $s$.
If $s,M \eval s',V$ then the plays of $\sem{s,M} : I \multimap A \otimes !\Gamma$ which begin
with a move of $A$ are identical to those of $\sem{s',V}$.
\end{lem}


\begin{lem}[Computational adequacy for PCF terms]
All PCF terms are computable. (i.e. $\sem{M} \neq \perp$ implies $M \eval$)
\end{lem}

\begin{lem}[Computational adequacy for IA terms]
All IA terms are computable. (i.e. $\sem{M} \neq \perp$ implies $M \eval$)
\end{lem}


The following result follows from soundness and computational adequacy of the model.
\begin{prop}[Inequational soundness]
\label{prop:ineqsoundness}
Let $M$ and $N$ be two closed terms then
$$\sem{M} \subseteq \sem{N} \implies  M \sqsubseteq N $$
\end{prop}

\begin{prop}[Definability]
\label{prop:definability}
Let $\sigma$ be a compact well-bracketed on a game $A$ denoting a IA type. Then there is
an IA-term $M$ such that $\sem{M} = \sigma$.
\end{prop}

The final standard result of game semantics can then be proved using proposition \ref{prop:ineqsoundness} and \ref{prop:definability}:
\begin{thm}[Full abstraction]
Let $M$ and $N$ be two closed IA-terms.
$$\sem{M} \precsim_b \sem{N} \ \iff \ M \sqsubseteq N$$
\end{thm}

where $\precsim_b$ denotes the intrinsic preorder of the category $\mathcal{C}_b$.


\subsection{Call-by-Value first-order Idealized Algol}

Game semantics for call-by-value programming Language.
