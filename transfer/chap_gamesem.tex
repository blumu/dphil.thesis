\chapter{Game semantics}

The aim of this chapter is to introduce game semantics. It starts
with a history of game semantics and a presentation of the full
abstraction problem for PCF which has been solved using game
semantics. It then goes on by introducing the basic notions of game
semantics and by giving a categorical interpretation of games.
Finally we show how games are used to define a syntax-independent
model of programming languages like PCF and Idealized Algol (IA).

This chapter is largely based on the tutorial by Samson Abramsky
tutorial on Game Semantics \cite{abramsky:game-semantics-tutorial}.
Many details and proofs will be omitted and we refer the reader to
\cite{hylandong_pcf, abramsky94full} for a complete description of
game semantics.

\section{History}

\subsection{Game semantics}

In the 1950s, Paul Lorenzen invented Game semantics as a new
approach to study semantics of intuitionistic logic \citep{lor61}.
In this setting, the notion of logical truth is modeled using game
theoretic concepts such as the existence of winning strategy.

Four decade later, game semantics is used to prove the full
completeness of Multiplicative Linear Logic (MLL)
\citep{abramsky92games,HO93a}. Shortly after, a connection between
games and linear logic has been established. Game semantics has then
been used as a new paradigm to study formal models of programming
languages. The idea is to model the execution of a program as a game
played by two protagonists: the Opponent representing the
environment and the Proponent representing the system. The meaning
of the program is then modeled by a strategy for the Proponent.


Subsequently, these game-based model have been used to give a
solution to the long-standing problem of ``Full abstraction of PCF''
\citep{abramsky94full, hylandong_pcf,Nickau:lfcs94}.

Based on that major result, and in a more applied direction, games
have been used as a new tool for software verification
\cite{ghicamccusker00}. This open-up a new field called Algorithmic
Game Semantics \citep{Abr02}.




\subsection{Model of programming languages}

Before the 1980s, there were many approaches to define models for
programming languages. Among the successful ones, there were the
axiomatic, operational and denotational semantics:
\begin{itemize}
\item Operational semantics gives a meaning to a program by describing the
behaviour of a machine executing the program. It is defined formally
by giving a state transition system.
\item Axiomatic semantics defined the behaviour of the program
with axioms and is used to prove program correctness by static
analysis of the code of the program.
\item The denotational semantics approach consists in mapping a program to a mathematical structure
having good properties such as compositionality. This mapping is
achieved by structural induction on the syntax of the program.
\end{itemize}

In the 1990s, three different independent research groups: Samson
Abramsky, Radhakrishnan Jagadeesan and Pasquale Malacaria
\citep{abramsky94full}, Martin Hyland and Luke Ong
\citep{hylandong_pcf} and Nickau \citep{Nickau:lfcs94} have
introduced game semantics, a new kind of semantics, in order to
solve a long standing problem in the semanticists community :
finding a fully abstract model for PCF.

\subsection{The problem of full abstraction for PCF}

PCF is a simple programming language introduced in a classical paper
by Plotkin ``LCF considered as a programming language''
(\cite{DBLP:journals/tcs/Plotkin77}). PCF is based on LCF, the Logic
of Computable Functions devised by Dana Scott in \cite{scott_lcf}.
It is a simply typed lambda calculus extended with arithmetic
operators, conditional and recursion.

The problem of the Full Abstraction for PCF goes back to the 1970s.
In \citep{scott93}, Scott gave a model for PCF based on domain
theory. This model gives a sound interpretation of observational
equivalence: if two terms have the same domain theoretic
interpretation then they are observationally equivalent. However the
converse is not true: there exist two PCF terms which are
observationally equivalent but have different domain theoretic
denotation. We say that the model is not fully abstract.

The key reason why the domain theoretic model of PCF is not fully
abstract is that the parallel-or operator defined by the following
truth table
\begin{center}
\begin{tabular}{l|lll}
p-or  & $\bot$ & tt & ff \\ \hline
$\bot$ & $\bot$ & tt & $\bot$\\
tt & tt & tt & tt\\
ff & $\bot$ & tt & ff\\
\end{tabular}
\end{center}
is not definable as a PCF term! It is possible to create two
different PCF terms that always behave the same except when they are
apply to a term computing p-or. Since p-or is not definable in PCF,
these two terms will have the same denotation. This implies that the
model is not fully abstract.


It is possible to patch PCF by adding the operator $p-or$, the
resulting language ``PCF+p-or'' becomes fully-abstracted by Scott
domain theoretic model \citep{DBLP:journals/tcs/Plotkin77}. However
the language we are now dealing with is strictly more powerful than
PCF, it allows parallel execution of commands whereas PCF only
permits sequential execution.

Another approach consists in eliminating  the undefinable elements
(like p-or) by strengthening the conditions on the function used in
the model. This approach has been followed by Berry in
\cite{berry-stable,gberry-thesis} where he gives a model based on
stable functions, a class of function smaller than the class of
strict and continuous function. Unfortunately this approach did not
succeed.

The only successful approaches to obtain a fully abstract model for
PCF were the ones taken by Ambramsky, Jagadeesan and Malacaria
\citep{abramsky94full}, Hyland and Ong \citep{hylandong_pcf} and
Nickau \citep{Nickau:lfcs94}, all based on game semantics.

This result has then been adapted to other varieties of programming
paradigm including languages with stores (Idealized Algol),
call-by-value \citep{honda99gametheoretic, abramsky98callbyvalue}
and call-by-name, general referencees
\citep{DBLP:conf/lics/AbramskyHM98}, polymorphism
\citep{DBLP:journals/apal/AbramskyJ05}, control features
(continuation and exception), non determinism, concurrency. In all
these cases, the game semantics model led to a syntax-independent
fully abstract model of the corresponding language.

\section{Games}
\label{sec:catgames}

We now introduce formally the notion of game that will be used in
the following section to give a model of the programming languages
PCF and Idealized Algol. The definitions are taken from
\cite{abramsky:game-semantics-tutorial, hylandong_pcf,
abramsky94full}.

The games we are interested in are two-players games. The players are named O for Opponent and P for Proponent.
The game played by O and P is constraint by the \emph{arena}.
The arena defines the possible moves of the game. By
analogy with real board games, the arena represents the board
together with the rules that tell players how they can make their moves
on the board. The analogy with board game will not go beyond that.
It is better to regard our games as dialogs between two players instead: one player O
interviews another person P. P's goal is to answer the initial question asked by O.
P can also ask question to O if he needs some precision about O's initial question.
Again O can then ask further question to P. This induces a flow of questions and answers between O and P that can goes on
possibly forever. In Game semantics, the attention is given to the study of this flow of questions and answers
and the notion of winner of the game is not a concern.

\subsection{Arenas}


Our games have two kind moves in our games: the questions and the answers.
We also distinguish moves played by O and those played by P.
An arena is represented by a directed acyclic graph (DAG) whose nodes correspond
to questions moves and leaves correspond to answers moves.
It is formally defined as follows:
\begin{dfn}[Arena]
An arena is a structure $\langle M, \lambda, \vdash \rangle$ where:
\begin{itemize}
\item $M$ is the set of possible moves;
\item $(M,\vdash)$ is a directed acyclic graph;

\item $\lambda : M \rightarrow \{ O, P\} \times \{Q, A\}$ is a labeling functions indicating whether a given move
    is a question or an answer and whether it can be played by O or by P.

    $\lambda = [\lambda^{OP},\lambda^{QA}]$ where $\lambda^{OP} : M \rightarrow  \{ O, P\}$
    and $\lambda^{QA} : M \rightarrow  \{ Q, A\}$.

    \begin{itemize}
    \item If $\lambda^{OP} (m) = O$, we call $m$ and O-move otherwise $m$ is a P-move.
    $\lambda^{QA} (m) = Q$ indicates that $m$ is a question otherwise $m$ is an answer.

    \item For any leaf $l$ of the tree $(M,\vdash)$, $\lambda^{QA} (l) = A$ and for any node
    $n \in (M,\vdash)$, $\lambda^{QA} (n) = Q$.
    \end{itemize}

\item The DAG $(M,\vdash)$ respects the following condition:
    \begin{itemize}
    \item[(e1)] The roots are O-moves: for any root $r$ of $(M,\vdash)$, $\lambda^{OP} (r) = O$.
    \item[(e2)] Enablers are all questions: $m \vdash n  \imp \lambda^{QA}(m) = Q$.
    % Or more succinctly, if we write $\dashv$ the relation $\vdash^-1$: $\lambda^{QA} \left( \dashv( (\lambda^{QA})^{-1}(\{A\}) ) \right) = \{ O \}$
    \item[(e3)] A player move must be justified by a move played by the other player:
         $m\vdash n \imp \lambda^{OP}(m) \neq \lambda^{OP}(n)$.
    \end{itemize}
\end{itemize}
\end{dfn}

For commodity we write the set $\{O,P\} \times \{Q,A\}$ as $\{OQ,OA,PQ,PA\}$.
$\overline{\lambda}$ denotes the labeling function $\lambda$ with the question and answer swapped. For instance:
$$\overline{\lambda(m)} = OQ \iff \lambda(m) = PQ$$

The roots of the DAG $(M,\vdash)$ are called the \emph{initial moves}.
Other moves must be enabled by some other question move. The edges of the DAG induces the enabling relation between moves.

The simplest possible arena, written $\mathbf{1}$, is the arena with an empty set of moves.

\begin{exmp}[The flat arena]
\label{exmp:flatarena}

 Let $A$ be any countable set then the flat arena over $A$
is defined to be the arena $\langle M, \lambda, \vdash \rangle$ such
that $M$ has one move $q$ with $\lambda(q) = OQ$ and for each
element in $A$, there is a corresponding move $a_i$ in $M$ with
$\lambda(a_i) = PA$ for some $i \in \nat$. The enabling relation
$\vdash$ is defined to be $\{ q \vdash a_i \ | i \in \nat \}$.

This arena is represented by the following tree:
\begin{center}
  \pstree[levelsep=6ex]
    { \TR{$q$} }
    {    \TR{$a_1$} \TR{$a_2$} \TR{\ldots} }
\end{center}
The vertices represent the moves and the edges represent the
enabling relation.

The flat arena over $\nat$ and $\mathbb{B}$ is written
$\mathbf{int}$ and  $\mathbf{bool}$ respectively.

\end{exmp}

Once the arena has been defined, the bases of the game are set and the players have something to play with.
We now need to describe the state of the game, for that purpose
we introduce \emph{justified sequences of moves}:
\begin{dfn}[Justified sequence of moves]
A justified sequence is a sequence of moves $s$ together with an associated sequence of pointers. Any
move $m$ in the sequence that is not initial has as pointer that points to a previous move $n$ that justifies it (i.e. $n \vdash m$).
\end{dfn}
The first move of a justified sequence must be an O-move since
initial moves are all O-moves.

A justified sequence can be encoded as a sequence of pairs: a pair encodes an element of the sequence together
with an index indicating the position where the element points to.

The pointers of a justified sequences are represented with arrows.
This is an example of justified sequence of moves:
$$\rnode{q4}{q}^4
\rnode{q3}{q}^3 \rnode{q2}{q}^2 \rnode{q3b}{q}^3 \rnode{q2b}{q}^2
\rnode{q1}{q}^1 \bkptrc{q3}{q4} \bkptrc{q2}{q3}
\bkptrc[ncurv=0.6]{q3b}{q4} \bkptrc{q2b}{q3b}$$

Sequence of moves will be used to record the history of all the moves that have been played.


\vspace{18pt}
\emph{Notation:} we write $s t$ or sometimes $s \cdot t$ do denote the
sequences obtain by concatenating $s$ and $t$. The empty sequence is
written $\epsilon$.
Given a sequence $s = m_1 \cdot m_2 \ldots m_n$ we write $s_{\leq m_i}$ for $m_1 \cdot m_2 \ldots m_i$,
the prefix sequence of $s$ up to the move $m_i$. We write $s_{< m_i}$ for $m_1 \cdot m_2 \ldots m_{i-1}$.


A justified sequence has two particular subsequences called the P-view and the O-view
of the sequence. The idea is that a view describes the local context
of the game. Here is the formal definition:
\begin{dfn}[View]
Given a justified sequence of moves $s$. We define the proponent view (P-view) noted $\pview{s}$ by induction:
\begin{align*}
\pview{\epsilon} &= \epsilon \\
\pview{s \cdot m} &= \pview{s} \cdot \ m && \mbox{ if $m$ is a P-move} \\
\pview{s \cdot m} &= m && \mbox{ if $m$ is initial (O-move) } \\
\pview{ s \cdot \rnode{m}{m} \cdot t \cdot \rnode{n}{n} \bkptra{50}{n}{m} } &=
 \pview{s} \cdot \rnode{mm}{m} \cdot \rnode{nn}{n} \bkptra{70}{nn}{mm} && \mbox{ if $n$ is a non initial O-move }
\end{align*}
The O-view $\oview{s}$ is defined similarly:
\begin{align*}
\oview{\epsilon} &= \epsilon \\
\oview{s \cdot m} &= \oview{s} \cdot \ m && \mbox{ if $m$ is a O-move} \\
\oview{ s \cdot \rnode{m}{m} \cdot t \cdot \rnode{n}{n} \bkptra{50}{n}{m} } &=
 \pview{s} \cdot \rnode{mm}{m} \cdot \rnode{nn}{n} \bkptra{70}{nn}{mm} && \mbox{ if $n$ is a P-move }
\end{align*}
\end{dfn}


\subsection{Games}

Not all justified sequences will be of interest for the
games that we will use. We call \emph{legal position} justified
sequences that verify two additional conditions: alternation and
visibility. Alternation says that players O and P plays
alternatively. Visibility expresses that each non-initial move is
justified by a move situated in the local context at that point.
The visibility condition gives some coherence to the
justification pointers of the sequence.

\begin{dfn}[Legal position]
A legal position is a justified sequence of move $s$ respecting the following constraints:
\begin{itemize}
\item \emph{Alternation}: For any subsequence $m \cdot n$ of $s$, $\lambda^{OP}(m) \neq \lambda^{OP}(n)$.
\item \emph{Visibility}: For any subsequence $t m$ of $s$ where $m$ is not initial, if $m$ is a P-move then $m$ points to a move in $\pview{s}$
and if $m$ is a O-move then $m$ points to a move in $\oview{s}$.
\end{itemize}
The set of legal position of an arena $A$ is noted $L_A$.
\end{dfn}

We say that a move $n$ is hereditarily justified by a move $m$ if there is a sequence of move
$m_1, \ldots, m_q$ such that:
$$ m \vdash m_1 \vdash m_2 \vdash \ldots m_q \vdash n$$
If a move has no justification pointer, we says that it is an
\emph{initial move} (in that case it must be a root of the DAG of the arena).

Suppose that $n$ is an occurrence of a move in the sequence $s$ then
$s \upharpoonright n$ denotes the subsequence of $s$ containing all the moves hereditarily justified by $n$.
Similarly, $s \upharpoonright I$ denotes the
subsequence of $s$ containing all the moves hereditarily justified by the moves in $I$.

\begin{dfn}[Game]
A game is a structure $\langle M, \lambda, \vdash, P \rangle$ such that
\begin{itemize}
\item $ \langle M, \lambda, \vdash \rangle$ is an arena.
\item $P$ is called the set of valid positions, it is:
    \begin{itemize}
    \item a non-empty prefix closed subset of the set of legal position
    \item closed by initial hereditary filtering: if $s$ is a valid position then for any set $I$ of occurrences of initial moves
    in $s$, $s\upharpoonright I$ is also a valid position.
    \end{itemize}
\end{itemize}
\end{dfn}

\begin{exmp}  Consider the flat arena  $\mathbf{int}$.
The set of valid position $P = \{ \epsilon, q \} \union \{ q \cdot
a_i \ | i \in \nat \}$ defines a game on the arena $\mathbf{int}$.
\end{exmp}

\subsection{Constructions on games}
\label{sec:gameconstruction}

We now define game constructors that will be useful later on.

Consider the two functions $f : A \rightarrow C$ and $g : B
\rightarrow C$, we write $[f,g]$ to denote the pairing of $f$ and
$g$ defined on the direct sum $A + B$. Given a game $A$ with a set
of moves $M_A$, we use the filtering operator $s \upharpoonright A$
do denote the subsequence of $s$ consisting of all moves in $M_A$.
Although this notation conflicts with the hereditarily filtering
operator, it should not cause any confusion.

\subsubsection{Tensor product}
Given two games $A$ and $B$ we define the tensor product constructor
$A \otimes B$ as follows:
\begin{eqnarray*}
  M_{A \otimes B} &=& M_A + M_B \\
  \lambda_{A\otimes B} &=& [\lambda_A,\lambda_B] \\
  \vdash_{A\otimes B} & = & \vdash_{A}\ \union\ \vdash_{B} \\
  P_{A\otimes B} & = & \{ s \in L_{A\otimes B} | s \upharpoonright A \in P_A \wedge s \ \upharpoonright B \in P_B  \}.
\end{eqnarray*}

In particular,  $n$ is initial in $A\otimes B$ if and only if $n$ is
initial in A or B. And $m \vdash_{A\otimes B} n$  holds if and only if $m
\vdash_{A} n$ or $m \vdash_{B} n$ holds.

\subsubsection{Function space}
The game $A \multimap B$ is defined as follows:
\begin{eqnarray*}
  M_{A \multimap B} &=& M_A + M_B \\
  \lambda_{A\multimap B} &=& [\overline{\lambda_A},\lambda_B] \\
  \vdash_{A\multimap B} & = & \vdash_{A}\ \union\ \vdash_{B}\ \union\  \{ (m,n) \ |\ m \mbox{ initial in } B \wedge n \mbox{ initial in } A \} \\
  P_{A\otimes B} & = & \{ s \in L_{A\otimes B} | s \upharpoonright A \in P_A \wedge s \ \upharpoonright B \in P_B  \}.
\end{eqnarray*}

Graphically if we draw a triangle to represent an arena $A$ then the
arena for $A \multimap B$ is represented as follows:
\begin{center}
\psset{xunit=.5pt,yunit=.5pt,runit=.5pt}
\begin{pspicture}(150,80)
\rput[tr](150,80){ \pnode(27,40){b} \pstribox{B} } \rput[bl](0,0){
\pnode(27,40){a} \pstribox{A} } \ncline{->}{a}{b}
\end{pspicture}
\end{center}

\subsubsection{Cartesian product}
The game $A \& B$ is defined as follows:
\begin{eqnarray*}
  M_{A \& B} &=& M_A + M_B \\
  \lambda_{A\& B} &=& [\lambda_A,\lambda_B] \\
  \vdash_{A\& B} & = & \vdash_{A}\ \union\ \vdash_{B} \\
  P_{A\& B} & = & \{ s \in L_{A\otimes B} | s \upharpoonright A \in P_A \wedge s \ \upharpoonright B = \epsilon  \} \\
        &&   \union \{ s \in L_{A\otimes B} | s \upharpoonright A \in P_B \wedge s \ \upharpoonright A = \epsilon  \}.
\end{eqnarray*}

A play of the game $A \& B$ is either a play of $A$ or a play of $B$ whether a play
of the game $A \otimes B$ may be an interleaving of plays on $A$ and plays on $B$.

\subsection{Representation of plays}

Plays of the game are usually represented in a table diagram. The
columns of the table correspond to the different components of the
arena and each row corresponds to one move in the play. The first
row always represents an O-move, this is because O is the only
player who can open a game (since roots of the arena are O-moves).

As an example the play
$$\rnode{q1}{q}\
 \rnode{q2}{q}
 \ \rnode{a2}{8}
\  \rnode{a1}{12}
  \bkptrc{a1}{q1}
\bkptrc{a2}{q2} $$
on the
game $\textbf{int} \multimap \textbf{int} $ can be represented by
the following diagram:

\begin{center}
\begin{tabular}{cccc}
\textbf{int} & $\imp$ & \textbf{int} & \\
&& q & O\\
q  &&& P\\
8  &&& O\\
&& 12 & P
\end{tabular}
\end{center}

When it is necessary, the justification pointers of the play can also
be shown on the diagram.


\subsection{Strategy}

During a game, the player who has to play may have several choices
for his next move. A strategy is a guide telling the player which move to make when the
game is in a given position. There is no notion of winning strategy since this is
not relevant for the games that we are considering.

\subsubsection{Definition}
Formally, a strategy is a partial function mapping legal position where Proponent has to move
to P-moves:
\begin{dfn}[Strategy]
\label{dfn:strategy}
A strategy for player P on a given game $\langle M, \lambda, \vdash, P \rangle$ is a
non-empty set of even-length positions from $P$ such that:
\begin{enumerate}
\item (\emph{no unreachable position}) if $sab \in \sigma$ then $s \in \sigma$
\item (\emph{determinacy}) if $sab, sac \in \sigma$ then $b = c$  and $b$ has the same justifier as
$c$.
\end{enumerate}
\end{dfn}

The idea is that the presence of the even-length sequence $s a b$ in
$\sigma$ tells the player P that whenever the game is in position
$s$ and player O plays the move $a$ then it must respond by playing
the move $b$.

The first condition ensures that the strategy $\sigma$ only
considers positions that the strategy itself could have led to in a
previous move. The second condition in the definition requires that
this choice of move is deterministic (i.e. there is a function $f$
from the set of odd length position to the set of moves $M$ such
that $f(s a) = b$).


For any game $A$, the smallest possible strategy is the strategy
that never respond given by $\{ \epsilon \}$. It is called the
\emph{empty strategy} and denoted $\bot$.


\begin{rem}
\label{rem:atlern_strategy}
There is an alternative definition of a strategy.
If we regard a strategy as an appropriated sub-tree of the game tree then
it can be represented as the collection of all paths in this sub-tree, that is to say a certain prefix-closed set
as opposed to the ``even length prefix''-closed set used in the definition above.

If $\sigma$ denotes a strategy in the sense of definition \ref{dfn:strategy} then the corresponding strategy in the alternative definition would be
$\sigma \union \textsf{dom}(\sigma)$ where
$$\textsf{dom}(\sigma) = \{ sa \in P_A^{odd} | \exists b . sab \in \sigma \}.$$
\end{rem}


\subsubsection{Copy-cat strategy}

For any arena $A$ there is a strategy on the game $A \multimap A$
called the \emph{copy-cat strategy}. We write $A_1$ and $A_2$ to
denote the first and second copy of the arena $A$ in the game $A
\multimap A$. If $A$ is the arena $A_1$ then $A^\perp$ denotes the
arena $A_2$ and reciprocally.

Let $A$ be one of the arena $A_1$ or $A_2$. The copy-cat strategy
operates as follows: whenever P has to respond to an O-move played
in $A$, it replicates the move played by O in the arena $A^{\perp}$
after that $O$ has to respond in $A^{\perp}$ and $P$ replicates this
response in $(A^\perp)^\perp = A$ and so on and so forth.


More formally, the copy-cat strategy is defined by:
$$ \textsf{id}_A = \{ s \in P^{\textsf{even}}_{A \multimap A} \ | \ \forall t \sqsubseteq^{\textsf{even}} s\ .\ t \upharpoonright A_1 = t \upharpoonright A_2 \}$$
where $P^{\textsf{even}}_A$ denotes the valid position of even
length in the game $A$ and $t \sqsubseteq^{\textsf{even}} s$ denotes
that $t$ is an even length prefix of $s$.

The copy-cat strategy is also called \emph{identity strategy} since
it is the identity for strategy composition as we will see in the
next paragraph.

\begin{exmp} The copy-cat strategy on $\textbf{int}$ is:
$$\begin{array}{ccc}
\textbf{int} & \imp & \textbf{int} \\
&& q\\
q \\
n \\
&& n
\end{array}
$$
Note that we introduced this type of diagram to represent plays of
games but, as we can see here, the same diagrams can be used to
represent strategies when the play represented is general enough.

The copy-cat strategy on $\textbf{int} \typar \textbf{int}$ is given
by the following diagram:
$$\begin{array}{ccccccc}
(\textbf{int} & \imp & \textbf{int}) & \imp & (\textbf{int} & \imp & \textbf{int}) \\
&&&& && q\\
&& q\\
q \\
&&&& q \\
&&&& m \\
m\\
&& n \\
&&&& && n
\end{array}$$
\end{exmp}

\subsubsection{Composition}

It is well-known that any model of the simply typed lambda-calculus
is a cartesian closed category \citep{CroleRL:catt}. Games are used
to give a fully-abstract model of PCF, an extended simply typed
lambda calculus, therefore the game model should fit into a
cartesian closed category. This category will have games as objects
and strategies as morphisms. In a category, morphisms should be able
to compose together, therefore there should be an appropriate notion
of strategy composition.

Composition of strategies is an essential feature of game semantics.
As we will see in the following section, in the game model of PCF,
strategies represent programs. Therefore, strategy composition will
prove to be very useful : obtaining the model of a composed program
boils down to composing the strategies of the composing programs.

The way composition is defined for strategies is similar to
``parallel composition plus hiding'' in the trace semantics of CSP
\citep{hoare_csp}. Consider two strategies $\sigma : A \multimap B$
and $\tau : B \multimap C$ that we wish to compose.

For any sequence of moves $u$ on three arenas $A$, $B$, $C$, we call
projection of $s$ on the game $A \multimap B$ and we write $u
\upharpoonright A,B$ for the subsequence of $s$ obtained by removing
from $u$ the moves in $C$ and pointers to moves in $C$. The
projection on $B \multimap C$ is defined similarly.

The definition of the projection on $A \multimap B$ differs
slightly: $u \upharpoonright A,C$ is the subsequence of $u$
consisting of the moves from $A$ and $C$ with some additional
pointers: we add a pointer from $a \in A$ to $c\in C$ whenever $a$
points to some move $b \in B$ itself pointing to $c$. All the
pointers to moves in $B$ are removed.


First we remark that for a given legal position $s$ in the game $A
\multimap C$, there is what is called an \emph{uncovering} of $s$.
The uncovering of $s$ is the maximal justified sequence of moves $u$
from the games $A$, $B$ and $C$ such that:
\begin{itemize}
\item The sequence $s$, considered as a pointer-less sequence, is a subsequence of
$u$;
\item the projection of $u$ on the game $A \multimap B$ lies in the
strategy $\sigma$;
\item the projection of $u$ on the game $B \multimap C$
lies in the strategy $\tau$;
\item and the projection of $u$ on the game $A \multimap C$ is a subsequence of $s$ (here the term ``subsequence'' refers to the sequence of nodes together with the auxiliary sequence of pointers).
\end{itemize}
This uncovering, noted $uncover(s, \sigma, \tau)$, is
defined uniquely for given strategies $\sigma$, $\tau$ and legal
position $s$ (this is proved in part II of \cite{hylandong_pcf}).

We define $\sigma \| \tau $ to be the set of uncovering of legal
positions in $A \multimap C$:
$$ \sigma \| \tau = \{ uncover(s, \sigma, \tau) \ | \ s \mbox{ is a legal position in } A \multimap C \}$$

The composition of $\sigma$, $\tau$ is defined to be the set of
projections of uncovering of legal positions in $A \multimap C$:

\begin{dfn}[Strategy composition]
Consider $\sigma : A \multimap B$ and  $\tau : B \multimap C$ two
strategies. We define $\sigma ; \tau$ to be:
$$ \sigma ; \tau = \{ u \upharpoonright A,C \ | \ u \in \sigma \|
\tau \}$$
\end{dfn}

It can be verified that composition is well-defined and associative
\citep{hylandong_pcf} and that the copy-cat strategy $\textsf{id}_A$ is the identity for composition.

\subsubsection{Constraint on strategies}

Different classes of strategies will be considered depending on the
features of the language that we want to model. Here is a list of
common restrictions that we will consider:
\begin{itemize}
\item \emph{Well-bracketing:}
We call \emph{pending question} the last question in a sequence that has not been answered.
A strategy $\sigma$ is well-bracketed if for every play $s \cdot m \in \sigma$ where $m$ is an answer, $m$ points to the pending question in $s$.

\item \emph{History-free strategies:} a strategy is history-free if the Proponent's move at any position of the game where he has to play
is determined by the last move of the Opponent. In other words, the
history prior to the last move is ignored by the Proponent when
deciding how to respond.

\item \emph{History-sensitive strategies:} The Proponent follows a history-sensitive strategy if he needs to have access to the full
history of the moves in order to decide which move to make.

\item \emph{Innocence:} a strategy is innocent if it determines Proponent's moves based on a restricted view of the history of the play, mainly the P-view
at that point. Such strategies can be specified by a partial
function mapping P-views to P-moves called the \emph{view function}. However not every partial
function from P-views to P-moves gives rise to an innocent strategy
(a sufficient condition is given in \cite{hylandong_pcf}).
\end{itemize}

The formal definition of innocence follows:
\begin{dfn}[Innocence]
Given positions $sab, ta \in L_A$ where $sab$ has even length and
$\pview{sa} = \pview{ta}$, there is a unique extension of $ta$ by
the move $b$ together with a justification pointer such that
$\pview{sab} = \pview{sa}$. We write this extension
$\textsf{match}(sab,ta)$.

The strategy $\sigma:A$ is \emph{innocent} if and only if:
$$ \left(
     \begin{array}{c}
       \pview{sa} = \pview{ta} \\
       sab \in \sigma \\
       t\in \sigma \wedge ta \in P_A \\
     \end{array}
   \right)
\quad \imp\quad  \textsf{match}(sab,ta) \in \sigma$$

\end{dfn}


\subsection{Categorical interpretation}

In this section we recall some results about the categorical representation of Games.
These results with complete details and proofs can be found in \cite{McC96b,hylandong_pcf,abramsky94full}.
We refer the reader to \cite{CroleRL:catt} for more information about category theory.

We consider the category $\mathcal{G}$ whose objects are games and morphisms are
strategies. A morphism from $A$ to $B$ is a strategy on the game $A \multimap B$.

Three other sub-categories of $\mathcal{G}$ are considered: each of them correspond to some restriction on strategies:
$\mathcal{G}_i$ is the sub-category
of $\mathcal{G}$ whose morphisms are the innocent strategies,
$\mathcal{G}_b$ has only the well-bracketed strategies and $\mathcal{G}_{ib}$ has the innocent and well-bracketed strategies.

\begin{prop}
$\mathcal{G}$, $\mathcal{G}_i$, $\mathcal{G}_b$ and $\mathcal{G}_{ib}$ are categories.
\end{prop}

Proving this requires to prove that composition of strategies is well-defined, associative, has a unit (the copy-cat strategy), preserves innocence and
well-bracketedness. See \cite{hylandong_pcf,abramsky94full} for a proof.


\subsubsection{Monoidal structure}

We have already defined the tensor product on games in section \ref{sec:gameconstruction}.
We now define the corresponding transformation on morphisms:
given two strategies $\sigma : A \multimap B$ and $\tau : C \multimap D$ the strategy
$\sigma \otimes \tau : (A \otimes C) \multimap (B\otimes D)$ is defined by:
$$ \sigma \otimes \tau = \{ s \in L_{A \otimes C \multimap B\otimes D} \ s \upharpoonright A,B \in \sigma
\wedge s \upharpoonright C,D \in \tau \}$$

It can be shown that the tensor product is associative, commutative and has
$I = \langle \emptyset, \emptyset,\emptyset, \{ \epsilon \} \rangle $ as identity.
Hence the game categories $\mathcal{G}$ is a symmetric monoidal categories. Moreover
$\mathcal{G}_i$ and  $\mathcal{G}_b$ are sub-symmetric monoidal categories of $\mathcal{G}$,
and $\mathcal{G}_{ib}$ is a sub-symmetric monoidal category of $\mathcal{G}_i$, $\mathcal{G}_b$ and
$\mathcal{G}$.

\subsubsection{Closed structure}

Given the games $A$, $B$ and $C$, we can transform strategies on $A\otimes B \multimap C$ to
strategies on $A \multimap (B \multimap C)$ by retagging the moves to the appropriate arenas. This transformation
defines an isomorphism noted $\Lambda_B$ and called currying. Therefore the hom-set $\mathcal{G}(A\otimes B, C)$ is isomorphic to the hom-set
$\mathcal{G}(A,B\multimap C)$ which makes $\mathcal{G}$ an autonomous (i.e. symmetric monoidal closed) category.

We write $ev_{A,B} : (A \multimap B) \otimes A \rightarrow B$ to denote the \emph{evaluation strategy} obtained by uncurrying the
identity map on $A \rightarrow B$. $ev_{A,B}$ is in fact the copycat strategy for the game
$(A \multimap B) \otimes A \rightarrow B$.

$\mathcal{G}_i$ and  $\mathcal{G}_b$ are sub-autonomous categories of $\mathcal{G}$,
and $\mathcal{G}_{ib}$ is a sub-autonomous category of $\mathcal{G}_i$, $\mathcal{G}_b$ and
$\mathcal{G}$.

\subsubsection{Cartesian product}
The cartesian product defined in section \ref{sec:gameconstruction} is indeed a cartesian product in the category
$\mathcal{G}$, $\mathcal{G}_i$, $\mathcal{G}_b$ and $\mathcal{G}_{ib}$.

The projections $\pi_1:A \& B \rightarrow A$ and $\pi_1:A \& B \rightarrow B$ are given by the obvious copy-cat strategies.
Given two category morphisms $\sigma :C \rightarrow A$ and $\tau : C \rightarrow B$ the pairing function
$\langle \sigma, \tau \rangle : C \rightarrow A \& B$ is given by:
\begin{eqnarray*}
\langle \sigma, \tau \rangle &=& \{ s \in L_{C\multimap A\&B} \ | \ s \upharpoonright C,A \in \sigma \wedge s \upharpoonright B = \epsilon  \} \\
&\union& \{ s \in L_{C\multimap A\&B} \ | \ s \upharpoonright C,A \in \sigma \wedge s \upharpoonright B = \epsilon  \}
\end{eqnarray*}

\subsubsection{Cartesian closed structure}
Having defined the cartesian product is not enough to turn $\mathcal{G}$ into a cartesian closed category :
we also need to define a terminal object $I$ and the exponential construct $A \imp B$ for any two games $A$ and $B$.
In fact, this cannot be done in the current categories $\mathcal{G}$ and we have to move on to another category
of games noted $\mathcal{C}$ whose objects and morphisms are certain sub-classes of games and strategies.

Before introducing the category $\mathcal{C}$ we need some new definitions:


For any game $A$ we define the exponential game noted $!A$.
The game $!A$ corresponds to a repeated version of the game $A$. Plays of $!A$ are interleaving of plays of
$A$. It is defined as follows:
\begin{eqnarray*}
  M_{!A} &=& M_A \\
  \lambda_{!A} &=& \lambda_A \\
  \vdash_{!A} & = & \vdash_{A} \\
  P_{!A} & = & \{ s \in L_{!A} | \mbox{ for each initial move $m$, } s \upharpoonright m \in P_A \}
\end{eqnarray*}
The following equalities hold:
\begin{eqnarray*}
  !(A \& B) &=& !A \otimes !B\\
  I &=& !I
\end{eqnarray*}

\begin{dfn}[Well-opened games]
A game $A$ is well-opened if for any position $s \in P_A$ the only initial move is the first
one.
\end{dfn}

Well-opened games have single thread of dialog. Then can be turned into games with multiple-thread of dialog
using the promotion operator:

\begin{dfn}[Promotion]
Consider a well-opened game $B$.
Given a strategy on ${!A} \multimap B$, we define it promotion $\sigma^\dagger : {!A} \multimap {!B}$ to be the
strategy which plays several copies of $\sigma$. It is formally defined by:
$$ \sigma^\dagger = \{ s \in L_{{!A} \multimap !B} \ | \ \mbox{ for all initial $m$, } s \upharpoonright m \in \sigma  \}.$$
\end{dfn}

It can be shown that promotion is well-defined (it is indeed a strategy) and that it preserves innocence and
well-bracketedness.


We now introduce the category of well-opened games:
\begin{dfn}[Category of well-opened games]
The category $\mathcal{C}$ of well-opened games is defined as follow:
\begin{enumerate}
\item The objects are the well-opened games,
\item a morphism $\sigma : A \rightarrow B$ is a strategy for the game $!A \multimap B$,
\item the identity map for $A$ is the copy-cat strategy on $!A \multimap A$ (which is well-defined for well-opened games).
It is called dereliction, noted
$\textsf{der}_A$ and defined formally by:
$$ \textsf{der}_A = \{ s \in P^{\textsf{even}}_{{!A} \multimap A} \ | \ \forall t \sqsubseteq^{\textsf{even}} s \ . \ t \upharpoonright {!A} = t \upharpoonright A \},$$
\item composition of morphisms $\sigma : {!A} \multimap B$ and $\tau : {!B} \multimap C$
noted $\sigma \fatsemi \tau : {!A} \multimap C$ is defined as $\sigma^\dagger;\tau$.
\end{enumerate}
\end{dfn}
$\mathcal{C}$ is a well-defined category and the three sub-categories
$\mathcal{C}_i$, $\mathcal{C}_b$, $\mathcal{C}_{ib}$ corresponding to sub-category
with innocent strategies, well-bracketed strategies and innocent and well-bracketed strategies respectively.


The category $\mathcal{C}$ has a terminal object $I$, for any two games $A$ and $B$ a product $A \& B$ and
an exponential $A \imp B$ defined to be $!A \multimap B$. The hom-sets $\mathcal{C}(A \& B,C)$ and
$\mathcal{C}(A,!B \multimap C)$ are isomorphic. Indeed:
\begin{eqnarray*}
\mathcal{C}(A\& B,C) &=& \mathcal{G}(!(A\& B),C) \\
&=& \mathcal{G}({!A}\otimes {!B},C) \\
&\cong& \mathcal{G}({!A}, {!B} \multimap C) \qquad  \mbox{($\mathcal{G}$ is a closed monoidal category)}\\
&=& \mathcal{C}(A, {!B} \multimap C)
\end{eqnarray*}
Hence $\mathcal{C}$ is a cartesian closed category. Moreover $\mathcal{C}_i$ and $\mathcal{C}_b$
are sub-cartesian closed caterogies of $\mathcal{C}$ and $\mathcal{C}_{ib}$ is as sub-cartesian closed category
of each of $\mathcal{C}$, $\mathcal{C}_i$ and $\mathcal{C}_b$.





\subsubsection{Order enrichment}

Strategies can be ordered using the inclusion ordering. Under this
ordering, the set of strategies on a given game $A$ is a pointed
directed complete partial order : the least upper bounds is the
union of two strategies and the least element is the empty strategy
$\{ \epsilon \}$.

Moreover all the operators on strategies that we have defined so far
(composition, tensor product, ...) are continuous. Hence the
category $\mathcal{C}$ and $\mathcal{G}$ are cpo-enriched.

This significant characteristic will prove to be extremely useful
when it comes to model programming languages with recursion such as
PCF.


\subsubsection{Intrinsic preoder}

We now define a pre-ordering on strategies. We assume that we are working in one of the categories
$\mathcal{C}$, $\mathcal{C}_i$, $\mathcal{C}_b$, $\mathcal{C}_{ib}$.

Let $\Sigma$ be the game with a single question $q$ and single answer $a$. There are only two strategies on $\Sigma$:
$\bot = \{ \epsilon \}$ and $\top = \{ \epsilon, q a \}$ which are both innocent and well-bracketed. These strategies are used
to test strategies: for any strategy $\sigma : {\bf 1} \rightarrow A$ and for any test strategy $\alpha : A \rightarrow \Sigma$ we say that $\sigma$
passes the test $\alpha$ if $\sigma \fatsemi \alpha = \top$.

The intrinsic preorder noted $\lesssim$ is then defined as follows:
for any strategy $\sigma,\tau$ on the game $A$, $\sigma \lesssim \tau$ if $\tau$ passes all the test passed by $\sigma$. Formally:
$$ \sigma \lesssim \tau \quad \iff \quad \forall \alpha : A \rightarrow \Sigma. \sigma \fatsemi \tau = \top \imp \tau \fatsemi \alpha = \top$$

One can check that the relation $\lesssim$ is indeed a preorder on the set of strategies of the considered category.
This preorder defines classes of equivalence: two strategies are in the same equivalence class if no test can distinguish them.
The quotiented category is written $\bf C/\lesssim$ where $\bf C$ ranges over $\{ \mathcal{C}_i, \mathcal{C}_i, \mathcal{C}_b, \mathcal{C}_{ib} \}$.

Later on we will state the full abstraction of the game semantics model of PCF. This result will
be proved in the quotiented category.

\subsection{Pointers are superfluous for games on arenas of order 2}

For any legal justified sequence of moves $s$, we write $?(s)$ for the
subsequence of $s$ obtain by keeping only the unanswered questions in $s$. It is easy to check that if $s$ satisfies alternation then $?(s)$ also
satisfies alternation.

\begin{lem}
  If $s\cdot q$ is a legal position (i.e. justified sequence satisfying visibility and alternation) satisfying
    well-bracketing where $q$ is a non-initial question then $q$ points in $?(s)$.
\end{lem}
\begin{proof}
    By induction on the length of $s \cdot q$. The base case $s=\epsilon$ is trivial.
    Let $s = s\cdot q$, where $q$ is not initial.

    Suppose $q$ is a P-move. We prove that $q$ cannot point to an O-question that has been answered.
    Suppose that an O-move $q'$ occurs before $q$ and is answered by the move $a$ also occurring before $q$.
    Then we have $s = s_1 \cdot q'^O \cdot s_2 \cdot a^P \cdot s_3 \cdot q^P$ where $a$ is justified by $q'$.
    $a$ is not in the P-view $\pview{s_{<q}}$. Indeed this would imply that some O-move occurring in $s_3$ points to $a$, but this is impossible
    since answer moves are not enablers. Hence the move $a$ must be situated underneath an O-to-P link. Let us note $m$ the origin of this link,
    the P-view of $s$ has the following form: $\pview{s} = \pview{s_1\cdot q'^O \cdot s_2 \cdot a^P \ldots m^O} \ldots q^P$ where $m$ is an O-move pointing before $a$.

    If $m$ is an answer move then it must point to the last unanswered move that is to say the last move in $?(s_{<m})$.
    If $m$ is a question move then it is not initial since there is a link going from $m$. Therefore by the induction hypothesis, $m$ must point
    to a move in $?(s_{<m})$.

    Since $s$ is well bracketed, all the question in the segment $q'\ldots a$ are answered.
    Therefore since $m$ points to an unanswered question occurring before $a$, $m$ must
    points to a move occurring strictly before $q'$. Consequently $q'$ does not occur in the P-view $\pview{s}$.
    By visibility, $q$ must point in the P-view $\pview{s}$ therefore $q$ does not point to $q'$.

    A similar argument holds if $q$ is an O-move.
\end{proof}

This means that in a well-bracketed legal position $s\cdot m$, if the move $m$ is not initial then $m$ must point to a question in $?(s)$
whether $m$ is a question or an answer (of course if $m$ is an answer then it points precisely to the \emph{last} question in $?(s)$).
Moreover if $m$ is a P-move then by visibility it should point in an unanswered question in $\pview{m}$ therefore
it should also points in $?(\pview{m})$.
Similarly, if $m$ is a non initial O-move then it points in $?(\oview{m})$.

\begin{lem}
Let $s$ be a legal well-bracketed position.
\begin{enumerate}
\item If $s=\epsilon$ or if the last move in $s$ is not a P-answer then $?(\pview{s}) = \pview{?(s)}$;
\item If $s=\epsilon$ or if the last move in $s$ is not an O-answer then $?(\oview{s}) = \oview{?(s)}$.
\end{enumerate}
\end{lem}
\begin{proof}
(i) By induction on the length of $s$. The base case is trivial.
Step case: suppose that $s \cdot m$ is a legal well-bracketed position.

If $m$ is an initial O-question then $?(\pview{s \cdot m}) = ?(m) = m = \pview{?(s) \cdot m} = \pview{?(s \cdot m)}$.

If $m$ is a non initial O-question then
$s \cdot m^O = s' \cdot q^P \cdot s'' \cdot m^O$ where $m$ is justified by $q$.
We have $?(\pview{s}) = ?(\pview{s'} \cdot q \cdot  m) = ?(\pview{s'}) \cdot q \cdot m$.
If $s'$ is not empty then its last move must be an O-move (by alternation), therefore by the induction hypothesis
$?(\pview{s'})= ?(\pview{?(s')})$.
By the previous lemma, the move $m$ must point in $?(s)$ therefore we have
$?(s \cdot m) = ?(s') \cdot q^P \cdot u \cdot m^O$ for some sequence $u$. And therefore
$\pview{?(s \cdot m)} = \pview{?(s')} \cdot q^P \cdot m^O$.

If $m$ is an O-answer then $s \cdot m = s' \cdot q^P \cdot s'' \cdot m^O$ where $m$ is justified by $q$.
Then $?(\pview{s\cdot m}) = ?(\pview{s'} q a) = ?(\pview{s'})$.
Moreover since $s$ is well-bracketed, we have $?(s) = ?(s')$.
Again the induction hypothesis permits to conclude.

If $m$ is a P-question then $\pview{s \cdot m} = \pview{s} \cdot m$ and $?(\pview{s \cdot m}) = ?(\pview{s}) \cdot m$.
Moreover $\pview{?(s \cdot m)} = \pview{?(s) \cdot m} = \pview{?(s)} \cdot m$.
By alternation if $s$ is not empty it must end with an O-move therefore the induction hypothesis permits to conclude.


(ii) The argument is similar to (i).
\end{proof}

Note that for (i), and similarly for (ii), it is important that $s$ does not ends with a P-answer. For instance consider the legal position:
$s = \justseq{ q_0^O &  q_1^P \pointto{l} &  q_2^O \pointto{l} &  q_3^P \pointto{l} &  q_4^O \pointto{lll} & a^P \pointto{l} }$
ending with a P-answer. We have $\pview{?(s)} = \pview{q_0 \cdot q_1 \cdot q_2 \cdot q_3} = q_0 \cdot q_1 \cdot q_2 \cdot q_3$
but $?(\pview{s}) = ?(q_0 \cdot q_1 \cdot q_4 \cdot a) = q_0 \cdot q_1 \cdot q_4$.


\vpsace{10pt}
By the previous remark and lemma we obtain the following corollary:
\begin{cor}
\label{cor:pendingview}
Let $s \cdot m$ be a legal well-bracketed position.
\begin{enumerate}
\item If $m$ is a P-move then it points in $?(\pview{s}) = \pview{?(s)}$;
\item if $m$ is a non initial O-move then it points in $?(\oview{s}) = \oview{?(s)}$.
\end{enumerate}

\end{cor}


We call height of an arena $\langle M, \lambda, \vdash \rangle$ the length of the longest sequence of moves
$m_1 \ldots m_h$ in $M$ such that $m_1 \vdash m_2 \vdash \ldots \vdash m_h$.
The order of the arena is defined to be its height minus two.

\begin{lem}[Pointers are superfluous up to order 2]
Let $A$ be the arena of order at most 2. Let $s$ be a justified sequence of moves in the arena $A$ satisfying
 alternation, visibility, well-openedness and well-bracketing then
the pointers of the sequence $s$ can be reconstructed uniquely.
\end{lem}



\begin{proof}
We represent an arena graphically as a forest of trees. We choose to display the sub-trees of a given node
from left to right by decreasing order of the sub-arena order.

Let $A$ be an arena of order 2.
The case where $A$ is a DAG with multiple roots can be reduced to the single root case as follows:
since the justified sequence that we consider are well-opened, the first move in $s$ noted $m_0$ is the only initial move in the sequence.
$m_0$ must be the root of some sub-arena $A'$ of $A$. Hence we just need to consider the arena $A'$ instead of $A$ and treat $s$ as a play
of $A'$ instead of $A$. We now assume that $A$ has a single root.

$A$ has the following shape:
\begin{center}
  \pstree[levelsep=6ex]
    { \TR{$q$} }
    {
\SubTree{$A_1$} \SubTree[linestyle=none]{$\ldots$} \SubTree{$A_n$}
    \TR{$a_1$} \TR{$a_2$} \TR{\ldots} }
\end{center}

where each triangle $A_i$ represents an arena of order 0 or 1.


We write $I_k$, where $k=0$ or $1$, for the set of indices $i$ such that the arena $A_i$ has order $k$:
$$I_k = \{ i \in 1.. n\ |\ \order{A_i} = k \}$$

We assume that the arena $A_k$ are trees, it is easy to generalize to any DAG.
The diagram below represents an arena $A_i$ where $i \in I_0$ on the left and an arena $A_j$ where $j \in I_1$ on the right:
\begin{center}
\
  \pstree[levelsep=6ex]
    {\TR{$q^i$}}
    { \TR{$a_1^i$} \TR{$a_2^i$} \TR{\ldots} }
\hspace{2cm}
  \pstree[levelsep=6ex]
    { \TR{$p^j$} }
    {
      \pstree[levelsep=6ex]
        { \TR{$q^j$} }
        { \TR{$a_1^j$} \TR{$a_2^j$} \TR{\ldots} }
      \TR{$b_1^j$} \TR{$b_2^j$} \TR{\ldots}
    }
\end{center}



Let $L$ be the following language $L = \{\ p^j q^j\ | \ j \in I_1
\}$. We consider the following cases:

\begin{center}
\begin{tabular}{c|c|l|l}
Case & $\lambda_{OP}(m)$ & $?(s) \in$ & for some ... \\ \hline
0 & O & $\{ \epsilon \}$ \\
A & P & $q$ \\
B & O & $q \cdot L^* \cdot p^j$     & $j \in I_1$ \\
C & P & $q \cdot L^* \cdot p^j q^j$ & $j \in I_1$ \\
D & O & $q \cdot L^* \cdot q^i$      & $i \in I_0$ \\
\end{tabular}
\end{center}

Let $s$ be a legal well-bracketed position in $L_A$.
We prove by induction on the length of $s$ that $?(s)$
corresponds to either case 0, A, B, C or D and that the pointers in
$s$ can be recovered uniquely.

\noindent \textbf{Base cases:}
If $s$ is the empty sequence $\epsilon$ then there is no pointer to
recover and $s$ corresponds to case 0.
If $s$ is a singleton then it must be the initial question $q$ and
there is not pointer to recover. This corresponds to case A.

\noindent \textbf{Step case:}
If $s = u \cdot m$ for some non empty legal well-bracketed position $u$ and move $m \in M_A$
then by the induction hypothesis the pointers in $u$ can all be recovered and $u$ corresponds to one of the
cases 0, A, B, C or D.
We proceed by case analysis:
\begin{description}
\item[case 0] This case cannot happen because $?(u) = \epsilon$ ($u$ is a complete play) implies that there cannot be any further move $m$.

Indeed the visibility condition implies that $m$ must point to a
P-question in the O-view at that point. But since $u$ is a complete
play, the O-view is $\oview{u} = q a$ which does not contain
any P-question. Hence the move $m$ cannot be justified and is not
valid.


\item[case A] $?(u) = q$ and the last move $m$ is played by P.
    There are several cases:
    \begin{itemize}
    \item $m$ is an answer $a_k$ to the initial question
    $q$ for some $k$, then $m$ points to $q$
    therefore $s$ is a complete play and $?(s) = \epsilon$, which corresponds to case 0.

    \item $m = q^i$ is an order 0 question ($i \in I_0$) then  $q^i$ points to the initial question $q$ and $s$ falls into category D.

    \item $m = p^i$ is a first order question, then $p^i$ points to $q$,
    $?(s)= q p^i$ and it is O's turn to play after $s$ therefore $s$ falls into category B.

    \end{itemize}


\item[case B] $?(u) \in q \cdot L^* \cdot p^i$ where $i \in I_1$ and O plays the move $m$.

By corollary \ref{cor:pendingview}, $m$ points in $\pview{?(u)} = q p^i$. Since $m$ is an O-move it must points to $p^i$.

In the arena $A_i$, $p^i$ enables two kind of moves:
if $m =b^j$ for some $j \in I_1$ then $?(s) = ?(u \cdot b^i) \in q \cdot L^*$ which is covered by case A and C.
If $m = q^i$ then have $?(s) = ?(u \cdot q^i) \in q \cdot L^* \cdot p^i q^i$ and $s$ falls into category C.


\item[case C] $?(u) \in q \cdot L^* \cdot p^i q^i$ where $i \in I_1$ and the move $m$ is played by $P$.

Suppose $m$ is an answer, then the well-bracketing condition imposes
$q^i$ being answered first. The move $m$ is therefore an integer $a^i$
pointing to $q^i$. We then have $?(s) = ?(u \cdot a^i) \in  q \cdot
L^* \cdot p^i$. This corresponds to case B.

Suppose $m$ is a question then it cannot point to $p^i$ since it is a P-move. It does not point to $q^i$ neither since $q^i$ does not enable
any move in the arena. Similarly $m$ does not point to any move in $L^*$. Hence $m$ must point to the initial question $q$.

There are two sub-cases, either $m = q^j$ for some $j \in I_0$ and then $s$ falls into category D
or $m = p^j$ for some $j \in I_1$ and $s$ falls into category B.


\item[case D] $?(u) \in q \cdot L^* \cdot q^i$ where $i \in I_0$ and the move $m$ is played by $O$.

    The same argument as in case B holds with an additional subcase:
    if $m$ is the answer $a^i_k$ for some $k$ then $m$ must point to
    $q^i$ since this is the only unanswered occurrence of its enabler.

    Then $?(s) = ?(u\cdot a^i_k) \in q \cdot L^* $ and
    $s$ falls either into category A or C.

\end{description}

This completes the induction.
\end{proof}


\subsection{... but in general pointers are necessary}
\label{subsec:pointer_necessary}

Up to order 2, the semantics of PCF terms is entirely defined by
pointer-less strategies. In other words, the pointers can be
uniquely reconstructed from any non justified sequence of moves
satisfying the visibility and well-bracketing condition.

At level 3 however, pointers cannot be omitted in general. Here is
an example taken from \cite{abramsky:game-semantics-tutorial}
illustrating this. Consider the following two terms, called the
Kierstead terms, of type $((\nat \typar \nat) \typar \nat) \typar
\nat$:

$$M_1 = \lambda f . f (\lambda x . f (\lambda y .y ))$$
$$M_2 = \lambda f . f (\lambda x . f (\lambda y .x ))$$

We assign tags to the types in order to identify in which arena the
questions are asked: $((\nat^1 \typar \nat^2) \typar \nat^3) \typar
\nat^4$. Consider now the following pointer-less sequence of moves
$s = q^4 q^3 q^2 q^3 q^2 q^1$. It is possible to retrieve the
pointers of the first five moves but there is an ambiguity for the
last move: does it point to the first or second occurrence of $q^2$
in the sequence $s$?

Note that the visibility condition does not eliminate the ambiguity,
since the two occurrences of $q^2$ both appear in the P-view at that
point (after recovering the pointers of $s$ up to the second last
move we get:
$$s = \rnode{q4}{q}^4
\rnode{q3}{q}^3
\rnode{q2}{q}^2
\rnode{q3b}{q}^3
\rnode{q2b}{q}^2
\rnode{q1}{q}^1
\bkptrc{q3}{q4}
\bkptrc{q2}{q3}
\bkptrc[ncurv=0.6]{q3b}{q4}
\bkptrc{q2b}{q3b}$$

 therefore the P-view of $s$ is $s$ itself.)

In fact these two different possibilities correspond to two
different strategies. Suppose that the link goes to the first
occurrence of $q^2$ then it means that the proponent is requesting
the value of the variable $x$ bound in the subterm $\lambda x . f (
\lambda y. ... )$. If P needs to know the value of $x$, this is
because P is in fact following the strategy of the subterm $\lambda
y . x$. And the entire play is part of the strategy $\sem{M_2}$.

Similarly, if the link points to the second occurrence of $q^2$ then
the play belongs to the strategy $\sem{M_1}$.

\section{The fully abstract game model for PCF}

In this section we introduce the functional languages PCF. We then
describe the game model introduced in \cite{abramsky94full} and
finally we will state the full abstraction result.

\subsection{The syntax of PCF}
PCF is a simply-type $\lambda$-calculus with the following
additions: integer constants  (of ground type), first-order
arithmetic operators, if-then-else branching, and the recursion
combinator $Y_A : (A\rightarrow A)\rightarrow A$ for any type $A$.

The types of PCF are given by the following grammar:
$$ T ::= \texttt{exp}\ |\ T \rightarrow T$$

and the structure of terms is given by:
\begin{eqnarray*}
 M ::= x\ |\ \lambda x :A . M \ |\ M M \ |\ \\
\ |\ n \ |\ \texttt{succ } M \ |\  \texttt{pred } M \\
\ |\ \texttt{cond } M M M \ |\ \texttt{Y}_A\ M
\end{eqnarray*}

where $x$ ranges over a set of countably many variables and $n$
ranges over the set of natural numbers.

Terms are generated according to the formation rules given in table
\ref{tab:pcf_formrules} where the judgement is of the form $ \Gamma  \vdash M : A$.

\begin{table}[htbp]
$$ (var) \rulef{}{x_1:A_1, x_2:A_2, \ldots x_n : A_n  \vdash x_i : A_i}\ i \in 1..n$$
$$ (app) \rulef{\Gamma \vdash M : A\rightarrow B \qquad \Gamma \vdash N:A}{\Gamma \vdash M\ N : B}
\qquad (abs) \rulef{\Gamma, x:A \vdash M : B}{\Gamma \vdash \lambda x :A . M : A\rightarrow B}$$

$$ (const) \rulef{}{\Gamma \vdash n :\texttt{exp}}
\qquad (succ) \rulef{\Gamma \vdash M:\texttt{exp} }{\Gamma \vdash \texttt{succ}\ M:\texttt{exp}}
\qquad (pred) \rulef{\Gamma \vdash M:\texttt{exp} }{\Gamma \vdash \texttt{pred}\ M:\texttt{exp}}$$

$$
(cond) \rulef{\Gamma \vdash M : \texttt{exp} \qquad \Gamma \vdash N_1 : \texttt{exp} \qquad \Gamma \vdash N_2 : \texttt{exp} }{\Gamma \vdash \texttt{cond}\ M\ N_1\ N_2}
\qquad  (rec) \rulef{\Gamma \vdash M : A\rightarrow A }{ \Gamma \vdash Y_A M : A}$$

\caption{Formation rules for PCF terms}
\label{tab:pcf_formrules}
\end{table}

\subsection{Operational semantics of PCF}

We give the big-step operational semantics of PCF. The notation $M \eval V$ means
that the closed term $M$ evaluates to the canonical form $V$. The canonical forms are given by the following
grammar:
$$V ::= n\ |\ \lambda x. M$$
In other word, a canonical form is either a number or a function.

The full operational semantics is given in table
\ref{tab:bigstep_pcf}. The evaluation rules are defined for closed
terms only therefore the context $\Gamma$ is not present in the
rules. We write $M \eval$ if $M \eval V$ for some value $V$.

\begin{table}[htbp]
$$\rulef{}{V \eval V} \quad \mbox{ provided that $V$ is in canonical form.} $$

$$ \rulef{M \eval \lambda x. M' \quad M'\subst{x}{N} \eval V}{M N \eval V}$$

$$\rulef{M \eval n}{\texttt{succ}\ M \eval n+1}
\qquad \rulef{M \eval n+1}{\texttt{pred}\ M \eval n}
\qquad \rulef{M \eval 0}{\texttt{pred}\ M \eval 0}$$

$$\rulef{M \eval 0 \quad N_1 \eval V}{\texttt{cond}\ M N_1 N_2  \eval V}
\qquad
 \rulef{M \eval n+1 \quad N_2 \eval V}{\texttt{cond}\ M N_1 N_2  \eval V}$$

$$\rulef{M (\mathrm{Y} M) \eval V }{\texttt{Y} M \eval V}$$
\label{tab:bigstep_pcf}
\caption{Big-step operational semantics of PCF}
\end{table}



\subsection{Game model of PCF}
\label{subsec:pcfgamemodel}

As we have seen in section \ref{sec:catgames}, games and strategies
form a cartesian closed category, therefore games can model the
simply-typed $\lambda$-calculus. We are now about to make this
connection concrete by explicitly giving the strategy corresponding
to a given $\lambda$-term. We will then extend the game model to PCF
and IA.

\subsubsection{Simply-typed $\lambda$-calculus fragment}

In the games that we are considering, the Opponent represents the
environment and the Proponent represents the lambda term. Opponent
opens the game by asking a question such as ``What is the output of
the function?'', the proponent then may then ask further information
such that ``What is the input of the function?'' O can then provide
$P$ with an answer (the value of the input) or can pursue with
another question. The dialog goes on until O gets the answer to his
initial question.

O represents the environment, he is responsible for proving input
values while P plays from the term's point of view: he is
responsible for performing the computation and returning the output
to O. P plays according to the strategy that is associated to the
$\lambda$-term being modeled.

We recall that in the cartesian closed category $\mathcal{C}$, the
objects are the arenas and the morphisms are the strategies. Given a
simple type $A$, we will model it as an arena $\sem{A}$. A context
$\Gamma = x_1 :A_1, \ldots x_n:A_n$ will be mapped to the arena
$\sem{\Gamma} = \sem{A_1} \times \ldots \times \sem{A_n}$ and a term
$\Gamma \vdash M : A$ will be modeled by a strategy on the arena
$\sem{\Gamma} \rightarrow \sem{A}$. Since $\mathcal{C}$ is cartesian
closed, there is is a terminal object $\textbf{1}$ (the empty arena)
that models the empty context ($\sem{\Gamma} = \textbf{1}$).


Let $\omega$ denotes the set of natural numbers. Consider the
following flat arena over $\omega$:
$$  \pstree[levelsep=6ex]
    {\TR[name=R]{q}}
    { \TR{1} \TR{2} \TR{\ldots}
    }
$$
Then the base type \texttt{exp} is interpreted by the flat game
$\nat$ over the previous arena where the set of valid position is:
$$P_N = \{ \epsilon, q \} \union \{ qn \ | \ n \in \omega \}$$


In this arena, there is only one question: the initial O-question, P
can then answer by playing a natural number $i \in \omega$. There
are only two kinds strategy on this arena:
\begin{itemize}
\item the empty strategy where P never answer the initial question. This corresponds to a non terminating computation;
\item the strategies where P answers by playing a number $n$. This models the numerical constants of the language.
\end{itemize}

Given the interpretation of base types, we define the interpretation
of $A\rightarrow B$ by induction:
$$\sem{A \rightarrow B} = \sem{A} \Rightarrow \sem{B}$$

where the operator $\Rightarrow$ denotes the arena construction $!A
\multimap B$, the exponential object of the cartesian closed
category $\mathcal{C}$.



Variables are interpreted by projection:
$$\sem{x_1 : A_1, \ldots, x_n:A_n \vdash x_i : A_i} = \pi_i : \sem{A_i} \times \ldots \times \sem{A_i} \times \ldots \times \sem{A_n} \rightarrow  \sem{A_i}$$

The abstraction $\Gamma \vdash \lambda x :A.M : A \rightarrow B$ is
modeled by a strategy on the arena $\sem{\Gamma} \rightarrow
(\sem{A}\Rightarrow\sem{B})$. This strategy is obtain by using the
currying operator of the cartesian closed category:
$$\sem{\Gamma \vdash \lambda x :A.M : A \rightarrow B} = \Lambda( \sem{\Gamma, x :A \vdash M : B})$$

The application $\Gamma \vdash M N$ is modeled using the evaluation
map $ev_{A,B} : (A\Rightarrow B)\times A \rightarrow B$:

$$\sem{\Gamma \vdash M N} = \langle \sem{\Gamma \vdash M, \Gamma \vdash N} \rangle \fatsemi ev_{A,B}$$


\subsubsection{PCF fragment}

We now show how to model PCF constructs in the game semantics
setting. In the following, the sub-arena of a game are tagged in
order to distinguish identical arenas present in different
components of the game. Moves are also tagged in the exponent in
order to identify the sub-arena in which moves are played. We will
omit the pointers in the play when there is no ambiguity.

The successor arithmetic operator is modeled by the following
strategy on the arena $\nat^1 \Rightarrow \nat^0$:
$$\sem{\texttt{succ}} = \{q^0 \cdot q^1 \cdot n^1 \cdot (n+1)^0\ |\ n \in \nat \}$$

The predecessor arithmetic operator is denoted by the strategy
$$\sem{\texttt{pred}} = \{q^0 \cdot q^1 \cdot n^1 \cdot (n-1)^0\ |\ n >0 \} \union \{ q^0 \cdot q^1 \cdot 0^1 \cdot 0^0 \} $$

Then given a term $\Gamma \vdash \texttt{succ }M : \texttt{exp}$ we
define:
$$\sem{\Gamma \vdash \texttt{succ } M : \texttt{exp}} = \sem{\Gamma \vdash M} \fatsemi \sem{\texttt{succ}} $$
$$\sem{\Gamma \vdash \texttt{pred } M : \texttt{exp}} = \sem{\Gamma \vdash M} \fatsemi \sem{\texttt{pred}} $$


The conditional operator is denoted by the following strategy on the
arena $\nat^3 \times \nat^2 \times \nat ^1 \Rightarrow \nat^0$:
$$\sem{\texttt{cond}} =
    \{ q^0 \cdot q^3 \cdot 0 \cdot q^2 \cdot n^2 \cdot n^0 \ | \ n \in \nat \}
    \union
    \{ q^0 \cdot q^3 \cdot m \cdot q^2 \cdot n^2 \cdot n^0 \ | \ m >0, n \in \nat \}
    $$


Given a term $\Gamma \vdash \texttt{cond}\ M\ N_1\ N_2$ we define:
$$\sem{\Gamma \vdash \texttt{cond}\ M\ N_1\ N_2} =
\langle \sem{\Gamma \vdash M}, \sem{\Gamma \vdash N_1}, \sem{\Gamma
\vdash N_2} \rangle \fatsemi \sem{\texttt{cond}}$$


The interpretation of the \texttt{Y} combinator is a bit more
complicated.

Consider the term $\Gamma \vdash M : A \rightarrow A$, its semantics
$f$ is a strategy on $\sem{\Gamma} \times \sem{A} \rightarrow
\sem{A}$. We define the chain $g_n$ of strategies on the arena
$\sem{\Gamma} \rightarrow \sem{A}$ as follows:
\begin{eqnarray*}
g_0 &=& \perp \\
g_{n+1} &=&  F(g_n) = \langle id_{\sem{\Gamma}}, g_n\rangle \fatsemi f
\end{eqnarray*}

where $\perp$ denotes the empty strategy $\{ \epsilon \}$.

It is easy to see that the $g_n$ forms a chain. We define
$\sem{\texttt{Y } M}$ to be the least upper bound of the chain $g_n$
(i.e. the  least fixed point of $F$). Its existence is guaranteed by
the fact that the category of games is cpo-enriched.

Since all the strategies that we have given are innocent and
well-bracketed, the game model of PCF can be interpreted in any of
the four categories $\mathcal{C}$, $\mathcal{C}_i$, $\mathcal{C}_b$,
$\mathcal{C}_{ib}$.



\subsection{Full-abstraction of PCF}
In this section we state the full abstraction result proved in
\cite{abramsky94full} and \cite{hylandong_pcf}.


\subsubsection{Observational preorder}

A context noted $C[-]$ is a term containing a hole denoted by $-$.
If $C[-]$ is a context then $C[A]$ denotes the term obtained after
replacing the hole by the term $A$.

If $M$ is a PCF term then we write $C[M]$ to denote the term
obtained after replacing the hole by the term $M$. $C[M]$ is
well-formed provided that $M$ has the appropriate type. Remark: this
capture permitting substitution must be distinguished from the
capture-free substitution which is noted $M[N/x]$ for any two terms
$M$ and $N$.


\begin{dfn}[Observational preorder]
We define the relation on terms $\obspre$ as follows: suppose $M$
and $N$ are two closed terms of the same type then:
\begin{eqnarray*}
M \obspre N &\iff& \parbox{10cm}{for all context $C[-]$ such that
                $C[M]$ and $C[N]$ are well-formed closed term of type \texttt{exp},
                    $C[M] \eval$ implies $C[N] \eval$}
\end{eqnarray*}
Observational equivalence is defined as the reflexive closure of
$\obspre$ noted $\obseq$.
\end{dfn}

Said informally, two programs are observationally equivalent if then
can be safely interchanged in any program context.

\subsubsection{Soundness and adequacy}
A model of a programming language is said to be \emph{sound} or
\emph{inequationally sound} if whenever the denotation of two
programs are equal then the two programs are observationally
equivalent, or more formally if for any closed terms $M$ and $N$ of
the same type:
$$ \sem{M} \subseteq \sem{N} \imp M \obspre N.$$

In a way, soundness is the minimum one can require for a model of
programming language: it guarantees that we can reason about the
program by manipulating the object of the denotational model.

It can be shown that the game model of PCF is sound for evaluation
and computationally adequate. These two properties imply the
soundness of the game model:

We said that the evaluation relation $\eval$ is sound if the
denotation is preserved by evaluation:
\begin{lem}[Soundness of evaluation]
\label{lem:evalsoundness}
 Let $M$ be a PCF term then
$$M \eval V \quad \imp \quad \sem{M} = \sem{V}.$$
\end{lem}

\begin{dfn}[Computable terms] \
\begin{itemize}
\item A closed term $\vdash M$ of base type is computable if $\sem{M} \neq \bot$
implies $M \eval$.
\item A higher-order closed term $\vdash M : A\rightarrow B$ is computable if $M N$ is computable for any computable closed term $\vdash  N:A$.
\item An open term $x_1 : A_1, \ldots, x_n : A_n \vdash M : A\rightarrow B$ is computable if $\vdash M [N_1/x_1, \ldots N_n/x_n]$ is computable
for all computable closed terms $N_1:A_1, \ldots, N_n:A_n$.
\end{itemize}
\end{dfn}

A model is \emph{computationally adequate} if all
terms are computable.
\begin{lem}[Computational adequacy]
\label{lem:computadequacy}
The game model of PCF is
computationally adequate.
\end{lem}
We refer the reader to \cite{abramsky:game-semantics-tutorial} for
the proofs.

Inequational soundness follows from the last two lemmas:
\begin{prop}[Inequational soundness]
\label{prop:ineqsoundness} Let $M$ and $N$ be two closed terms then
$$\sem{M} \subseteq \sem{N} \implies  M \obspre N $$
\end{prop}
\begin{proof}
  Suppose that $\sem{M} \subseteq \sem{N}$ and $C[M] \eval$ for some context $C[-]$. Then by compositionality of game semantics we also have
  $C[\sem{M}] \subseteq C[\sem{N}]$.
  Lemma \ref{lem:evalsoundness} gives $\sem{C[M]} \neq \bot$, therefore $\sem{C[N]} \neq \bot$.
  Lemma \ref{lem:computadequacy} then implies that $C[N] \eval$.
  Hence $M \obspre N$.
\end{proof}

\subsubsection{Definability}

We will now consider only strategies that are innocent and
well-bracketed (i.e. we work in the category $\mathcal{C}_{ib}$).

The definability result says that every compact element of the model
is the denotation of some term.
The compact morphisms of the category $\mathcal{C}_{ib}$ are those
with finite view-function.

The economical syntax of PCF prevents us from stating this
result directly: we need to consider an extension of PCF with some additional
constants. Indeed, there are strategies that are not the denotation of any term
in PCF, for instance the ternary conditional strategy : this
strategy denotes the computation that tests the value of its first
parameter, if its equal to zero or one then it returns the value of
the second or third parameter respectively, otherwise it returns the
value of the fourth parameter. This strategy is illustrated by the
following diagram:
$$
\begin{array}{ccccccccc}
!\bf N & \otimes & !\bf N & \otimes & !\bf N & \otimes & !\bf N & \multimap & !\bf N \\
&&&&&&&&q \\
q \\
0 \\
&& q \\
&& n \\
&&&&&&&&n \\
\hline
&&&&&&&&q \\
q \\
1 \\
&&&& q \\
&&&& n \\
&&&&&&&&n \\
\hline
&&&&&&&&q \\
q \\
m>1 \\
&&&&&& q \\
&&&&&& n \\
&&&&&&&&n \\
\end{array}
$$

It is possible to simulate this computation in PCF using the conditional operator, for instance the following term is a potential candidate:
$$ T = \texttt{cond}\ M\  N_1 (\texttt{cond}\  (\texttt{pred } M)\  N_2\  N_3)$$

Unfortunately the game semantics of $T$ is not given by the strategy that we have just defined, it is instead the following one:
$$
\begin{array}{ccccccccc}
!\bf N & \otimes & !\bf N & \otimes & !\bf N & \otimes & !\bf N & \multimap & !\bf N \\
&&&&&&&&q \\
q \\
0 \\
&& q \\
&& n \\
&&&&&&&&n \\
\hline
&&&&&&&&q \\
q \\
1 \\
q \\
0 \\
&&&& q \\
&&&& n \\
&&&&&&&&n \\
\hline
&&&&&&&&q \\
q \\
m>1 \\
q \\
m-1>0 \\
&&&&&& q \\
&&&&&& n \\
&&&&&&&&n \\
\end{array}
$$

To make up for this deficiency we add a family of terms to PCF: the $k$-ary conditionals:
$$ \texttt{case}_k\ N\ N_1\ N_2\ \ldots\ N_k$$
with the desired operational semantics:
$$ \rulef{M \eval i \quad N_{i+1} \eval V}{\texttt{case}_k\ N\ N_1\ N_2\ \ldots\ N_k\ \eval V}\ i \in \{0, \ldots,k-1\}.$$
The denotation of this term is given by the first strategy illustrated above.
The extended language is called PCF'.

We can now prove the definability result:
\begin{prop}[Definability]
\label{prop:definability} Let $A$ be a PCF type and $\sigma$ be a compact innocent and well-bracketed
strategy on $A$. There exists a PCF' term $M$ such that $\sem{M} = \sigma$.
\end{prop}

Note that definability is proved for PCF' and not for PCF.
Nevertheless, PCF' is a conservative extension of PCF: if $M$ and $N$ are terms such that for any PCF-context $C[-]$,
$C[M] \eval \imp C[N] \eval$ then the same is true for any PCF'-context. This is because $\texttt{case}_k$ constructs can be ``simulated''
in PCF, for instance $\texttt{case}_3$ can be replaced by the PCF term $T$ which shares the same operational semantics.

This observation will allow us to use definability in PCF' to
prove the full-abstraction of PCF.


\subsubsection{Full abstraction}

Full abstraction of PCF cannot be stated directly in the category $\mathcal{C}_{ib}$. Instead we need to consider the quotiented category
$\mathcal{C}_{ib}/\lesssim_{ib}$.

First we need to show that $\mathcal{C}_{ib}/\lesssim_{ib}$ is a model of PCF.
$\mathcal{C}_{ib}/\lesssim_{ib}$ is a posset-enriched cartesian closed category. The game semantics of the basic types and constants of PCF
can be transposed from $\mathcal{C}_{ib}$ to $\mathcal{C}_{ib}/\lesssim_{ib}$. Unfortunately it is not know whether $\mathcal{C}_{ib}/\lesssim_{ib}$
is enriched over the category of CPOs. However it can be proved that it is a rational category \citep{abramsky94full}
and this suffices to ensure that $\mathcal{C}_{ib}/\lesssim_{ib}$ is indeed a model of PCF.

The full abstraction of the game model then follows from
proposition \ref{prop:ineqsoundness} and \ref{prop:definability}:
\begin{thm}[Full abstraction]
Let $M$ and $N$ be two closed IA-terms.
$$\sem{M} \precsim_{ib} \sem{N} \ \iff \ M \obspre N$$
where $\precsim_{ib}$ denotes the intrinsic preorder of the category $\mathcal{C}_{ib}$.
\end{thm}

\section{The fully abstract game model for Idealized Algol (\ialgol)}

We now extend the work of the previous section to the language
\ialgol, an imperative extension of PCF. We start by giving the
syntax and operational semantics of the language, we then describe
the game model which was introduced in \cite{abramsky99full}.
Finally we will state the full abstraction result for the game
model.

\subsection{The syntax of \ialgol}
IA is an extension of PCF introduced by J.C. Reynold in
\cite{Reynolds81}. It adds imperative features such as local
variables and sequential composition.

On top of \texttt{exp}, PCF has the following two new types:
\texttt{com} for commands and \texttt{var} for variables. There is a
constant \texttt{skip} of type \texttt{com} which corresponds to the
command that do nothing.

Commands can be composed using the
sequential composition operator $\texttt{seq}_A$: suppose that $M$ and $N$ are of type
\texttt{com} and $A$ respectively then they can be composed to form the term
$S = \texttt{seq}_A M N : \texttt{com}$. $S$ denotes program that executes $M$ until it terminates and then
behave like $N:A$. If $A = \texttt{exp}$ then the expression is allowed to have a side-effect and $S$ returns the expression computed by $N$, if
$A = \texttt{com}$ then the command $N$ is executed after $M$.
We say that the language has \emph{active expressions} to indicate the presence of the
sequential operator $\texttt{seq}_{exp}$ in the language.


Local variable are
declared using the \texttt{new} operator, variable content is altered
using \texttt{assign} and retrieved using \texttt{deref}.

In addition IA has the constant \texttt{mkvar} that can be used to
create a particular kind of variables. The \texttt{mkvar} operator
works in an object oriented fashion: it takes two arguments, the
first one is a function (called the acceptor) that affects a value
to the variable and the second argument is an expression that
returns a value from the variable. This mechanism is similar to
the ``set/get'' object programming paradigm used by C++ programmers.

Variables created with \texttt{mkvar} are less constraint than the
variables created with \texttt{new}. Indeed, variables created with
\texttt{new} act like memory cells, they obey the following rule: the value read
from the variable is always the last value that has been assigned to
it. This rule does not apply to variables created with
\texttt{mkvar}. For instance the variable:
$$\texttt{mkvar}\ (\lambda v.\texttt{skip})\ 0$$
will always return $0$ even if another number has been assigned it.


One may think that this addition to the language is artificial,
however the full abstraction result of the game model of IA relies
upon this addition. At present, it is still an open problem to find
a fully abstract model of IA deprived of \texttt{mkvar}.

Judgement are of the form $\Gamma \vdash M : A$.
If the judgement $\Gamma = \emptyset$ we say that $M$ is a closed term.
The set of additional formations rules completing those of PCF are
given in table \ref{tab:ia_formrules}.

\begin{table}[htbp]
$$ \rulef{\Gamma \vdash M : \texttt{com} \quad \Gamma \vdash N :A}
    {\Gamma \vdash \texttt{seq}_A \ M\ N\ : A} \quad A \in \{ \texttt{com}, \texttt{exp}\}$$

$$ \rulef{\Gamma \vdash M : \texttt{var} \quad \Gamma \vdash N : \texttt{exp}}
    {\Gamma \vdash \texttt{assign}\ M\ N\ : \texttt{com}}
\qquad
 \rulef{\Gamma \vdash M : \texttt{var}}
    {\Gamma \vdash \texttt{deref}\ M\ : \texttt{exp}}$$

$$ \rulef{\Gamma, x : \texttt{var} \vdash M : A}
    {\Gamma \vdash \texttt{new } x \texttt{ in } M} \quad A \in \{ \texttt{com}, \texttt{exp}\}$$

$$ \rulef{\Gamma \vdash M_1 : \texttt{exp} \rightarrow \texttt{com} \quad \Gamma \vdash M_2 : \texttt{exp}}
    {\Gamma \vdash \texttt{mkvar } M_1\ M_2\ : \texttt{var}}$$

\caption{Formation rules for IA terms}
\label{tab:ia_formrules}
\end{table}


\subsection{Operational semantics of \ialgol}

The operational semantics of IA is given in a slightly different form compared to PCF.
Instead of giving the semantics for closed terms we consider terms
whose free variables are all of type \texttt{var}. Terms are
``closed'' by mean of stores. A store is a function mapping free
variables of type \texttt{var} to natural numbers. Suppose $\Gamma$
is a context containing only variables of type \texttt{var}, then we
say that $\Gamma$ is a \texttt{var}-context. A store with domain
$\Gamma$ is called a $\Gamma$-store. The notation $s\ |\ x \mapsto
n$ refers to the store that maps $x$ to $n$ and otherwise maps
variables according to the store $s$.

%%%% The following is poorly written:
%
%In PCF, the evaluation rules were given for closed terms only.
%Suppose that we proceed the same way for IA and consider the
%evaluation rule for the $\texttt{new}$ construct: the conclusion is
%$\texttt{new } x:=0 \texttt{ in } M$ and the premise is an
%evaluation for a certain term constructed from $M$, more precisely
%the term $M$ where \emph{some} occurrences of $x$ are replaced by
%the value $0$. Because of the presence of the \texttt{assign}
%operator, we cannot simply replace all the occurrences of $x$ in $M$
%(the required substitution is  more complicated than the
%substitution used for beta-reduction).


The canonical forms for IA are given by the grammar:
$$ V ::= \texttt{skip}\ |\ n\ |\ \lambda x. M\ |\ x\ |\  \texttt{mkvar}\ M\ N$$

where $n \in \nat$ and $x: \texttt{var}$.


In \ialgol, a program is a term together with a $\Gamma$-store such
that $\Gamma \vdash M : A$. The evaluation semantics is expressed by
the judgment form:
$$s,M \eval s', V$$
where $s$ and $s'$ are $\Gamma$-stores, $V$ is a canonical form and $\Gamma \vdash V : A$.

The operational semantics for IA is given by the rule of PCF (table \ref{tab:bigstep_pcf})
together with the rules of table \ref{tab:bigstep_ia} where the following abbreviation is used:
$$ \rulef{M_1 \eval V_1 \quad M_2 \eval V_2}{M \eval V} \qquad \mbox{for} \qquad
  \rulef{s,M_1 \eval s',V_1 \quad s', M_2 \eval s'',V_2 }{s,M \eval s'',V}
$$


\begin{table}[htbp]
$$\mbox{\textbf{Sequencing }}
    \rulef{M \eval \iaskip \quad N \eval V}{\texttt{seq } M\ N \eval V}
$$

$$\mbox{\textbf{Variables }}
    \rulef{s,N \eval s',n \quad s',M \eval s'',x}{s, \iaassign\ M\ N \eval (s''\ |\ x \mapsto n),\iaskip}
\qquad
    \rulef{s,M \eval s',x }{s, \iaderef\ M \eval s',s'(x)}$$

$$\mbox{\texttt{\textbf{mkvar}}}
    \rulef{N \eval n \quad M \eval \texttt{mkvar}\ M_1\ M_2 \quad M_1\ n \eval \iaskip}
    {\iaassign\ M\ N \eval \iaskip}
\qquad
    \rulef{N \eval \texttt{mkvar } M_1\ M_2 \quad M_2\ \eval n}
    {\iaderef\ M \eval n}
$$

$$\mbox{\textbf{Block}}
    \rulef{(s\ |\ x \mapsto 0),M \eval (s'\ |\ x \mapsto n),V }
    {s, \texttt{new } x \texttt{ in } M \eval s',V}
$$

\label{tab:bigstep_ia}
\caption{Big-step operational semantics of IA}
\end{table}


\subsection{Game model of \ialgol}

All the strategies used to model PCF are well-bracketed and
innocent. On the other hand, to obtain a model of IA we need to
introduce strategies that are not innocent.
This is necessary to model memory cell variable created with the \texttt{new} operator.
The intuition is that a cell needs to
remember what was the last value written in it in order to be able
to return it when it is read, and this can only be done by looking
at the whole history of moves, not only those present in the P-view.

Hence we now consider the categories $\mathcal{C}$ and $\mathcal{C}_b$.

\subsubsection{Base types}

The type \texttt{com} is modeled by the flat game with a single initial question \texttt{run} and a single answer
\texttt{done}. The idea is that O can request the execution of a command by playing \texttt{run}, P then execute the command
and if it terminates acknowledge it by playing \texttt{done}.

The variable type \texttt{var} is modeled by the game $\mathtt{com^{\bf N} \times exp}$ illustrated below:
\begin{center}
\begin{pspicture}(10cm,1.7cm)
$\rput[b]{0}(3cm,0){
\pstree[treemode=U,levelsep=8ex,nodesep=2pt]
    {\TR[name=R]{\mathtt{ok}}}
    { \TR{\mathtt{write}_0} \TR{\mathtt{write}_1} \TR{\mathtt{write}_2} \TR{\ldots}
    }
}
\rput[b]{0}(8cm,0){
\pstree[levelsep=8ex,nodesep=2pt]
    { \TR[name=R]{\mathtt{read}} }
    { \TR{0} \TR{1} \TR{2} \TR{\ldots} }
    }$
\end{pspicture}
\end{center}

\subsubsection{Constants}

\texttt{skip} is interpreted by the strategy $\{ \epsilon, \iarun \cdot \iadone \}$.
The sequential composition $\mathtt{seq_{exp}}$ is interpreted by the following strategy:
$$
\begin{array}{ccccc}
!\mathtt{com} & \otimes & ! \mathtt{exp} & \multimap & \mathtt{exp}\\
&&&&q\\
\iarun\\
\iadone\\
&&q\\
&&n\\
&&&&n
\end{array}
$$

Assignment \iaassign\ and dereferencing \iaderef\ are denoted  by the
following strategies (left and right respectively):
$$
\begin{array}{ccccc}
!\mathtt{var} & \otimes & ! \mathtt{exp} & \multimap & \mathtt{com}\\
&&&&q\\
&&q\\
&&n\\
\iawrite_n\\
\iaok\\
&&&&\iadone
\end{array}
\hspace{3cm}
\begin{array}{ccccc}
!\mathtt{var} & \multimap & \mathtt{exp}\\
&&q\\
\iaread\\
n\\
&&n
\end{array}
$$

\iamkvar\ is modeled by the paired strategy $\langle \iamkvar_{acc} , \iamkvar_{exp}
\rangle$ where $\iamkvar_{acc}$ and $\iamkvar_{exp}$ are the following strategies:
$$
\begin{array}{ccccccc}
(\mathtt{!exp} & \multimap & \mathtt{com}) & \otimes & !\mathtt{exp} & \multimap & \mathtt{com}^\omega\\
&&&&&&\iawrite_n\\
&&\iarun\\
q\\
n\\
&&\iadone \\
&&&&&&\iaok
\end{array}
\hspace{1.5cm}
\begin{array}{ccccccc}
(\mathtt{!exp} & \multimap & \mathtt{com}) & \otimes & !\mathtt{exp} & \multimap & \mathtt{exp}\\
&&&&&&\iaread\\
&&&&q\\
&&&&n\\
&&&&&&n
\end{array}
$$


The strategies used until now are all innocent. In order to model the \ianew operator, we need to introduce non-innocent strategies, sometimes called
\emph{knowing strategies}. We define the knowing well-bracketed strategy $cell : I \multimap !\mathtt{var}$ that models a storage cell: it responds to \iawrite\
with \iaok\ and responds
to \iaread\ with the last value written or $0$ if no value has yet been written.

Consider the term $\Gamma,x:\mathtt{var} \vdash M : A$ modeled by $\sem{M}$ then the term
 $\Gamma \vdash \ianew\ x \texttt{ in } M : A$  will be modeled by the strategy $(id_{\sem{\Gamma}} \otimes cell) \fatsemi \sem{M}$ on the game
 $!\Gamma \multimap \iacom$.

\subsection{Full abstraction of \ialgol}

We now state the full abstraction result. All the details are omitted, the reader is refered
to \cite{abramsky:game-semantics-tutorial,AM97a} for the proofs.

\subsubsection{Inequational soundness}

The inequational soundness result can be also proved for \ialgol.
Proving soundness of the evaluation requires a bit more work than in the PCF case because
the store needs to be made explicit. Also, an appropriate notion of \emph{computable term} must be defined
that takes into account the presence of stores in the evaluation semantics.
Again it is possible to prove that the model is computational adequate.
The inequational soundness then follows from evaluation soundness and computational adequacy:

%\begin{lem}[Soundness for IA terms] Let $\Gamma \vdash M : A$ be an IA term and a $\Gamma$ store $s$.
%If $s,M \eval s',V$ then the plays of $\sem{s,M} : I \multimap A
%\otimes !\Gamma$ which begin with a move of $A$ are identical to
%those of $\sem{s',V}$.
%\end{lem}

\begin{prop}[Inequational soundness]
\label{prop:ia_ineqsoundness} Let $M$ and $N$ be two \ialgol\ closed terms then
$$\sem{M} \subseteq \sem{N} \implies  M \obspre N $$
\end{prop}

\subsubsection{Definability}

The proof of definability is based on a factoring argument: strategies in
$\mathcal{G}_b$ can all be obtained by composing the non-innocent strategy $cell$ with an innocent strategy.
The strategy $cell$ can therefore be viewed as a generic non-innocent strategy. Using this factorization argument,
it is possible to prove the definability result:
\begin{prop}[Definability]
\label{prop:ia_definability} Let $\sigma$ be a compact well-bracketed
strategy on a game $A$ denoting a IA type. There is an IA-term $M$ such
that $\sem{M} = \sigma$.
\end{prop}

\subsubsection{Full abstraction}

Full abstraction for the model $\mathcal{C}_b$ is a consequence of proposition
\ref{prop:ia_ineqsoundness} and \ref{prop:ia_definability}:
\begin{thm}[Full abstraction]
Let $M$ and $N$ be two closed \ialgol-terms.
$$\sem{M} \precsim_b \sem{N} \ \iff \ M \obspre N$$
where $\precsim_b$ denotes the intrinsic preorder of the category
$\mathcal{C}_b$.
\end{thm}


\section{Algorithmic game semantics}

After the resolution of the ``Full Abstraction of PCF'' problem,
game semantics has become a very successful paradigm in fundamental
computer science. It has permitted to give full abstract semantics
for a variety of programming languages. More recently, game
semantics has emerged as a new approach to program verification and
program analysis. In particular in the paper \cite{ghicamccusker00},
the authors considered a fragment of Idealized Algol for which the
game semantics of programs can be expressed simply using regular
expressions. In this setting, observational equivalence of programs
becomes decidable. Consequently, numbers of interesting verification
problem become solvable. This development opened up a new direction
of research called \emph{Algorithmic game semantics}.

\subsection{Characterization of observational equivalence}

In \citep{AM97a} it is shown that observational equivalence of IA is
characterized by the equality of the set of complete plays.

A play of a game is \emph{complete} if it is maximal and all
question have been answered. A game is \emph{simple} if the complete
plays are exactly those in which the initial question has been
answered. It can be shown that for any IA type $T$, $\sem{T}$ is a
simple game. The following characterization theorem holds for simple
games:
\begin{thm}[Characterization Theorem for Simple Game (Abramsky, McCusker 1997)]
Let $\sigma$ and $\tau$ be strategies on a simple game $A$ then:
$$\sigma \leq \tau \iff \textsf{comp}(\sigma) = \textsf{comp}(\tau)$$
\end{thm}
Therefore IA terms are fully described by the set of complete plays of
the term's strategy.

\subsection{Finitary fragments of Idealized algol}
We introduce
some fragments of the language \ialgol. Firstly, \emph{Finitary
Idealized Algol} denotes the recursion-free sub-fragment of \ialgol\
over finite ground types (i.e. $\nat$ is replaced by the set $0..max$ for some
fixed value $max$).

\begin{dfn}[$i$th order \ialgol\ term]
A term $\Gamma \vdash M:T$ of finitary Idealized algol is an $i$th-order term if any sequent $\Gamma' \vdash N:A$ appearing
in the typing derivation of $M$ is such that $\ord{A} \leq i$ and all the variables in $\Gamma'$ are of order strictly less than $i$.
\end{dfn}

$\ialgol_i$ denotes the fragment of finitary Idealized Algol
consisting of the collection of $i$th-order terms.

$\ialgol_i + \textsf{while}$ denotes the fragment $\ialgol_i$ augmented with
primitive recursion : the formation rules of $\ialgol_i + \textsf{while}$  are those
of $\ialgol_i$ together with the following rule:
$$  \rulef{\Gamma \vdash M : \iabool \qquad \Gamma \vdash N : \iacom}{\Gamma \vdash \iawhile\ M \iado\ N : \iacom } \quad \mbox{where } \forall x \in \Gamma : \ord{x} < i $$

Finally $\ialgol_i + \textsf{Y}_j$ where $j
< i$ denotes the fragment $\ialgol_i$ augmented with a set of
fixed-point iterators $\textsf{Y}_A : (A\rightarrow A ) \rightarrow
A$ for any type $A$ of order $j$ at most. The formation rules of $\ialgol_i + \textsf{Y}_j$  are those
of $\ialgol_i$ together with the following rule:
$$  \rulef{\Gamma \vdash \lambda x . M : A\rightarrow A}{\Gamma \vdash Y_A M : A} \quad \mbox{where } \forall x \in \Gamma : \ord{x} < i
                                                                            \mbox{ and } \ord{A} \leq j $$

We recall the observational equivalence decision problem: given two
$\beta$-normal forms $M$ and $N$ in a given fragment of \ialgol,
does $M \approx N$ hold?

This problem has been investigated and decidability results have
been obtained for a complete class of fragments of Idealized Algol.
These results help us to understand the limits of Algorithmic Game
Semantics. We now present briefly those results.

\subsubsection{$\ialgol_2$ fragment}
In \cite{ghicamccusker00}, Dan R. Ghica and Guy McCusker considered the $\ialgol_2$ fragment.
They show that in $\ialgol_2$ the set of complete plays are
representable by extended regular languages.

\begin{lem}[Ghica and McCusker 2000]
For any $\ialgol_2$-term $\Gamma \vdash M : T$, the set of complete
plays of $\sem{\Gamma \vdash M : T}$ is regular.
\end{lem}
Since equivalence of regular expression is decidable, this shows
decidability of observational equivalence of $\ialgol_2$-terms. In
the same paper they show that the same result holds for the
$\ialgol_2 +\textsf{while}$ fragment.

In \cite{Ong02}, it is shown that observational equivalence is
undecidable for $\ialgol_2 + \textsf{Y}_1$.


\subsubsection{Other fragments of IA}

Observational equivalence is decidable for $\ialgol_3$. This is
proved in \cite{Ong02} by reduction to the \emph{Deterministic
Push-down Automata Equivalence} problem. Unfortunately, this result
does not extend beyond order $3$: Murawski showed in
\cite{murawski03program} that the problem is undecidable for
$\ialgol_i$ with $i\geq4$.

However in $\ialgol_3 + \textsf{while}$ the problem becomes
decidable. More precisely, it is shown in \cite{C:MW05} that
for $\ialgol_2 + \textsf{while}$ and $\ialgol_3 + \textsf{while}$ the problem is EXPTIME.

Moreover in \cite{C:MOW05} it is shown that $\ialgol_i +Y_0$, for $i
= 1, 2, 3$ is as difficult as the DPDA equivalence problem. This
problem is decidable \citep{DBLP:journals/tcs/Senizergues01} but no
complexity result is known about it. We only know that it is
primitive recursive \citep{stirling02}.

\subsubsection{The complete classification}
\begin{center}
\begin{tabular}{rcccc}
Fragment  & pure & +while & +Y0 & +Y1 \\ \hline \hline
$\ialgol_0$ & PTIME & $\times^{(i)}$ & $\times$ & $\times$  \\
$\ialgol_1$ & coNP & PSPACE & DPDA EQUIV & $\times$ \\
$\ialgol_2$ & PSPACE & PSPACE & DPDA EQUIV & undecidable \\
$\ialgol_3$ &EXPTIME & EXPTIME & DPDA EQUIV & undecidable \\
$\ialgol_i, i \geq 4$  & undecidable & undecidable & undecidable
& undecidable
\end{tabular}
\vspace{12pt}

\emph{Notes}: The $\times$ symbol denotes undefined \ialgol\ fragments.
(i) Adding iteration to $\ialgol_0$ does not increase the power of the language since variables are forbidden in the language.
\end{center}

The coNP and PSPACE results are due to Murawski \citep{Mur04b}.

%\input dataref
