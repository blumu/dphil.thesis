\section{Game semantics of simply-typed $\lambda$-terms}

In this section we introduce the concepts of computation tree and
traversals of the computation tree. We will prove a theorem
revealing a correspondence between traversals of the computation
tree and the game semantics of a simply-typed term.
We will then apply this result to the analysis of the game semantics
of safe term and prove that safety leads to an economy of
pointers: for safe $\lambda$-terms the pointers from the game
semantics can be reconstructed uniquely from the moves of the play.


%Is there any unsafe term whose game semantics is a strategy where
%pointers can be recovered?
%
%The answer is yes: take the term $T_i = (\lambda x y . y) M_i S$
%where $i =1..2$ and $\Gamma \vdash_s S : A$. $T_1$ and $T_2$ both
%$\beta$-reduce to the safe term $S$, therefore
%$\sem{T_1}=\sem{T_2}=\sem{S}$. But $T_1$ is safe whereas $T_2$ is
%unsafe. Since it is possible to recover the pointer from the game
%semantics of $S$, it is as well possible to recover the pointer from
%the semantics of $T_2$ which is unsafe.

\subsection{$\eta$-long normal form, computation tree and traversals}
We work in the general setting of the simply-typed $\lambda$ calculus with
a fixed set of higher-order constants noted $\Sigma$.


The $\eta$-expansion of $M: A\typear B$ is defined to be the term $\lambda x . M x : A\typear B$ where $x:A$ is a fresh variable.
It is easy to check that if $M$ is safe then $\lambda x . M x$ is also safe.

A term $M : (A_1,\ldots,A_n,o)$ can be expanded in several steps
into $\lambda \varphi_1 \ldots \varphi_l . M \varphi_1 \ldots
\varphi_l$ where the $\varphi_i:A_i$ are fresh variables. The
$\eta$-normal form of a term is obtained by hereditarily
$\eta$-expanding every subterm occurring at an operand position:

\begin{dfn}[$\eta$-long normal form]
A simply-typed term is either an abstraction or it can be written uniquely as
$s_0 s_1 \ldots s_m$ where $m\geq0$ and $s_0$ is a variable, a $\Sigma$-constant or an abstraction.
The $\eta$-long normal form of a term $M$ denoted $\aux{M}$ or sometimes $\etanf{M}$
is defined as follows:
\begin{align*}
\aux{\alpha s_1 \ldots s_m : (A_1,\ldots,A_n,o)} &= \lambda \overline{\varphi} . \alpha \aux{s_1}\ldots \aux{s_m} \aux{\varphi_1} \ldots \aux{\varphi_n}
& \mbox{with $m,n\geq0$}\\
%\aux{(\lambda x . s_0) s_1 \ldots s_m } &=& (\lambda x . \aux{s_0}) \aux{s_1} \aux{s_2} \ldots \aux{s_m}
\aux{\lambda x . s } &= \lambda x . \aux{s} \\
\aux{(\lambda x . s_0) s_1 \ldots s_m : (A_1,\ldots,A_n,o) } &= \lambda \overline{\varphi} . (\lambda x . \aux{s_0}) \aux{s_1} \ldots \aux{s_m} \aux{\varphi_1} \ldots \aux{\varphi_n}
& \mbox{with $m\geq 1,n\geq0$}
\end{align*}
where $x$ is a variable and $\alpha$ is either a variable or a constant.
\end{dfn}

For $n=0$, the first clause in the definition becomes:
$$\aux{x s_1 \ldots s_m : o} = \lambda . x \aux{s_1} \aux{s_2} \ldots \aux{s_m}.$$
We deliberately keep the \textsl{dummy} lambda in the right-hand side of the equation since it
plays an important role in the correspondence with game semantics.

The $\eta$-long normal form appeared in \citep{DBLP:journals/tcs/JensenP76}
under the name \emph{long reduced form}
and in \citep{DBLP:journals/tcs/Huet75}
under the name \emph{$\eta$-normal form}. It was then investigated in \citep{huet76}
under the name \emph{extensional form}.

Note that our version of the $\eta$-long normal form is defined for any simply-typed term, not only for $\beta$-normal terms.
Moreover it is defined in such a way that $\beta$-normality is preserved:
\begin{lem}
The $\eta$-long normal form of a term in $\beta$-normal form is also in $\beta$-normal form.
\end{lem}
\begin{proof}
By induction on the structure of the term and the order of its type.
\emph{Base case}:
If $M=x:0$ then $\aux{x} = \lambda . x$ is also in $\beta$-nf.
\emph{Step case}:
The case $M = \aux{(\lambda x . s_0) s_1 \ldots s_m : (A_1,\ldots,A_n,o)}$ with $m>0$ is not possible since $M$ is in
$\beta$-normal form.
Suppose $M = \lambda x . s$ then $s$ is in $\beta$-nf. By the induction hypothesis $\aux{s}$ is also in $\beta$-nf and therefore
so is $\aux{M} = \lambda x . \aux{s}$.

Suppose $M= \alpha s_1 \ldots s_m : (A_1,\ldots,A_n,o)$. Let $i,j$ range over $1..n$ and $1..m$ respectively.
The $s_j$ are in $\beta$-nf and the $\varphi_i$ are variables of order smaller than $M$. Hence by the induction hypothesis,
the $\aux{\varphi_i}$ and the $\aux{s_j}$ are in $\beta$-nf.
Hence $\aux{M}$ is also in $\beta$-nf.
\end{proof}


We now give a representation of a term by a tree defined
by induction on the structure of the $\eta$-long normal form:
\begin{dfn}[Computation tree]
For any term $M$ in $\eta$-normal form we define the tree $\tau(M)$ by induction
on the structure of the term.
Since $M$ is in $\eta$-normal form, there are only two cases:
$M$ is either an abstraction or it is of ground type and can be written uniquely as
$s_0 s_1 \ldots s_m : 0$ where $m\geq0$,  $s_0$ is a variable, a
constant or an abstraction and each of the $s_j$ for $j\in 1..m$ is in $\eta$-normal form:
\begin{itemize}
\item for $n\geq0$, the tree for $\lambda x_1 \ldots x_n. N$ where $N$ is not an abstraction is:
$$ \tau(\lambda x_1 \ldots x_n . N) =
      \pstree[levelsep=4ex]
        { \TR{\lambda x_1 \ldots x_n} }
        { \SubTree{\tau(N)^{-}} }
$$
where $\tau(N)^{-}$ denotes the tree obtained after deleting the root of $\tau(N)$.


\item for $m\geq0$ and a variable or constant $\alpha$, the tree for $\alpha s_1 \ldots s_m$ is:
$$ \tau( \alpha s_1 \ldots s_m) =
    \tree{\lambda}
    {
        \pstree[levelsep=4ex]
            { \TR{\alpha} }
            { \SubTree{\tau(s_1)} \SubTree[linestyle=none]{\ldots} \SubTree{\tau(s_m)}
            }
    }
$$


\item the tree for $(\lambda x.s_0) s_1 \ldots s_n$ is:
$$ \tau((\lambda x.s_0) s_1 \ldots s_n) =
    \tree{\lambda}
    {
        \pstree[levelsep=4ex]
            { \TR{@} }
            {
            \SubTree{\tau(\lambda x.s_0)}    \SubTree{\tau(s_1)} \SubTree[linestyle=none]{\ldots} \SubTree{\tau(s_n)}
            }
    }
$$
\end{itemize}

The \emph{computation tree} of a simply-typed term $M$ (whether or not in $\eta$-normal form) is noted $\tau(M)$
and defined to be $\tau(M) = \tau(\etanf{M})$.
\end{dfn}

The nodes (and leaves) of the tree are of three kinds:
\begin{itemize}
\item $\lambda$-node labelled $\lambda \overline{x}$ (note that a $\lambda$-node represents several consecutive variable abstractions),
\item application node labelled $@$,
\item variable or constant nodes labelled $\alpha$ for some constant or variable $\alpha$.
\end{itemize}
We write $N$ for the set of nodes of $\tau(M)$, $N_\Sigma$ to denotes the subset of $\Sigma$-labelled nodes
and $N_@$ to denote the subset of $@$-labelled nodes.


Let $\mathcal{T}$ denotes the set of $\lambda$-terms.
Each subtree of the computation tree $\tau(M)$ represents a subterm of $\aux{M}$.
We define the function $\kappa : N \rightarrow \mathcal{T}$ that maps a node $n \in N$ to the subterm of $\aux{M}$
represented by the subtree of $\tau(M)$ rooted at $n$.
In particular if $r$ is the root of $\tau(M)$ then $\kappa(r) = \aux{M}$.

\begin{dfn}[Node order]
\label{def:nodeorder}
The node-order function $\textsf{ord}$ is defined on nodes as follows:
\begin{eqnarray*}
\ord{n} = \left\{
  \begin{array}{ll}
    \ord{T}, & \hbox{if $n$ is a variable or constant node labelled $\alpha$ of type $T$;} \\
    1 + \max_{z\in \overline{\xi}\union fv(M)} \ord{z}, & \hbox{if $n$ is the root of $\tau(M)$;} \\
    1 + \max_{z\in \overline{\xi}} \ord{z}, & \hbox{if $n$ is labelled $\lambda \overline{\xi}$ and is not the root;} \\
    1, & \hbox{if $n$ is labelled $\lambda$ and is not the root;} \\
    0, & \hbox{if $n$ is labelled $@$.}
  \end{array}
\right.
\end{eqnarray*}
\end{dfn}

\noindent Some remarks:
\begin{itemize}
\item In a computation tree, nodes at even level are abstraction node and nodes at odd level are either application nodes,
variable or constant nodes;

\item for any ground type variable or constant $\alpha$,
$\tau(\alpha) = \tau(\lambda . \alpha) =  \pstree[levelsep=3ex]
    { \TR{\lambda } }
    { \TR{\alpha}
    }$;

\item for any higher-order variable or constant $\alpha : (A_1,\ldots,A_p,o)$, the computation tree $\tau(\alpha)$ has following form:
$ \pstree[levelsep=3ex]{\TR{\lambda}}
        {\pstree[levelsep=3ex]
                { \TR{x} }
                { \tree{\lambda \overline{\xi_1}}{\TR{\ldots}} \TR{\ldots} \tree{\lambda \overline{\xi_p}}{\TR{\ldots}}
                }
        }
$;

\item for any abstraction node
        $ \pstree[levelsep=4ex]
            { \TR{\lambda \overline{\varphi}} }
            { \pstree[levelsep=3ex]
                {\TR{n}}
                {\TR{\lambda \overline{\xi_1}} \TR{\ldots} \TR{\lambda \overline{\xi_p}}}
            }
        $,
    we have $\ord{\kappa(n)}=0$.

\end{itemize}



\subsubsection{Pointers and justified sequence of nodes}

\begin{dfn}[Binder]
Let $n$ be a variable node of the computation tree labelled $x$. We
say a node $n$ is bound by the node $m$ if $m$ is the closest node
in the path from $n$ to the root of the tree such that $m$ is
labelled $\lambda \overline{\xi}$ with $x\in \overline{\xi}$. $m$ is
called the binder of $n$.
\end{dfn}

\begin{dfn}[Enabling]
The enabling relation $\vdash$ is defined on the set of nodes of the
computation tree. We write $m \vdash n$ and we say that the node $n$
is enabled by $m$ or that $m$ enables $n$ if and only if
\begin{itemize}
\item $n$ is a bound variable node and $m$ is the binder of $n$,
\item or $n$ is a free variable node and $r$ is the root of the computation tree,
\item or $n$ is a $\lambda$-node and $m$ is the parent node of $n$.
\end{itemize}
\end{dfn}



\begin{dfn}[Justified sequence of nodes]
A \emph{justified sequence of nodes} is an alternating sequence of
lambda and non lambda nodes from the computation tree $\tau(M)$
together with pointers. A node $n$ in the sequence
that is either a variable node or a lambda-node different from the root of the computation tree
has a pointer to a node $m$ occurring before $n$ in the sequence such that $m \vdash n$.

If $n$ points to $m$ we say that $m$ justifies $n$ and we write:
$$\rnode{m}{m} \cdot \ldots \cdot \rnode{n}{n} \bkptra[nodesep=1pt]{40}{n}{m}$$


We sometimes add a label to the edge to specify that either node $n$
is labelled by the $i$th variable abstracted in the lambda node
$m$ or that $n$ is the $i$th child of the non-lambda node $m$.
Hence the pointers in a justified sequence of nodes must be of one
of the following forms: \vspace{2pt}
$$
\rnode{m}{r} \cdot \ldots \cdot \rnode{n}{z} \bkptra[nodesep=1pt]{40}{n}{m}
\hspace{1.5cm}
\rnode{m}{\lambda \overline{\xi}} \cdot \ldots \cdot \rnode{n}{\xi_i} \bkptra[nodesep=1pt]{40}{n}{m} \bklabel{i}
\hspace{1.5cm}
\rnode{m}{@ } \cdot \ldots \cdot \rnode{n}{\lambda \overline{\xi}} \bkptra[nodesep=1pt]{40}{n}{m} \bklabel{j}
\hspace{1.5cm}
\rnode{m}{x} \cdot \ldots \cdot \rnode{n}{\lambda \overline{\xi}} \bkptra[nodesep=1pt]{40}{n}{m} \bklabel{k}
\hspace{1.5cm}
\rnode{m}{f } \cdot \ldots \cdot \rnode{n}{\lambda \overline{\xi}} \bkptra[nodesep=1pt]{40}{n}{m} \bklabel{k}
$$
for some variables $x,\xi_1, \ldots \xi_n$, $\Sigma$-constant $f$, $i \in 1..n$, $j \in 0..1$, $k \in 1 ..arity(m)$,
variable $z$ free in $M$ and where $r$ denotes the root of $\tau(M)$.

With the following conventions:
\begin{itemize}
\item the first child of a $@$-node is numbered $0$,
\item the first child of a variable or constant node is numbered $1$,
\item the first variable in $\overline{\xi}$ is numbered $1$ ($\overline{\xi} = \xi_1, \ldots \xi_n$).
\end{itemize}
\end{dfn}

Note that justified sequences are also defined for open terms:
a node labelled $x$ where $x$ is a variable free in $M$ must point to the root of the computation tree.

We write $s \jseq t$ to denote that the two justified sequences $t$ and $s$ have
the same nodes and same pointers.

We say that a node $n_0$ of a justified sequence is hereditarily justified by $n_p$ if there are nodes $n_1, n_2, \ldots n_{p-1}$ in
the sequence such that for all $i\in 0..p-1$, $n_i$ points to $n_{i+1}$.

If $N$ is a set of nodes and $s$ a justified sequence of nodes then
we write $s \upharpoonright N$ to denote the subsequence of $s$
obtained by keeping only the nodes that are hereditarily
justified by nodes in $N$. This subsequence is also a justified
sequence of nodes. If $n$ denotes a node of $\tau(M)$ we
abbreviate $s \upharpoonright \{ n \}$ into $ s\upharpoonright n$.


\begin{dfn}[P-view of justified sequence of nodes]
The P-view of a justified sequence of nodes $t$ of $\tau(M)$ noted $\pview{t}$ is defined as follows:
\begin{eqnarray*}
 \pview{\epsilon} &=&  \epsilon \\
 \pview{s \cdot n }  &=&  \pview{s} \cdot n \\
 \pview{s \cdot \rnode{m}{m} \cdot \ldots \cdot \rnode{lmd}{\lambda \overline{\xi}}} &=& \pview{s} \cdot \rnode{m2}{m} \cdot \rnode{lmd2}{\lambda \overline{\xi}}
   \bkptra[nodesep=1pt]{30}{lmd}{m}
   \bkptra[nodesep=1pt]{60}{lmd2}{m2} \\
 \pview{s \cdot r }  &=&  r
\end{eqnarray*}
where $r$ is the root of the tree $\tau(M)$ and
$n$ ranges over non-lambda nodes (i.e. labelled either $@$ or by a variable or $\Sigma$-constant).

In the second clause, the pointer associated to $n$ is preserved from the left-hand side to the right-hand side:
if in the left-hand side, $n$ points to some node in $s$ that is also present in $\pview{s}$ then in the right-hand side,
  $n$ points to this occurrence of the node in $\pview{s}$.

Similarly, in the third clause the pointer associated to $m$ is preserved.
\end{dfn}

We also define O-view, the dual notion of P-view:
\begin{dfn}[O-view of justified sequence of nodes]
The O-view of a justified sequence of nodes $t$ of $\tau(M)$ noted $\oview{t}$ is defined as follows:
\begin{eqnarray*}
 \oview{\epsilon} &=&  \epsilon \\
 \oview{s \cdot \lambda \overline{\xi} }  &=&  \oview{s} \cdot \lambda \overline{\xi} \\
 \oview{s \cdot \rnode{m}{m} \cdot \ldots \cdot \rnode{x}{x}} &=& \oview{s} \cdot \rnode{m2}{m} \cdot \rnode{n2}{x} \\
   \bkptra[nodesep=1pt]{30}{x}{m}
   \bkptra[nodesep=1pt]{60}{n2}{m2}
 \oview{s \cdot n }  &=&  n
\end{eqnarray*}
where $x$ ranges over variable nodes and  $n$ ranges over non-lambda nodes without pointer (either $@$ or $f$ for some
$\Sigma$-constant $f$).

The pointer associated to $\lambda \overline{\xi}$ in the second equality
as well as the pointer associated to $m$ in the third equality are preserved from the left-hand side to the right-hand side of the equalities.
\end{dfn}

\begin{dfn}[Alternation and Visibility] \ \\
A justified sequence of nodes $s$ satisfies:
\begin{itemize}
\item \emph{alternation} if for any two consecutive nodes in $s$, one is a $\lambda$-node
and the other is not;

\item \emph{P-visibility} if every variable node in $s$ points to a node occurring in the P-view a that point;

\item  \emph{O-visibility} if every lambda node in $s$ points to a node occurring in the O-view a that point.
\end{itemize}
\end{dfn}

\begin{property}
\label{proper:pview_visibility}
The P-view (resp. O-view) of a justified sequence verifying P-visibility (resp. O-visibility)
is a well-formed justified sequence verifying P-visibility (resp. P-visibility).
\end{property}
This is proved by an easy induction.

\subsubsection{Adding value leaves to the computation tree}
\label{sec:adding_value_leaves}

We now add leaves to the computation tree. These leaves called
\emph{value-leaves} are attached to the nodes of the current computation tree.
Each value-leaf corresponds to a possible value of the base type $o$.

We write $\mathcal{D}$ to denote the set of values of the base type $o$.
The values leaves are added as follows: for each node $n \in \tau(M)$ which is not labelled by $@$
and for each value $v \in \mathcal{D}$ we attach a child leaf labelled $n^v$ to the node $n$.

Everything that has been defined for computation tree can be extended to this new version of computation tree.
The node order of a value-leaf is defined to be $0$. The enabling relation $\vdash$ is extended so that every leaf is enabled
by its parent node. The definition of justified sequence does not change.
For the definition of P-view, O-view and visibility, value leaves are treated as $\lambda$ nodes if they are at odd level in the computation tree and
as variable nodes if there at a even level.

From now the term ``computation tree'' refers to this extended definition.


Let $n$ be a node of justified sequence of nodes that is not a value-leaf nor an application node $@$.
We say that $n$ is an \emph{unmatched nodes} if $n$ is not pointed to by any value-leaf in the sequence.
We say that $n$ is \emph{matched} by an occurrence of a value-leaf $n^v$ if $n^v$ points to $n$ in the traversal.
The last unmatched node is called the \emph{pending node}.
A justified sequence of node is \emph{well-bracketed} if
each value-leaf in the traversal points to the pending node at that point.

If $t$ is a traversal then we write $?(t)$ to denote the sequence
obtained from $t$ by conserving only unmatched nodes. $?(t)$ does not contain any $@$-node.

We call \emph{input variable} a variable that is justified by the root of $\tau(M)$ (i.e. either free in $M$ or bound by the root of $\tau(M)$).

\subsubsection{Traversal of the computation tree}
\label{subsec:traversal}

Intuitively, a \emph{traversal} is a justified sequence of nodes of the computation tree where each node
indicates a step that is taken during the evaluation of the term.

\begin{dfn}[Traversal for pure simply-typed $\lambda$-calculus]
\label{def:traversal}
In the simply-typed $\lambda$-calculus with no constants,
a traversal over a computation tree $\tau(M)$
is a justified sequence of nodes defined by induction on the rules
given below. A \emph{maximal-traversal} is a traversal that cannot be
extended by any rule.

\emph{Initialization rules}
\begin{itemize}
\item ($\epsilon$) The empty sequence of node $\epsilon$ is a traversal of $\tau(M)$.

\item (Root) A traversal can only starts from the root of the tree: if $r$ denotes root of $\tau(M)$ then the sequence $t = r$
is a traversal.
\end{itemize}


\emph{Structural rules}
\begin{itemize}
\item (Lam) Suppose that $t \cdot \lambda \overline{\xi}$ is a traversal and $n$ is the only child node of $\lambda \overline{\xi}$ in
the computation tree then
$$t \cdot \lambda \overline{\xi} \cdot n$$
is also a traversal
where $n$ points to the (only) occurrence of its enabler in $\pview{t \cdot \lambda \overline{\xi}}$.
In particular, if $n$ is a free variable node then $n$ points to the first node of $t$.

\item (App) If $t \cdot @$ is a traversal then so is
$$t \cdot \rnode{m}{@} \cdot
\rnode{n}{n} \bkptra[nodesep=1pt]{80}{n}{m} \bklabelb{0}
$$

i.e. the next visited node is the $0$th child node of $@$ : the
node corresponding to the operator of the application.
\end{itemize}

\emph{Input variable rules}

Suppose $t = t_1 \cdot p \cdot t_2$ is a traversal where $p$ is the pending $\lambda$-node in $t$ (i.e. $?(t_2)=\epsilon$) then:
\begin{itemize}
\item (InputVar$^0$) If $p = x$ is a ground-type input variable then for any $v \in \mathcal{D}$
the following is a traversal
$$t_1 \cdot \rnode{x}{x} \cdot t_2 \cdot \rnode{xv}{x^v}
\bkptra[nodesep=1pt]{60}{xv}{x}$$


\item (InputVar$^{\geq 1}$) If $p = x$ is a non-ground type input variable then the following is a traversal:
$$t_1 \cdot \rnode{m}{x} \cdot t_2 \cdot
\rnode{n}{n} \bkptra[nodesep=1pt]{80}{n}{m} \bklabelb{i} \qquad
\mbox{ for } 1 \leq i \leq arity(x).$$
and for any $v\in \mathcal{D}$ the following sequence is also a traversal:
$$t_1 \cdot \rnode{x}{x} \cdot t_2 \cdot \rnode{xv}{x^v}
\bkptra[nodesep=1pt]{60}{xv}{x}$$
\end{itemize}

\emph{Copy-cat rules}
\begin{itemize}
  \item (CCAnswer-$@$) If $t \cdot \lambda \overline{\xi} \cdot \rnode{app}{@} \cdot \rnode{lz}{\lambda \overline{z}} \cdot \ldots \cdot  \rnode{lzv}{\lambda \overline{z}^v}
              \bkptra[nodesep=1pt]{30}{lzv}{lz}
              \bkptra[nodesep=1pt]{40}{lz}{app} \bklabelc{0}$
              is a traversal then so is:
              $t \cdot \rnode{lmd}{\lambda \overline{\xi}} \cdot \rnode{app}{@} \cdot \rnode{lz}{\lambda \overline{z}} \cdot \ldots \cdot \rnode{lzv}{\lambda \overline{z}^v} \cdot
              \rnode{lmdv}{\lambda \overline{\xi}^v}
              \bkptra[nodesep=1pt]{30}{lzv}{lz}
              \bkptra[nodesep=1pt]{40}{lz}{app} \bklabelc{0}
                \bkptra[nodesep=1pt]{20}{lmdv}{lmd}$

  \item (CCAnswer-$\lambda$) If $t \cdot \lambda \overline{\xi} \cdot \rnode{x}{x} \cdot \ldots \cdot  \rnode{xv}{x^v}
              \bkptra[nodesep=1pt]{30}{xv}{x}$
              is a traversal then so is:
              $t \cdot \rnode{lmd}{\lambda \overline{\xi}} \cdot \rnode{x}{x} \cdot \ldots \cdot \rnode{xv}{x^v} \cdot
              \rnode{lmdv}{\lambda \overline{\xi}^v}
              \bkptra[nodesep=1pt]{30}{xv}{x}
                \bkptra[nodesep=1pt]{20}{lmdv}{lmd}$

     \item (CCAnswer-var) If $t \cdot y \cdot \rnode{lmd}{\lambda \overline{\xi}}
                   \cdot \ldots
                   \cdot \rnode{lmdv}{\lambda \overline{\xi}^v} \bkptra[nodesep=1pt]{30}{lmdv}{lmd}$ is a traversal,
                   where $y$ is a non-input variable node, then the following is also a traversal:
        $$t \cdot \rnode{y}{y}
            \cdot \rnode{lmd}{\lambda \overline{\xi}}
            \cdot \ldots
            \cdot \rnode{lmdv}{\lambda \overline{\xi}^v}
            \cdot \rnode{yv}{y^v}
                \bkptra[nodesep=1pt]{30}{yv}{y}
                \bkptra[nodesep=1pt]{30}{lmdv}{lmd}.$$


\item (Var)
If $t \cdot x_i$ is a traversal where $x_i$ is not an input variable,
then the next node to visit in the traversal must correspond to the term that would be substituted
for $x_i$ if the $\beta$-redex in term $M$ were reduced.

The binding node $\lambda \overline{x}$ must have been visited
previously in the traversal. Since $\lambda \overline{x}$ is not the
root of the tree, it must be justified by some previous node in the
traversal. This implies that $\lambda \overline{x}$ is not the first
node in the traversal and therefore there is an application node $n$
preceding $\lambda \overline{x}$ in the traversal: $t \cdot x_i = t'
\cdot n \cdot x_i$. We do a case analysis on $n$:

    \begin{itemize}
    \item Suppose $n$ is an application node $@$ then $\lambda \overline{x}$ is the first child node of $n$
    and $n$ has exactly $|\overline{x}| + 1$ children nodes:
    $$\pstree[levelsep=8ex]{\TR{\stackrel{\vdots}{@^{[n]}}}}
    {   \pstree[linestyle=dotted]{\TR{\lambda \overline{x}}\treelabel{0}}
            {\TR{x_i }}
        \tree{\lambda \overline{\eta_1}}{\vdots}\treelabel{1}
        \TR[edge=\dedge]{}
        \tree{\lambda \overline{\eta_i}}{\vdots}\treelabel{i}
        \TR[edge=\dedge]{}
        \tree{\lambda \overline{\eta_{|x|}}}{\vdots}\treelabel{|x|}
    }
    $$
    Then the following justified sequence is also a traversal:
    \vspace{0.3cm}
    $$t' \cdot \rnode{n}{@^{[n]}} \cdot
    \rnode{lx}{\lambda \overline{x}} \cdot \ldots \cdot
    \rnode{x}{x_i} \cdot
    \rnode{mi}{\lambda \overline{\eta_i}} \cdot \ldots
    \bkptra[ncurv=0.45]{45}{mi}{n} \bklabel{i}
    \bkptra[nodesep=0pt,ncurv=0.6]{50}{x}{lx} \bklabel{i}
    $$
    i.e. the next step of the traversal is a jump to the $i$th child of
    $@$ ($\lambda \overline{\eta_i}$) which corresponds to the term that would be substituted for $x_i$ if the $\beta$-reduction was
    performed.



    \item Suppose $n$ is labelled $y$. This means that this occurrence of the variable $y$ is substituted by the term
    $\kappa(\lambda \overline{x})$ during the evaluation of the term. This implies that $y$ is not a ground type variable (indeed
     $\overline{x}$ is not empty since $x_i \in \overline{x}$, therefore
    $\ord{y} = \ord{\lambda \overline{x}} > 0$).
    $y$ is neither a constant nor a free variable (otherwise $y$ would not be substituted during the evaluation of the term).
    Hence $y$ must be a variable bound by a node different from the
    root.

    During reduction, the occurrence of the variable $x_i$ will be substituted by the term represented by
    node $\lambda \overline{\eta_i}$ (the $i$th child node of $y
    @$).
    Hence the following justified sequence is also a traversal:
    \vspace{0.2cm}
    $$t' \cdot \rnode{n}{y^{[n]}} \cdot
    \rnode{lx}{\lambda \overline{x}} \cdot \ldots \cdot
    \rnode{x}{x_i} \cdot
    \rnode{mi}{\lambda \overline{\eta_i}} \cdot \ldots
    \bkptra[ncurv=0.6]{50}{x}{lx} \bklabel{i}
    \bkptra[ncurv=0.5]{50}{mi}{n} \bklabel{i}$$

    \end{itemize}
\end{itemize}
We write $\travset(M)$ for the set of traversals of $\tau(M)$.
\end{dfn}

\begin{exmp}
Consider the following tree:
$$\tree{\lambda}
{
    \tree{@}
    {
        \pstree[levelsep=8ex,linestyle=dotted]{\TR{\lambda y}\treelabel{0} }
        {
            \pstree[levelsep=8ex]{\TR{y}}
            {
                \tree{\lambda \overline{\eta_1}}{\vdots} \treelabel{1}
                \TR[edge=\dedge]{}
                \tree{\lambda \overline{\eta_i}}{\vdots}\treelabel{i}
                \TR[edge=\dedge]{}
                \tree{\lambda \overline{\eta_n}}{\vdots}\treelabel{n}
            }
        }
        \pstree[levelsep=6ex,linestyle=dotted]{\TR{\lambda \overline{x}}\treelabel{1}}{ \tree{x_i}{\TR{} \TR{} } }
    }
}
$$
The following justified sequence is a traversal of the tree:
\vspace{0.3cm}
$$ \lambda \cdot
\rnode{app}{@}  \cdot
\rnode{ly}{\lambda y} \cdot \ldots \cdot
\rnode{y}{y} \cdot
\rnode{lx}{\lambda \overline{x}} \cdot \ldots \cdot
\rnode{x}{x_i} \cdot
\rnode{leta}{\lambda \overline{\eta_i} } \cdot \ldots
\bkptra[ncurv=0.6,nodesep=0]{40}{x}{lx}  \bklabel{i}
\bkptra[ncurv=0.5]{50}{leta}{y}  \bklabel{i}
\bkptra[ncurv=0.6,nodesep=0]{40}{y}{ly}  \bklabel{1}
\bkptra[ncurv=0.5]{50}{lx}{app}  \bklabel{1}$$
\end{exmp}


\begin{dfn}[Well-behaved traversal rule]
\label{def:wellbehaved_traversal}
A traversal rule is \emph{well-behaved} if it can be stated under the following form:
$$\rulef{t = t_1\cdot n \cdot t_2 \in \travset \quad ?(t_2) = \epsilon \quad P(t_2)}
  { \stackrel{  \rule{0pt}{3pt} }{t' = t_1\cdot \rnode{n}{n} \cdot t_2 \cdot \rnode{m}{m} \in \travset} } \bkptra[nodesep=1pt]{35}{m}{n}$$
such that:
\begin{enumerate}
  \item $n$ is not a $\lambda$-node;
  \item $P$ expresses some property which must be verified by the segment of traversal $t_2$;
  \item $m$ is uniquely determined by $t$ (i.e. the rule is deterministic).
\end{enumerate}
\end{dfn}
We have the following immediate properties: $m$ must be a child node of $n$ and therefore $m$ must be a $\lambda$-node;
if $t$ is well-bracketed then $t'$ is also well-bracketed
and if $?(t)$ satisfies alternation (resp. visibility) then so does $?(t')$.


For example, the rules (InputVar$^0$) and (InputVar$^{\geq1}$) verify all the condition of well-behaviour except determinism.


In the presence of higher-order constants, there must be additional rules to take into account the
constant nodes of the computation tree.
From now on, we assume that some constant rules have been fixed and that they respect the following two conditions:
\begin{itemize}
  \item[(C1)] constant traversal rules are well-behaved;
  \item[(C2)] the system of constant traversal rules is deterministic (i.e. the domains of application of the
  constant rules do not overlap.
\end{itemize}


\begin{prop}
\label{prop:pviewtrav_is_path}
Let $t$ be a traversal. Then:
\begin{itemize}
\item[(i)] $t$ is a well-defined and well-bracketed justified sequence;
\item[(ii)] $?(t)$ is a well-defined justified sequence verifying alternation, P-visibility and O-visibility;
\item[(iii)] $\pview{?(t)}$ is a path in the computation tree going from the root to the last node in $?(t)$.
\end{itemize}
\end{prop}
This is the counterpart of proposition 6 from \cite{OngHoMchecking2006} which is proved by induction on the traversal rules.
This proof can be easily adapted to take into account the constant rules (since constants rules are required to be well-behaved)
and the presence of value-leaves in the traversal.

%In particular to prove that the copy-cat rules are well-defined, one needs to ensure that
%if the last two unmatched nodes are $y$ and $\lambda \overline{\xi}$ in that order, for some non-input variable node $y$ then necessary
%      $y$ and $\lambda \overline{\xi}$ are consecutive nodes in the traversal.
%    This is because in a traversal, a non input variable $y$ is always followed by a lambda node and whenever this lambda node is answered
%    there is only one way to extend the traversal : by using the copy cat rule to answer the $y$ node.


\begin{dfn}[Reduced-traversal]
Let $r$ be the root of the computation tree. A \emph{reduced-traversal} is a justified sequence of nodes $s$ such that
$s \jseq t \upharpoonright r$ for some traversal $t$. $s$ is called the reduction of $t$.
\end{dfn}

Since $@$-nodes and $\Sigma$-constant do not have pointer, a reduced-traversal contains only
non-lambda nodes and variable nodes.


\begin{lem}
\label{lem:var_followedby_child}
Let $M$ be a term in $\beta$-normal form and $t$ be a traversal of $\tau(M)$.
If $?(t) = u_1 \cdot \rnode{m}{m} \cdot u_2 \cdot \rnode{n}{n} \bkptra[nodesep=1pt]{30}{n}{m}$ and $m$ is a not a $\lambda$-node then $u_2 = \epsilon$.
\end{lem}
\begin{proof}
By induction on the traversal rules. The only relevant rules are (Var), (CCAnswer-var), (InputVar$^0$), (InputVar$^{\geq 1}$)
and the constant rules.
Since the term is in $\beta$-normal form, there is no $@$-node in $\tau(M)$ and therefore (Var) cannot be used.
For the rules (CCAnswer-var), (InputVar$^0$) and (InputVar$^{\geq 1})$ we just use the well-bracketedness of traversals.
For the constant rules, the result is a consequence of condition (C1) stating that constant rules are the well-behaved.
\end{proof}

\begin{lem}[Views of reduced-traversal]
\label{lem:redtrav_trav} Let $M$ be a term in $\beta$-normal form,
$r$ denote the root of $\tau(M)$ and $t$ be a traversal of $\tau(M)$. We have
\begin{itemize}
\item[(i)] $ \pview{?(t) \upharpoonright  r } \jseq \pview{?(t)} \upharpoonright r$;
\item[(ii)] if the last node in $t$ is hereditarily justified by $r$ then $ \oview{?(t) \upharpoonright r } \jseq \oview{?(t)}$.
\end{itemize}
\end{lem}

\begin{proof}
(i) By induction. Base case: it is trivially true for the empty
traversal $t = \epsilon$. Step case: consider a traversal $t$ and
suppose that the property (i) is verified for all traversal smaller
than $t$. There are three cases:
\begin{itemize}
\item Suppose $?(t) = t' \cdot r$ then:
    \begin{align*}
    \pview{?(t)} \upharpoonright  r
        &\jseq  \pview{t' \cdot r } \upharpoonright  r       & (\mbox{definition of } ?(t))\\
        &\jseq  r \upharpoonright  r                         & (\mbox{def. P-view})\\
        &\jseq  r                                                & (\mbox{def. operator $\upharpoonright$})\\
        &\jseq  \pview{(t' \upharpoonright  r ) \cdot r }    & (\mbox{def. P-view})\\
        &\jseq  \pview{(t' \cdot r)  \upharpoonright  r }    & (\mbox{def. operator $\upharpoonright$})\\
        &\jseq \pview{?(t) \upharpoonright  r }                & (\mbox{definition of } ?(t))
    \end{align*}

\item Suppose $?(t) = t' \cdot n$ where $n$ is a non-lambda
move. We have:
    \begin{equation}
    \pview{?(t)} = \pview{t' \cdot n} = \pview{t'} \cdot n  \label{eq_tprime}
    \end{equation}
    \begin{itemize}
    \item If $n$ is not hereditarily justified by $r$ then:
    \begin{align*}
    \pview{?(t)} \upharpoonright  r
        &\jseq (\pview{t'} \cdot n) \upharpoonright  r  & (\mbox{equation \ref{eq_tprime}}) \\
        &\jseq \pview{t'} \upharpoonright  r            & (n \mbox{ is not hereditarily justified by } r) \\
        &\jseq \pview{t' \upharpoonright  r }           & (\mbox{induction hypothesis}) \\
        &\jseq \pview{(t' \cdot n) \upharpoonright  r } & (n \mbox{ is not hereditarily justified by } r) \\
        &\jseq \pview{?(t) \upharpoonright  r  }           & (\mbox{definition of } ?(t))
    \end{align*}

    \item If $n$ is hereditarily justified by $r$ then:
    \begin{align*}
    \pview{?(t)} \upharpoonright  r
    &\jseq (\pview{t'} \cdot n) \upharpoonright  r      & (\mbox{equation \ref{eq_tprime}}) \\
    &\jseq (\pview{t'} \upharpoonright  r  ) \cdot n    & (n \mbox{ is hereditarily justified by } r)\\
    &\jseq \pview{t' \upharpoonright  r } \cdot n       & (\mbox{induction hypothesis}) \\
    &\jseq \pview{(t' \upharpoonright  r ) \cdot n }    & (\mbox{P-view computation}) \\
    &\jseq \pview{(t' \cdot n) \upharpoonright  r  }    & (n \mbox{ is hereditarily justified by } r) \\
    &\jseq \pview{?(t) \upharpoonright  r  }               & (\mbox{definition of } ?(t))
    \end{align*}
    \end{itemize}


\item Suppose that $?(t) =  t' \cdot \rnode{m}{m} \cdot  u \cdot \rnode{lmd}{n}
    \bkptra[nodesep=1pt]{30}{lmd}{m}$ where $n$ is a $\lambda$ node then by lemma
    \ref{lem:var_followedby_child} we have $u = \epsilon$ and therefore:
        \begin{align*}
        \pview{?(t)} \upharpoonright  r
        &= \pview{t' \cdot \rnode{m}{m} \cdot \rnode{n}{n}} \upharpoonright  r
               \bkptra[nodesep=1pt]{60}{n}{m}                   & (u=\epsilon)\\
        &\jseq (\pview{t'} \cdot \rnode{m}{m} \cdot \rnode{lmd}{n} ) \upharpoonright  r
               \bkptra[nodesep=1pt]{60}{lmd}{m}                 & (\mbox{P-view computation}) \\
        &\jseq \pview{t'} \upharpoonright  r                & (m, n \mbox{ are not hereditarily justified by } r) \\
        &\jseq \pview{t' \upharpoonright  r }               & \mbox{(induction hypothesis)} \\
        &\jseq \pview{ (t' \cdot \rnode{m}{m} \cdot \rnode{lmd}{n}) \upharpoonright r }
                        \bkptra[nodesep=1pt,ncurv=0.7]{40}{lmd}{m}
                                                            & (\mbox{def. operator $\upharpoonright$ and } m, \lambda \mbox{ are not her. just. by } r) \\
        &\jseq \pview{ ?(t) \upharpoonright r }                & \mbox{(def. of $?(t)$)}
        \end{align*}
\end{itemize}
(ii) By a straightforward induction similar to (i).
\end{proof}

\begin{lem}[Traversal of $\beta$-normal terms]
\label{lem:betaeta_trav}
Let $M$ be a $\beta$-normal term, $r$ denotes the root of the tree $\tau(M)$ and
$t$ be a traversal of $\tau(M)$.
For any node $n$ occurring in $t$:
\begin{eqnarray*}
r \mbox{ does not hereditarily justify } n  \  \iff \   n \mbox{
is hereditarily justified by some node in } N_\Sigma;
\end{eqnarray*}
%\begin{itemize}
%\item[(i)]
%for any node $n$ occurring in $t$:
%\begin{eqnarray*}
%r \mbox{ does not hereditarily justify } n  \  \iff \   n \mbox{
%is hereditarily justified by some node in } N_\Sigma;
%\end{eqnarray*}
%\item[(ii)] For any $\lambda$-node $n$ occurring in $t$, $t_{\geq n} \in \travset(\kappa(n))$,
%
% where $t_{\geq n}$ denotes the justified sequence of nodes obtained by taking the suffix of $t$ starting at $n$ and
% such that any dangling link going from a variable node to a node preceding $n$ is ``fixed'' into a pointer going to $n$.
% \end{itemize}
\end{lem}
\begin{proof}
%(i)
 In a computation tree, the only nodes that do not have justification pointer are:
the root $r$, $@$-nodes and $\Sigma$-constant nodes.
But since $M$ is in $\beta$-normal form the computation tree has no $@$-node.
Hence nodes are either hereditarily justified by $r$ or
hereditarily justified by a node in $N_\Sigma$. Moreover $r$ is not in
$N_\Sigma$ therefore the ``or'' is exclusive : a node cannot be hereditarily justified both by $r$ and by some node in $N_\Sigma$.

%(ii) Since $M$ is in $\beta$-normal, the rules (App) and (Var) cannot be used. Therefore the traversals
%follow an inductive exploration of the computation tree without making any ``jump''.
%Consequently, by taking the prefix of $t$ starting at a $\lambda$-node, we obtain
%a traversal of a sub-computation tree of $\tau(M)$. However by taking the prefix we obtain some dangling pointers.
%The ``fix'' applied to the dangling pointers correspond to the
%The formal proof is by an easy induction on the traversal rules. For the constant rules, we appeal to well-behaviour of the rules.

\end{proof}


\subsection{Game semantics of simply-typed $\lambda$-calculus with $\Sigma$-constants}
\label{sec:assumptions}

We are working in the general setting of an applied simply-typed $\lambda$-calculus with a given set of higher-order constants $\Sigma$.
The operational semantics of these constants is given by certain reduction rules.
We assume that a fully abstract model of the calculus is provided by mean of a category of well-bracketed games.
For instance, if $\Sigma$ is the set of PCF constants then we work in the category $\mathcal{C}_{b}$
of well-bracketed defined in section \ref{subsec:pcfgamemodel} of the first chapter.

We will use the alternative representation of strategy defined in remark \ref{rem:atlern_strategy}: a
strategy is given by a prefix-closed set instead of an ``even length
prefix''-closed set. In practice this means that we replace the set
of plays $\sigma$ by $\sigma \union \textsf{dom}(\sigma)$. This
permits to avoid considerations on the parity of the length of
traversals when we show the correspondence between traversals and
game semantics. We write $\sem{\Gamma \vdash M : A}$ for the strategy denoting the simply-typed term
$\Gamma \vdash M : A$ and $\textsf{Pref}(S)$ to denote the
prefix-closure of the set $S$.


\subsection{Correspondence between computation trees and arenas}

\subsubsection{Example}
By representing side-by-side the computation tree and the type arena of a term in $\eta$-normal form we observe
that some nodes of the computation tree can be mapped to question moves of the arena.

\begin{exmp}
Consider the following term $M \equiv \lambda f z . (\lambda g x . f (f x)) (\lambda y. y) z$ of type $(o \typear o) \typear o \typear o$.
Its $\eta$-long normal form is $\lambda f z . (\lambda g x . f (f x)) (\lambda y. y) (\lambda .z)$.
The computation tree is:

$$
\tree{\lambda f z}
{ \tree{@}
    {
        \tree{\lambda g x}
            { \tree{f}{   \tree{\lambda}{ \tree{f}{  \tree{\lambda}{\TR{x}}} }  }
            }
        \tree{\lambda y}{\TR{y}}
        \tree{\lambda}{\TR{z}}
    }
}
$$

The arena for the type $(o \typear o) \typear o \typear o$ is:
$$\tree{q^1}
{
    \tree{q^3}
        {  \tree{q^4}
                {\TR{a^4_1} \TR{\ldots}}
            \TR{a^3_1} \TR{\ldots} }
    \tree{q^2}
    { \TR{a^2_1} \TR{a^2_2}\TR{\ldots} }
    \TR{a_1} \TR{a_2}\TR{\ldots}
}
$$

\newlength{\yNull}
\def\bow{\quad\psarc{->}(0,\yNull){1.5ex}{90}{270}}

The figure below represents the computation tree (left) and the arena (right). The dashed line defines a
partial function $\varphi$ from the set of nodes in the computation
tree to the set of moves (for simplicity, we now omit answers moves
when representing arenas):
$$
\tree{ \Rnode{root} {\lambda f z w}^{[1]} }
     {  \tree{@^{[2]}}
        {   \tree{\lambda g x ^{[3]}}
                { \tree{\Rnode{f}{f^{[6]}}}{  \tree{\Rnode{lmd}\lambda^{[7]}}{ \tree{\Rnode{f2}{f^{[8]}}} {\tree{\Rnode{lmd2}\lambda^{[9]}}{\TR{x^{[10]}}}}}  }
                }
            \tree{\lambda y ^{[4]}}{\TR{y}}
            \tree{\lambda ^{[5]}}{\TR{\Rnode{z}z}}
        }
    }
\hspace{3cm}
  \tree[levelsep=12ex]{ \Rnode{q1}q^1 }
    {   \pstree[levelsep=4ex]{\TR{\Rnode{q3}q^3}}{\TR{\Rnode{q4}q^4}}
        \TR{\Rnode{q2}q^2}
        \TR{\Rnode{q5}q^5}
    }
\psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
\ncline{->}{root}{q1} \aput*{:U}{\varphi}
\ncarc{->}{z}{q2}
\ncline{->}{f}{q3}
\ncline{->}{lmd}{q4}
\ncline{->}{f2}{q3}
\ncline{->}{lmd2}{q4}
$$

Consider the justified sequence of moves $s \in \sem{M}$:
\vspace{0.5cm}
 $$s =
\rnode{q1}{q}^1\
\rnode{q3}{q}^3\
\rnode{q4}{q}^4\
\rnode{q3b}{q}^3\
\rnode{q4b}{q}^4\
\rnode{q2}{q}^2
\bkptrc{q3}{q1}
\bkptrc[ncurv=0.5]{q3b}{q1}
\bkptrc{q4}{q3}
\bkptrc{q4b}{q3b}
\bkptrc[ncurv=0.5]{q2}{q1}
\in \sem{M}$$

There is a corresponding justified sequence of nodes in the computation tree:
\vspace{0.5cm}
$$r =
\rnode{q1}{\lambda f z} \cdot
\rnode{q3}{f}^{[6]} \cdot
\rnode{q4}{\lambda^{[7]}} \cdot
\rnode{q3b}{f}^{[8]} \cdot
\rnode{q4b}{\lambda^{[9]}} \cdot
\rnode{q2}{z}
\bkptra[ncurv=1]{60}{q3}{q1}
\bkptra[ncurv=1]{60}{q4}{q3}
\bkptra[ncurv=0.4]{75}{q3b}{q1}
\bkptra[ncurv=0.8]{70}{q4b}{q3b}
\bkptra[ncurv=0.4]{80}{q2}{q1}$$
such that $s_i = \varphi(r_i)$ for all $i < |s|$.

The sequence $r$ is in fact a reduced-traversal, it is the reduction of the following traversal:
\vspace{1cm}
$$t =
\rnode{q1}{\lambda f z} \cdot
\rnode{n2}{@^{[2]}} \cdot
\rnode{n3}{\lambda g x^{[3]}} \cdot
\rnode{q3}{f}^{[6]} \cdot
\rnode{q4}{\lambda^{[7]}} \cdot
\rnode{q3b}{f}^{[8]} \cdot
\rnode{q4b}{\lambda^{[9]}} \cdot
\rnode{n8}{x^{[10]}} \cdot
\rnode{n9}{\lambda^{[5]}} \cdot
\rnode{q2}{z}
\bkptra[ncurv=0.6]{60}{q3}{q1}
\bkptra[ncurv=1]{60}{q4}{q3}
\bkptra[ncurv=0.4]{75}{q3b}{q1}
\bkptra[ncurv=0.8]{70}{q4b}{q3b}
\bkptra[ncurv=0.4]{80}{q2}{q1}
\bkptra[ncurv=0.4]{60}{n3}{n2}
\bkptra[ncurv=0.4]{60}{n8}{n3}
\bkptra[ncurv=0.4]{60}{n9}{n2}
$$

This example suggests that a relation exists between game semantics and computation trees.
\end{exmp}


\subsubsection{Computation tree-arena correspondence}

Let us analyze precisely the relationship between the game semantics
and the computation tree. Let $\Gamma \vdash M : A$ be a term in
$\eta$-long normal form.
The computation tree $\tau(M)$ is represented by $(N,E)$ where $N$
is the set of nodes and value-leaves of the tree and $E$ is the
parent-child relation. $E^+$ denotes the transitive closure of $E$:
$E^+(n)$ is the set of nodes $m$ such that there is a path from $n$
to $m$ in the computation tree.

Let $\mathcal{D}$ be the set of values of the base type $o$. If $n$
is a node in $N$ then $n^v$ denotes the value-leave of $n$
corresponding to the value $v$, where $v$ ranges in $\mathcal{D}$.
Similarly, if $q$ is a question in $\sem{A}$ then the answer moves
enabled by $q$ are written $q^v$ where $v$ ranges in $\mathcal{D}$.

\begin{dfn}[Relation between moves of the arena and nodes of the computation tree]
\label{def:phi_procedure}
If $m$ denotes a moves in an arena $A$ we write $A_m$ to denote the sub-arena
of $A$ rooted at $m$.

We consider the computation tree of a simply typed-term.
For any arena $A$, we define a function $f_A(n,q)$ taking two parameters:
a node $n$ of the computation tree and a question move $q$ of the arena $A$
such that $q$ and $n$ have the same type.
$f_A(n,q)$ returns a partial function from $N$ to $A$. It is defined as follows:
\noindent
\begin{itemize}
\item[case 1] If $n$ is an order $0$ $\lambda$-node (labelled $\lambda$) or a ground type variable node then
        $$f_A(n,q) \leftarrow \{ n \mapsto q \} \quad \union \quad  \{ n^v \mapsto q^v \ | \ v \in \mathcal{D} \}$$

\item[case 2] If $n$ is a $\lambda$-node labelled $\lambda \overline{\xi} = \lambda \xi_1 \ldots \xi_p$ with $p\geq 1$ then
    the computation tree and the arena $A_q$ have the following form
    (value leaves and answer moves are not represented for simplicity):
    $$ \tree[levelsep=6ex]{ \Rnode{r}\lambda \overline{\xi}  ^{[n]}}
        {
            \tree[levelsep=6ex]{x}
            {   \TR{\ldots} \TR{\ldots} \TR{\ldots}
            }
        }
    \hspace{3cm}
    \tree{ \Rnode{q0}q }
        {
            \tree[linestyle=dotted]{q^1}{\TR{} \TR{} }
            \tree[linestyle=dotted]{q^2}{\TR{} \TR{} }
            \TR{\ldots}
            \tree[linestyle=dotted]{q^p}{\TR{} \TR{} }
        }
    \psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
    \ncline{->}{r}{q0}
    \ncarc{->}{q2}{z}
    \ncline{->}{q3}{f}
    \ncline{->}{q4}{lmd}
    \ncline{->}{q3}{f2}
    \ncline{->}{q4}{lmd2}
    $$

    For each of the abstracted variable $\xi_i$ there exists a corresponding question move $q_i$ of the same order
    in the arena.  $f_A(n,q)$ maps each free occurrence of a variable $\xi_i$ to the corresponding move $q_i$:
    $$
    f_A(n,q) \leftarrow  \{ n \mapsto q \} \quad  \union \quad  \{ n^v \mapsto q^v \ | \ v \in \mathcal{D} \}
                      \quad \union \quad  \Union_{\stackrel{\displaystyle m \in N | n \vdash m}{\displaystyle m \mbox{ labelled } \xi_i}} f_A( m, q_i)
    $$

\item[case 3] If $n$ is a variable node labelled $x$ with $\ord{x}>0$ and $x:(A_1|\ldots|A_m|o)$ then
the computation tree and the arena $A_q$ have the following form:
    $$\tree[levelsep=6ex]{\Rnode{r}{x^{[n]}}}
        {   \tree{\TR{\lambda \overline{\eta}_1}}{\vdots} \TR{\ldots}
        \tree{\TR{\lambda \overline{\eta}_m }}{\vdots}
        }
    \hspace{3cm}
    \tree{ \Rnode{q0}q }
        {
            \tree[linestyle=dotted]{\Rnode{q1}{q^1}}{\TR{} \TR{} }
            \tree[linestyle=dotted]{\Rnode{q2}{q^2}}{\TR{} \TR{} }
            \TR{\ldots}
            \tree[linestyle=dotted]{\Rnode{qm}{q^m}}{\TR{} \TR{} }
        }
    \psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
    \ncline{->}{r}{q0}
    \ncarc{->}{q2}{z}
    \ncline{->}{q3}{f}
    \ncline{->}{q4}{lmd}
    \ncline{->}{q3}{f2}
    \ncline{->}{q4}{lmd2}
    $$

    $f_A(n,q)$ maps each child node of $n$ to the corresponding question move $q_i$ of the same type
    in the arena $A_q$:
    $$f_A(n,q) \leftarrow
         \{ n \mapsto q \} \quad \union\quad \{ n^v \mapsto q^v \ | \ v \in \mathcal{D}   \} \quad\union\quad     \Union_{i=1..m} f_A( \lambda \overline{\eta}_i, q_i)
    $$
\end{itemize}

Note that $f_A(n,q)$ is only a partial function from $N$ to $A$ since it is not defined on
nodes that are hereditarily justified by a variables free in $M$ or by a node in $N_@ \union N_\Sigma$.
\end{dfn}

Suppose $\Gamma \vdash M  : T$ is a simply typed term and $N$ denotes the set of nodes of the computation tree.
We write $\mathcal{M}_M$ to denote the following disjoint union of arenas:
$$\mathcal{M}_M = \sem{\Gamma \rightarrow T} \quad \uplus \quad  \biguplus_{n \in N |  n \in E \relimg{N_@ \union N_\Sigma} } \sem{type(\kappa(n))}.$$

Moves in $\mathcal{M}_M$ are implicitly tagged so it is possible to recover the arena that they belong to.


\begin{dfn}[Total mapping from nodes to moves]
Let $\Gamma \vdash M : T$ be a simply-typed term
with $\Gamma = x_1:X_1 \ldots x_p : X_p$.
We write $q_{\sem{\Gamma}}^1$, \ldots, $q_{\sem{\Gamma}}^p$ to denotes the initial question moves of the
component $\Gamma$ of the arena $\sem{\Gamma \rightarrow T}$ and $q^0_A$ to denote the single initial question of any arena $A$
(arenas involved in the game semantics of pure simply-typed $\lambda$-calculus have a single root).
$r$ denotes the root of the computation tree.

We define the total function $\varphi_M : N\setminus (N_@ \union N_\Sigma) \rightarrow \mathcal{M}_M$ as follows:
\begin{align*}
\varphi_M =
        f_{\sem{\Gamma \rightarrow T}}(r, q^0_{\sem{\Gamma \rightarrow T}}) \quad
    & \union \quad
    \Union_{n \in N | n \mbox{ labelled } x_i }  f_{\sem{\Gamma \rightarrow T}}(n, q^i_{\sem{\Gamma}} ) \\
    & \union \quad
        \Union_{n \in N | E(@,n)}  f_{\sem{type(\kappa(n))}}(n, q^0_{\sem{type(\kappa(n))}} )
\end{align*}
When there is no ambiguity we just write $\varphi$ instead of $\varphi_M$.
\end{dfn}

Nodes of $\tau(M)$ are either hereditarily justified by the root, by a $@$-node or by a $\Sigma$-node, therefore
$\varphi$ is a totally defined on $N\setminus (N_@ \union N_\Sigma)$.

\begin{exmp}
Consider the term $\lambda x . (\lambda g . g x) (\lambda y . y)$ with $x,y:o$ and $g:(o,o)$.
The diagram below represents the computation tree (middle), the arenas
$\sem{(o,o)\rightarrow o}$ (left), $\sem{o \rightarrow o}$ (right), $\sem{o\rightarrow o}$ (rightmost)
and the function $\varphi = f(\lambda x, q_{\lambda x}) \union f(\lambda g, q_{\lambda g}) \union f(\lambda y, q_{\lambda y})$
(dashed-lines).
$$
\psset{levelsep=4ex}
\pstree{\TR[name=root]{\lambda x}}
{
    \pstree{\TR[name=App]{@}}
    {
            \pstree{\TR[name=lg]{\lambda g}}
                { \pstree{\TR[name=lgg]{g}}{
                        \pstree{\TR[name=lgg1]{\lambda}}
                        { \TR[name=lgg1x]{x}  } } }
            \pstree{\TR[name=ly]{\lambda y}}
                    {\TR[name=lyy]{y}}
    }
}
\rput(5cm,-1cm){
  \pstree{\TR[name=A1lx]{q_{\lambda x}}}
        { \TR[name=A1x]{q_x} }
}
\rput(-6cm,-1.5cm){
    \pstree{\TR[name=A2lg]{q_{\lambda g}}}
    {
        \pstree{\TR[name=A2g]{q_g}}
        {  \TR[name=A2g1]{q_{g_1}}   }
        %\TR[name=A2x]{q_x}
    }}
\rput(2.5cm,-1.5cm){
    \pstree{\TR[name=A3ly]{q_{\lambda y}}}
        { \TR[name=A3y]{q_y} %\TR[name=A3x]{q_x}
        }
}
\psset{nodesep=1pt,arrows=->,arcangle=-20,arrowsize=2pt 1,linestyle=dashed,linewidth=0.3pt}
\ncline{->}{root}{A1lx} \mput*{f(\lambda x, q_{\lambda x})}
\ncarc{->}{lgg1x}{A1x}
\ncline{->}{lg}{A2lg} \mput*{f(\lambda g, q_{\lambda g})}
\ncline{->}{lgg}{A2g}
\ncline{->}{lgg1}{A2g1}
\ncline{->}{ly}{A3ly} \mput*{f(\lambda y, q_{\lambda y})}
\ncline{->}{lyy}{A3y}
$$
\end{exmp}

The following properties follow immediately from the definition of the procedure $f$:
\begin{property} \
\label{proper:phi_conserve_order}
\begin{itemize}
\item[(i)] $\varphi$ maps $\lambda$-nodes to O-questions, variable nodes to
P-questions, value-leaves of $\lambda$-nodes to P-answers and
value-leaves of variable nodes to O-answers;
\item[(ii)] $\varphi$ maps nodes of a given order to moves of the same order;
\item[(iii)] for any traversal $t$: $?(\varphi(t)) = \varphi(?(t))$.
\end{itemize}
where $?(s)$ denotes the set of unanswered questions in a justified sequence of moves $s$ and $?(t)$ denotes the
set of unmatched nodes in justified sequence of nodes $t$ (see section \ref{sec:adding_value_leaves}).
\end{property}
Note that to make property (ii) holds for open terms, it was necessary to chose a definition of node-order that differ
between the root node and other $\lambda$-nodes (see definition definition \ref{def:nodeorder}).


By extension, the function $\varphi$ is also defined on justified
sequences of nodes: if $t$ is the justified sequences of nodes $t =
t_0 t_1 \ldots$ then $\varphi(t)$ denotes the following sequence of
moves:
$$\varphi(t) = \varphi(t_0)\ \varphi(t_1)\  \varphi(t_2) \ldots$$
where the pointers of the justified sequence of move $\varphi(t)$
are defined to be exactly those of the justified sequences of nodes
$t$.
This definition implies that $\varphi : N\setminus (N_@ \union N_\Sigma)^* \rightarrow \mathcal{M}^*$ regarded as a function
from pointer-less sequences of nodes to pointer-less sequences of moves is a monoid homomorphism.

\begin{property}
\label{proper:phi_pview} Suppose $\varphi(t) \jseq s$ where $s$ is a
justified sequence of moves and $t$ is a justified sequence of nodes
then
\begin{itemize}
\item (i) $s$ and $t$ have the same pointers;
\item (ii) the P-view of $s$ and the P-view of $t$ are computed
identically: the set of indices of elements that must be removed
from both sequences in order to obtain their P-view is the same;
\item (iii) the O-view of $s$ and the O-view of $t$ are computed identically.
\end{itemize}
\end{property}
\begin{proof}
(i): By definition of $\varphi$, $t$ and $\varphi(t)$ have the same
pointers.

(ii) and (iii): $\varphi$ maps lambda nodes to O-question,
non-lambda nodes to P-question, value leaves of lambda nodes to P-answers and
value leaves of non-lambda to O-answers. Therefore since $t$ and $s$ have the
same pointers, the computations of the P-view (resp. O-view) of the
sequence of moves and the P-view (resp. O-view) of the sequence of
nodes follow the same steps.
\end{proof}


\subsection{Category of interaction games}

In game semantics, strategy composition is achieved by performing a CSP-like ``composition + hiding''.
It is possible to define an alternative semantics where the internal moves are not hidden when performing composition.
This semantics has been named \emph{interaction} semantics in \cite{DBLP:conf/sas/DimovskiGL05}.

In addition to the moves of the standard semantics, the interaction semantics contains certain
internal moves of the computation.
Consequently, the interaction semantics depends on the syntactical structure of the term and therefore cannot
lead to a full abstraction result. However this semantics will prove to be useful to identify
a correspondence between the game semantics
of a term and the traversals of its computation tree.

We will be interested in the interaction semantics computed from the
$\eta$-normal form of a term. However we do not want to keep all the internal moves. We will only keep the internal
moves that are produced when composing two subterms of the computation tree that are joined by an $@$ node.
This means that when computing the strategy of
$y N_1 \ldots N_p$ where $y$ is a variable, we keep the internal moves of $N_1$, \ldots, $N_p$, but
we omit the internal moves produced by the copy-cat projection strategy denoting $y$.

\begin{dfn}[Type-tree]
We call \emph{type decomposition tree} or \emph{type-tree}, a tree whose leaves are labelled with linear simple types
and nodes are labelled with symbol in
%$\{ \fatsemi, \times, !, \otimes \} \union \{ @_k \ | k \geq 2 \} $.
$\{ ;, \times, !, \otimes, \Lambda \} $.

Nodes labelled $;$, $\times$ or $\otimes$ are binary nodes, nodes labelled $!$, $\dagger$ or $\Lambda$ are unary nodes.
%and nodes labelled $@_k$ are $k$-ary nodes.


Every node or leaf of the tree has a linear type, this type is determined by the
structure of the tree as follows:
\begin{itemize}
\item a leaf has the type of its label;

\item a $\times$-node with two children nodes of type $A$
and $B$ is of type $A \times B$;

\item a $\otimes$-node with two children nodes of type $A$
and $B$ is of type $A\otimes B$;

\item a $!$-node with a child node of type $A$ is of type $!A$;

\item a $\Lambda$-node with the child node of type $A \otimes B \multimap C$ is of type $!A \multimap (!A \multimap C)$;

\item a $;$-node with two children nodes of type $!A\multimap B$
and $!B \multimap C$ is of type $!A \multimap C$;

%\item a $@_k$-node with children nodes $T_0, T_1, \ldots, T_{k-1}$ representing the types
%$(A_1, \ldots A_{k-1}, B)$, $A_1$, \ldots, $A_{k-1}$ respectively represents the type $B$.
\end{itemize}

For a type-tree to be well-defined, the children nodes's type must be compatible with the meaning of the node, for instance
the two children nodes of a $\fatsemi$-node must be of type $!A\rightarrow B$ and $!B\rightarrow C$.
%and for $@_k$-node the type of the children nodes must be of the form $(A_1, \ldots A_{k-1}, B)$, $A_1$, \ldots, $A_{k-1}$.

We write $type(T)$ to denote the type represented by the root of the tree $T$. An we say that $T$ is a \emph{valid
tree decomposition} of $type(T)$.

If $T_1$ and $T_2$ are type-tree we write $T_1 \times T_2$ to denotes the tree obtained by attaching $T_1$ and $T_2$ to a $\times$-node.
Similarly we use the notations $T_1 \otimes T_2$, $T_1 ; T_2$, $\Lambda(T_1)$ and $!T_1$.
%, $@_k(T_0, \ldots , T_{k-1})$
\end{dfn}


Let $T$ be a type-tree. Each leaf or node of type $A$ in $T$ can be mapped to the
(standard) arena $\sem{A}$. By taking the image of $T$ across this mapping we obtain a tree whose leaves and nodes are labelled by arenas.
This tree written $\intersem{T}$ is called the \emph{interaction arena} of type $T$.
We write $root(\intersem{T})$ to denote the arena located at the root of the interaction arena $\intersem{T}$.

An \emph{interaction strategy} $\Sigma$ on the interaction arena
$\intersem{T}$ is a composition of several standard strategies where
certain internal moves are not hidden. Formally this can be defined as
follows:
\begin{dfn}[Interaction strategy]
An interaction strategy $\Sigma$ on a game $\intersem{T}$ noted
$\Sigma: \intersem{T}$ is a tree type $T$ where
\begin{itemize}
\item each leaf $\sem{A}$ of
$\intersem{T}$ is annotated with a (standard) strategy $\sigma$ on the
game $\sem{A}$;
\item each $;$-node is annotated with a set of index $U \subseteq \nat$.
\end{itemize}
\end{dfn}
A $;$-node with children of type $!A\multimap B$ and $!B\multimap C$ is annotated with a set of index $U$ indicating
which components of $B$ should be uncovered when performing composition.

We introduce the notation $\Sigma_1 \fatsemi^U \Sigma_2$ for $\Sigma_1^\dagger ; ^U \Sigma_2$.
\begin{exmp}
The diagrams below represent a type-tree $T$ (left) the corresponding interaction arena $\intersem{T}$ (middle) and an
interaction strategy $\Sigma$ (right):
$$
\pstree[levelsep=6ex]{\TR{;}}
        {
            \pstree[levelsep=6ex]{\TR{;}}
            { \TR{A\multimap B}
              \TR{B\multimap C}
            }
            \TR{C\multimap D}
        }
\hspace{1cm}
\pstree[levelsep=6ex]{\TR{;}}
        {
            \pstree[levelsep=6ex]{\TR{;}}
            { \TR{\sem{A\multimap B}}
              \TR{\sem{B\multimap C}}
            }
            \TR{\sem{C\multimap D}}
        }
\hspace{1cm}
\pstree[levelsep=6ex]{\TR{;^{\{0\}}}}
        {
            \pstree[levelsep=6ex]{\TR{;^{\{0\}}}}
            { \TR{A\multimap B^{\sigma_1}}
              \TR{B\multimap C^{\sigma_2}}
            }
            \TR{C\multimap D^{\sigma_3}}
        }
$$
\end{exmp}
An interaction strategy can also be written as an expression, for instance the strategy represented above is given
by the expression $\Sigma = (\sigma_1 ;^{\{0\}} \sigma_2) ;^{\{0\}} \sigma_3$.


\begin{dfn}[Composition of interaction strategies]
Suppose $\Sigma_1 : \intersem{T_1}$ and $\Sigma_2 :
\intersem{T_2}$ are interaction strategies where $type(T_1) = A \rightarrow B$
and $type(T_2) = B \rightarrow C$ then
the \emph{interaction composition} of $\Sigma_1$ and $\Sigma_2$ written $\Sigma_1 ; \Sigma_2$
is the interaction strategy on $\intersem{T_1 ; T_2}$ obtained by copying the annotation of the leaves and nodes from $\Sigma_1$ and $\Sigma_2$
to the corresponding leaves and nodes of the type-tree $T_1 ; T_2$ and by annotating the root node with $\emptyset$.
\end{dfn}

A play of the interaction semantics is called an \emph{uncovered
play}, it is a play containing internal moves.
The moves are implicitly tagged so that it is possible to retrieve in which component
of which node or leaf-arenas the move belongs to. Note that a same move can belong to different node/leaf-arenas.
The internal moves of an interaction play on the game $\intersem{T}$ are those which do not
belong to the arena $root(\intersem{T})$.

For any uncovered play $s$ and any interaction arena $\intersem{T}$
we can define the filtering operator $s\upharpoonright \intersem{T}$ to be the
sequence of moves obtained from $s$ by keeping only the moves
belonging to a node or leaf-arena of $\intersem{T}$.


Interaction strategies can alternatively be represented by mean of sets of
uncovered plays instead of annotated type-trees. This set is defined
inductively on the structure of the annotated type-tree $\Sigma$ as follows:
\begin{itemize}
\item for a leaf $\sem{A}$ of $\Sigma$ annotated by $\sigma :\sem{A}$, it is just the set of plays of the standard strategy $\sigma$.
\item for a $\otimes$-node with two children strategies $\Sigma_1$ and $\Sigma_2$, it is the tensor product noted $\Sigma_1 \otimes \Sigma_2$;
\item for a $\times$-node, it is the pairing noted $\langle \Sigma_1, \Sigma_2 \rangle$;
\item for a $!$-node with a child strategy $\Sigma$, it is the promotion noted $\Sigma^\dagger$;
\item for a $\Lambda$-node with a child strategy $\Sigma$, it is the same set of plays but with the moves retagged appropriately;

\item for a $;^U$-node, it is the ``uncovered-composition'' of $\Sigma_1 : \intersem{T_1}$ and $\Sigma_2 :\intersem{T_2}$ noted $\Sigma_1
;^U \Sigma_1$. Suppose that $type(T_1) =
A \multimap B_0 \times \ldots B_l$ and $type(T_2) = B_0 \times \ldots B_l \multimap C$
then $\Sigma_1
;^U \Sigma_1$ is the set of uncovered plays
obtained by performing the usual composition, while ignoring and
copying the internal moves from arenas in $\intersem{T_1}$ or $\intersem{T_2}$
and preserving any internal move played during the composition in a component $B_k$ for some $k \in U$. Formally:
$$ \Sigma_1 \| \Sigma_2 = \{ u \in int(\intersem{T}) \ | \ u \upharpoonright \intersem{T_1} \in \Sigma_1 \mbox{ and } u \upharpoonright \intersem{T_2} \in \Sigma_2 \}$$
$$ \Sigma_1 ;^{\{i_0, \ldots i_l\}} \Sigma_2 = \{ u \upharpoonright A, B_{i_0}, \ldots, B_{i_l}, C \ | \ u \in \Sigma_1 \| \Sigma_2 \}$$
where $int(\intersem{T})$ denotes the set of sequence of moves belonging to some arena in $\intersem{T}$.


%\item for a $@_k$-node, it is the
%``uncovered-evaluation'' of its children's strategies $\Sigma_0$, $\Sigma_{k-1}$. It is noted
%$\langle \Sigma_0, \Sigma_1, \ldots, \Sigma_{k-1} \rangle \intercomp ev_k$ and defined to be the a set of uncovered plays
%obtained by performing the ``uncovered-composition'' of $\langle \Sigma_0, \Sigma_1, \ldots, \Sigma_{k-1} \rangle$
%with the usual standard evaluation strategy with $k-1$ parameters;
\end{itemize}
where the tensor product, pairing and promotion are defined similarly as in the standard game semantics.


We can now define the category $\mathcal{I}$ of interaction games:
\begin{dfn}[Category of interaction games]
The category of interaction games is noted $\mathcal{I}$. The
objects of $\mathcal{I}$ are those of $\mathcal{C}$ : the arenas $\sem{A}$ for some linear type $A$. The morphisms of
the category are the interaction strategies: a morphism from $A$
to $B$ is an interaction strategy $\Sigma$ on some interaction arena
$\intersem{T}$ such that $root(\intersem{T}) = \sem{A\rightarrow B}$.

The composition of morphisms is given by the interaction strategy composition $\fatsemi$.
The identity on $A$ is the single leaf interaction arena $\sem{A}$ annotated with $id_A$.
\end{dfn}

It can be check that this indeed define a category. The constructions of the category $\mathcal{C}$ can be transposed to $\mathcal{I}$
making $\mathcal{I}$ a cartesian closed category.


\begin{dfn}[Valid strategy]
Consider a term $\Gamma \vdash M : A$ and $\Sigma : \intersem{T}$ an interaction strategy.
We say that $\Sigma$ is a valid interaction strategies for $M$ if $root(\intersem{T}) = \sem{\Gamma \rightarrow A}$
or equivalently if $type(T) = \Gamma \rightarrow A$.
\end{dfn}


\subsubsection{Modeling the $\lambda$-calculus in $\mathcal{I}$}

We would like to use the category $\mathcal{I}$ to model terms of the
simply-typed lambda calculus. However there may be several valid type decomposition tree for a given term $M$ and therefore
several strategies denoting $M$!

To fix this problem, we will compute the interaction strategy from the
the computation tree of $M$. Since the computation tree is unique it will be possible to uniquely define
the interaction strategy of a term.


\begin{dfn}[Interaction strategy of a term]
Let $\Gamma \vdash M : A$ be a term with $\Gamma = x_1:X_1, \ldots, x_k:X_k$.
Let $\pi_i : \sem{\Gamma} \rightarrow \sem{X_i}$ denotes the $i$th projection copycat strategy
and $ev^p$ denotes the evaluation strategy with $p$ parameters.

The \emph{interaction strategy of $M$} written $\intersem{\Gamma \vdash M : A}$ is defined by structural induction on the
computation tree $\tau(M)$:

\begin{tabularx}{14cm}{lX}
$\tree[levelsep=6ex]{\lambda \xi_1\ldots \xi_n}{\TR{x_i}}$ &
       $\intersem{M} = \Lambda^n(\pi_i)$ \\ \hline
$ \tree[levelsep=6ex]{\lambda \xi_1\ldots \xi_n}
        { \tree[levelsep=6ex]{x_i}
            {   \TR{\tau(N_1)} \TR{\ldots} \TR{\tau(N_p)}}}
    $
&    where $\Gamma \vdash x_i : (A_1,\ldots,A_p,B)$ and $\Gamma \vdash N_j : A_j$ for $j\in 1..p$
    $$\intersem{M} = \Lambda^n(\langle \pi_i, \intersem{\Gamma \vdash N_1 : A_1}, \ldots, \intersem{\Gamma \vdash N_p : A_p}  \rangle
    \fatsemi ^{1..p} ev^p)$$
\\ \hline
$ \tree[levelsep=6ex]{\lambda \xi_1\ldots \xi_n}
        { \tree[levelsep=6ex]{@}
            {   \TR{\tau(N_0)} \TR{\ldots} \TR{\tau(N_p)}}}
    $ &
    where $\Gamma \vdash N_0 : (A_1,\ldots,A_p,B)$ and $\Gamma \vdash N_j : A_j$ for $j\in 1..p$
    $$\intersem{M} = \Lambda^n(\langle \intersem{\Gamma \vdash N_0 : A_0}, \ldots, \intersem{\Gamma \vdash N_p : A_p}  \rangle
    \fatsemi^{0..p} ev^p)$$
\end{tabularx}
\vspace{10pt}

The interaction arena of the strategy $\intersem{\Gamma \vdash M : A}$ is noted
$\intersem{\Gamma \rightarrow A}_M$.
\end{dfn}



\begin{exmp}
Consider the term $\lambda x . (\lambda f . f x) (\lambda y . y)$.
Its computation tree is:
$$
\tree{\lambda x} {
    \pstree[levelsep=4ex]{\TR{@}}
    {       \pstree[levelsep=4ex]{\TR{\lambda f}}
                { \tree{f}{  \tree{\lambda}{ \TR{x}  } } }
            \pstree[levelsep=4ex]{\TR{\lambda y}}
                    {\TR{y}}
    } }
$$
and its interaction strategy is $\langle \sem{ x:X \vdash \lambda f . f x} , \sem{ x:X \vdash \lambda y . y} \rangle \fatsemi^{\{0,1\}} ev_2$.
\end{exmp}


\subsubsection{From interaction semantics to standard semantics and vice-versa}

In the standard semantics, given two strategies $\sigma : A \rightarrow B$, $\tau : B \rightarrow C$ and
a sequence $s \in \sigma \fatsemi \tau$, it is possible to (uniquely) recover the internal moves. The uncovered sequence is noted
 ${\bf u}(s, \sigma, \tau)$. The algorithm to obtain this unique uncovering is given in part II of \cite{hylandong_pcf}.

Given a term $M$, we can completely uncover the internal moves of a sequence $s\in\sem{M}$
by performing the uncovering recursively at every $@$ nodes of the computation tree.
This operation is called \emph{full-uncovering with respect to $M$}.
Consequently, the interaction semantics can be computed from the standard semantics.

Conversely, the standard semantics can be recovered from the interaction semantics by filtering the moves, keeping only the ones played
in the root arena:
\begin{eqnarray}
 \sem{\Gamma \vdash M : A} = \intersem{\Gamma \vdash M : A} \upharpoonright \sem{\Gamma \rightarrow T} \label{eqn:int_std_gamsem}
\end{eqnarray}


\subsubsection{Full abstraction}

Let $\mathcal{I'}$ denotes lluf sub-category of $\mathcal{I}$ obtained by conserving only strategies $\Sigma$ with a single
annotated leaf and no nodes. We have the following lemma:
\begin{lem}[$\mathcal{I'}$ is isomorphic to $\mathcal{C}$]
$\mathcal{I'} \cong \mathcal{C}$
\end{lem}
\begin{proof}
We define the functor $F:\mathcal{I'} \rightarrow \mathcal{C}$
by $F(A) = A$ for any object $A\in \mathcal{I'}$ and for $\Sigma \in \mathcal{I'}(A,B)$,
$F(\Sigma)$ is defined to be the annotation $\sigma$ of the only leaf in $\Sigma$.
The functor $G:\mathcal{C} \rightarrow \mathcal{I'}$ is defined by
by $G(A) = A$ for any object $A\in \mathcal{C}$ and for $\sigma \in \mathcal{C}(A,B)$,
$G(\sigma)$ is the tree formed with the single annotated leaf $\sem{A}^\sigma$.
Then $F;G =id_{\mathcal{I'}}$ and $G;F =id_{\mathcal{C}}$.
\end{proof}

Consequently the lluf sub-category $\mathcal{I'}$ is fully abstract for the simply-typed lambda calculus.
Note that this is a major difference with $\mathcal{I}$ which is not fully-abstract since there may be several maps denoting a given
term.




\subsection{Some properties of $\varphi$}

Before being able to to reveal the correspondence between the
interaction game semantics and traversals of the computation tree we
need to introduce some definitions and lemmas.

\begin{dfn}[$@$-hiding of traversals]
Let $t$ be a traversal of $\tau(M)$.

We write $t-@$ for the sequence sequence of nodes with pointers
(i.e. not a proper justified sequence of nodes) obtained by removing
from $t$ all $@$-nodes and replacing any link pointing to an $@$-node
by a link pointing to the predecessor node of $@$ in $t$.

Suppose $u = t-@$ is as sequence of nodes obtained by applying the
previously defined transformation on the traversal $t$, then $t$ can
be recovered from $u$ by reinserting the $@$ nodes as follows:
\begin{itemize}
\item replace any two consecutive lambda-nodes $n_1 \cdot n_2$ in $j$
by $n_1 \cdot @ \cdot n_2$ where $@$ denotes the parent node of
$n_2$ which is also the child node of $n_1$ in the computation tree;
\item replace any link in $u$ pointing from a $\lambda$-node to $n_1$ by a link pointing to the inserted $@$ node.
\end{itemize}
We write $u+@$ for this second transformation.
\end{dfn}
These transformations are well-defined since in a traversal, the node
$@$ always occurs in-between nodes $n_1$ and $n_2$ where in the computation tree $n_1$ is the parent node of $@$
and $n_2$ is the first child node of $@$:
$$      \pstree[levelsep=4ex]{\TR{n_1}\treelabel{0} }
        {
            \pstree[levelsep=3ex]{\TR{@}}
            {
                \tree{n_2}{\vdots}
                \TR[edge=\dedge]{}
                \TR[edge=\dedge]{}
            }
        }
$$

The following lemma follows directly from the definition:
\begin{lem}
\label{lem:minus_at_plus_at} For any traversal $t$, $(t-@)+@=t$.
\end{lem}

\begin{lem}
Let $M$ be a term in $\beta$-normal form, $t \in
\travset(M)$ and $r$ the root of $\tau(M)$ then:
$$t = t \upharpoonright r = t - @.$$
\end{lem}
\begin{proof}
This is because the computation tree of a term in $\beta$-normal
does not contain any $@$ node and therefore all the nodes are
hereditarily justified by the root.
\end{proof}

We introduce the following notation:
\begin{eqnarray*}
\travset(M)^{-@} &=& \{ t - @ \ | \  t \in \travset(M) \} \\
\travset(M)^{\upharpoonright r} &=& \{ t  \upharpoonright r \ | \  t  \in \travset(M) \} .
\end{eqnarray*}

We then have $\travset(M)^{-@} \cong \travset(M)$ because of lemma \ref{lem:minus_at_plus_at}.

\begin{lem}[Filtering lemma] Let $\Gamma \vdash M :T$ be a term and $r$ the root of $\tau(M)$ then:
\label{lem:varphi_filter}
$$ \varphi(\travset^{-@}(M)) \upharpoonright \sem{\Gamma \rightarrow T} = \varphi(\travset^{\upharpoonright r}(M)) $$
In other words, for any traversal $t$ of the computation tree we have:
$$\varphi(t-@) \upharpoonright \sem{\Gamma \rightarrow T} = \varphi(t\upharpoonright r)$$
\end{lem}
\begin{proof}
    From the definition of $\varphi$, the nodes of the computation tree that are mapped by $\varphi$
    to moves in the arena $\sem{\Gamma \rightarrow T}$ are exactly the nodes that are hereditarily justified by $r$.
    Since $@$ is not hereditarily justified by $r$ the result follows immediately.
\end{proof}

The function $\varphi$ regarded as a function from the set of nodes $N\setminus (N_@ \union N_\Sigma)$ of the computation tree to moves in arenas is not injective.
For instance the two occurrences of $x$ in the computation tree of the term $\lambda f x. f x x$ are mapped to the same question. However
the function $\varphi$ regarded as a function from sequences of nodes to sequences of moves is injective:
\begin{lem}[$\varphi$ is injective]
\label{lem:varphiinjective}
$\varphi$ regarded as a function defined on the set of
sequences of nodes is injective in the sense that for any two traversal $t_1$ and $t_2$:
\begin{itemize}
\item[(i)] if $\varphi (t_1 - @ ) = \varphi (t_2 - @ )$ then $t_1-@ =t_2 -@$;
\item[(ii)] if $\varphi (t_1 \upharpoonright r ) = \varphi (t_2 \upharpoonright r )$ then $t_1\upharpoonright r = t_2\upharpoonright r$.
\end{itemize}
\end{lem}
\begin{proof}
(i) Suppose that $t_1-@\neq t_2-@$ then necessarily $t_1 \neq t_2$. Therefore
 $t_1 = t' \cdot n_1 \cdot u_1$ and $t_2 = t' \cdot n_2 \cdot u_2$ for some sequences $t'$, $u_1$, $u_2$
and some nodes $n_1\neq n_2$.
The rules defining traversals are almost all deterministic. For instance, the constant rules must be deterministic by assumption C1 and C2.
In fact, the non-determinism only comes from the rules
($\mbox{InputVar}^0$) and ($\mbox{InputVar}^{\geq 1}$) which deal with input variables. Both rules permit to extend the traversal
with an additional node. Suppose that $E$ denotes the set of possible nodes extending the traversal then the rules are such that
$\varphi$ maps two different nodes in $E$ to two different moves in the same arena. Since $E$ does not contain any $@$-node we have
$\varphi(n_1) \neq \varphi(n_2)$, $n_1 \neq @$ and $n_2 \neq @$.

If we regard sequences of nodes and moves as \emph{pointer-less} sequences then we are allowed to write the following:
$$ (t' \cdot n_1 \cdot u_1) - @ = (t' - @) \cdot n_1 \cdot (u_1 -@)$$

Finally since $\varphi_M$ is a monoid homomorphism we have:
$$ \varphi(t_1-@) = \varphi(t'-@) \cdot \varphi(n_1) \cdot \varphi(u_1) \neq \varphi(t'-@) \cdot \varphi(n_2) \cdot \varphi(u_2) = \varphi(t_2-@) $$
where the equalities and inequalities denotes comparison of \emph{pointer-less} sequences.

(ii) Again, suppose that $t \upharpoonright r \neq t' \upharpoonright r$ then
 $t_1 = t'_1 \cdot n_1 \cdot u_1$ and $t_2 = t_2' \cdot n_2 \cdot u_2$ for some sequences $t_1'$, $t_2'$ $u_1$, $u_2$
 such that $t'_1 \upharpoonright r = t'_2 \upharpoonright r $
and some nodes $n_1 \neq n_2$ both hereditarily justified by the root.
For the same reason as in (i), we must have $\varphi(n_1) \neq \varphi(n_2)$. Hence:
$$ \varphi(t_1\upharpoonright r) =
        \varphi(t'_1\upharpoonright r) \cdot \varphi(n_1) \cdot \varphi(u_1 \upharpoonright r)
    \neq \varphi(t'_1\upharpoonright r) \cdot \varphi(n_2) \cdot \varphi(u_2 \upharpoonright r)
         = \varphi(t_2\upharpoonright r).$$
\end{proof}

\begin{cor} \
\label{cor:varphi_bij}
\begin{itemize}
\item[(i)] $\varphi$ defines a bijection from $\travset(M)^{-@}$
to $\varphi(\travset(M)^{-@})$;
\item[(ii)] $\varphi$ defines a bijection from $\travset(M)^{\upharpoonright r}$ to
$\varphi(\travset(M)^{\upharpoonright r})$.
\end{itemize}
\end{cor}

\subsection{The correspondence theorem for the pure simply-typed $\lambda$-calculus}
The correspondence theorem establishes a connection between
the interaction semantics of a term and the traversals of its computation tree.

We are now going to state and prove this theorem for the pure simply-typed $\lambda$-calculus without constants ($\Sigma = \emptyset$).
The cartesian closed category of games $\mathcal{C}$ defined in section \ref{subsec:pcfgamemodel} of the first chapter is used as a
model of the simply-typed $\lambda$-calculus. We write $\sem{\Gamma \vdash M : A}$ for the strategy denoting the simply-typed term
$\Gamma \vdash M : A$.

\begin{prop}
\label{prop:rel_gamesem_trav} Let $\Gamma \vdash M : T$ be a
term of the pure simply-typed $\lambda$-calculus and $r$ be the root
of $\tau(M)$. Then:
\begin{itemize}
\item[(i)]  $\varphi_M(\travset(M)^{-@}) = \intersem{M}$
\item[(ii)] $\varphi_M(\travset(M)^{\upharpoonright r}) = \sem{M}$
\end{itemize}
\end{prop}


\begin{rem} The proof that follows is quite tedious but the idea is simple. Let us give the intuition.
    We start by reducing the problem to the case of closed terms only. Then the proof proceeds by induction on the structure of the computation tree.
    It is straightforward to prove the result for term that are abstraction of a single variable.
    Now consider an application $M$ with the following computation tree $\tau(M)$:
    $$ \tree[levelsep=4ex]{\lambda \overline{\xi}^{[0]}}
        { \tree[levelsep=4ex]{\xi_i^{[1]}}
            {   \TR{\tau(N_1)} \TR{\ldots} \TR{\tau(N_p)}}}
    $$

    A traversal of $\tau(M)$ proceeds as follows: it starts at the root $\lambda \overline{\xi}$ of the tree $\tau(M)$ (rule
    (Root)), it then passes the node $@$ (rule (Lam)).
    After this initialization part, it proceeds by traversing the term $N_0$ (rule (App)).
    At some point, a variable in $\overline{y_0}$ is visited, the traversal
    of $N_0$ is interrupted and the traversal jumps (rule (Var)) to the root of $\tau(N_i)$ and goes on by traversing $\tau(N_i)$.
    When traversing $N_i$, if the traversal encounters a variable in $\overline{y_i}$ then the traversal of $N_i$ is interrupted and
    the traversal of $N_0$ resumes.  This schema is repeated until the traversal of $\tau(N_0)$ is completed\footnote{Since we are considering
    simply-typed terms, the traversal does indeed terminate. However this will not be true when we adapt this result to PCF.}.

    The traversal of $M$ is therefore made of an initialization part followed by an interleaving of a traversal of $N_0$ and
    several traversals of $N_1$. This schema is reminiscent of the way the evaluation copycat map $ev$ works in game semantics.

    The key idea is that every time the traversal pauses the traversal of a subterm and switches to another one,
    the jump is permitted by one of the four copycat rules (Var), (CCAnswer-$@$), (CCAnswer-$\lambda$) or (CCAnswer-var).

    We then show by (a second) induction that these copycat rules defines exactly what the copycat strategy $ev$ performs on sets of moves.

%    In the game semantics, the evaluation map (a copy-cat strategy) copies this opening move to an initial move $m_0$ in the game
%    $B_0$ and the game continues in $B_0$. We reflect this in the traversal : we make $t$ follow
%    the ``script'' given by the traversal $t^0_{m_0}$.
%    The rule (App) allow us to initiate this simulation
%    by visiting the  first move in $t^0_{m_0}$: the root of $\tau(N_0)$.
%
%    This simulation continues until it reaches a node $\alpha_0$ which is hereditarily justified by the root
%    $\tau(N_0)$: $\alpha_0$ is present in the
%    reduced-traversal of $t^0_{m_0}$ therefore $\varphi_{N_0}(\alpha_0)$ is an un-hidden move played in $A_0$.
%
%    In the game semantics this corresponds to a move played in a component $A_k$ for some $k\in 1..p$ of
%    of the game $B_0$ in which case the evaluation map copies the move to an initial move $m_1$ in the corresponding component $B_k$.
%
%    To reflect this the traversal now opens up a new thread and
%    simulates the traversal $t^k_{m_1}$.
%    Again, this simulation stops when we reach a node
%    $\alpha_1$ in $t^k_{m_1}$ which is hereditarily justified by the root of
%    $\tau(N_k)$: $\alpha_1$ must be present in the reduced-traversal
%    of $t^k_{m_1}$ therefore $\varphi_{N_k}(\alpha_1)$ is an un-hidden move played in $A_k$.
%    In the game semantics, this move $\alpha$ is copied
%    back to the component $B_k$ of the game $B_0$.
%
%    The traversal now resumes the simulation of $t^0_{m_0}$. And the
%    process goes continuously.

\end{rem}

Let us fix some notation: we write $s\upharpoonright A,B$ for the
sequence obtained from $s$ by keeping only the moves that are in $A$ or $B$ and by removing any link pointing to a move that
has been removed.
If $m$ is an initial move, we write $s \upharpoonright m$ to
denote the thread of $s$ initiated by $m$, i.e. the sequence obtained from $s$ by keeping all the moves
hereditarily justified by $m$.
We also write $s \upharpoonright A,B,m$ where $m$ is an initial move
for the sequence obtained from $s \upharpoonright A,B$ by keeping
all moves hereditarily justified by $m$.



\begin{proof}
(i) Suppose $\Gamma = \xi_1:X_1,\ldots \xi_n:X_n$. Then we have:
\begin{eqnarray*}
\intersem{\Gamma \vdash M:T} &=& \Lambda^n( \intersem{\emptyset \vdash \lambda \xi_1\ldots \xi_n . M: (X_1,\ldots,X_n,T) } ) \\
        &\simeq& \intersem{\emptyset \vdash \lambda \xi_1\ldots \xi_n . M: (X_1,\ldots,X_n,T) }.
\end{eqnarray*}
Similarly the computation tree $\tau(M)$ is isomorphic to
$\tau(\lambda \xi_1\ldots \xi_n . M)$ (up to a renaming of the root
of the computation tree) therefore $\travset(M)$, the set of
traversal of $\tau(M)$, is also isomorphic to
$\travset(\lambda \xi_1\ldots \xi_n . M)$. Hence we can make
the assumption that $M$ is a closed term. If we prove that the
property is true for all closed terms of a given height then it will
be automatically true for any open term of the same height.


Let us assume that $M$ is already in $\eta$-long normal form. We
proceed by induction on the height of of the tree $\tau(M)$ and by
case analysis on the structure of the computation tree:
\begin{itemize}

%  \item[(order 0 constant)] $M = f \in \Sigma$. The tree $\tau(M)$ has the following form:
%  $$ \tree[levelsep=6ex]{\lambda}{ \TR{f} }$$
%  There is only one question in the game arena: the initial question $q$ verifying $ q = \varphi_M(\lambda)$.
%  It suffices to take $t = \lambda^{|\tildes|}$.

%  \item[(abstraction of a constant)]
%      $M$ is an order 0 constant: same treatment as the (constant) case above.

  \item (abstraction of a variable): $M \equiv \lambda \overline{\xi} . x$
      Since $M$ is in $\eta$-long normal form, $x$ must be of ground type and since $M$ is
      closed we have $x = \xi_i \in \overline{\xi}$ for some $i$.
      Hence $\tau(M)$ has the following shape:
        $$ \tree[levelsep=6ex]{ \lambda \overline{\xi}^{[0]} }{\TR{\xi_i^{[1]}}}$$
        The arena is of the following form (only question moves are represented):
        $$ \tree{ q_0 }
        {   \tree[linestyle=dotted]{q^1}{\TR{} \TR{} }
            \tree[linestyle=dotted]{q^2}{\TR{} \TR{} }
            \TR{\ldots}
            \tree[linestyle=dotted]{q^n}{\TR{} \TR{} }
            \TR{q'}
        }$$
        where $q'$ denotes the root of the flat arena $\sem{o}$.

        Let $\pi_i$ denotes the $i$th projection of the interaction game
        semantics. We have:
        \begin{align*}
        \intersem{M} &= \intersem{\emptyset \vdash \lambda \overline{\xi} . \xi_i} \\
                     &= \Lambda^n(\intersem{\overline{\xi} \vdash  \xi_i}) \\
                     &= \Lambda^n(\pi_i) \\
                     &\cong \pi_i \\
                     &= \textsf{Pref}(\{ q \cdot q_0 \cdot q^v \cdot q_0^v \ | \ v\in \mathcal{D} \})
        \end{align*}

        Since $M$ is in $\beta$-normal we have $\travset(M)^{-@} = \travset(M)$.
        One can check that the set of traversals of $M$ is the set of prefix of
        the traversal $\lambda \overline{\xi} \cdot \xi_i \cdot \xi_i^v \cdot \lambda
        \overline{\xi}^v$. Therefore:
        $$ \travset^{-@}(M) = \travset(M) = \textsf{Pref}( \lambda \overline{\xi} \cdot \xi_i \cdot \xi_i^v \cdot \lambda \overline{\xi}^v)
        $$

        The pointers of the traversal $\lambda \overline{\xi} \cdot \xi_i \cdot \xi_i^v \cdot \lambda
        \overline{\xi}^v$ are the same as the play $q \cdot q_0 \cdot q^v \cdot
        q_0^v$. Therefore since $\varphi_M(\lambda \overline{\xi}) = q_0$ and $\varphi_M(\xi_i) =
        q'$ we have:
        $$ \varphi_M(\travset^{-@}(M)) = \intersem{M}$$


    \item (abstraction of an application): we have $M = \lambda \overline{\xi} . N_0 N_1 \ldots N_p$. Let $\Gamma$ be the context
    $\Gamma = \overline{\xi} : \overline{X}$. Then we have the following sequents:
    $\emptyset \vdash M : (X_1,\ldots,X_n,o)$,
    $\Gamma \vdash N_0 N_1 \ldots N_p : o$,
    $\Gamma \vdash N_i : B_i$ for $i\in 0..p$ with $B_0 = (B_1,\ldots,B_p,o)$ and $p\geq 1$.

    There are two subcases, either $N_0 \equiv \xi_i$ where $\alpha$ is a variable in $\overline{\xi}$ and the tree has the following form:
    $$ \tree[levelsep=6ex]{\lambda \overline{\xi}^{[0]}}
        { \tree[levelsep=6ex]{\xi_i^{[1]}}
            {   \TR{\tau(N_1)} \TR{\ldots} \TR{\tau(N_p)}}}
    $$
    or $N_0$ is not a variable and the tree $\tau(M)$ has the following form:
    $$ \tree[levelsep=6ex]{\lambda \overline{\xi}^{[0]}}
        { \tree[levelsep=6ex]{@^{[1]}}
            {
            \tree[levelsep=6ex]{\lambda y_1 \ldots y_p}{\ldots}
            \TR{\tau(N_1)} \TR{\ldots} \TR{\tau(N_p)}}}
    $$

    We only consider the second case, the first one can be treated
    similarly. Moreover we make the assumption that $p=1$. It is
    straightforward to generalize to any $p\geq1$.
    We write $\lambda \overline{z}$ to denote the root of the tree $\tau(N_1)$.


    We have:
    \begin{align*}
    \intersem{M}
        &=  \Lambda^n( \intersem{\Gamma \vdash N_0 N_1 : o} )
            & \mbox{(game semantics for abstraction)}\\
        &\cong  \intersem{\Gamma \vdash N_0 N_1 : o}
            & \mbox{(up to moves retagging)}\\
        &=  \langle \intersem{\Gamma \vdash N_0}, \intersem{\Gamma \vdash N_1} \rangle \fatsemi^{0..1} ev
            & \mbox{(game semantics for application)}\\
        &=  \langle \varphi_{N_0} (\travset^{-@}(N_0)), \varphi_{N_1}(\travset^{-@}(N_1) \rangle \fatsemi^{0..1} ev
            & \mbox{(induction hypothesis)}\\
        &=  \langle \varphi_{M} (\travset^{-@}(N_0)), \varphi_{M}(\travset^{-@}(N_1)) \rangle \fatsemi^{0..1} ev
            & \mbox{($\varphi_M = f(0,q_0) \union \varphi_{N_0} \union \varphi_{N_1}$)} \\
        &=  \underbrace{\langle \varphi_{M} (\travset^{-@}(N_0)), \varphi_{M}(\travset^{-@}(N_1)) \rangle}_{\sigma} \parallel ev
            & \mbox{($\fatsemi^{0..1}$ and $\parallel$ are the same operator)}
    \end{align*}


    The strategies $\sigma$ and $ev$ are defined on the arena $!A \multimap B$ and $!B \multimap C$ respectively where:
    \begin{eqnarray*}
        A &=& \intersem{\Gamma} = \intersem{X_1} \times \ldots \times \intersem{X_n}\\
        B &=& \intersem{B_0} \times \intersem{B_1} = \intersem{B_1' \rightarrow o'} \times \intersem{B_1} \\
        C &=& \intersem{o}
    \end{eqnarray*}

    Then $u \in \intersem{M} \cong \sigma^{\dag} \parallel ev$ if and only if
    \begin{eqnarray*}
      &&      \left\{
            \begin{array}{ll}
                u \in int(!A,!B,C)\\
                u \upharpoonright !A,!B  \in \sigma^\dagger \\
                u \upharpoonright !B,C  \in  ev
            \end{array}
            \right. \\
    & \mbox{or equivalently} & \left\{
    \begin{array}{ll}
        u \in int(!A,!B,C) \\
        \hbox{for any initial $m$ in $u \upharpoonright !A,!B$ there is $j \in 0..p$ such that } \\
        \left\{\begin{array}{ll}
            u \upharpoonright !A,B_j, m \in \varphi_{M} (\travset^{-@}(N_j)) \label{eq:def_z} \\ % \intersem{\Gamma \vdash N_j}  \label{eq:def_z} \\
            u \upharpoonright !A, B_k,m = \epsilon \quad \mbox{ for every } k\neq j \label{eq:b}
        \end{array}
        \right.
    \end{array}
    \right.
    \end{eqnarray*}


    We first prove that $\intersem{M} \subseteq \varphi_{M}( \travset^{-@}(M) )$


    Suppose $u \in \intersem{M}$. We give a constructive proof by induction on the length of $u$ that
    there exists a sequence of nodes $t$ in $N$ such that $\varphi_M(t-@) = u$.
    Let $q_o$ be the initial question of the arena $\sem{M}$ and $q_1$ the initial question of $\sem{N_0}$.

    Base cases:
    \begin{itemize}
    \item $u=\epsilon$ then $\varphi(\epsilon) = u$ where the traversal $\epsilon$ is formed with the rule ($\epsilon$).
    \item If $|u|=1$ then $u=q_0$ is the initial move in $C$ and $\varphi(\lambda \overline{\xi}) = u$. The traversal
    $\lambda \overline{\xi}$ is formed with the rule (Root).
    \end{itemize}

    Step cases: Suppose that $u' = \varphi_M(t'-@)$ and $u = u' \cdot m \in \intersem{M}$ with $|u|>1$ for some traversal $t'$ of $\tau(M)$.
    Let us write $m^1$ for the last move in $u'$.

    \begin{enumerate}
    \item Suppose $m \in C$. In $C$ there are no internal moves, the only moves of $C$ are therefore $q_0$ and
    $q_0^v$ for some $v\in\mathcal{D}$. Since $|u|>1$ and $q_0$ occurs only once in $u$ we have $m = q_0^v$
    for some $v\in \mathcal{D}$.  Therefore $m^1$, the previous move in $u'$ must be the answer to the initial question move
    $q_1$ in $o'$ that the copy-cat strategy duplicated in $C$: $u'=q_1^v$. Similarly $n'$ the last move in $t'$ is equal to
    $\varphi(u') = \lambda y_1^p$.

    By property \ref{proper:phi_conserve_order} (iii) $?(\varphi(t')) = \varphi(?(t'))$ and
    since $q_0$ is the pending question in $u$,
    the first node of $t$ is also the pending node in $t$.

    Hence we can use the rule (CCAnswer-$\lambda$) and we get $t = t' \cdot \lambda \overline{\xi}^v$
    where $\lambda \overline{\xi}^v$ points to the first node in $t'$.

    \item Suppose that $m \in A \union B_0$ and $m^1 \in A \union B_0$.
    Since $m$ and $m^1$ are consecutive moves in the sequence $u$ they must be hereditarily justified by the same initial
    $m_0$ in $B_0$. This is because $ev$ is responsible for switching thread in $B_0$ therefore there must be a copycat
    move between to moves that belong to different threads.

    We then have $(u \upharpoonright !A, !B)\upharpoonright m_0 = \varphi_{N_0}(t_0-@)$ for some traversal $t_0$ of $N_0$.
    The last two moves in $u$ are $m^1 \cdot m$ therefore
    if $n^1 \cdot n$ are the last two moves in $t_0-@$ we have
    $\varphi_{N_0}(n^1) = m^1$ and $\varphi_{N_0}(n) = m$.

    $n$ points to some node in $t_0$ that also occur in $t'$. Let us call $n^2$ this node.
    Since $(u \upharpoonright !A, !B)\upharpoonright m_0 = \varphi_{N_0}(t_0-@)$,
    $n_2$ must have the same position in $t'$ as the node pointed to by $m$ in $u'$.

    Hence we just need to take $t = t' \cdot n$ where $n$ points to $n^2$ in $t'$.

    This is indeed a valid traversal of $\tau(M)$
    because the rule that has been used by the traversal $t_0$
    of $\tau(N_0)$ to visit the node $n$ after the node $n^1$ can also be used by the traversal $t$ to visit $n$ after $n^1$.

    This can be check formally by inspecting all the traversal rules. The key reason is that
    all the nodes in $t_0-@$ are presents in $t'$ with the same pointers but with some nodes interleaved in between.
    However these interleaved nodes are inserted in a way that still permits to use the traversal rule.

    \item Suppose that $m \in A \union B_1$ and $m^1 \in A \union B_1$.
    The proof is similar to the previous case.

    \item Suppose that $m \in A \union B_0$ and $m^1 \in A \union B_1$.

    $t$ is obtained from $t-@$ using the transformation $+@$. We apply the same transformation to $u$ in order
    to make $O$-questions and $P$-questions in $u$ match with $\lambda$-nodes and variable nodes in $t'$ respectively.
    We write this sequence $u+@$.
    The $+@$ operation only insert nodes in the sequence but not at the end
    therefore $m^1$, the last move in $u'$, is also the last move in $u'+@$.
    Let us note $n^1$ for the last move in $t'$.

        \begin{enumerate}
        \item If $n^1$ is the application node $@$ then it must be the parent of the node $\lambda y_1$ since it
        is the only non-internal $@$ node present in $t'$.
        Therefore $t'=\lambda \overline{\xi} \cdot @$ and $u= q_0 \cdot m$.
        But $m$ is the copy of $q_0$ replicated by $ev$ in $o'$ therefore $m=q_1$.
        Applying the (App) rule on $t'$ produces the traversal $\lambda \overline{\xi} \cdot @ \cdot \lambda y_1$
        with $\varphi((\lambda \overline{\xi} \cdot @ \cdot \lambda y_1)-@ ) = q_0 \cdot q_1 = u$.

        \item If $n^1$ is a variable node then $m^1$ is a P-move and $m$ is an O-move
            and therefore $m$ is the copy of $m^1$ duplicated in $B_1$ by the evaluation strategy.
            Consequently, $m^1$ points to some $m^2$ and $m$ points to the node preceding $m^2$ written $m^3$.
            The diagram below shows an example of such sequence:
                $$
                \begin{array}{cccccccc}
                & (B_1' &\rightarrow & o') & \times & B_1 & \rightarrow & o' \\
                O & &&&&&& \rnode{q0}{q_0 (\lambda \overline{\xi})} \\
                P & &&&&& \\
                O & && \rnode{q1}{q_1 (\lambda \overline{y})} \\
                P & \rnode{m3}{m^3 (y_1)} \\
                O & &&&& \rnode{m2}{m^2 (\lambda \overline{z})} \\
                P & &&&& \rnode{m1}{m^1 (z_i)} \\
                O & \rnode{m}{m} \\
                \end{array}
                \ncline[nodesep=3pt]{->}{q1}{q0} \mput*{@}
                \nccurve[nodesep=3pt,ncurv=2,angleA=180,angleB=180]{->}{m1}{m2}
                \ncarc[nodesep=3pt,ncurv=1,angleA=90,angleB=180]{->}{m3}{q1}
                \ncarc[nodesep=3pt,ncurv=1,angleA=90,angleB=180]{->}{m}{m3}
                \ncline[nodesep=3pt]{->}{m2}{q0}
                $$

        $t'$  and $u+@$ have the following form:
        \begin{eqnarray*}
                t'&=& \ldots \cdot n^3 \cdot \rnode{n2}{n^2} \cdot \ldots \cdot \rnode{n1}{n^1} \\ \\
                u+@ &=& \ldots \cdot \rnode{m3}{m^3} \cdot \rnode{m2}{m^2} \cdot \ldots \cdot \rnode{m1}{m^1} \cdot \rnode{m}{m}
            \bkptra{30}{m1}{m2} \bkptra{30}{m}{m3}
            \bkptra{30}{n1}{n2}
        \end{eqnarray*}

        Moves that are copied by the copy-cat evaluation strategy are all non internal moves i.e. moves in $\sem{B_1'}$.
        The function $\varphi_{N_0}$ is such that only nodes that are hereditarily justified by the root of $\tau(N_0)$ are mapped
        to nodes in $\sem{B_1'}$.

        Similarly, the evaluation strategy copies the moves in $\sem{B_1'}$ to moves in $\sem{B_1}$
        and nodes in $\varphi^{-1}_{N_0}(\sem{B_1})$ are all hereditarily justified by the root of $\tau(N_1)$.

        Consequently the nodes $n^1$, $n^2$, $n^3$ are not $@$ nodes.

        Since $n^1$ is a variable node then $n^2$ is a lambda node and $n^3$ is a variable node. We can therefore use the $(Var)$ rule
        to extend the traversal $t'$. We obtain a traversal of the following form where $n$ is a child node of $n^3$:
        \begin{eqnarray*}
            t&=& \ldots \cdot \rnode{n3}{n^3} \cdot \rnode{n2}{n^2} \cdot \ldots \cdot \rnode{n1}{n^1} \cdot \rnode{n}{n}
            \bkptra{30}{n1}{n2} \bkptra{30}{n}{n3}
        \end{eqnarray*}

        The pointers of $t'$ and $u'+@$ are the same. Moreover whenever $\varphi$ maps $n^1$ to the $i$th child move of
        $\varphi(n^2)$ it also maps $n$ to the $i$th child move of $\varphi(n^2)$. Hence $\varphi(n) = m$ and $\varphi(t-@) = u$.

        \item If $n^1$ is the value-leaf of a variable node then we proceed the same way as in the previous case:
        $n^1$ is a value-leaf of the variable node $n^2$ and we can use the rule
        (CCAnswer-$\lambda$) rule to extend the traversal $t'$.

        \item Suppose that $n^1$ is a lambda node then $m^1$ is an O-move. Therefore $m^1$ has just been copied by the evaluation strategy
         from $B_1'$ to $B_1$. Then the move following $m^1$ should also be played in $B_1$ before being copied
         back to $B_1'$ by the evaluation strategy. But since $m \in B_0$ this case does not happen.


        \item If $n^1$ is a value-leaf of a lambda node then $n^2$ is a lambda node and $n^3$ is a variable node.
        We can therefore use the rule (CCAnswer-var) or (CCAnswer-@) to extend the traversal $t'$.
        \end{enumerate}

    \item Suppose $m \in A \union B_1$ and $m^1 \in A \union B_0$ then
    the proof is similar to the previous case.
    \end{enumerate}


  For the converse, $\varphi_{M}( \travset^{-@}(M) ) \subseteq \intersem{M}$, it is an easy induction
  on the traversal rules. We omit the details here.
\end{itemize}

(ii) is an immediate consequence of (i):
\begin{align*}
\sem{M} &= \intersem{M} \upharpoonright \sem{\Gamma \rightarrow T} & \mbox{(eq. \ref{eqn:int_std_gamsem})} \\
        &= \varphi_M(\travset^{-@}(M)) \upharpoonright \sem{\Gamma \rightarrow T} & \mbox{(by (i))}\\
        &= \varphi_M(\travset^{\upharpoonright r}(M)) & \mbox{(lemma \ref{lem:varphi_filter})}\\
\end{align*}
\end{proof}


Putting corollary \ref{cor:varphi_bij} and proposition
\ref{prop:rel_gamesem_trav} together we obtain the following
theorem:

\begin{thm}[Game semantics--traversals correspondence]
For any pure simply-typed term $M$, $\varphi_M$ defines a bijection from
$\travset(M)^{\upharpoonright r}$ to $\sem{M}$ and a bijection
from $\travset(M)^{-@}$ to $\intersem{M}$:
\begin{eqnarray*}
 \varphi_M  &:& \travset(M)^{\upharpoonright r} \stackrel{\cong}{\longrightarrow} \sem{M} \\
 \varphi_M  &:& \travset(M)^{-@} \stackrel{\cong}{\longrightarrow} \intersem{M}
\end{eqnarray*}

Moreover if $M$ is in $\beta$-normal form and $s$ is a
\emph{maximal} play then  $t$ is a \emph{maximal} traversal.
\end{thm}

\begin{proof}
The first part is an immediate consequence of corollary
\ref{cor:varphi_bij} and proposition
\ref{prop:rel_gamesem_trav}.

Finally, if $M$ is in $\beta$-normal form then
$\travset(M)^{\upharpoonright r} = \travset(M)$
therefore $\varphi$ is a bijection from $\travset(M)$ to
$\sem{M}$. Suppose $s$ is a maximal play and suppose $t' \sqsubseteq
t$ then since $\varphi$ is monotonous $s = \varphi(t) \sqsubseteq
\varphi(t')$. But $s$ is maximal therefore $s = \varphi(t') =
\varphi(t)$. Since $\varphi$ is injective we have $t'=t$.
\end{proof}

The following diagram recapitulates the main results of this section:
$$
\xymatrix @C=6pc{
                                           & \travset(M)^{-@} \ar@/_/[dl]_{+@}  \ar[r]^{\varphi_M}_\cong & \intersem{M} \ar@/_/[dd]_{\upharpoonright \sem{\Gamma\rightarrow T}} \\
\travset(M) \ar@/_/[ur]_{-@}^{\cong} \ar[dr]^{\upharpoonright r}  \\
                                           & \travset(M)^{\upharpoonright r} \ar[r]^{\varphi_M}_\cong & \sem{M} \ar@/_/[uu]^{\cong}_{\mbox{full uncovering}}
}
$$



\subsection{Application: game semantics characterization of safe terms}
We now use the correspondence theorem to study the game semantics of
safe terms. We prove that pointers in the game semantics of
safe terms without constants can be uniquely recovered.

The example of section \ref{subsec:pointer_necessary} gives a good
intuition: remember that in order to distinguish the terms
$M_1 = \lambda f . f (\lambda x . f (\lambda y .y ))$ and
$M_2 = \lambda f . f (\lambda x . f (\lambda y .x ))$ we had to keep the pointers in the plays of strategies.
However, if we limit ourself to the safe $\lambda$-calculus then the
ambiguity disappears since $M_1$ is safe whereas $M_2$ is not (because
in the subterm $f (\lambda y . x)$, the free variable $x$ has the same
order as $y$ but $x$ is not abstracted together with $y$).

\begin{dfn}[Regular strategy]
A strategy $\sigma : A$ is said to be \emph{regular} if for any sequence of moves $s q \in P_A$
where $q$ is a question move in $M_A$ we have:
\begin{eqnarray*}
s q \in \sigma \wedge |s| \mbox{ even } &\implies& \parbox[t]{10cm}{$q$ points to the last P-move in $\oview{?(s)}$ with order strictly greater than $\ord{q}$;} \\
s q \in \sigma \wedge |s| \mbox{ odd } &\implies& \parbox[t]{10cm}{$q$  points to the last O-move in $\pview{?(s)}$ with order strictly greater than $\ord{q}$.}
\end{eqnarray*}
\end{dfn}

\begin{lem}
\label{lem:regular_pointers_uniqu_recover}
Pointers are superfluous for regular strategies.
\end{lem}
\begin{proof}
Suppose $\sigma$ is a regular strategy. We prove that pointers in a play $s\in \sigma$ are uniquely recoverable by induction on the length of $s$.
\noindent \emph{Base case}: if $s \in \sigma$ with $|s| \leq 1$ then there is no pointer to recover.
\noindent \emph{Step case}: suppose $s m \in \sigma$. If $m$ is an answer move then
thanks to the well-bracketing condition $m$ points to the last unanswered question in $s$.
Suppose $m$ is a question move.
If $m$ is a P-move then $|s|$ is odd and by regularity
$m$ points to the last O-move in $\pview{?(s)}$ with order strictly greater than $\ord{q}$.
Similarly, if $m$ is an O-move then $|s|$ is even and by regularity
$m$ points to the last P-move in $\oview{?(s)}$ with order strictly greater than $\ord{q}$.
By the induction hypothesis the pointers in $s$ are recoverable, this ensures that the
P-view $\pview{?(s)}$ and the O-view $\oview{?(s)}$ can be computed. Consequently the pointer for $m$ can be (uniquely) recovered.
\end{proof}

\begin{exmp}
The evaluation map $ev$ is denoted by a non-regular strategy. Indeed consider the play $s = q_0 q_1 q_2 q_3 \in \sem{ev}$
shown on the diagram below:
$$\begin{array}{cccccccc}
(A & \implies & B) & \times  & A & \stackrel{ev}{\longrightarrow} & B \\
&&&&&& q_0 \\
&& q_1 \\
 q_2 \\
 &&&&q_3
\end{array}$$
The order of the moves are as follows:  $\ord{q_3} = \ord{A}$, $\ord{q_2} = \ord{A}$,
$\ord{q_1} = \max( 1+\ord{A}, \ord{B})$ and $\ord{q_0} = 1 + \ord{q_1}$.
The last O-move in $?(\pview{s})= s$ with order strictly greater than $\ord{q_3}$ is $q_1$. However $q_3$ points to $q_0$ therefore $\sem{ev}$ is not regular.
\end{exmp}


In a computation tree a binder node always occurs in the path from the bound node to the root.
We now introduce a class of computation tree in which binder nodes can be uniquely recovered from the order of the nodes.
We write $[n_1,n_2]$ to denote the path from node $n_1$ to node $n_2$ if it exists and $]n_1,n_2]$ for
the sequence of nodes obtained by removing $n_1$ from $[n_1,n_2]$.

\begin{dfn}[Regular computation tree]
A variable node $x$ of a computation tree is said to be \emph{regular} if either:
\begin{enumerate}
\item $x$ is \emph{bound} by the first $\lambda$-node in the path to the root that has
order strictly greater than $\ord{x}$. Formally:
$$ x \mbox{ bound by } n \quad \imp \quad n \in [r,x] \wedge \ord{n} > \ord{x} \wedge \forall \lambda\mbox{-node } n' \in ]n,x] . \ord{n'} \leq \ord{x},$$

\item $x$ is a \emph{free variable} and all the $\lambda$-nodes in the path to the root except the root have order
smaller or equal to $\ord{x}$. Formally:
$$ x \mbox{ free } \quad \imp \quad  \forall \lambda\mbox{-node } n' \in ]r,x] . \ord{n'} \leq \ord{x}. $$
\end{enumerate}
where $r$ denotes the root of the computation tree.

A computation tree is said to be \emph{regular} if all the variable nodes are regular.
\end{dfn}

\begin{prop}[Tree regularity and strategy regularity coincide] \
\label{prop:regular_comp_imp_regular_strat}
\begin{enumerate}
\item[(i)] If a term in $\beta$-normal form has a regular computation tree then it is denoted by a regular strategy.
\item[(ii)] in the pure $\lambda$-calculus ($\Sigma=\emptyset$), reciprocally if a term is denoted by a regular strategy then
the computation tree of its $\beta$-normal is regular.
\end{enumerate}
\end{prop}

\begin{proof}
Let $\Gamma \vdash M : A$ be a simply-typed term in $\beta$-normal form
and $r$ denotes the root of $\tau(M)$.

\noindent %\emph{`If' part:}
(i) Suppose that $\tau(M)$ is regular.
Consider a justified sequence of move $s \in \sem{\Gamma \vdash M}$
ending with a question move $q$ (note that $q$ is also the last question in $?(s)$).
By proposition \ref{prop:rel_gamesem_trav}, there
is a reduced-traversal $t \upharpoonright r$ of $\tau(M)$ such that $\varphi_{M}(t \upharpoonright r) \jseq s$.
We assume that the last node $n$ of $t$ is hereditarily justified by $r$ (otherwise we replace $t$ by its longest prefix verifying this condition).
Then $n$ is also the last node in $?(t \upharpoonright r)$ and $t \upharpoonright r$.

\begin{itemize}
\item If $|s|$ is even then $q$ is a P-move:
\begin{itemize}
\item Suppose that $n$ is a variable node $x$ bound by a node $m$ occurring in $t$.
Since $M$ is in $\beta$-normal form, lemma \ref{lem:redtrav_trav}(i) gives:
$ \pview{?(t \upharpoonright r)} \jseq \pview{?(t)} \upharpoonright  r$.
By proposition \ref{prop:pviewtrav_is_path}, $\pview{?(t)} = [r,n]$ and since
$\tau(M)$ is regular, $m$ is the last $\lambda$-node in $[r,n]$ of order strictly greater than $\ord{n}$.
Since $n$ is hereditarily justified by the root, so is $m$ and therefore $m$ occurs in $\pview{?(t \upharpoonright r)}$.
But $\pview{?(t \upharpoonright r)}$ is a subsequence of $\pview{?(t)}$ therefore $m$ is also be the last $\lambda$-node
in $\pview{?(t \upharpoonright  r)}$ that has order strictly greater than $\ord{n}$.

By property \ref{proper:phi_pview} (ii), the P-view of $?(s)$ and the P-view of $?(t \upharpoonright r)$ are computed
similarly and have the same pointers. This means that
node $n$ and  move $q$ both point to the same position in
the justified sequence $\pview{?(t\upharpoonright r)}$ and $\pview{?(s)}$ respectively.

Finally, since $\varphi$ maps nodes of a given order to moves of the same order (property \ref{proper:phi_conserve_order}),
$q$ must point to the last O-move in $\pview{?(s)}$ whose
order is strictly greater than $\ord{q}$.


\item If $n$ is a free variable node $x$ then $n$ is enabled by the root which is the first node in $t$.
By definition of $\varphi$, $\varphi(n) = x$ must be a move enabled by the initial move $q_0 = \varphi(r)$ in the arena $\sem{\Gamma \rightarrow A}$.
Therefore $\ord{q_0} > \ord{x}$.
By regularity of the computation tree, all the $\lambda$-nodes in $]r,n]$ have smaller than $\ord{n}$. Therefore by the correspondence theorem,
all the O-moves in $\pview{?(s)}$ have order smaller than $\ord{x}$.
\end{itemize}



\item If $|s|$ is odd then $q$ is an O-move:

$M$ is in $\beta$-normal form and $t$ is a traversal of $\tau(M)$
whose last node $n$ is hereditarily justified by $r$. Therefore by lemma \ref{lem:redtrav_trav} (ii),
$ \oview{?(t \upharpoonright r)} \jseq \oview{?(t)}$.

A lambda-nodes always points to its parent node in the computation
tree. For terms in $\beta$-normal form, this parent node must be a
variable node of order strictly greater than $\ord{n}$.

By inspecting the formation rules for traversals (definition
\ref{def:traversal}) we remark that a lambda-node occurring in a
traversal always points to the last node with order strictly greater
that $\ord{n}$ in the O-view of the sequence of unmatched nodes at
that point (there are just two cases, $n$ points either to the
preceding node or to the third previous node in $\oview{?(t)}$).

Similarly, as in the P-move case, we conclude that $q$ points to the
last question move in $\oview{?(s)}$ of order strictly greater than
$\ord{q}$.
\end{itemize}

\noindent  %\emph{`Only-if' part:}
(ii) Suppose that the strategy $\sem{M}$ is regular.
Let $x$ be variable node of $\tau(M)$.
Since $M$ is in $\beta$-normal form, by lemma \ref{lem:betaeta_trav},
$x$ is either hereditarily justified by the root $r$ or by a constant in $N_\Sigma$.
In the pure simply-type $\lambda$-calculus we have $\Sigma=\emptyset$ therefore $x$ is hereditarily justified by $r$.


We remark that for terms in $\beta$-normal form, every variable node occurring in the computation tree can be visited by some traversal:
there is a traversal $t \cdot x$ for some $t \in \travset(M)$.
The correspondence theorem gives $\varphi((t \cdot x) \upharpoonright r) = \varphi((t \upharpoonright r) \cdot x) \in \sem{M}$.
Since $\sem{M}$ is regular, $\varphi(x)$ must point to the last move in $\pview{?(\varphi(t \upharpoonright r))}$ with
order strictly greater than $\ord{\varphi(x)}$.
Consequently $x$ points to the last node in $\pview{?(t \upharpoonright r)}$ with
order strictly greater than $\ord{x}$.
We have:
\begin{align*}
\pview{?(t \upharpoonright r)} &= \pview{?(t) \upharpoonright r} = \pview{?(t)} \upharpoonright r & \mbox{by lemma \ref{lem:redtrav_trav}} \\
& = \pview{?(t)} & \mbox{$M$ is a $\beta$-nf and $N_\Sigma = \emptyset$} \\
& = [r,x[ & \mbox{by proposition \ref{prop:pviewtrav_is_path}}.
\end{align*}
Therefore if $x$ is a bound variable node then it is bound by the last $\lambda$-node in $[r,x[$ with order strictly greater than $\ord{x}$
and if $x$ is a free variable then it points to $r$ and therefore all the $\lambda$-node in $]r,x[$ have order smaller than $\ord{x}$.
Hence $\tau(M)$ is regular.
\end{proof}


\parpic[r]{
    \psset{levelsep=4ex}
    \pstree{\TR{$\lambda x^3$}}{\pstree{\TR{$f^2$}}{ \pstree{\TR{$\lambda y^1$}}{ \TR{$x^0$} }}}
}

\noindent \emph{Examples:}
Consider the $\beta$-normal term $\lambda x . f (\lambda y .x)$ where $x,y:o$ and $f:(o,o),o$. The figure on the right represents
the computation tree with the order of each node in the exponent part.
Since node $x$ of order $0$ is not bound by the order 1 node $\lambda y$, $\tau(M)$ is not regular and by proposition
\ref{prop:regular_comp_imp_regular_strat} $\sem{\lambda x . f (\lambda y .x)}$ is not regular.
Similarly we can check that the denotation of $f (\lambda y .x)$ is not regular whereas $\lambda y. x$ has a regular denotation.
Also for any higher-order variable $x:A$, the computation tree $\tau(x)$ is regular, therefore
the projection strategies $\pi_i$ are regular.
From these examples we observe that application does not preserve regularity: $\sem{f}$ and $\sem{\lambda y. x}$ are regular whereas
$\sem{f (\lambda y .x)}$ is not.

%In fact regularity is not preserved by composition. Indeed,
%$\sem{f (\lambda y . x) \cong \langle id_{\Gamma}, \sem{\lambda y . x} \rangle} $
%$\sem{f (\lambda y .x)} = \langle \sem{f}, \sem{\lambda y. x} \rangle \fatsemi ev$ is not.


\begin{lem}[Safety--regularity]
\label{lem:regularity}
Let $\Gamma \vdash M$ be a simply-typed term.
\begin{itemize}
\item[(i)] If $M$ is a safe term then $\tau(M)$ is regular;
\item[(ii)] reciprocally, if $M$ is \emph{closed} and $\tau(M)$ is regular then the $\eta$-normal form of $M$ is safe.
\end{itemize}
\end{lem}
\begin{proof}
(i) Suppose that $M$ is safe. The safety property is preserved after taking the $\eta$-normal form, therefore
$\etanf{M}$ is also safe. Hence $\tau(M)$ is the tree representation of a safe term.

In the safe $\lambda$-calculus when applying the abstraction rule the variables in the lowest partition (smallest order) of the context
must all be abstracted together.
In the computation tree consecutive abstractions are merged into a single node, therefore the safety of $\etanf{M}$ implies
that: for each $\lambda$-node $\lambda \overline{\xi}$, any variable $x$ occurring free in $\kappa(\lambda \overline{\xi})$
has order greater or equal to $\ord{\lambda \overline{\xi}}$. Reciprocally, if a lambda node $\lambda \overline{\xi}$
binds a variable node $x$ then $\ord{\lambda \overline{\xi}} = 1+\max_{z\in\overline{\xi}} \ord{z} > \ord{x}$.

Let $x$ be a bound variable node. In a computation tree, a binder node always occurs in the path from the bound node to the root,
therefore by the previous observation $x$ must be bound by the first $\lambda$-node occurring in $[r,x]$
with order strictly greater than $\ord{x}$.
Similarly, let $x$ be a free variable node in $\tau$ then $x$ is not bound by any of the $\lambda$-nodes occurring in $[r,x]$.
Therefore, by the previous observation, all these $\lambda$-nodes have order smaller than $\ord{x}$.
Hence $\tau$ is regular.

(ii) We assume that $M$ is already in $\eta$-normal form. Suppose $M$ is closed and $\tau(M)$ is regular,
we prove that $M$ is safe by induction on its structure:
\emph{Base case:} $M = \lambda \overline{\xi} . \alpha$ for some variable or constant $\alpha$ then $\alpha$ is safe therefore so is $\lambda \overline{\xi} . \alpha$.

\emph{Step case:} If $M = \lambda \overline{\xi} . N_1 \ldots N_p$.
Let $i$ ranges over $1..p$. $N_i$ can be written $\lambda \overline{\eta_i} . N'_i$ where $N'_i$ is not an abstraction.
By the induction hypothesis, $\lambda \overline{\xi} . N_i = \lambda \overline{\xi} \overline{\eta_i} . N'_i$ is safe.
By looking at the formation rules of safe $\lambda$-calculus we observe that the safety
of $\lambda \overline{\xi} \overline{\eta_i} . N'_i$ can only be derived by applying the (abs) rules on the term $N'_i$. Hence
$N'_i$ is necessarily safe.
Let $z$ be a variable occurring free in $N'_i$. Since $M$ is closed, $z$ is either bound by $\lambda \overline{\eta_1}$ or by $\lambda \overline{\xi}$.
If it is bound by $\lambda \overline{\xi}$ then since $\tau(M)$ is regular we have $\ord{z} \geq \ord{\lambda \overline{\eta_1}} = \ord{N_i}$.
Hence we can abstract the variables $\overline{\eta_1}$ by using the (abs) rule of the safe $\lambda$-calculus and we get that $N_i$ is safe.

Since the term is in $\eta$-normal form, the application $N_1 \ldots N_p$ is total (i.e. $N_1$ is a function taking $p-1$ parameters
and it is applied to $p-1$ arguments), therefore since the $N_i$ are safe, by the (app) rule of the safe $\lambda$-calculus
$N_1 \ldots N_p$ is also safe.
By the (abs) rule we conclude that $M = \lambda \overline{\xi} . N_1 \ldots N_p$ is safe.
\end{proof}

Note that in (ii) the condition saying that $M$ is closed is necessary.  For instance, the two terms
$\lambda x y .x$ and $\lambda y . x$ where $x,y:o$ have (isomorphic) regular computation trees. However $\lambda x y .x$ is safe
whereas $\lambda y . x$ is not.



Putting proposition \ref{prop:regular_comp_imp_regular_strat} and lemma \ref{lem:regularity} together we
obtain a game semantics characterization of safe terms:
\begin{cor}[Regular strategies characterize safe terms]
Let $M$ be a closed pure simply-typed term (with no constants) then:
$$ \sem{M} \mbox{ is regular if and only if $\etabetanf{M}$ is safe,} $$
where $\etabetanf{M}$ denotes the $\eta$-normal form of the $\beta$-normal form of $M$.
\end{cor}



\begin{thm}[Pointers are superfluous for safe terms]
Pointers in the game semantics of safe terms are uniquely recoverable.
\end{thm}
\begin{proof}
Suppose that a safe simply-typed term $M$ is safe then its $\beta$-normal form $M'$ is also safe.
By lemma \ref{lem:regularity} (i), $\tau(M')$ is regular and
by proposition \ref{prop:regular_comp_imp_regular_strat},
$\sem{M'}$ is a regular strategy.
By lemma \ref{lem:regular_pointers_uniqu_recover}, the pointers in $\sem{M'}$ are uniquely recoverable.
Finally, the soundness of the game model gives $\sem{M} = \sem{M'}$.
\end{proof}


\section{Game semantics of Safe Idealized Algol}

Safe Idealized Algol, or Safe \ialgol\ for short, is Idealized Algol where the application and abstraction rules are restricted
the same way as in the safe $\lambda$-calculus (see rules of section \ref{sec:safe_nonhomog}).

The properties of the Safe $\lambda$-calculus can be transposed straightforwardly to Safe \ialgol.
In particular, it can be shown that safety is preserved by $\beta$-reduction and that
no variable capture occur when performing substitution on a safe term.

A natural question to ask is whether we can extend the result about game semantics of safe $\lambda$-terms to safe \ialgol-terms.
We conjecture that indeed the pointers in the game semantics of safe IA terms can be recovered uniquely.
In this section we lay out the key elements of a possible proof of this conjecture.

If our conjecture is true then there may be potential application in algorithmic game semantics.
For instance, by following the framework of \cite{ghicamccusker00}, it may be possible to give
a characterization of the game semantics of some higher-order fragments of Safe Idealized Algol using
extended regular expressions.
Subsequently, this would lead to the decidability of program equivalence
for the considered higher-order fragments of Safe \ialgol.


\subsection{Small-step semantics of Safe \ialgol}
In the first chapter we defined the operational semantics of \ialgol\ using a big step semantics.
The operational semantics of \ialgol can be defined equivalently using a small-step semantics.
The reduction rules of the small-step semantics are of the form $s,e \rightarrow s',e'$ where $s$ and $s'$ denotes the
stores and $e$ and $e'$ denotes \ialgol expressions.

Firstly we define rules to show how to reduce redexes. There are the following ones:
\begin{itemize}
\item the reduction of safe-redex (relation $\beta_s$ from definition \ref{dfn:safereduction});
\item reduction rules for PCF constants:
\begin{eqnarray*}
\pcfsucc\ n &\rightarrow& n+1 \\
\pcfpred\ n+1 &\rightarrow& n \\
\pcfpred\ 0 &\rightarrow& 0 \\
\pcfcond\ 0\ N_1 N_2 &\rightarrow& N_1 \\
\pcfcond\ n+1\ N_1 N_2 &\rightarrow& N_2 \\
Y\ M &\rightarrow& M (Y M)
\end{eqnarray*}
\item reduction rules for \ialgol\ constants:
\begin{eqnarray*}
\iaseq\ \iaskip\  M &\rightarrow& M \\
s, \ianewin{x}\ M &\rightarrow& (s|x\mapsto 0), M \\
s, \iaassign\ x\ n &\rightarrow& (s|x\mapsto n), \iaskip \\
s, \iaderef\ x &\rightarrow& s, s(x) \\
\iaassign\ (\iamkvar M N)\ n &\rightarrow& M n \\
\iaderef\ (\iamkvar M N) &\rightarrow& N
\end{eqnarray*}
\end{itemize}

Redex can also be reduced when they occur as subexpressions
within a larger expression. We make use of evaluation contexts to
indicate when such reduction can happen. Evaluation contexts are given by the following grammar:
\begin{eqnarray*}
E[-] &::=& - |\ E N\ |\ \pcfsucc\ E\ |\ \pcfpred\ E\ |\ \pcfcond\ E\ N_1\ N_2\ |\ \\
&&    \iaseq\ E\ N\ |\ \iaderef\ E\ |\ \iaassign\ E\ n\ |\ \iaassign\ M\ E \ |\ \\
&&    \iamkvar\ M\ E\ |\ \iamkvar\ E\ M\ |\ \ianewin{x}\ E  .
\end{eqnarray*}

The small-step semantics is completed with following rule:
$$ \rulef{M \rightarrow N}{E[M] \rightarrow E[N]} $$

\begin{lem}[Reduction preserves safety]
\label{lem:ia_safety_preserved}
Let $M$ be a safe \ialgol\ term.
If $M \rightarrow N$ then $N$ is also a safe term.
\end{lem}
This can be proved straightforwardly by induction on the structure of M.


\subsection{Safe PCF}
Let us first show how the results about Safe $\lambda$-calculus can be extended to the PCF fragment of Safe \ialgol.

The $Y$ combinators needs a special treatment. In order to deal with it, we follow the idea of \cite{abramsky:game-semantics-tutorial}:
we consider the sublanguage $\pcf_1$ of \pcf\ in which the only allowed use of the $Y$ combinator is in terms of the form $Y( \lambda x:A .x )$ for some type $A$.
We will write $\Omega_A$ to denote the non-terminating term $Y(\lambda x:A .x)$ for a given type $A$.

We introduce the \emph{syntactic approximants} to $Y_A M$:
\begin{eqnarray*}
Y^0_A M &=& \Gamma \vdash \Omega_A : A\\
Y^{n+1}_A M &=& M( Y^n M )
\end{eqnarray*}
For any PCF term $M$ and natural number $n$ we define $M_n$ to be the PCF term obtained from $M$ by replacing each subterm of the form $Y N$
with $Y^n N_n$.
We have $\sem{M} = \Union_{n\in\omega} \sem{M_n}$ (\cite{abramsky:game-semantics-tutorial}, lemma 16).


\subsubsection{Computation tree}

Let $N$ be a term of type $A \rightarrow A$. We would like to define a unique computation tree for $Y_A N$.
To do that we make use of the syntactic approximants to $Y_A N$.

We introduce a special $\Sigma$-constant $\bot$ representing the non-terminating computation
of ground type $\Omega_o$. Given any type $A = (A_1, \ldots, A_n, o)$, the computation tree $\tau(\Omega_A)$ is
defined to be the tree representation of $\lambda x_1:A_1 \ldots x_n:A_n . \bot$.
The computation tree for $Y_A^i N = N( \ldots (N \Omega_A) \ldots )$ is then constructed in the standard way.


Let us introduce a partial order on the set of computation trees.
Formally, a tree $t$ is given by a labelling function $t:T\rightarrow L$ where
$T$, called the domain of $t$ and noted $dom(t)$, is a non-empty prefix-closed subset of some free monoid $X^*$
and $L$ denotes the set of possible labels ($\Sigma$-constants, $\bot$, $@$, variables,
abstraction of any sequence of variable).
Intuitively, $T$ represents the structure of the tree (the set of all paths) and $t$ is the labelling function mapping paths to labels.

We now use the \emph{approximation ordering} on trees defined in \cite{KNU02}, section 1.
We write $t' \sqsubseteq t$ if the tree $t'$ is obtained from $t$ by replacing some of its subtrees by $\bot$. Formally:
$$t' \sqsubseteq t \quad \iff dom(t') \subseteq dom(t) \wedge \forall  w \in dom(t'). (t'(w) = t(w) \vee t'(w) = \bot).$$

We define $\tau(Y_A N)$ to be $\Union_{n\in\omega}(\tau(Y_A^n N))_{n\in\omega}$.
This is well-defined since the sequence of computation trees $(\tau(Y_A^n N))_{n\in\omega}$ is a chain
and the set of trees with the approximation ordering is a complete partial order.



%We handle this case by considering the infinite computation tree
%obtained by expanding the recursion infinitely. For instance consider the term $M = Y (\lambda f x. f x)$ where $f:(o,o)$ and $x:o$.
%Its computation tree $\tau(M)$ is defined to be the computation tree
%of the infinite term $(\lambda f x. f x) ((\lambda f x. f x) ((\lambda f x. f x)  ( \ldots$.
%$$\tree{\lambda}{
%\tree{@}
%     { % \tree{\lambda x}
%        {   \tree{\lambda x} {\TR{x}}
%            \TR{\tau(M)}
%        }}}
%$$

The other operators of \ialgol\ are just treated as standard constants and the computation tree are
constructed from the $\eta$-normal form of the term in the standard way. For instance the diagram below show
the computation tree for $\pcfcond\ b\ x\ y$ (left) and $\lambda x . 5$ (right):
$$
\tree{\lambda b x y}
     {  \tree{\pcfcond}
        {   \tree{\lambda} {\TR{b}}
            \tree{\lambda} {\TR{x}}
            \tree{\lambda} {\TR{y}}
        }
    }
\hspace{2cm}
\tree{\lambda x}{  \TR{5} }
$$
The node labelled $5$ has, like any other node, children value-leaves which are not represented on the diagram above for simplicity.

\subsubsection{Traversal}

New traversal rules accompany the additional constants of \ialgol.
There is one additional rule for natural number constants:
\begin{itemize}
\item (Nat) If $t \cdot m$ is a traversal where $m$ denotes a node labelled with some numeral constant $i\in \nat$ then
            $t \cdot \rnode{m}{m} \cdot \rnode{mv}{m^i} \bkptra[nodesep=0pt]{40}{mv}{m}$
            is also a traversal where $m^i$ denotes the value leaf of $m$ corresponding to the value $i\in \nat$.
\end{itemize}

\noindent The traversals rules for \pcfpred\ and \pcfsucc\ are defined similarly. We just gives the ones for \pcfsucc.
\begin{itemize}
\item (Succ) If $t \cdot \pcfsucc$ is a traversal and $\lambda$ denotes the only child node of \pcfsucc\ then
$t \cdot \rnode{succ}{\pcfsucc} \cdot \rnode{l}{\lambda}
\bkptra[nodesep=1pt]{60}{l}{succ} \bklabel{1}$
is also a traversal.

\item (Succ') If
$t_1 \cdot \rnode{succ}{\pcfsucc} \cdot \rnode{l}{\lambda} \cdot t_2 \cdot \rnode{lv}{\lambda^n}
\bkptra[nodesep=1pt]{60}{l}{succ} \bklabel{1}
\bkptra[nodesep=1pt]{40}{lv}{l}$
is a traversal for some $n \in \nat$ then
$t_1 \cdot \rnode{succ}{\pcfsucc} \cdot \rnode{l}{\lambda} \cdot t_2 \cdot \rnode{lv}{\lambda^n} \cdot \rnode{succv}{\pcfsucc^{n+1}}
\bkptra[nodesep=1pt]{60}{l}{succ} \bklabel{1}
\bkptra[nodesep=1pt]{25}{succv}{succ}
\bkptra[nodesep=1pt]{40}{lv}{l}
$
is also a traversal.
\end{itemize}

\noindent In the computation tree, nodes labelled with \pcfcond\ have three children nodes numbered from
$1$ to $3$ corresponding to the three parameters of the operator \pcfcond. The traversal rules are:
\begin{itemize}
\item (Cond-If) If $t_1 \cdot \pcfcond$ is a traversal and $\lambda$ denotes the first child of \pcfcond\ then
$t_1 \cdot \rnode{cond}{\pcfcond} \cdot \rnode{l}{\lambda}
\bkptra[nodesep=1pt]{60}{l}{cond} \bklabel{1}$
is also a traversal.

\item (Cond-ThenElse) If
$t_1 \cdot \rnode{cond}{\pcfcond} \cdot \rnode{l}{\lambda} \cdot t_2 \cdot \rnode{lv}{\lambda^n}
\bkptra[nodesep=1pt]{60}{l}{cond} \bklabel{1}
\bkptra[nodesep=1pt]{40}{lv}{l}$
then
$t_1 \cdot \rnode{cond}{\pcfcond} \cdot \rnode{l}{\lambda} \cdot t_2 \cdot \rnode{lv}{\lambda^n} \cdot \rnode{condthenelse}{\lambda}
\bkptra[nodesep=1pt]{60}{l}{cond} \bklabel{1}
\bkptra[nodesep=1pt]{40}{lv}{l}
\bkptra[nodesep=1pt]{35}{condthenelse}{cond} \bklabelc{2+[n>0]}
$
is also a traversal.



\item (Cond') If
$t_1 \cdot \rnode{cond}{\pcfcond} \cdot t_2 \cdot \rnode{l}{\lambda} \cdot t_3 \cdot \rnode{lv}{\lambda^n}
\bkptra[nodesep=1pt]{40}{l}{cond} \bklabel{k}
\bkptra[nodesep=1pt]{40}{lv}{l}$ for $k=2$ or $k=3$
then
$t_1 \cdot \rnode{cond}{\pcfcond} \cdot t_2 \cdot \rnode{l}{\lambda} \cdot t_3 \cdot \rnode{lv}{\lambda^n} \cdot \rnode{condv}{\pcfcond^n}
\bkptra[nodesep=1pt]{40}{l}{cond} \bklabel{k}
\bkptra[nodesep=1pt]{40}{lv}{l}
\bkptra[nodesep=1pt]{20}{condv}{cond}
$
is also a traversal.
\end{itemize}
This complete the definition of traversal for the \pcf\ subset of \ialgol.

\subsubsection{Correspondence theorem}
The game model of the language PCF is given by the category $\mathcal{C}_b$ of
well-bracketed strategies. Hence the well-bracketing assumption stated in section \ref{sec:assumptions} is satisfied.

Proposition \ref{prop:rel_gamesem_trav} has been proved in the context of the simply-typed $\lambda$-calculus \emph{with no constants}.
Let us see how to extend it to PCF.
\begin{prop}
Let $\Gamma \vdash M : T$ be a PCF term and $r$ be the root of $\tau(M)$. Then:
$$\varphi_M(\travset(M)^{\upharpoonright r}) = \sem{M}$$
\end{prop}
\begin{proof}
We just need to complete the proof by induction of proposition \ref{prop:rel_gamesem_trav}.
...
\end{proof}

It is straightforward to check that the traversal rules for the $\Sigma$-constants of PCF are well-behaved. Furthermore, the rules
have disjoint domains of application therefore conditions (C1) and (C2) of section \ref{subsec:traversal} are satisfied.
Consequently lemma \ref{lem:varphiinjective} holds :
$\varphi$ defines a bijection from $\travset(M)^{\upharpoonright r}$ to $\varphi(\travset(M)^{\upharpoonright r})$ and
$$\varphi : \travset(M)^{\upharpoonright r} \stackrel{\cong}{\longrightarrow} \sem{M} $$


\subsubsection{Regularity}

Because of the presence of the Y combinator, a difficulty arises : computation trees of \pcf\ terms are potentially infinite.
Despite this characteristics, lemma \ref{lem:regularity} still hold in the \pcf\ setting:
\begin{lem}[Safety--regularity]
\label{lem:pcf_saferegular}
If $\Gamma \vdash M$ is a safe PCF term then $\tau(M)$ is regular.
\end{lem}
\begin{proof}
Suppose that a variable node $z$ belongs to $\tau(M) = \Union_{k\in\omega} \tau(M_k)$ then there exists $k\in \omega$
such that $z$ belongs to $\tau(M_k) \sqsubseteq \tau(M)$.
Moreover if we write $r_k$ to denote the root of the tree $\tau(M_k)$ then the path $[r_k,z]$ in $\tau(M_k)$
is equal to the path $[r,z]$ in $\tau(M)$.

Let $i$ denotes the number of occurrences of the Y combinator in $M$. We prove by induction on $i$ that $M_k$ is
safe for any $k\in \omega$.
\emph{Base case:} $i=0$ then $M_k = M$.
\emph{Step case:} $i>0$. Let $Y_A N$ be a subterm of $M$.
Since $M$ is safe, $N$ is also safe. The number of occurrences of the Y combinator in $N$ is smaller than $i$ therefore
by the induction hypothesis $N_k$ is safe. Consequently the term $Y_A^k N_k = \underbrace{N_k ( \ldots ( N_k}_k \Omega ) \ldots )$ is also safe.
Hence $M_k$ must be safe.

Clearly, lemma \ref{lem:regularity} is still valid in $\pcf_1$ (the subterms of the form $\Omega$ are just
represented by the constant $\bot$ in the computation tree).
Therefore since $M_k$ is in $\pcf_1$, $\tau(M_k)$ must be regular.
Consequently, the node $z$ is regular in $\tau(M_k)$ and since $[r,z]=[r_k,z]$, the corresponding node $z$ in
the tree $\tau(M)$ is also regular.

Hence $\tau(M)$ is regular.
\end{proof}

\begin{thm}[Pointers are superfluous for Safe PCF]
Pointers in the game denotation of safe terms are uniquely recoverable.
\end{thm}
\begin{proof}
Since condition C1 is verified, lemma \ref{lem:redtrav_trav} holds in the Safe PCF setting. Therefore
proposition \ref{prop:regular_comp_imp_regular_strat}(i) also holds: terms in $\beta$-nf
with a regular computation tree are denoted by regular strategies.

Safety is preserved by reduction (lemma \ref{lem:ia_safety_preserved}), therefore
by lemma \ref{lem:pcf_saferegular} and soundness of the game denotation, any Safe PCF term must be
denoted by a regular strategy.

Hence pointer are superfluous in the game denotation of safe PCF terms.
\end{proof}



\subsection{Safe \ialgol}



\subsubsection{Overview of the main steps of the proof}
We need to follow the same recipe used for the Safe $\lambda$-calculus case.
Let us recapitulates the main ingredients:
\begin{enumerate}
\item define the computation tree of a term;
\item define a notion of traversal over a computation tree;
\item prove that P-view of traversals are paths in the computation tree;
\item find a correspondence between traversals of the computation tree and plays in some interaction game semantics;
\item define a ``reduction'' operation on traversals that eliminates the ``internal nodes'' of the computation. This leads to a
correspondence between the standard game semantics and some set of sequences of nodes obtained from traversals;
\item prove that the P-view of the reduction of a traversal is the reduction of the P-view
and that the O-view of a traversal is the O-view of its reduction (lemma \ref{lem:redtrav_trav});
\item prove that computation tree of safe term are regular;
\item prove that regular computation trees are denoted by regular strategies.
\end{enumerate}

In the following sections we give more details about each of these steps.

\subsubsection{Computation tree and traversals for \ialgol-$\{\ianew\}$ }

The nodes of the computation tree need to be accommodated to take into account the new base types of \ialgol.
We now annotate the nodes of the computation tree with base types: each node is annotated by the return type of the subterm
that it represents.

\ldots
% the
%nodes of the computation tree have value-leaves attached to them, one for each value of the return type. For instance the term
%$\iaseqexp \iaskip

%The (Var) rule needs to be accommodated to take into account the ground types of \ialgol. For the type \iacom, the definition is similar

%\iaseqexp \iaseqcom, \iaskip

\todobox{TODO: for IA the computation tree becomes a computation DAG; define traversals rules for IA.}
%arena in IA may have two roots : the arena for the type var. How to
%define a computation tree that can take this into account? For
%instance for the \texttt{new} operator,  We need to introduce
%infinitely many nodes to make the correspondence with the
%infinite number of initial question moves in the arena!

\subsubsection{Game semantics correspondence}

%mkvar: solution guy mccusker: observational equivalence still
%decidable without mkvar.

\todobox{TODO: Game play--computation DAG traversal correspondence theorem;
prove the counterpart of lemma \ref{lem:redtrav_trav} for traversal of \ialgol\ terms;
check that computation DAG of Safe \ialgol\ terms are regular;
consequently by lemma \ref{lem:regular_pointers_uniqu_recover}, pointers in the strategy are  superfluous for Safe IA terms.
}

%In \ialgol, most of the operators added on top of the $\lambda$-calculus are of order $1$ at most. The two exceptions
%are the Y-combinator and the \iamkvar\ operator.


%Let us a give a counter-example to show why it is important to have constant of order $1$ at most.
%Consider for instance a conditional operator $\pcfcond:(o,(o,o),(o,o),o,o)$ of order $2$.
%We can then build the following term in $\beta$-normal form $M = \lambda f b . (\pcfcond  b (\lambda x . f x) (\lambda y.y) x) 5$
%where $f:(o,o), b:o$. The computation tree of $M$ is:
%
%$$
%\tree{\lambda f b u}
%     {  \tree{\pcfcond}
%        {   \tree{\lambda} {\TR{b}}
%            \tree{\lambda x}
%                { \tree{f}{  \tree{\lambda}{ \TR{x} } } }
%            \tree{\lambda y}{\TR{y}}
%            \tree{\lambda}{u}
%        }
%    }
%$$
%$$ t = \lambda f b u \cdot \pcfcond \cdot b \cdot b^1 \cdot \lambda^b \cdot \lambda x \cdot f \cdot \lambda \cdot x \cdot $$



\section{Further possible developments}

We have given an account of the game semantics of Safe $\lambda$-calculus. However the nature of this calculus
is still not well known. We propose the following possible roadmap for further research:
\begin{enumerate}
\item find a categorical interpretation of the Safe $\lambda$-calculus;
\item study the proof theory obtained by the Curry-Howard isomorphism and determine whether it has nice properties that can be helpful in theorem proving;
\item find which complexity class is characterized by the Safe-$\lambda$ calculus.
\end{enumerate}

In a different direction of research, we would like to establish relations between
Safe $\lambda$-calculus and others languages with pointer-less game semantics.
In particular Abramsky has proposed in \cite{abramsky:mchecking_ia} a language
called Serially Re-entrant Idealized Algol, or SRIA for short. This
language allows multiple occurrences or uses of arguments, as long
as they do not overlap in time. In the games of this language there
is at most one pending occurrence of a question at any time, so that
each move has a unique justifier and so justification pointers may
be ignored.
Clearly the Serially Re-entrant and safety properties are not the same since for instance the Kierstead terms
$\lambda f . f (\lambda x . f (\lambda y .y ))$ and
$\lambda f . f (\lambda x . f (\lambda y .x ))$ are both not Serially Re-entrant whereas the first one is safe.
However it would still be interesting to find out how SRIA relates to Safe Idealized Algol.
